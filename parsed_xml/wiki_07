<doc id="328240" url="https://en.wikipedia.org/wiki?curid=328240" title="Marketing strategy">
Marketing strategy

Marketing strategy is a long-term, forward-looking approach to planning with the fundamental goal of achieving a sustainable competitive advantage. Strategic planning involves an analysis of the company's strategic initial situation prior to the formulation, evaluation and selection of market-oriented competitive position that contributes to the company's goals and marketing objectives.

Strategic marketing, as a distinct field of study emerged in the 1970s, and built on strategic management that preceded it. Marketing strategy highlights the role of marketing as a link between the organization and its customers.

Scholars continue to debate the precise meaning of marketing strategy. Consequently, the literature offers many different definitions. On close examination, however, these definitions appear to centre around the notion that strategy refers to a broad statement of what is to be achieved.

Marketing Strategy is:

The distinction between “strategic” and “managerial” marketing is used to distinguish "two phases having different goals and based on different conceptual tools. Strategic marketing concerns the choice of policies aiming at improving the competitive position of the firm, taking account of challenges and opportunities proposed by the competitive environment. On the other hand, managerial marketing is focused on the implementation of specific targets." Marketing strategy is about "lofty visions translated into less lofty and practical goals [while marketing management] is where we start to get our hands dirty and make plans for things to happen." Marketing strategy is sometimes called "higher order" planning because it sets out the broad direction and provides guidance and structure for the marketing program.

Marketing scholars have suggested that strategic marketing arose in the late 1970s and its origins can be understood in terms of a distinct evolutionary path:

Marketing strategy involves mapping out the company's direction for the forthcoming planning period, whether that be three, five or ten years. It involves undertaking a 360° review of the firm and its operating environment with a view to identifying new business opportunities that the firm could potentially leverage for competitive advantage. Strategic planning may also reveal market threats that the firm may need to consider for long-term sustainability. Strategic planning makes no assumptions about the firm continuing to offer the same products to the same customers into the future. Instead, it is concerned with identifying the business opportunities that are likely to be successful and evaluates the firm's capacity to leverage such opportunities. It seeks to identify the "strategic gap"; that is the difference between where a firm is currently situated (the "strategic reality" or "inadvertent strategy") and where it should be situated for sustainable, long-term growth (the "strategic intent" or "deliberate strategy").

Strategic planning seeks to address three deceptively simple questions, specifically:

A fourth question may be added to the list, namely 'How do we know when we got there?' Due to increasing need for accountability, many marketing organisations use a variety of marketing metrics to track strategic performance, allowing for corrective action to be taken as required. On the surface, strategic planning seeks to address three simple questions, however, the research and analysis involved in strategic planning is very sophisticated and requires a great deal of skill and judgement.

Strategic analysis is designed to address the first strategic question, "Where are we now?" Traditional market research is less useful for strategic marketing because the analyst is not seeking insights about customer attitudes and preferences. Instead strategic analysts are seeking insights about the firm's operating environment with a view to identifying possible future scenarios, opportunities and threats.

Strategic planning focuses on the 3C's, namely: Customer, Corporation and Competitors. A detailed analysis of each factor is key to the success of strategy formulation. The 'competitors' element refers to an analysis of the strengths of the business relative to close rivals, and a consideration of competitive threats that might impinge on the business' ability to move in certain directions. The 'customer' element refers to an analysis of any possible changes in customer preferences that potentially give rise to new business opportunities. The 'corporation' element refers to a detailed analysis of the company's internal capabilities and its readiness to leverage market-based opportunities or its vulnerability to external threats.

Mintzberg suggests that the top planners spend most of their time engaged in analysis and are concerned with industry or competitive analyses as well as internal studies, including the use of computer models to analyze trends in the organization. Strategic planners use a variety of research tools and analytical techniques, depending on the environment complexity and the firm's goals. Fleitcher and Bensoussan, for instance, have identified some 200 qualitative and quantitative analytical techniques regularly used by strategic analysts while a recent publication suggests that 72 techniques are essential. No optimal technique can be identified as useful across all situations or problems. Determining which technique to use in any given situation rests with the skill of the analyst. The choice of tool depends on a variety of factors including: data availability; the nature of the marketing problem; the objective or purpose, the analyst's skill level as well as other constraints such as time or motivation.

The most commonly used tools and techniques include:

Research methods

Analytical techniques

Gap analysis is a type of higher order analysis that seeks to identify the difference between the organisation's current strategy and its desired strategy. This difference is sometimes known as the "strategic gap." Mintzberg identifies two types of strategy namely "deliberate strategy" and "inadvertent strategy." The deliberate strategy represents the firm's strategic intent or its desired path while the inadvertent strategy represents the path that the firm may have followed as it adjusted to environmental, competitive and market changes. Other scholars use the terms "realized strategy" versus "intended" strategy to refer to the same concepts. This type of analysis indicates whether an organisation has strayed from its desired path during the planning period. The presence of a large gap may indicate the organisation has become "stuck in the middle"; a recipe for strategic mediocrity and potential failure.

The category/brand development index is a method used to assess the sales potential for a region or market and identify market segments that can be developed (i.e. high CDI and high BDI). In addition, it may be used to identify markets where the category or brand is under-performing and may signal underlying marketing problems such as poor distribution (i.e. high CDI and low BDI).

BDI and CDI are calculated as follows:

Strategic planning typically begins with a scan of the business environment, both internal and external, this includes understanding strategic constraints. An understanding of the external operating environment, including political, economic, social and technological which includes demographic and cultural aspects, is necessary for the identification of business opportunities and threats. This analysis is called PEST; an acronym for Political, Economic, Social and Technological. A number of variants of the PEST analysis can be identified in literature, including: PESTLE analysis (Political, Economic, Social, Technological, Legal and Environmental); STEEPLE (adds ethics); STEEPLED (adds demographics) and STEER (adds regulatory).

The aim of the PEST analysis is to identify opportunities and threats in the wider operating environment. Firms try to leverage opportunities while trying to buffer themselves against potential threats. Basically, the PEST analysis guides strategic decision-making. The main elements of the PEST analysis are:

When carrying out a PEST analysis, planners and analysts may consider the operating environment at three levels, namely "the supranational"; "the national" and "subnational" or local level. As businesses become more globalized, they may need to pay greater attention to the supranational level.

In addition to the PEST analysis, firms carry out a Strengths, Weakness, Opportunities and Threats (SWOT) analysis. A SWOT analysis identifies: 

Typically the firm will attempt to leverage those opportunities that can be matched with internal strengths; that is to say the firm has a capability in any area where strengths are matched with external opportunities. It may need to build capability if it wishes to leverage opportunities in areas of weakness. An area of weakness that is matched with an external threat represents a vulnerability, and the firm may need to develop contingency plans.

The vision and mission address the second central question, 'Where are we going?' At the conclusion of the research and analysis stage, the firm will typically review its vision statement, mission statement and, if necessary, devise a new vision and mission for the outlook period. At this stage, the firm will also devise a generic competitive strategy as the basis for maintaining a sustainable competitive advantage for the forthcoming planning period.

A vision statement is a realistic, long term future scenario for the organisation. (Vision statements should not be confused with slogans or mottos.) A vision statement is designed to present a realistic long-term future scenario for the organisation. It is a "clearly articulated statement of the business scope." A strong vision statement typically includes the following:
Some scholars point out the market visioning is a skill or competency that encapsulates the planners' capacity "to link advanced technologies to market opportunities of the future, and to do so through a shared understanding of a given product market.

A mission statement is a clear and concise statement of the organisation’s reason for being and its scope of operations, while the generic strategy outlines how the company intends to achieve both its vision and mission.

Mission statements should include detailed information and must be more than a simple "motherhood statement". A mission statement typically includes the following:

The generic competitive strategy outlines the fundamental basis for obtaining a sustainable competitive advantage within a category. Firms can normally trace their competitive position to one of three factors:

It is essential that the internal analysis provide a frank and open evaluation of the firm's superiority in terms of skills, resources or market position since this will provide the basis for competing over the forthcoming planning period. For this reason, some companies engage external consultants to provide an independent assessment of the firms capabilities and resources.

In 1980, Michael Porter developed an approach to strategy formulation that proved to be extremely popular with both scholars and practitioners. The approach became known as the "positioning school" because of its emphasis on locating a defensible "competitive position" within an industry or sector. In this approach, strategy formulation consists of three key strands of thinking: analysis of the five forces to determine the sources of competitive advantage; the selection of one of three possible positions which leverage the advantage and the value chain to implement the strategy. In this approach, the strategic choices involve decisions about whether to compete for a share of the total market or for a specific target group (competitive scope) and whether to compete on costs or product differences (competitive advantage). This type of thinking leads to three generic strategies:

According to Porter, these strategies are mutually exclusive and the firm must select one approach to the exclusion of all others. Firms that try to be all things to all people can present a confused market position which ultimately leads to below average returns. Any ambiguity about the firm's approach is a recipe for "strategic mediocrity" and any firm that tries to pursue two approaches simultaneously is said to be "stuck in the middle" and destined for failure.

Porter's approach was the dominant paradigm throughout the 1980s. However, the approach has attracted considerable criticism. One important criticism is that it is possible to identify successful companies that pursue a hybrid strategy - such as low cost position and a differentiated position simultaneously. Toyota is a classic example of this hybrid approach. Other scholars point to the simplistic nature of the analysis and the overly prescriptive nature of the strategic choices which limits strategies to just three options. Yet others point to research showing that many practitioners find the approach to be overly theoretical and not applicable to their business.

During the 1990s, the "resource-based view" (also known as the "resource-advantage theory") of the firm became the dominant paradigm. It is an inter-disciplinary approach that represents a substantial shift in thinking. It focuses attention on an organisation's internal resources as a means of organising processes and obtaining a competitive advantage. The resource-based view suggests that organisations must develop unique, firm-specific core competencies that will allow them to outperform competitors by doing things differently and in a superior manner.

Barney stated that for resources to hold potential as sources of sustainable competitive advantage, they should be valuable, rare and imperfectly imitable. A key insight arising from the resource-based view is that not all resources are of equal importance nor possess the potential to become a source of sustainable competitive advantage. The sustainability of any competitive advantage depends on the extent to which resources can be imitated or substituted. Barney and others point out that understanding the causal relationship between the sources of advantage and successful strategies can be very difficult in practice. Barney uses the term "causally ambiguous" which he describes as a situation when "the link between the resources controlled by the firm and the firm's sustained competitive advantage is not understood or understood only very imperfectly." Thus, a great deal of managerial effort must be invested in identifying, understanding and classifying core competencies. In addition, management must invest in organisational learning to develop and maintain key resources and competencies.

Market Based Resources include:

In the resource-based view, strategists select the strategy or competitive position that best exploits the internal resources and capabilities relative to external opportunities. Given that strategic resources represent a complex network of inter-related assets and capabilities, organisations can adopt many possible competitive positions. Although scholars debate the precise categories of competitive positions that are used, there is general agreement, within the literature, that the resource-based view is much more flexible than Porter's prescriptive approach to strategy formulation.

Hooley et al., suggest the following classification of competitive positions:

The choice of competitive strategy often depends on a variety of factors including: the firm's market position relative to rival firms, the stage of the product life cycle. A well-established firm in a mature market will likely have a different strategy than a start-up.

Growth of a business is critical for business success. A firm may grow by developing the market or by developing new products. The Ansoff product and market growth matrix illustrates the two broad dimensions for achieving growth. The Ansoff matrix identifies four specific growth strategies: market penetration, product development, market development and diversification. 

A horizontal integration strategy may be indicated in fast changing work environments as well as providing a broad knowledge base for the business and employees. A benefit of horizontal diversification is that it is an open platform for a business to expand and build away from the already existing market.

High levels of horizontal integration lead to high levels of communication within the business. Another benefit of using this strategy is that it leads to a larger market for merged businesses, and it is easier to build good reputations for a business when using this strategy. A disadvantage of using a diversification strategy is that the benefits could take a while to start showing, which could lead the business to believe that the strategy in ineffective. Another disadvantage or risk is, it has been shown that using the horizontal diversification method has become harmful for stock value, but using the vertical diversification had the best effects.

A disadvantage of using the horizontal integration strategy is that this limits and restricts the field of interest that the business. Horizontal integration can affect a business's reputation, especially after a merge has happened between two or more businesses. There are three main benefits to a business's reputation after a merge. A larger business helps the reputation and increases the severity of the punishment. As well as the merge of information after a merge has happened, this increases the knowledge of the business and marketing area they are focused on. The last benefit is more opportunities for deviation to occur in merged businesses rather than independent businesses.


Vertical integration is when business is expanded through the vertical production line on one business. An example of a vertically integrated business could be Apple. Apple owns all their own software, hardware, designs and operating systems instead of relying on other businesses to supply these. By having a highly vertically integrated business this creates different economies therefore creating a positive performance for the business. Vertical integration is seen as a business controlling the inputs of supplies and outputs of products as well as the distribution of the final product. Some benefits of using a Vertical integration strategy is that costs may be reduced because of the reducing transaction costs which include finding, selling, monitoring, contracting and negotiating with other firms. Also by decreasing outside businesses input it will increase the efficient use of inputs into the business. Another benefit of vertical integration is that it improves the exchange of information through the different stages of the production line. Some competitive advantages could include; avoiding foreclosures, improving the business marketing intelligence, and opens up opportunities to create different products for the market. Some disadvantages of using a Vertical Integration Strategy include the internal costs for the business and the need for overhead costs. Also if the business is not well organised and fully equipped and prepared the business will struggle using this strategy. There are also competitive disadvantages as well, which include; creates barriers for the business, and loses access to information from suppliers and distributors.

In terms of market position, firms may be classified as market leaders, market challengers, market followers or market nichers.

As the speed of change in the marketing environment quickens, time horizons are becoming shorter. Nevertheless, most firms carry out strategic planning every 3– 5 years and treat the process as a means of checking whether the company is on track to achieve its vision and mission. Ideally, strategies are both dynamic and interactive, partially planned and partially unplanned. Strategies are broad in their scope in order to enable a firm to react to unforeseen developments while trying to keep focused on a specific pathway. A key aspect of marketing strategy is to keep marketing consistent with a company's overarching mission statement.

Strategies often specify how to adjust the marketing mix; firms can use tools such as Marketing Mix Modeling to help them decide how to allocate scarce resources, as well as how to allocate funds across a portfolio of brands. In addition, firms can conduct analyses of performance, customer analysis, competitor analysis, and target market analysis.

Marketing strategies may differ depending on the unique situation of the individual business. According to Lieberman and Montgomery, every entrant into a market – whether it is new or not – is classified under a Market Pioneer, Close Follower or a Late follower

Market pioneers are known to often open a new market to consumers based off a major innovation. They emphasise these product developments, and in a significant number of cases, studies have shown that early entrants – or pioneers – into a market have serious market-share advantages above all those who enter later. Pioneers have the first-mover advantage, and in order to have this advantage, business’ must ensure they have at least one or more of three primary sources: Technological Leadership, Preemption of Assets or Buyer Switching Costs. Technological Leadership means gaining an advantage through either Research and Development or the “learning curve”. This lets a business use the research and development stage as a key point of selling due to primary research of a new or developed product. Preemption of Assets can help gain an advantage through acquiring scarce assets within a certain market, allowing the first-mover to be able to have control of existing assets rather than those that are created through new technology. Thus allowing pre-existing information to be used and a lower risk when first entering a new market. By being a first entrant, it is easy to avoid higher switching costs compared to later entrants. For example, those who enter later would have to invest more expenditure in order to encourage customers away from early entrants. However, while Market Pioneers may have the “highest probability of engaging in product development” and lower switching costs, to have the first-mover advantage, it can be more expensive due to product innovation being more costly than product imitation. It has been found that while Pioneers in both consumer goods and industrial markets have gained “significant sales advantages”, they incur larger disadvantages cost-wise.

Being a Market Pioneer can, more often than not, attract entrepreneurs and/or investors depending on the benefits of the market. If there is an upside potential and the ability to have a stable market share, many businesses would start to follow in the footsteps of these pioneers. These are more commonly known as Close Followers. These entrants into the market can also be seen as challengers to the Market Pioneers and the Late Followers. This is because early followers are more than likely to invest a significant amount in Product Research and Development than later entrants. By doing this, it allows businesses to find weaknesses in the products produced before, thus leading to improvements and expansion on the aforementioned product. Therefore, it could also lead to customer preference, which is essential in market success. Due to the nature of early followers and the research time being later than Market Pioneers, different development strategies are used as opposed to those who entered the market in the beginning, and the same is applied to those who are Late Followers in the market. By having a different strategy, it allows the followers to create their own unique selling point and perhaps target a different audience in comparison to that of the Market Pioneers. Early following into a market can often be encouraged by an established business’ product that is “threatened or has industry-specific supporting assets”.

Those who follow after the Close Followers are known as the Late Entrants. While being a Late Entrant can seem very daunting, there are some perks to being a latecomer. For example, Late Entrants have the ability to learn from those who are already in the market or have previously entered. Late Followers have the advantage of learning from their early competitors and improving the benefits or reducing the total costs. This allows them to create a strategy that could essentially mean gaining market share and most importantly, staying in the market. In addition to this, markets evolve, leading to consumers wanting improvements and advancements on products. Late Followers have the advantage of catching the shifts in customer needs and wants towards the products. When bearing in mind customer preference, customer value has a significant influence. Customer value means taking into account the investment of customers as well as the brand or product. It is created through the “perceptions of benefits” and the “total cost of ownership”. On the other hand, if the needs and wants of consumers have only slightly altered, Late Followers could have a cost advantage over early entrants due to the use of product imitation. However, if a business is switching markets, this could take the cost advantage away due to the expense of changing markets for the business. Late Entry into a market does not necessarily mean there is a disadvantage when it comes to market share, it depends on how the marketing mix is adopted and the performance of the business. If the marketing mix is not used correctly – despite the entrant time – the business will gain little to no advantages, potentially missing out on a significant opportunity.

The differentiated strategy

The customised target strategy
The requirements of individual customer markets are unique, and their purchases sufficient to make viable the design of a new marketing mix for each customer.

If a company adopts this type of market strategy, a separate marketing mix is to be designed for each customer.

Specific marketing mixes can be developed to appeal to most of the segments when market segmentation reveals several potential targets.

Whereas the vision and mission provide the framework, the "goals define targets within the mission, which, when achieved, should move the organization toward the performance of that mission." "Goals" are broad primary outcomes whereas, "objectives" are measurable steps taken to achieve a goal or strategy. In strategic planning, it is important for managers to translate the overall strategy into goals and objectives. Goals are designed to inspire action and focus attention on specific desired outcomes. Objectives, on the other hand, are used to measure an organisation's performance on specific dimensions, thereby providing the organisation with feedback on how well it is achieving its goals and strategies.

Managers typically establish objectives using the "balanced scorecard" approach. This means that objectives do not include desired financial outcomes exclusively, but also specify measures of performance for customers (e.g. satisfaction, loyalty, repeat patronage), internal processes (e.g., employee satisfaction, productivity) and innovation and improvement activities.

After setting the goals marketing strategy or marketing plan should be developed. The marketing strategy plan provides an outline of the specific actions to be taken over time to achieve the objectives. Plans can be extended to cover many years, with sub-plans for each year. Plans usually involve monitoring, to assess progress, and prepare for contingencies if problems arise. Simultaneous such as customer lifetime value models can be used to help marketers conduct "what-if" analyses to forecast what potential scenarios arising from possible actions, and to gauge how specific actions might affect such variables as the revenue-per-customer and the churn rate.

Developing competitive strategy requires significant judgement and is based on a deep understanding of the firm's current situation, its past history and its operating environment. No heuristics have yet been developed to assist strategists choose the optimal strategic direction. Nevertheless, some researchers and scholars have sought to classify broad groups of strategy approaches that might serve as broad frameworks for thinking about suitable choices.

In 2003, Raymond Miles proposed a detailed scheme using the categories:

Marketing warfare strategies are competitor-centered strategies drawn from analogies with the field of military science. Warfare strategies were popular in the 1980s, but interest in this approach has waned in the new era of relationship marketing. An increased awareness of the distinctions between business and military cultures also raises questions about the extent to which this type of analogy is useful. In spite of its limitations, the typology of marketing warfare strategies is useful for predicting and understanding competitor responses.

In the 1980s, Kotler and Singh developed a typology of marketing warfare strategies:


Marketing strategy and marketing mix are related elements of a comprehensive marketing plan. While marketing strategy is aligned with setting the direction of a company or product/service line, the marketing mix is majorly tactical in nature and is employed to carry out the overall marketing strategy. The 4P's of the marketing mix (Price, Product, Place and Promotion) represent the tools that marketers can leverage while defining their marketing strategy to create a marketing plan.




</doc>
<doc id="39206" url="https://en.wikipedia.org/wiki?curid=39206" title="Business">
Business

Business is the activity of making one's living or making money by producing or buying and selling products (such as goods and services). Simply put, it is "any activity or enterprise entered into for profit. It does not mean it is a company, a corporation, partnership, or have any such formal organization, but it can range from a street peddler to General Motors." 

Having a business name does not separate the business entity from the owner, which means that the owner of the business is responsible and liable for debts incurred by the business. If the business acquires debts, the creditors can go after the owner's personal possessions. A business structure does not allow for corporate tax rates. The proprietor is personally taxed on all income from the business.

The term is also often used colloquially (but not by lawyers or by public officials) to refer to a company. A company, on the other hand, is a separate legal entity and provides for limited liability, as well as corporate tax rates. A company structure is more complicated and expensive to set up, but offers more protection and benefits for the owner.

Forms of business ownership vary by jurisdiction, but several common entities exist:

"Less common types of companies are:"
Note that "Ltd after the company's name signifies limited company, and PLC (public limited company) indicates that its shares are widely held."

In legal parlance, the owners of a company are normally referred to as the "members". In a company limited or unlimited by shares (formed or incorporated with a share capital), this will be the shareholders. In a company limited by guarantee, this will be the guarantors. Some offshore jurisdictions have created special forms of offshore company in a bid to attract business for their jurisdictions. Examples include "segregated portfolio companies" and restricted purpose companies.

There are, however, many, many sub-categories of types of company that can be formed in various jurisdictions in the world.

Companies are also sometimes distinguished into public companies and private companies for legal and regulatory purposes. Public companies are companies whose shares can be publicly traded, often (although not always) on a stock exchange which imposes listing requirements/Listing Rules as to the issued shares, the trading of shares and a future issue of shares to help bolster the reputation of the exchange or particular market of exchange. Private companies do not have publicly traded shares, and often contain restrictions on transfers of shares. In some jurisdictions, private companies have maximum numbers of shareholders.

A parent company is a company that owns enough voting stock in another firm to control management and operations by influencing or electing its board of directors; the second company being deemed as a subsidiary of the parent company. The definition of a parent company differs by jurisdiction, with the definition normally being defined by way of laws dealing with companies in that jurisdiction.


Accounting is the measurement, processing, and communication of financial information about economic entities such as businesses and corporations. The modern field was established by the Italian mathematician Luca Pacioli in 1494. Accounting, which has been called the "language of business", measures the results of an organization's economic activities and conveys this information to a variety of users, including investors, creditors, management, and regulators. Practitioners of accounting are known as accountants. The terms "accounting" and "financial reporting" are often used as synonyms.

Finance is a field that deals with the study of investments. It includes the dynamics of assets and liabilities over time under conditions of different degrees of uncertainty and risk. Finance can also be defined as the science of money management. Finance aims to price assets based on their risk level and their expected rate of return. Finance can be broken into three different sub categories: public finance, corporate finance, and personal finance.

Manufacturing is the production of merchandise for use or sale using labour and machines, tools, chemical and biological processing, or formulation. The term may refer to a range of human activity, from handicraft to high tech, but is most commonly applied to industrial production, in which raw materials are transformed into finished goods on a large scale.

Marketing is defined by the American Marketing Association as "the activity, set of institutions, and processes for creating, communicating, delivering, and exchanging offerings that have value for customers, clients, partners, and society at large." The term developed from the original meaning which referred literally to going to a market to buy or sell goods or services. Marketing tactics include advertising as well as determining product pricing.

With the rise in technology, marketing is further divided into a class called digital marketing. It is marketing products and services using digital technologies.

Research and development refer to activities in connection with corporate or government innovation. Research and development constitute the first stage of development of a potential new service or product. Research and development are very difficult to manage since the defining feature of the research is that the researchers do not know in advance exactly how to accomplish the desired result. 

Injuries cost businesses billions of dollars annually. Studies have shown how company acceptance and implementation of comprehensive safety and health management systems reduce incidents, insurance costs, and workers’ compensation claims. New technologies, like wearable safety devices and available online safety training, continue to be developed to encourage employers to invest in protection beyond the "canary in the coal mine" and reduce the cost to businesses of protecting their employees.

Sales are activity related to selling or the number of goods or services sold in a given time period. Sales are often integrated with all lines of business and are key to a companies' success.

The efficient and effective operation of a business, and study of this subject, is called management. The major branches of management are financial management, marketing management, human resource management, strategic management, production management, operations management, service management, and information technology management. 

Owners may manage their businesses themselves, or employ managers to do so for them. Whether they are owners or employees, managers administer three primary components of the business' value: financial resources, capital (tangible resources), and human resources. These resources are administered in at least six functional areas: legal contracting, manufacturing or service production, marketing, accounting, financing, and human resources.

In recent decades, states modeled some of their assets and enterprises after business enterprises. In 2003, for example, the People's Republic of China modeled 80% of its state-owned enterprises on a company-type management system. Many state institutions and enterprises in China and Russia have transformed into joint-stock companies, with part of their shares being listed on public stock markets.

Business process management (BPM) is a holistic management approach focused on aligning all aspects of an organization with the wants and needs of clients. BPM attempts to improve processes continuously. It can, therefore, be described as a "process optimization process". It is argued that BPM enables organizations to be more efficient, effective and capable of change than a functionally focused, traditional hierarchical management approach. 

Most legal jurisdictions specify the forms of ownership that a business can take, creating a body of commercial law for each type.

The major factors affecting how a business is organized are usually:


Many businesses are operated through a separate entity such as a corporation or a partnership (either formed with or without limited liability). Most legal jurisdictions allow people to organize such an entity by filing certain charter documents with the relevant Secretary of State or equivalent and complying with certain other ongoing obligations. The relationships and legal rights of shareholders, limited partners, or members are governed partly by the charter documents and partly by the law of the jurisdiction where the entity is organized. Generally speaking, shareholders in a corporation, limited partners in a limited partnership, and members in a limited liability company are shielded from personal liability for the debts and obligations of the entity, which is legally treated as a separate "person". This means that unless there is misconduct, the owner's own possessions are strongly protected in law if the business does not succeed.

Where two or more individuals own a business together but have failed to organize a more specialized form of vehicle, they will be treated as a general partnership. The terms of a partnership are partly governed by a partnership agreement if one is created, and partly by the law of the jurisdiction where the partnership is located. No paperwork or filing is necessary to create a partnership, and without an agreement, the relationships and legal rights of the partners will be entirely governed by the law of the jurisdiction where the partnership is located. A single person who owns and runs a business is commonly known as a "sole proprietor", whether that person owns it directly or through a formally organized entity. Depending on the business needs, an adviser can decide what kind is proprietorship will be most suitable.

A few relevant factors to consider in deciding how to operate a business include:


A very detailed and well-established body of rules that evolved over a very long period of time applies to commercial transactions. The need to regulate trade and commerce and resolve business disputes helped shape the creation of law and courts. The Code of Hammurabi dates back to about 1772 BC for example and contains provisions that relate, among other matters, to shipping costs and dealings between merchants and brokers. The word "corporation" derives from the Latin "corpus", meaning body, and the Maurya Empire in Iron-Age India accorded legal rights to business entities.

In many countries, it is difficult to compile all the laws that can affect a business into a single reference source. Laws can govern the treatment of labour and employee relations, worker protection and safety, discrimination on the basis of age, gender, disability, race, and in some jurisdictions, sexual orientation, and the minimum wage, as well as unions, worker compensation, and working hours and leave.

Some specialized businesses may also require licenses, either due to laws governing entry into certain trades, occupations or professions, that require special education or to raise revenue for local governments. Professions that require special licenses include law, medicine, piloting aircraft, selling liquor, radio broadcasting, selling investment securities, selling used cars, and roofing. Local jurisdictions may also require special licenses and taxes just to operate a business.

Some businesses are subject to ongoing special regulation, for example, public utilities, investment securities, banking, insurance, broadcasting, aviation, and health care providers. Environmental regulations are also very complex and can affect many businesses.

 When businesses need to raise money (called capital), they sometimes offer securities for sale.

Capital may be raised through private means, by an initial public offering or IPO on a stock exchange, or in other ways.

Major stock exchanges include the Shanghai Stock Exchange, Singapore Exchange, Hong Kong Stock Exchange, New York Stock Exchange and NASDAQ (the USA), the London Stock Exchange (UK), the Tokyo Stock Exchange (Japan), and Bombay Stock Exchange (India). Most countries with capital markets have at least one.

Businesses that have gone public are subject to regulations concerning their internal governance, such as how executive officers' compensation is determined, and when and how information is disclosed to shareholders and to the public. In the United States, these regulations are primarily implemented and enforced by the United States Securities and Exchange Commission (SEC). Other western nations have comparable regulatory bodies. The regulations are implemented and enforced by the China Securities Regulation Commission (CSRC) in China. In Singapore, the regulatory authority is the Monetary Authority of Singapore (MAS), and in Hong Kong, it is the Securities and Futures Commission (SFC).

The proliferation and increasing complexity of the laws governing business have forced increasing specialization in corporate law. It is not unheard of for certain kinds of corporate transactions to require a team of five to ten attorneys due to sprawling regulation. Commercial law spans general corporate law, employment and labor law, health-care law, securities law, mergers and acquisitions, tax law, employee benefit plans, food and drug regulation, intellectual property law on copyrights, patents, trademarks, telecommunications law, and financing.

Other types of capital sourcing include crowdsourcing on the Internet, venture capital, bank loans, and debentures.

Businesses often have important "intellectual property" that needs protection from competitors for the company to stay profitable. This could require patents, copyrights, trademarks, or preservation of trade secrets. Most businesses have names, logos, and similar branding techniques that could benefit from trademarking. Patents and copyrights in the United States are largely governed by federal law, while trade secrets and trademarking are mostly a matter of state law. Because of the nature of intellectual property, a business needs protection in every jurisdiction in which they are concerned about competitors. Many countries are signatories to international treaties concerning intellectual property, and thus companies registered in these countries are subject to national laws bound by these treaties. In order to protect trade secrets, companies may require employees to sign noncompete clauses which will impose limitations on an employee's interactions with stakeholders, and competitors.

A trade union (or labor union) is an organization of workers who have come together to achieve common goals such as protecting the integrity of its trade, improving safety standards, achieving higher pay and benefits such as health care and retirement, increasing the number of employees an employer assigns to complete the work, and better working conditions. The trade union, through its leadership, bargains with the employer on behalf of union members (rank and file members) and negotiates labor contracts (collective bargaining) with employers. The most common purpose of these associations or unions is "maintaining or improving the conditions of their employment". This may include the negotiation of wages, work rules, complaint procedures, rules governing hiring, firing, and promotion of workers, benefits, workplace safety and policies.


</doc>
<doc id="59563876" url="https://en.wikipedia.org/wiki?curid=59563876" title="OSTO System Model">
OSTO System Model

The OSTO System Model is based on the OSTO System Theory, which comprehends complex systems and organizations as living systems and maps these by means of the OSTO System Model. The model is cybernetic in nature and is deduced from the theory of closed loops. The basics of this theory have been formulated by David P. Hanna in the 1980’s and have been published initially in 1988. The model assumes that several central transformation processes take place on the inside of a complex organization. These are deeply influenced by mutual reactions between the inner life of the organization and the outside (environment). In terms of closed loop theory, the OSTO System Model depicts the essential elements of such a living system in its interconnectedness, dependencies, and reciprocal reactions. Thinking in network structures is, thus, a crucial part of the OSTO System Theory.

The acronym “OSTO” stands for open, sociotechnical, economic (German: “oekonomisch”) aspects of a system. With regard to organizations and economically working companies, the model takes into consideration the openness of systems towards their environments as well as the fact that they are multidimensional, socio-techno-economic structures. Taking into consideration these four aspects, the model displays the complexity of such a system in its numerous dimensions.

The OSTO System Model is a concrete model of the OSTO thought framework. In practice this model is used as a managerial and reflection tool.

Looking through the so-called “OSTO glasses” is to facilitate managing the steadily increasing dynamism and complexity of systems such as to find new action strategies by creating distance.
Consequently, for organizational development the method is applied in the field of change management. Companies use the methods in the area of 
diagnosis, design and redesign of organizations as well as in project management. 
OSTO has developed concepts for education and human resource development in line with the systemic qualification of managers (“SYMA®”). 
The approach is mainly taught at the University of Klagenfurt and at RWTH Aachen University. 
It is mainly concentrated in the institute of cybernetics as well as at the chair of information management in mechanical engineering and at the center 
for learning and knowledge management. Each year, more than 1000 students acquire knowledge of the OSTO System Theory during a mandatory course 
in their studies of mechanical engineering.

In the OSTO System approach, organizations are analyzed as open systems. In this context, the attribute “open” refers as well to the spatial and subject 
level as to the temporal aspect. On the spatial and subject level, not only intended but also unintended exchange with the environment is analyzed. 
Systems are hardly ever closed. In consequence of that, bidirectional reciprocal exchange between a system and its environment has to be monitored very 
closely. Internal relationships as well as external dependencies of the entire system have to be grasped in order to develop a long-term strategy that 
takes consequences into consideration.

The social side of the system comprises the classical areas of design and process organization, information and decision procedures, 
division of functions and tasks, as well as the reward and control system. This aspect does, however, also consider the motivation throughout the 
company and the relationships among employees and the overall organizational culture. For understanding this part and its influence on the whole 
system it is crucial to know that trust plays the most important part in all procedures and processes in which humans are involved.

The technical side of the system mainly focuses on the material aspects of companies, such as machines, equipment, internal and external architecture 
as well as tools and procedures. Additionally, it comprises the conceptualization of technology with regard to centralized and/or decentralized solutions. 
Another problem that is tackled within this part of the model is the question as to how technical concepts and tool further fragmentation of work or – if 
intended so- in how far they enable integrated wholesome work structures.

The economic side of the system describes all aspects which are directly linked to the economic efficiency of the organization, such as revenue trends, productivity development, controlling procedures, remuneration systems, investment and budget planning, fiscal aspects, lead times, cost structure, etc.

Complexity, with regard to entrepreneurial action was first described by organizational theorists in the years around 1975. Hence, different management 
schools and consultants tried to develop new forms of organizational development since: They intended to understand the internal and external complexities 
of companies by developing thought frameworks and creating models. 
Up to this point, there were models describing organizations as Tayloristic structures with subdivision of work (design and process organization). 
These models are still in use. However, they bear the disadvantage of being incapable of depicting the necessary flexibility. The systemic approach 
represents organizations as living organisms which need to flexibly adapt to new conditions. The new aspect of these models is the fact that they consider 
the internal and external complexity of an organization and the social psychological phenomena in and around an organization enter the scope of analysis.
The three most important models in this development are the viable system model (cf. Stafford Beer, 1959), the new St. Gallen Management Model 
(cf. Rüegg-Stürm, 2002) and the OSTO System Model. These models structure the (multidimensional) complexity of large organizational structures into 
illustrations of one or more dimensions. Another, rather non-famous model, is the “Sensitivity Model” by Frederic Vester.

The OSTO System Model is based on the “Organization Performance Model” which has been developed, tested and published by David P. Hanna in 1988 in his 
time as a consultant for Procter & Gamble. Further important participants in this development include Clark/Krone 1972, Krone 1974 and Krug 1992. 
Later on, the model has been further developed and systemized for science by Heijo Rieckmann (Klagenfurt University) and Klaus Henning (RWTH Aachen University) as well as for systemic consulting of organizations by Renate Henning.

Every organization is separated from its environments (at least) theoretically by differing borders. Possible forms of such borders are: Physical 
(e.g. buildings), temporal (e.g. work shifts), social (e.g. teams), or psychological (stereotypes, prejudices) system borders. In order to describe and define a system as accurately as possible it is necessary to determine the borders of a system very carefully. It is a current perception that system borders are partly permeable.

The environments of a system, i.e. everything outside its borders, have a strong influence on every organization. The model assumes that systems without 
any environment that they interact with cannot exist. A system that is hardly influenced by an environment described as an autarkical system. On the 
contrary, a system that is strongly formed by external influences is named a dependent system. In the context of companies an environment can be as 
diverse as to be the marketplace, customers, political conditions etc.

The reason for existing of a system – also to be grasped as the purpose – is the contractual, reciprocal relationship between the system and its environments. It describes which need of the environments is to be satisfied by the core processes of the organization. The Reason for Existing can never be defined unilaterally, which separates it from unilateral, personal interests. In its form it is not to be seen as static, but is also influenced in various ways from the inside and by external factors of the system such that a regular comparison with reality is important. In conjunction with the mission and the goals the Reason for Existing incorporates the overruling “company strategy”.

Next to the Reason for Existing, for every living system a sound mission that is oriented towards the future bears many advantages. The mission questions the long-term sensibility of the Reason for Existing. The internal motivation and identification on the one hand and the acceptance in society on the other hand are maintained through long-term, future oriented thinking. The mission focuses on sensibility with regard to sustainability based on individual, cultural, ethical and further aspects.

In applied practice, the Ultimate Anchor plays a minor role. It deeply analyses [basis and meta value, views on life and the world, images of people and gods which creates the framework of convictions and beliefs in which “questions for meaning” are shaped.] 

Mission as well as Ultimate Anchor were added to the OSTO System Model by Rieckmann and Henning in the second half of the 1980´s since both aspects become increasingly important under the influence of globalization and crisis in society.,

An appropriate depiction of the initial outputs is necessary for the organizational diagnosis. In that regard it is important that “Output” comprises both numerically graspable as well as qualitative aspects (e.g. work place satisfaction, motivation etc.). It is just as important to capture the factually or seemingly useless initial results and not only the “official” or “desired” results.

The term “Outcome” comprises all financial events of an organization: Income from product sales, R&D, etc. It is intended so that the term is slightly broader such that the organization under scrutiny utilizing the model decides itself whether “Outcome” includes prices, sales volume, return on investment (ROI), or other aspects.

The OSTO System Model points out that inside an organization the information from the environment, the Reason for Existing and the outputs/outcome are turned into real results through transformational processes. The model provides two explanations for that

The process version explains the processing of information from the environment, the reason for existing and the outputs/outcome by means of a transformational process. This process is made up of three central core processes. The term “core process” is to underline that only processes that go to the core of the subject matter, i.e. those which ensure the existence of the company, are relevant. There are three core process that are to be distinguished:

The task core process comprises all activities, communications, actions, etc. which aim at creating the system results (output).

An important basis for all processes of within a system is the energy (work power, performance) which each single person in a system provides and is capable of deploying towards the goals of a system. The systemic approach describes this by the term “Individual Core Process”.

Throughout the social core process, the humans in an organization work towards the goals of a system. In the SCP, the individual core process and the task core process are linked such that synergy effects are yielded from collaboration.

The Structural version explains the system’s internal transformation process through strategies, design elements and (system-) behavior. The transformational process is such structured by the design elements of the company. They are intended to concentrate and to structure all processes and structures within an organization:

In the OSTO map, the goals of a company belong to the internal design of an organization, i.e. the so-called transformational process. With respect to systemic theory, the goals are to be grasped as an internal specification and are derived from the reason for existing. They define the internal needs for actions. For reaching the goals it is necessary to formulate strategies that define how things are to be implemented such that the goals are achieved. The strategies are realized by appropriate adaptions to the design elements.

In every system/organization there is an abundance of very different behavioral patterns (e.g. leadership behavior, work behavior, etc.) which are produced by the design elements. This implies that the system behavior can only be influenced through the design elements. Since systems are dynamic processes, they are not oriented towards subjects but rather towards events. The overall system can have characteristics which are not inert to any of its component parts (loyal/cooperative characteristic) and does in general not behave like the sum of its parts. The OSTO System Model is currently the only model of this kind which closely analyses the behavior of an organization.

The design element human comprises the members of a company/organization and their roles (talents, qualifications etc.), expectations and needs of material character. Furthermore, the network of socio-emotional relationships and interaction circumstances (“climate”) is included in these conditions of collaboration.

Technology as a design element comprises the technical machines, the means of production, property plant and equipment, etc. and the relationships among them, i.e. all material and spatial conditions of a system.

The organizational structure describes the operating procedures and processes of an organization, i.e. the functions, hierarchies, reporting structures as well as the regulation of processes in temporal, spatial and subject aspects.

Functions and tasks as a design element is derived from the open property of companies/organizations. It comprises the description of the tasks which stem from customer needs as well as the division of tasks as specific work orders, expectations towards functions, jobs, etc. Consequently it is possible to develop processes in order to install and foster changes in organizations.

The decision making system describes where, how, to whom, on which level, at which spot and by means of which tools decisions are made. It furthermore describes which mechanisms, processes, rules etc. guide the decision processes.

The information system describes who receives or does not receive which information when, from whom and by which means. It also analyzes why this is so.

Amplifying and reduction systems of material and immaterial as well as formal and informal character are described through the reward and control system of an organization. As such it analyzes mechanisms and procedures which observe and guide human and technical behavior, results and processes. This includes amongst others remuneration structures and the unwritten rules of a company.

By means of the development and renewal system the flexibility as well as the performance and adaption capacities of an organization are maintained and increased. This can also revolve around a group of employees within the company which have the mandate to develop the company internally and externally. Generally, this can be subsumed under the term innovation management.

According to the model, feedback is of crucial importance for the survival of a system, i.e. of an organization that is confronted with turbulent environments. As systems are to be understood as open systems they rely on feedback loops in order to remain existent. The feedback consists of loops that have a guiding, stabilizing and renewing effect on the system. According to literature there are four types of feedback.

Quality feedbacks are reactions to the quality of the output. Usually, all types of quality management use quality feedback as a starting point of their methods.

Renewal feedbacks report reaction of the environment with regard to the reason for existing. This form of feedback is to analyze the demands of the environment (e.g. Development of new markets).

Responsibility feedbacks question the mission of the system. They refer to the long-term chances of survival of the system and its environment (earth-humanity-future-problem). In that regard the focus of this form of feedback is sustainability.

Awareness feedbacks contain information about basic “truths” – about humans, the way humans live together and transcendent values – and about absolute (“true”) values. In this context, the consequences for the system and the members of the system (e.g. through religious orientations) are reflected.

The OSTO System Model is, just like the St. Gallen Management Model and the Viable System Model, to be categorized into economic and sociological system theory. The difference from these rather production oriented models is the fact that the OSTO System Model is process oriented and assumes an open system which is guided by permanent feedback. In contrast to other models it analyzes systems independently from hierarchies and is not based on management ratios. It is also the only model which takes (system-) behavior into consideration. Additionally, conscious and unconscious goals and strategies are rendered visible and intended as well as unintended outputs are unveiled and taken into consideration.

The model assumes that the central transformational processes marked in the model take place on the inside of a complex organization. However, the concepts with regard to system and organization are not definitely pointed out in theory. On the part of system theory there is hardly any link to the modern theory of social systems with their core concepts of the observed observer and the autopoiesis. On the part of organizational theory, Karl E. Weick described the problem that the term organization leaves open in how far a special behavior of an involved person takes place at a certain place or refers to a certain place very early on. In the same manner it is not clear in how far behavior is controlled by an organization or contributes to the embodiment of an organization or if both or none of this is true. Gareth Morgan also alluded to the fact that organizations can be analyzed from different perspectives. Dependent upon the perspective the analysis yields pronouncedly different implications for the design, change, and the guiding- and leadership concepts.



</doc>
<doc id="59769241" url="https://en.wikipedia.org/wiki?curid=59769241" title="Performance effects">
Performance effects

Strategy researchers want to understand differences in firm performance. For example, what can explain performance differences between Toyota’s cars business and Samsung’s mobile phones business? Studies show that just three effects account for most performance differences between such businesses: the industry to which a business belongs (automotive industry vs electronics industry), the corporation it is part of (Toyota vs. Samsung), and the business itself.

Performance usually means financial performance, measured most often as return on assets (ROA) or less often as return on sales (ROS), return on invested capital (ROIC), or market share.

A performance effect is an observed difference in business performance. For example, it compares the performance of Toyota’s cars business and that of Samsung’s mobile phones business. A performance effect is "not" a causal effect. For example, it does not indicate what the performance of the mobile phone business would have been if Toyota instead of Samsung was the owner.

Performance effects occur at multiple level of analysis. 

Industry, corporate, business, and year effects are among the most investigated levels of analyses. An industry is a group of businesses that sell similar goods or services. For example, Toyota’s cars business belongs to the automotive industry and Samsung’s mobile phones business to the electronics industry. A corporation is the legal owner of the business. For example, Berkshire Hathaway owns many businesses including of clothing, building products, and insurance. Thus, a corporation can own more than one business. A business is then defined by what it does (i.e. industry) and by whom it is owned (i.e. corporation). Year refers to the year of performance.

An industry effect is the performance difference of businesses in an industry and those in other industries. A corporate effect is the performance difference of businesses of a corporation and those of other corporations. A business effect is the performance difference of a business and those of other businesses. A year effect is the performance difference of businesses in one year and those in another year.

Formally, we can write the performance (p) of a business in industry "i", corporation "c", and year "t" as:

Here "m" is the mean performance of all businesses across all years. I is the industry effect for industry "i" (the performance difference between industry "i" and the mean); C is the corporate effect for corporation "c" (the performance difference between corporation "c" and the mean); B is the business effect for a business in industry "i" and corporation "c" (the performance difference between that business and the mean); Y is the year effect for year "t" (the performance difference between year "t" and the mean); and e is an error term (the performance difference between a business and the mean that is not accounted for by industry, corporate, business, and year effects).

A meta-analysis finds that the strongest effects are business, then corporate, then industry, and then year. Figures 1 and 2 show the strength of each effect with effect sizes in variance and in standard deviation, respectively.

Other performance effects include CEO and geographical region or country. 

An effect size is a measure of the magnitude of performance differences.

A common measure is the variance. A finding of 36% for business effects means that the variance in business effects is 36% of the total variance in performance. Conversely, the variance in performance is for about one third related to differences between business with the other two thirds related to other effects (e.g. different industries, different corporations, different year, and random differences). An upside of the variance measure is that the effects sum to 100%. A downside is that the variance uses squared distances so that large effects are amplified and small effects are shrunk.

Another measure is the standard deviation, which is the square root of the variance. An upside of this measure is that the standard deviation relates to linear distances so effects are not similarly amplified or shrunk. For example, business effects are greater than year effects by about factor 45 when using variance and by about only factor 8 when using standard deviation. Relatedly, the standard deviation measure has the same unit of measurement as performance. For example, if performance is in dollars, then the standard deviation is also in dollars (the variance would be in dollars squared). A downside is that the effects measured in standard deviations do not sum to 100%.

An alternative measure is the sum of squares measure. It seeks to attribute squared performance difference to the different effects. Because the sum of squares measure does not account for degrees of freedom, it is sensitive to sample dimensions. For example, sampling more businesses in the same number of industries will change the ratio of sum of squares due to industry and sum of squares due to business.

Different methods are used to estimate effect sizes, including hierarchical linear model, or analysis of variance (ANOVA), or variance components analysis (VCA).

• Strategy
• Strategic management

(2018 Award Recipient of The Dan and Mary Lou Schendel Best Paper Prize)


</doc>
<doc id="31318089" url="https://en.wikipedia.org/wiki?curid=31318089" title="Business for Peace Foundation">
Business for Peace Foundation

Business for Peace (BfP) is a non-profit foundation based in Oslo, Norway. Each year, the foundation names up to seven Honourees who receive the Oslo Business for Peace Award, in recognition of their individual and outstanding businessworthy contribution to the building of trust, stability and peace. The Honourees are selected by an independent committee composed of winners of either the Nobel Peace Prize or Nobel Memorial Prize in Economic Sciences.

The Foundation works worldwide to promote a better understanding of how ethical and responsible business can contribute to building trust, stability and peace. Each year, the foundation arranges the Oslo Business for Peace Summit, which concludes with the presentation of the award to that year's Honourees.

Companies are increasingly seen to be prospering at the expense of the broader community, resulting in an adversarial relationship between business and society.
The Business for Peace Foundation was established to inspire business leaders and businesses to reconnect with society, to the mutual benefit of both. The Foundation works to demonstrate that business can be a force of mutual good, able to contribute significantly to the building of trust, stability and peace. The Foundation promotes the concept of “being businessworthy”, seeking to raise business practices from short-term win-lose dynamics to fulfilling longer-term business aims.

The foundation draws inspiration from the dictum:

Adam Smith advocated that a business should advance the prosperity and well-being of the communities where it was active. Subsequently, Smith's invisible hand has been used to defend laissez-faire economics that stand in contrast to the actual business philosophy he promoted in his seminal works "The Wealth of Nations" and "Theory of Moral Sentiments".

The award committee of the Business for Peace Foundation selects Honourees who each have demonstrated that it is possible for a business to enter into partnership with society, while remaining profitable and capable of longer-term growth. The goal of the foundation is to provide its Honourees with a platform from which to share their business wisdom with the world, hoping to inspire other business leaders to emulate their examples.

Kofi A. Annan has endorsed the efforts of the foundation, stating that "It is important to inspire and encourage businesspersons to be conscious of the role they can play as individuals to foster stability and peace. I think the idea behind the Oslo Business for Peace Award, and the potential impact it may have, is inspiring".

The Business for Peace Foundation works together with nominating partners that help search the world for candidates who embody the values described by the criteria for the Oslo Business for Peace Award.
Beginning in 2009, the foundation has entered into a formal collaboration with the International Chamber of Commerce, the largest and most representative business organization in the world. Its hundreds of thousands of member companies in 130 countries have interests spanning every sector of private enterprise. The foundation also works together with Principles for Responsible Investment, the United Nations Development Programme and the United Nations Global Compact, in searching the world for eligible candidates to the award.
The honourees named by the foundation are also able to nominate candidates for the award in subsequent years.

Oddvar Hesjedal serves as secretary of nominations, guiding the nomination process through the year and assisting the award committee in its work.

The Oslo Business for Peace Award aims to highlight ethical and responsible business practices, and the commitment of business leaders as individuals towards creating sustainable long-term success of benefit to their businesses, society and themselves. The independent Award Committee evaluates the Nominees according to three criteria established by the Business for Peace Foundation.

To be considered Businessworthy, and a candidate for the Award, the Nominees must be:


Being businessworthy is to apply your business energy ethically and responsibly with the purpose of creating economic value that also creates value for society. Being businessworthy embodies tested and true ethical and responsible principles for longer-term business interactions that build trust between the parties involved.
Business deals are sealed with a handshake, and lasting business relationships are created when handshakes are made in good faith between partners intent on creating mutual benefits for one another.
The foundation has coined the word 'businessworthy' to describe the qualities it looks for when searching the world for worthy nominees to the award.

In the spirit of corporate social responsibility, ethically aware businesses build win-win enduring relationships, forging a union between not only the business partners, but also with the societies which are touched by their business activity.
The Business for Peace Foundation seeks to demonstrate that there are legion examples where businesses work as a force of good together with society, achieving results that build trust and contribute to stability and peace. It is the ambition of the foundation that these examples will inform decision makers worldwide, inspiring them to redirect their business activities in accordance with businessworthy principles.

In the January–February 2011 issue of Harvard Business Review, professor Michael E. Porter and Mark R. Cramer proposed what they called Creating Shared Value, while declaring that "Companies must take the lead in bringing business and society back together". Their notion of shared value corresponds well with the criteria of businessworthiness informing the Business for Peace Foundation's search for Honourees.

Following the nomination process, the Honourees are selected by an independent committee composed of winners of either the Nobel Peace Prize or Nobel Memorial Prize in Economic Sciences.
Present members of the committee are businesswoman Ouided Bouchamaoui, peace activist Leymah Gbowee, professor Finn Kydland and professor Eric S. Maskin. Previous members include human rights advocate and lawyer Shirin Ebadi (2014 – 2018), economist Michael Spence (2009 – 2017), professor Muhammad Yunus (2009 – 2013) and professor Wangari Maathai (2009 – 2011).

The statue "the Just Man" has been created by the artist Bruce Naigles, and is presented to the Business for Peace Honourees during the formal award ceremony at Oslo City Hall.
Honourees also receive a diploma noting their exemplary business wisdom.










Starting in May 2007, the Oslo Business for Peace Summit has been held annually in the Oslo City Hall. The Summit examines the relationship between ethical and responsible business practices and the promotion of trust, stability and peace. Highly respected statesmen, businesspersons, academics and business thinkers have participated at the Summits through the years.

Summit Themes:

2007 - Peace and Stability through Trade

2008 - Globalisation: the good, the bad and the ugly

2009 - The World in Recession, a call for a more ethically aware capitalism?
At the 2009 Summit, the Natural Resource Charter was presented.

2010 - New Times, the potential of business to contribute to stability and peace

2011 - Business as an Instrument of Peace - Research Symposium in Oslo, in collaboration with the USIP, the Norwegian Ministry of Foreign Affairs and the Peace Research Institute Oslo

2012 - The Essences of Trust in Business Today

2013 - Business in Fragile Environments

2014 - The New Imperative: Creating Shared Value

2015 - How Sustainability can Drive Value Creation

2016 - The Opportunities for Business to Act as a Problem Solver in Society

2017 - Brundtland +30: Breakthrough Ideas for Futureproofing the Global Economy

2018 - Building Trust: Accelerating Climate Leadership

2019 - Navigating in a World of Imbalance

A selection of speakers who have contributed to the Summits: Kjell Magne Bondevik, Alexandra, Countess of Frederiksborg, Roberto Servitje (Grupo Bimbo), Guy F. Tozzoli (World Trade Center), Vijay Kalantri (All India Association of Industries), Jan Egeland, Bob Geldof, Nabil Shaath, Anders Källström, Khater Massaad, Jinghai Zheng, John Lervik, Margaret Beckett, Erik Solheim, Festus G. Mogae, Kandeh Yumkella, Jeremy Rifkin, Anthony J. Venables, Gobind Nankani, Petter Nore, Long Yongtu, Timothy L. Fort, Patricia Aburdene, Juan Carlos Echeverry, Børge Brende, Henrik Syse and Erna Solberg.



</doc>
<doc id="60280137" url="https://en.wikipedia.org/wiki?curid=60280137" title="FEBC international">
FEBC international

FEBC International is a firm specializing in procurement for hotels, palaces and high-end residential units. The company services clients in Europe, Middle East, Africa and the Far East. Some of the firm's clients include Hilton Worldwide, Marriott International Inc, and Radisson Hotel Group.

FEBC offers FF&E, OS&E procurement to hotels worldwide. It has a team of 50+ employees who speak multiple languages. The company has over 25 years of experience in the hospitality sector completing projects in over 25 countries worldwide.

The company obtained ISO certification in 2015 and is the sole provider of ISO certified hospitality procurement services worldwide.


</doc>
<doc id="33616691" url="https://en.wikipedia.org/wiki?curid=33616691" title="Fayolism">
Fayolism

Fayolism was a theory of management that analyzed and synthesized the role of management in organizations, developed around 1900 by the French management theorist Henri Fayol (1841–1925). It was through Fayol's work as a philosopher of administration that he contributed most widely to the theory and practice of organizational management.
Fayol believed by focusing on managerial practices he could minimize misunderstandings and increase efficiency in organizations. He enlightened managers on how to accomplish their managerial duties, and the practices in which they should engage. In his book "General and Industrial Management" (published in French in 1916, then published in English in 1949), Fayol outlined his theory of general management, which he believed could be applied to the administration of myriad industries. His concern was with the administrative apparatus (or functions of administration), and to that end he presented his "administrative theory", that is, principles and elements of management.

His theories and ideas were ideally a result of his environment—a post revolutionized France with an emerging republic bourgeois. A bourgeois himself, he believed in controlling workers to achieve greater productivity over all other managerial considerations. However, through reading "General and Industrial Management," it is apparent that Fayol advocated a flexible approach to management, one he believed could be applied to any circumstance whether in the home, the workplace, or within the state. He stressed the importance and the practice of forecasting and planning in order to apply these ideas and techniques, which demonstrated his ability and emphasis in being able to adapt to any sort of situation. In "General and Industrial Management" he outlines an agenda whereby, under an accepted theory of management, every citizen is exposed and taught some form of management education and allowed to exercise management abilities first at school and later on in the workplace.

Fayol has been regarded by many as the father of the modern operational management theory, and his ideas have become a fundamental part of modern management concepts. Fayol is often compared to Frederick Winslow Taylor who developed Scientific Management. Taylor's Scientific Management deals with the efficient organization of production in the context of a competitive enterprise that is concerned with controlling its production costs. Taylor's system of scientific management is the cornerstone of classical theory. Fayol was also a classical theorist, and referred to Taylor in his writing and considered him a visionary and pioneer in the management of organizations.

However, Fayol differed from Taylor in his focus. Taylor's main focus was on the task, whereas Fayol was more concerned with management. Another difference between the two theorists is their treatment of workers. Fayol appears to have slightly more respect for the worker than Taylor had, as evidenced by Fayol's proclamation that workers may indeed be motivated by more than just money. Fayol also argued for equity in the treatment of workers.

According to Claude George (1968), a primary difference between Fayol and Taylor was that Taylor viewed management processes from the bottom up, while Fayol viewed it from the top down. In Fayol's book "General and Industrial Management," Fayol wrote that He suggests that Taylor has staff analysts and advisors working with individuals at lower levels of the organization to identify the ways to improve efficiency. According to Fayol, the approach results in a "negation of the principle of unity of command". Fayol criticized Taylor’s functional management in this way. Those eight, Fayol said, were 
This, he said, was an unworkable situation, and that Taylor must have somehow reconciled the dichotomy in some way not described in Taylor's works.

Fayol's desire for teaching a generalized theory of management stemmed from the belief that each individual of an organization at one point or another takes on duties that involve managerial decisions. Unlike Taylor, however, who believed management activity was the exclusive duty of an organizations dominant class. Fayol's approach was more in sync with his idea of Authority, which stated, "...that the right to give orders should not be considered without the acceptance and understanding of responsibility."

Noted as one of the early fathers of the "Human Relations" movements, Fayol expressed ideas and practices different from Taylor, in that they showed flexibility and adaptation, and stressed the importance of interpersonal interaction among employees.

During the early 20th century, Fayol developed 14 principles of management to help managers manage their affairs more effectively. Organizations in technologically advanced countries interpret these principles quite differently from the way they were interpreted during Fayol's time as well. These differences in interpretation are in part a result of the cultural challenges managers face when implementing this framework. The fourteen principles are: 
Within his theory, Fayol outlined five elements of management that depict the kinds of behaviors managers should engage in so that the goals and objectives of an organization are effectively met. The five elements of management are:


Fayol believed that animosity and unease within the workplace occurred among employees in different departments. Many of these "misunderstandings" were thought to be caused by improper communication, mainly through letters (or in present-day emails). Among scholars of organizational communication and psychology, letters were perceived to induce or solidify a hierarchical structure within the organization. Through this type of vertical communication, many individuals gained a false feeling of importance. Furthermore, it gave way to selfish thinking and eventual conflict among employees in the workplace.

This concept was expressed in Fayol's book, "General and Industrial Management", by stating," in some firms... employees in neighboring departments with numerous points of contact, or even employees within a department, who could quite easily meet, communicate with each other in writing... there is to be observed a certain amount of animosity prevailing between different departments or different employees within a department. The system of written communication usually brings this result. There is a way of putting an end to this deplorable system ... and that is to forbid all communication in writing which could easily and advantageously be replaced by verbal ones."

Fayol believed that managerial practices were key to predictability and efficiency in organizations. The Administrative theory views communication as a necessary ingredient to successful management and many of Fayol's practices are still alive in today's workplace. The elements and principles of management can be found in modern organizations in several ways: as accepted practices in some industries, as revamped versions of the original principles or elements, or as remnants of the organization's history to which alternative practices and philosophies are being offered. The U.S. military is a prime example of an organization that has continued to use these principles.



</doc>
<doc id="60786452" url="https://en.wikipedia.org/wiki?curid=60786452" title="Betahaus">
Betahaus

Betahaus is a coworking space in Berlin and was started in January 2009 by the six founders Tonia Welter, Gregor Scheppan, Stephan Bielefeldt, Madeleine von Mohl, Max von der Ahé and Christoph Fahle, the official opening in Berlin took place in April 2009. Thus, the Betahaus was a pioneer and the first under similar facilities in Berlin.

Betahaus has locations in Sofia, Hamburg and Barcelona. Well-known start-ups that started here are, for example, Coffee Circle, Ezeep, GoEuro (Omio), car2go and Clue.

At the end of 2018, Betahaus moved from Prinzessinenstrasse in Berlin's Kreuzberg district to the old taz building in Rudi-Dutschke-Strasse in Berlin. The locations in Hamburg and Cologne had to file for bankruptcy. While the Cologne location was closed, the Hamburg location could be saved.

The company generates 40 percent of its turnover through the workspaces it offers. 40 percent are taken with events and conferences and 20 percent with a public Café. An example of an event is the "Female-Founders-Breakfast", to which former minister for economy affairs Brigitte Zypries invited in 2014. In 2009, the Yes Men presented their film The Yes Men standing in a shopping cart in Betahaus as part of Berlinale.

Official Webpage


</doc>
<doc id="1725756" url="https://en.wikipedia.org/wiki?curid=1725756" title="Business directory">
Business directory

A business directory is a website or printed listing of information which lists businesses within niche based categories. Businesses can be categorized by niche, location, activity, or size. Business may be compiled either manually or through an automated online search software. Online yellow pages are a type of business directory, as is the traditional phone book.
The details provided in a business directory may vary. They may include the business name, addresses, telephone numbers, location, contact information, type of service or products the business provides, the number of employees, the served region and any professional associations. 

Some directories include a section for user reviews, comments, and feedback. Business directories in the past would take a printed format but have recently been upgraded to websites due to the advent of the internet.

Many business directories offer complimentary listings in addition to the premium options. There are many business directories and some of these have moved over to the internet and away from printed format. Whilst not being search engines, business directories often have a search function, enabling users to search businesses by Zip Code, country, state, area or city.

Business directories can be in either hard copy or in digital format. Ease of use and distribution means that many trade directories have a digital version.



</doc>
<doc id="509995" url="https://en.wikipedia.org/wiki?curid=509995" title="Abstract and concrete">
Abstract and concrete

Abstract and concrete are classifications that denote whether the object that a term describes has physical referents. Abstract objects have no physical referents, whereas concrete objects do. They are most commonly used in philosophy and semantics. Abstract objects are sometimes called abstracta (sing. abstractum) and concrete objects are sometimes called "concreta" (sing. "concretum"). An abstract object is an object that does not exist at any particular time or place, but rather exists as a type of thing—i.e., an idea, or abstraction. The term "abstract object" is said to have been coined by Willard Van Orman Quine. The study of abstract objects is called abstract object theory.

The type–token distinction identifies physical objects that are tokens of a particular type of thing. The "type" of which it is a part is in itself an abstract object. The abstract-concrete distinction is often introduced and initially understood in terms of paradigmatic examples of objects of each kind:

Abstract objects have often garnered the interest of philosophers because they raise problems for popular theories. In ontology, abstract objects are considered problematic for physicalism and some forms of naturalism. Historically, the most important ontological dispute about abstract objects has been the problem of universals. In epistemology, abstract objects are considered problematic for empiricism. If abstracta lack causal powers or spatial location, how do we know about them? It is hard to say how they can affect our sensory experiences, and yet we seem to agree on a wide range of claims about them. 

Some, such as Edward Zalta and arguably, Plato in his Theory of Forms, have held that abstract objects constitute the defining subject matter of metaphysics or philosophical inquiry more broadly. To the extent that philosophy is independent of empirical research, and to the extent that empirical questions do not inform questions about abstracta, philosophy would seem especially suited to answering these latter questions. 

In modern philosophy, the distinction between abstract and concrete was explored by Immanuel Kant and G. W. F. Hegel.

Gottlob Frege said that abstract objects, such as numbers, were members of a third realm, different from the external world or from internal consciousness. 

Another popular proposal for drawing the abstract-concrete distinction contends that an object is abstract if it lacks any causal powers. A causal power has the ability to affect something causally. Thus, the empty set is abstract because it cannot act on other objects. One problem for this view is that it is not clear exactly what it is to have a causal power. For a more detailed exploration of the abstract-concrete distinction, follow the link below to the "Stanford Encyclopedia" article.

Recently, there has been some philosophical interest in the development of a third category of objects known as the quasi-abstract. Quasi-abstract objects have drawn particular attention in the area of social ontology and documentality. Some argue that the over-adherence to the platonist duality of the concrete and the abstract has led to a large category of social objects having been overlooked or rejected as nonexisting because they exhibit characteristics that the traditional duality between concrete and abstract regards as incompatible. Specially, the ability to have temporal location, but not spatial location, and have causal agency (if only by acting through representatives). These characteristics are exhibited by a number of social objects, including states of the international legal system.

Jean Piaget uses the terms "concrete" and "formal" to describe two different types of learning. Concrete thinking involves facts and descriptions about everyday, tangible objects, while abstract (formal operational) thinking involves a mental process.


</doc>
<doc id="25200737" url="https://en.wikipedia.org/wiki?curid=25200737" title="Knowledge arena">
Knowledge arena

A knowledge arena is a virtual space where individuals can manipulate concepts and relationships to form a concept map. Individuals using a computer with appropriate software can represent concepts and the relationships between concepts in a node-relationship-node formalism. The process of thinking about the concepts and making associations between them has been called "off-loading" by McAleese.

The concept map is a form of a semantic network or semantic graph. It is formally based on graph theory. In the concept map, concepts are represented by nodes. The relationship between nodes are represented by "typed links" or "edges". (See Graph theory.) In creating a map or graphic representation of what is known an individual intentionally interacts with the graphical interface or map and through a reflective process adds nodes (concepts) and /or adds relationships (edges or typed links) or modifies existing node-relationship-node instances. It is likely that the process of engaging with concepts and relationships between concepts brings about the creation of understandings as well as making the understandings explicit.

Many different claims have been made for the utility of the concept map. The interactive and reflective nature of map creation is highlighted by the use of the description Knowledge Arena. Although maps may represent what an individual knows at a point in time; it is likely that by interacting with the concepts and relationships in the knowledge arena individual continues to create and modify what that individual "knows".

See also 


</doc>
<doc id="17306829" url="https://en.wikipedia.org/wiki?curid=17306829" title="Conceptual necessity">
Conceptual necessity

Conceptual necessity is a property of the certainty with which a state of affairs, as presented by a certain description, occurs: it occurs by conceptual necessity if and only if it occurs just by virtue of the meaning of the description. If someone is a bachelor, for instance, then he is bound to be unmarried by conceptual necessity, because the meaning of the word "bachelor" determines that he is.

Alternatively, there is metaphysical necessity, which is a certainty determined, not by the meaning of a description, but instead by facts in the world described.

Historically, Baruch Spinoza was a subscriber to this belief.



</doc>
<doc id="58267" url="https://en.wikipedia.org/wiki?curid=58267" title="Conceptual schema">
Conceptual schema

A 'conceptual schema' is a high-level description of a business's informational needs. It typically includes only the main concepts and the main relationships among them. Typically this is a first-cut model, with insufficient detail to build an actual database. This level describes the structure of the whole database for a group of users. The conceptual model is also known as the data model that can be used to describe the conceptual schema when a database system is implemented. It hides the internal details of physical storage and targets on describing entities, datatype, relationships and constraints.

A conceptual schema or conceptual data model is a map of concepts and their relationships used for databases. This describes the semantics of an organization and represents a series of assertions about its nature. Specifically, it describes the things of significance to an organization ("entity classes"), about which it is inclined to collect information, and characteristics of ("attributes") and associations between pairs of those things of significance ("relationships").

Because a conceptual schema represents the semantics of an organization, and not a database design, it may exist on various levels of abstraction. The original ANSI four-schema architecture began with the set of "external schema" that each represent one person's view of the world around him or her. These are consolidated into a single "conceptual schema" that is the superset of all of those external views. A data model can be as concrete as each person's perspective, but this tends to make it inflexible. If that person's world changes, the model must change. Conceptual data models take a more abstract perspective, identifying the fundamental things, of which the things an individual deals with are just examples.

The model does allow for what is called inheritance in object oriented terms. The set of instances of an entity class may be subdivided into entity classes in their own right. Thus, each instance of a "sub-type" entity class is also an instance of the entity class's "super-type". Each instance of the super-type entity class, then is also an instance of one of the sub-type entity classes.

Super-type/sub-type relationships may be "exclusive" or not. A methodology may require that each instance of a super-type may "only" be an instance of "one" sub-type. Similarly, a super-type/sub-type relationship may be "exhaustive" or not. It is exhaustive if the methodology requires that each instance of a super-type "must be" an instance of a sub-type. A sub-type named other is often necessary.


A data structure diagram (DSD) is a data model or diagram used to describe conceptual data models by providing graphical notations which document entities and their relationships, and the constraints that bind them.





</doc>
<doc id="4849201" url="https://en.wikipedia.org/wiki?curid=4849201" title="Object of the mind">
Object of the mind

An object of the mind is an object that exists in the imagination, but which, in the real world, can only be represented or modeled. Some such objects are abstractions, literary concepts, or fictional scenarios.

Closely related are intentional objects, which are what thoughts and feelings are about, even if they are not about anything real (such as thoughts 
about unicorns, or feelings of apprehension about a dental appointment which is subsequently cancelled). However, intentional objects may coincide with real objects (as in thoughts about horses, or a feeling of regret about a missed appointment).

Mathematics and geometry describe abstract objects that sometimes correspond to familiar shapes, and sometimes do not. Circles, triangles, rectangles, and so forth describe two-dimensional shapes that are often found in the real world. However, mathematical formulas do not describe individual physical circles, triangles, or rectangles. They describe ideal shapes that are objects of the mind. The incredible precision of mathematical expression permits a vast applicability of mental abstractions to real life situations.

Many more mathematical formulas describe shapes that are unfamiliar, or do not necessarily correspond to objects in the real world. For example, the Klein bottle is a one-sided, sealed surface with no inside or outside (in other words, it is the three-dimensional equivalent of the Möbius strip). Such objects can be represented by twisting and cutting or taping pieces of paper together, as well as by computer simulations. To hold them in the imagination, abstractions such as extra or fewer dimensions are necessary.

If-then arguments posit logical sequences that sometimes include objects of the mind. For example, a counterfactual argument proposes a hypothetical or subjunctive possibility which "could" or "would" be true, but "might not" be false. Conditional sequences involving subjunctives use intensional language, which is studied by modal logic, whereas classical logic studies the extensional language of necessary and sufficient conditions.

In general, a logical antecedent is a sufficient condition, and a logical consequent is a necessary condition(or the contingency) in a logical conditional. But logical conditionals accounting only for necessity and sufficiency do not always reflect every day if-then reasoning, and for this reason they are sometimes known as material conditionals. In contrast, indicative conditionals, sometimes known as non-material conditionals, attempt to describe if-then reasoning involving hypotheticals, fictions, or counterfactuals.

Truth tables for if-then statements identify four unique combinations of premises and conclusions: true premises and true conclusions; false premises and true conclusions; true premises and false conclusions; false premises and false conclusions. Strict conditionals assign a positive truth-value to every case except the case of a true premise and a false conclusion. This is sometimes regarded as counterintuitive, but makes more sense when false conditions are understood as objects of the mind.

A false antecedent is a premise known to be false, fictional, imaginary, or unnecessary. In a conditional sequence, a false antecedent may be the basis for any consequence, true or false.

The subjects of literature are sometimes false antecedents. For example, the contents of false documents, the origins of stand-alone phenomena, or the implications of loaded words. Also, artificial sources, personalities, events, and histories. False antecedents are sometimes referred to as "nothing", or "nonexistent", whereas nonexistent referents are not referred to.

Art and acting often portray scenarios without any antecedent except an artist's imagination. For example, mythical heroes, legendary creatures, gods, and goddesses.

A false consequent, in contrast, is a conclusion known to be false, fictional, imaginary, or insufficient. In a conditional statement, a fictional conclusion is known as a non sequitur, which literally means "out of sequence". A conclusion that is out of sequence is not contingent on any premises that precede it, and it does not follow from them, so such a sequence is not conditional. A conditional sequence is a connected series of statements. A false consequent cannot follow from true premises in a connected sequence. But, on the other hand, a false consequent can follow from a false antecedent.

As an example, the name of a team, a genre, or a nation is a collective term applied ex post facto to a group of distinct individuals. None of the individuals on a sports team is the team itself, nor is any musical chord a genre, nor any person America. The name is an identity for a collection that is connected by consensus or reference, but not by sequence. A different name could equally follow, but it would have different social or political significance.

In philosophy, mind-body dualism is the doctrine that mental activities exist apart from the physical body, notably posited by René Descartes in "Meditations on First Philosophy".

Many objects in fiction follow the example of false antecedents or false consequents. For example, "The Lord of the Rings" by J.R.R. Tolkien is based on an imaginary book. In the "Appendices" to "The Lord of the Rings", Tolkien's characters name the "Red Book of Westmarch" as the source material for "The Lord of the Rings", which they describe as a translation. But the "Red Book of Westmarch" is a fictional document that chronicles events in an imaginary world. One might imagine a different translation, by another author.

Social reality is composed of many standards and inventions that facilitate communication, but which are ultimately objects of the mind. For example, money is an object of the mind which currency represents. Similarly, languages signify ideas and thoughts.

Objects of the mind are frequently involved in the roles that people play. For example, acting is a profession which predicates real jobs on fictional premises. Charades is a game people play by guessing imaginary objects from short play-acts.

Imaginary personalities and histories are sometimes invented to enhance the verisimilitude of fictional universes, and/or the immersion of role-playing games. In the sense that they exist independently of extant personalities and histories, they are believed to be fictional characters and fictional time frames.

Science fiction is abundant with future times, alternate times, and past times that are objects of the mind. For example, in the novel "Nineteen Eighty-Four" by George Orwell, the number 1984 represented a year that had not yet passed.

Calendar dates also represent objects of the mind, specifically, past and future times. In "", which was released in 1986, the narration opens with the statement, "It is the year 2005." In 1986, that statement was futuristic. During the year 2005, that reference to the year 2005 was factual. Now, "The Transformers: The Movie" is retro-futuristic. The number 2005 did not change, but the object of the mind that it represents did change.

Deliberate invention also may reference an object of the mind. The intentional invention of fiction for the purpose of deception is usually referred to as lying, in contrast to invention for entertainment or art. Invention is also often applied to problem solving. In this sense the physical invention of materials is associated with the mental invention of fictions.

Convenient fictions also occur in science.

The theoretical posits of one era's scientific theories may be demoted to mere objects of the mind by subsequent discoveries: some standard examples include phlogiston and ptolemaic epicycles.

This raises questions, in the debate between scientific realism and instrumentalism about the status of current posits, such as black holes and quarks. Are they still merely intentional, even if the theory is correct?

The situation is further complicated by the existence in scientific practice of entities which are explicitly held not to be real, but which nonetheless serve a purpose—convenient fictions. Examples include field lines, centers of gravity, and electron holes in semiconductor theory.

A reference that names an imaginary source is in some sense also a self-reference. A self-reference automatically makes a comment about itself. Premises that name themselves as premises are premises by self-reference; conclusions that name themselves as conclusions are conclusions by self-reference.

In their respective imaginary worlds the "Necronomicon", "The Hitchhiker's Guide to the Galaxy", and the "Red Book of Westmarch" are realities, but only because they are referred to as real. Authors use this technique to invite readers to pretend or to make-believe that their imaginary world is real. In the sense that the stories that quote these books are true, the quoted books exist; in the sense that the stories are fiction, the quoted books do not exist.

Austrian philosopher Alexius Meinong (1853–1920) advanced nonexistent objects in the 19th and 20th century within a “theory of objects”. He was interested in intentional states which are directed at nonexistent objects. Starting with the “principle of intentionality”, mental phenomena are intentionally directed towards an object. People may imagine, desire or fear something that does not exist. Other philosophers concluded that intentionality is not a real relation and therefore does not require the existence of an object, while Meinong concluded there is an object for every mental state whatsoever—if not an existent then at least a nonexistent one.




</doc>
<doc id="28547570" url="https://en.wikipedia.org/wiki?curid=28547570" title="Terminology model">
Terminology model

A terminology model is a refinement of a concept system. Within a terminology model the concepts (object types) of a specific problem or subject area are defined by subject matter experts in terms of concept (object type) definitions and definitions of subordinated concepts or characteristics (properties). Besides object types, the terminology model allows defining hierarchical classifications, definitions for object type and property behavior and definition of casual relations.

The terminology model is a means for subject matter experts to express their knowledge about the subject in subject specific terms. Since the terminology model is structured rather similar to an object-oriented database schema, is can be transformed without loss of information into an object-oriented database schema. Thus, the terminology model is a method for problem analysis on the one side and a mean of defining database schema on the other side.

Several terminology models have been developed and published in the field of statistics:




</doc>
<doc id="599917" url="https://en.wikipedia.org/wiki?curid=599917" title="Mental image">
Mental image

A mental image or mental picture is an experience that, on most occasions, significantly resembles the experience of perceiving some object, event, or scene, but occurs when the relevant object, event, or scene is not actually present to the senses. There are sometimes episodes, particularly on falling asleep (hypnagogic imagery) and waking up (hypnopompic), when the mental imagery, being of a rapid, phantasmagoric and involuntary character, defies perception, presenting a kaleidoscopic field, in which no distinct object can be discerned. Mental imagery can sometimes produce the same effects as would be produced by the behavior or experience imagined.

The nature of these experiences, what makes them possible, and their function (if any) have long been subjects of research and controversy in philosophy, psychology, cognitive science, and, more recently, neuroscience. As contemporary researchers use the expression, mental images or imagery can comprise information from any source of sensory input; one may experience auditory images, olfactory images, and so forth. However, the majority of philosophical and scientific investigations of the topic focus upon "visual" mental imagery. It has sometimes been assumed that, like humans, some types of animals are capable of experiencing mental images. Due to the fundamentally introspective nature of the phenomenon, there is little to no evidence either for or against this view.

Philosophers such as George Berkeley and David Hume, and early experimental psychologists such as Wilhelm Wundt and William James, understood ideas in general to be mental images. Today it is very widely believed that much imagery functions as mental representations (or mental models), playing an important role in memory and thinking. William Brant (2013, p. 12) traces the scientific use of the phrase "mental images" back to John Tyndall's 1870 speech called the "Scientific Use of the Imagination". Some have gone so far as to suggest that images are best understood to be, by definition, a form of inner, mental or neural representation; in the case of hypnagogic and hypnapompic imagery, it is not representational at all. Others reject the view that the image experience may be identical with (or directly caused by) any such representation in the mind or the brain, but do not take account of the non-representational forms of imagery.

In 2010, IBM applied for a patent on a method to extract mental images of human faces from the human brain. It uses a feedback loop based on brain measurements of the fusiform face area in the brain that activates proportionate with degree of facial recognition. It was issued in 2015.

The notion of a "mind's eye" goes back at least to Cicero's reference to mentis oculi during his discussion of the orator's appropriate use of simile.

In this discussion, Cicero observed that allusions to "the Syrtis of his patrimony" and "the Charybdis of his possessions" involved similes that were "too far-fetched"; and he advised the orator to, instead, just speak of "the rock" and "the gulf" (respectively)—on the grounds that "the eyes of the mind are more easily directed to those objects which we have seen, than to those which we have only heard".

The concept of "the mind's eye" first appeared in English in Chaucer's (c. 1387) Man of Law's Tale in his "Canterbury Tales", where he tells us that one of the three men dwelling in a castle was blind, and could only see with "the eyes of his mind"; namely, those eyes "with which all men see after they have become blind". The phrase remained rarely used and the OED incorrectly ascribes it to Shakespeare, as the first time the literally introspective phrase ‘the mind's eye’ is used in English was in Hamlet. As an example of introspection, it demonstrates that the internal life of the mind rarely came into focus in literature until the introspective realism movement in the 19th century.

The biological foundation of the mind's eye is not fully understood. Studies using fMRI have shown that the lateral geniculate nucleus and the V1 area of the visual cortex are activated during mental imagery tasks. Ratey writes:
The visual pathway is not a one-way street. Higher areas of the brain can also send visual input back to neurons in lower areas of the visual cortex. [...] As humans, we have the ability to see with the mind's eye – to have a perceptual experience in the absence of visual input. For example, PET scans have shown that when subjects, seated in a room, imagine they are at their front door starting to walk either to the left or right, activation begins in the visual association cortex, the parietal cortex, and the prefrontal cortex - all higher cognitive processing centers of the brain.

The rudiments of a biological basis for the mind's eye is found in the deeper portions of the brain below the neocortex, or where the center of perception exists. The thalamus has been found to be discrete to other components in that it processes all forms of perceptional data relayed from both lower and higher components of the brain. Damage to this component can produce permanent perceptual damage, however when damage is inflicted upon the cerebral cortex, the brain adapts to neuroplasticity to amend any occlusions for perception. It can be thought that the neocortex is a sophisticated memory storage warehouse in which data received as an input from sensory systems are compartmentalized via the cerebral cortex. This would essentially allow for shapes to be identified, although given the lack of filtering input produced internally, one may as a consequence, hallucinate - essentially seeing something that isn't received as an input externally but rather internal (i.e. an error in the filtering of segmented sensory data from the cerebral cortex may result in one seeing, feeling, hearing or experiencing something that is inconsistent with reality).

Not all people have the same internal perceptual ability. For many, when the eyes are closed, the perception of darkness prevails. However, some people are able to perceive colorful, dynamic imagery. The use of hallucinogenic drugs increases the subject's ability to consciously access visual (and auditory, and other sense) percepts.

Furthermore, the pineal gland is a hypothetical candidate for producing a mind's eye; Rick Strassman and others have postulated that during near-death experiences (NDEs) and dreaming, the gland might secrete a hallucinogenic chemical "N","N"-Dimethyltryptamine (DMT) to produce internal visuals when external sensory data is occluded. However, this hypothesis has yet to be fully supported with neurochemical evidence and plausible mechanism for DMT production.

The hypothesized condition where a person lacks a mind's eye is called aphantasia. The term was first suggested in a 2015 study.

Common examples of mental images include daydreaming and the mental visualization that occurs while reading a book. Another is of the pictures summoned by athletes during training or before a competition, outlining each step they will take to accomplish their goal. When a musician hears a song, he or she can sometimes "see" the song notes in their head, as well as hear them with all their tonal qualities. This is considered different from an after-effect, such as an afterimage. Calling up an image in our minds can be a voluntary act, so it can be characterized as being under various degrees of conscious control.

According to psychologist and cognitive scientist Steven Pinker, our experiences of the world are represented in our minds as mental images. These mental images can then be associated and compared with others, and can be used to synthesize completely new images. In this view, mental images allow us to form useful theories of how the world works by formulating likely sequences of mental images in our heads without having to directly experience that outcome. Whether other creatures have this capability is debatable.

There are several theories as to how mental images are formed in the mind. These include the dual-code theory, the propositional theory, and the functional-equivalency hypothesis. The dual-code theory, created by Allan Paivio in 1971, is the theory that we use two separate codes to represent information in our brains: image codes and verbal codes. Image codes are things like thinking of a picture of a dog when you are thinking of a dog, whereas a verbal code would be to think of the word "dog". Another example is the difference between thinking of abstract words such as "justice" or "love" and thinking of concrete words like "elephant" or "chair." When abstract words are thought of, it is easier to think of them in terms of verbal codes—finding words that define them or describe them. With concrete words, it is often easier to use image codes and bring up a picture of a "human" or "chair" in your mind rather than words associated or descriptive of them.

The propositional theory involves storing images in the form of a generic propositional code that stores the meaning of the concept not the image itself. The propositional codes can either be descriptive of the image or symbolic. They are then transferred back into verbal and visual code to form the mental image.

The functional-equivalency hypothesis is that mental images are "internal representations" that work in the same way as the actual perception of physical objects. In other words, the picture of a dog brought to mind when the word "dog" is read is interpreted in the same way as if the person looking at an actual dog before them.

Research has occurred to designate a specific neural correlate of imagery; however, studies show a multitude of results. Most studies published before 2001 suggest neural correlates of visual imagery occur in Brodmann area 17. Auditory performance imagery have been observed in the premotor areas, precunes, and medial Brodmann area 40. Auditory imagery in general occurs across participants in the temporal voice area (TVA), which allows top-down imaging manipulations, processing, and storage of audition functions. Olfactory imagery research shows activation in the anterior piriform cortex and the posterior piriform cortex; experts in olfactory imagery have larger gray matter associated to olfactory areas. Tactile imagery is found to occur in the dorsolateral prefrontal area, inferior frontal gyrus, frontal gyrus, insula, precentral gyrus, and the medial frontal gyrus with basal ganglia activation in the ventral posteriomedial nucleus and putamen (hemisphere activation corresponds to the location of the imagined tactile stimulus). Research in gustatory imagery reveals activation in the anterior insular cortex, frontal operculum, and prefrontal cortex. Novices of a specific form of mental imagery show less gray matter than experts of mental imagery congruent to that form. A meta-analysis of neuroimagery studies revealed significant activation of the bilateral dorsal parietal, interior insula, and left inferior frontal regions of the brain.

Imagery has been thought to cooccur with perception; however, participants with damaged sense-modality receptors can sometimes perform imagery of said modality receptors. Neuroscience with imagery has been used to communicate with seemingly unconscious individuals through fMRI activation of different neural correlates of imagery, demanding further study into low quality consciousness. A study on one patient with one occipital lobe removed found the horizontal area of their visual mental image was reduced.

Visual imagery is the ability to create mental representations of things, people, and places that are absent from an individual’s visual field. This ability is crucial to problem-solving tasks, memory, and spatial reasoning. Neuroscientists have found that imagery and perception share many of the same neural substrates, or areas of the brain that function similarly during both imagery and perception, such as the visual cortex and higher visual areas. Kosslyn and colleagues (1999) showed that the early visual cortex, Area 17 and Area 18/19, is activated during visual imagery. They found that inhibition of these areas through repetitive transcranial magnetic stimulation (rTMS) resulted in impaired visual perception and imagery. Furthermore, research conducted with lesioned patients has revealed that visual imagery and visual perception have the same representational organization. This has been concluded from patients in which impaired perception also experience visual imagery deficits at the same level of the mental representation.

Behrmann and colleagues (1992) describe a patient C.K., who provided evidence challenging the view that visual imagery and visual perception rely on the same representational system. C.K. was a 33-year old man with visual object agnosia acquired after a vehicular accident. This deficit prevented him from being able to recognize objects and copy objects fluidly. Surprisingly, his ability to draw accurate objects from memory indicated his visual imagery was intact and normal. Furthermore, C.K. successfully performed other tasks requiring visual imagery for judgment of size, shape, color, and composition. These findings conflict with previous research as they suggest there is a partial dissociation between visual imagery and visual perception. C.K. exhibited a perceptual deficit that was not associated with a corresponding deficit in visual imagery, indicating that these two processes have systems for mental representations that may not be mediated entirely by the same neural substrates.

Schlegel and colleagues (2013) conducted a functional MRI analysis of regions activated during manipulation of visual imagery. They identified 11 bilateral cortical and subcortical regions that exhibited increased activation when manipulating a visual image compared to when the visual image was just maintained. These regions included the occipital lobe and ventral stream areas, two parietal lobe regions, the posterior parietal cortex and the precuneus lobule, and three frontal lobe regions, the frontal eye fields, dorsolateral prefrontal cortex, and the prefrontal cortex. Due to their suspected involvement in working memory and attention, the authors propose that these parietal and prefrontal regions, and occipital regions, are part of a network involved in mediating the manipulation of visual imagery. These results suggest a top-down activation of visual areas in visual imagery.

Using Dynamic Causal Modeling (DCM) to determine the connectivity of cortical networks, Ishai et al. (2010) demonstrated that activation of the network mediating visual imagery is initiated by prefrontal cortex and posterior parietal cortex activity. Generation of objects from memory resulted in initial activation of the prefrontal and the posterior parietal areas, which then activate earlier visual areas through backward connectivity. Activation of the prefrontal cortex and posterior parietal cortex has also been found to be involved in retrieval of object representations from long-term memory, their maintenance in working memory, and attention during visual imagery. Thus, Ishai et al. suggest that the network mediating visual imagery is composed of attentional mechanisms arising from the posterior parietal cortex and the prefrontal cortex.

Vividness of visual imagery is a crucial component of an individual’s ability to perform cognitive tasks requiring imagery. Vividness of visual imagery varies not only between individuals but also within individuals. Dijkstra and colleagues (2017) found that the variation in vividness of visual imagery is dependent on the degree to which the neural substrates of visual imagery overlap with those of visual perception. They found that overlap between imagery and perception in the entire visual cortex, the parietal precuneus lobule, the right parietal cortex, and the medial frontal cortex predicted the vividness of a mental representation. The activated regions beyond the visual areas are believed to drive the imagery-specific processes rather than the visual processes shared with perception. It has been suggested that the precuneus contributes to vividness by selecting important details for imagery. The medial frontal cortex is suspected to be involved in the retrieval and integration of information from the parietal and visual areas during working memory and visual imagery. The right parietal cortex appears to be important in attention, visual inspection, and stabilization of mental representations. Thus, the neural substrates of visual imagery and perception overlap in areas beyond the visual cortex and the degree of this overlap in these areas correlates with the vividness of mental representations during imagery.

Mental images are an important topic in classical and modern philosophy, as they are central to the study of knowledge. In the "Republic", Book VII, Plato has Socrates present the Allegory of the Cave: a prisoner, bound and unable to move, sits with his back to a fire watching the shadows cast on the cave wall in front of him by people carrying objects behind his back. These people and the objects they carry are representations of real things in the world. Unenlightened man is like the prisoner, explains Socrates, a human being making mental images from the sense data that he experiences.

The eighteenth-century philosopher Bishop George Berkeley proposed similar ideas in his theory of idealism. Berkeley stated that reality is equivalent to mental images—our mental images are not a copy of another material reality but that reality itself. Berkeley, however, sharply distinguished between the images that he considered to constitute the external world, and the images of individual imagination. According to Berkeley, only the latter are considered "mental imagery" in the contemporary sense of the term.

The eighteenth century British writer Dr. Samuel Johnson criticized idealism. When asked what he thought about idealism, he is alleged to have replied "I refute it thus!" as he kicked a large rock and his leg rebounded. His point was that the idea that the rock is just another mental image and has no material existence of its own is a poor explanation of the painful sense data he had just experienced.

David Deutsch addresses Johnson's objection to idealism in "The Fabric of Reality" when he states that, if we judge the value of our mental images of the world by the quality and quantity of the sense data that they can explain, then the most valuable mental image—or theory—that we currently have is that the world has a real independent existence and that humans have successfully evolved by building up and adapting patterns of mental images to explain it. This is an important idea in scientific thought.

Critics of scientific realism ask how the inner perception of mental images actually occurs. This is sometimes called the "homunculus problem" (see also the mind's eye). The problem is similar to asking how the images you see on a computer screen exist in the memory of the computer. To scientific materialism, mental images and the perception of them must be brain-states. According to critics, scientific realists cannot explain where the images and their perceiver exist in the brain. To use the analogy of the computer screen, these critics argue that cognitive science and psychology have been unsuccessful in identifying either the component in the brain (i.e., "hardware") or the mental processes that store these images (i.e. "software").

Cognitive psychologists and (later) cognitive neuroscientists have empirically tested some of the philosophical questions related to whether and how the human brain uses mental imagery in cognition.

One theory of the mind that was examined in these experiments was the "brain as serial computer" philosophical metaphor of the 1970s. Psychologist Zenon Pylyshyn theorized that the human mind processes mental images by decomposing them into an underlying mathematical proposition. Roger Shepard and Jacqueline Metzler challenged that view by presenting subjects with 2D line drawings of groups of 3D block "objects" and asking them to determine whether that "object" is the same as a second figure, some of which rotations of the first "object". Shepard and Metzler proposed that if we decomposed and then mentally re-imaged the objects into basic mathematical propositions, as the then-dominant view of cognition "as a serial digital computer" assumed, then it would be expected that the time it took to determine whether the object is the same or not would be independent of how much the object had been rotated. Shepard and Metzler found the opposite: a linear relationship between the degree of rotation in the mental imagery task and the time it took participants to reach their answer.

This mental rotation finding implied that the human mind—and the human brain—maintains and manipulates mental images as topographic and topological wholes, an implication that was quickly put to test by psychologists. Stephen Kosslyn and colleagues showed in a series of neuroimaging experiments that the mental image of objects like the letter "F" are mapped, maintained and rotated as an image-like whole in areas of the human visual cortex. Moreover, Kosslyn's work showed that there are considerable similarities between the neural mappings for imagined stimuli and perceived stimuli. The authors of these studies concluded that, while the neural processes they studied rely on mathematical and computational underpinnings, the brain also seems optimized to handle the sort of mathematics that constantly computes a series of topologically-based images rather than calculating a mathematical model of an object.

Recent studies in neurology and neuropsychology on mental imagery have further questioned the "mind as serial computer" theory, arguing instead that human mental imagery manifests both visually and kinesthetically. For example, several studies have provided evidence that people are slower at rotating line drawings of objects such as hands in directions incompatible with the joints of the human body, and that patients with painful, injured arms are slower at mentally rotating line drawings of the hand from the side of the injured arm.

Some psychologists, including Kosslyn, have argued that such results occur because of interference in the brain between distinct systems in the brain that process the visual and motor mental imagery. Subsequent neuroimaging studies showed that the interference between the motor and visual imagery system could be induced by having participants physically handle actual 3D blocks glued together to form objects similar to those depicted in the line-drawings. Amorim et al. have shown that, when a cylindrical "head" was added to Shepard and Metzler's line drawings of 3D block figures, participants were quicker and more accurate at solving mental rotation problems. They argue that motoric embodiment is not just "interference" that inhibits visual mental imagery but is capable of facilitating mental imagery.

As cognitive neuroscience approaches to mental imagery continued, research expanded beyond questions of serial versus parallel or topographic processing to questions of the relationship between mental images and perceptual representations. Both brain imaging (fMRI and ERP) and studies of neuropsychological patients have been used to test the hypothesis that a mental image is the reactivation, from memory, of brain representations normally activated during the perception of an external stimulus. In other words, if perceiving an apple activates contour and location and shape and color representations in the brain’s visual system, then imagining an apple activates some or all of these same representations using information stored in memory. Early evidence for this idea came from neuropsychology. Patients with brain damage that impairs perception in specific ways, for example by damaging shape or color representations, seem to generally to have impaired mental imagery in similar ways. Studies of brain function in normal human brains support this same conclusion, showing activity in the brain’s visual areas while subjects imagined visual objects and scenes.

The previously mentioned and numerous related studies have led to a relative consensus within cognitive science, psychology, neuroscience, and philosophy on the neural status of mental images. In general, researchers agree that, while there is no homunculus inside the head viewing these mental images, our brains do form and maintain mental images as image-like wholes. The problem of exactly how these images are stored and manipulated within the human brain, in particular within language and communication, remains a fertile area of study.

One of the longest-running research topics on the mental image has basis on the fact that people report large individual differences in the vividness of their images. Special questionnaires have been developed to assess such differences, including the Vividness of Visual Imagery Questionnaire (VVIQ) developed by David Marks. Laboratory studies have suggested that the subjectively reported variations in imagery vividness are associated with different neural states within the brain and also different cognitive competences such as the ability to accurately recall information presented in pictures Rodway, Gillies and Schepman used a novel long-term change detection task to determine whether participants with low and high vividness scores on the VVIQ2 showed any performance differences. Rodway et al. found that high vividness participants were significantly more accurate at detecting salient changes to pictures compared to low-vividness participants. This replicated an earlier study.

Recent studies have found that individual differences in VVIQ scores can be used to predict changes in a person's brain while visualizing different activities. Functional magnetic resonance imaging (fMRI) was used to study the association between early visual cortex activity relative to the whole brain while participants visualized themselves or another person bench pressing or stair climbing. Reported image vividness correlates significantly with the relative fMRI signal in the visual cortex. Thus, individual differences in the vividness of visual imagery can be measured objectively.

Logie, Pernet, Buonocore and Della Sala (2011) used behavioural and fMRI data for mental rotation from individuals reporting vivid and poor imagery on the VVIQ. Groups differed in brain activation patterns suggesting that the groups performed the same tasks in different ways. These findings help to explain the lack of association previously reported between VVIQ scores and mental rotation performance.

Some educational theorists have drawn from the idea of mental imagery in their studies of learning styles. Proponents of these theories state that people often have learning processes that emphasize visual, auditory, and kinesthetic systems of experience. According to these theorists, teaching in multiple overlapping sensory systems benefits learning, and they encourage teachers to use content and media that integrates well with the visual, auditory, and kinesthetic systems whenever possible.

Educational researchers have examined whether the experience of mental imagery affects the degree of learning. For example, imagining playing a five-finger piano exercise (mental practice) resulted in a significant improvement in performance over no mental practice—though not as significant as that produced by physical practice. The authors of the study stated that "mental practice alone seems to be sufficient to promote the modulation of neural circuits involved in the early stages of motor skill learning".

In general, Vajrayana Buddhism, Bön, and Tantra utilize sophisticated visualization or "imaginal" (in the language of Jean Houston of Transpersonal Psychology) processes in the thoughtform construction of the yidam sadhana, kye-rim, and dzog-rim modes of meditation and in the yantra, thangka, and mandala traditions, where holding the fully realized form in the mind is a prerequisite prior to creating an 'authentic' new art work that will provide a sacred support or foundation for deity.

Mental imagery can act as a substitute for the imagined experience: Imagining an experience can evoke similar cognitive, physiological, and/or behavioral consequences as having the corresponding experience in reality. At least four classes of such effects have been documented.



</doc>
<doc id="698226" url="https://en.wikipedia.org/wiki?curid=698226" title="Concept map">
Concept map

A concept map or conceptual diagram is a diagram that depicts suggested relationships between concepts. It is a graphical tool that instructional designers, engineers, technical writers, and others use to organize and structure knowledge.

A concept map typically represents ideas and information as boxes or circles, which it connects with labeled arrows in a downward-branching hierarchical structure. The relationship between concepts can be articulated in linking phrases such as "causes", "requires", or "contributes to".

The technique for visualizing these relationships among different concepts is called "concept mapping". Concept maps have been used to define the ontology of computer systems, for example with the object-role modeling or Unified Modeling Language formalism.

A concept map is a way of representing relationships between ideas, images, or words in the same way that a sentence diagram represents the grammar of a sentence, a road map represents the locations of highways and towns, and a circuit diagram represents the workings of an electrical appliance. In a concept map, each word or phrase connects to another, and links back to the original idea, word, or phrase. Concept maps are a way to develop logical thinking and study skills by revealing connections and helping students see how individual ideas form a larger whole. An example of the use of concept maps is provided in the context of learning about types of fuel.

Concept maps were developed to enhance meaningful learning in the sciences. A well-made concept map grows within a "context frame" defined by an explicit "focus question", while a mind map often has only branches radiating out from a central picture. Some research evidence suggests that the brain stores knowledge as productions (situation-response conditionals) that act on declarative memory content, which is also referred to as chunks or propositions. Because concept maps are constructed to reflect organization of the declarative memory system, they facilitate sense-making and meaningful learning on the part of individuals who make concept maps and those who use them.


Concept mapping was developed by Joseph D. Novak and his research team at Cornell University in the 1970s as a means of representing the emerging science knowledge of students. It has subsequently been used as a tool to increase meaningful learning in the sciences and other subjects as well as to represent the expert knowledge of individuals and teams in education, government and business. Concept maps have their origin in the learning movement called constructivism. In particular, constructivists hold that learners actively construct knowledge.

Novak's work is based on the cognitive theories of David Ausubel, who stressed the importance of prior knowledge in being able to learn (or "assimilate") new concepts: "The most important single factor influencing learning is what the learner already knows. Ascertain this and teach accordingly." Novak taught students as young as six years old to make concept maps to represent their response to focus questions such as "What is water?" "What causes the seasons?" In his book "Learning How to Learn", Novak states that a "meaningful learning involves the assimilation of new concepts and propositions into existing cognitive structures."

Various attempts have been made to conceptualize the process of creating concept maps. Ray McAleese, in a series of articles, has suggested that mapping is a process of "off-loading". In this 1998 paper, McAleese draws on the work of Sowa and a paper by Sweller & Chandler. In essence, McAleese suggests that the process of making knowledge explicit, using "nodes" and "relationships", allows the individual to become aware of what they know and as a result to be able to modify what they know. Maria Birbili applies that same idea to helping young children learn to think about what they know. The concept of the "knowledge arena" is suggestive of a virtual space where learners may explore what they know and what they do not know.

Concept maps are used to stimulate the generation of ideas, and are believed to aid creativity. Concept mapping is also sometimes used for brain-storming. Although they are often personalized and idiosyncratic, concept maps can be used to communicate complex ideas.

Formalized concept maps are used in software design, where a common usage is Unified Modeling Language diagramming amongst similar conventions and development methodologies.

Concept mapping can also be seen as a first step in ontology-building, and can also be used flexibly to represent formal argument — similar to argument maps.

Concept maps are widely used in education and business. Uses include:



</doc>
<doc id="30226192" url="https://en.wikipedia.org/wiki?curid=30226192" title="Polar concept argument">
Polar concept argument

A polar concept argument is a type of argument that posits the understanding of one concept, from the mere understanding of its polar opposite. A well-known instance of a polar concept argument is Gilbert Ryle's argument against scepticism (1960). According to Anthony Grayling's characterisation, Ryle's argument can be stated as follows:

According to Ryle's polar concept argument, counterfeit and genuine coins come in pairs, and one cannot conceive of counterfeit coins without also capturing the essence of the genuine coins at the same time. When one grasps the essence of one polar concept, one also grasps immediately the essence of its polar opposite. Ryle's original argument (1960) runs as follows:

A polar concept argument bears on some more or less strong version of dialectical monism, a philosophical doctrine that views reality as a unified whole, due to the complementarity of polar concepts.



</doc>
<doc id="34644725" url="https://en.wikipedia.org/wiki?curid=34644725" title="Jurisprudence of concepts">
Jurisprudence of concepts

The jurisprudence of concepts was the first "sub-school" of legal positivism, according to which, the written law must reflect concepts, when interpreted. Its main representatives were Ihering, Savigny and Puchta.

This school was, thus, the preceding trigger of the idea that law comes from a dogmatic source, imposition from man over man and not a "natural" consequence of other sciences or of metaphysical faith.

Among the main characters of the "jurisprudence of concepts" are:

So, according to this school, law should have prevailing sources based upon the legislative process, although needing to be proven by more inclusive ideas of a social sense.



</doc>
<doc id="26167139" url="https://en.wikipedia.org/wiki?curid=26167139" title="Definitionism">
Definitionism

Definitionism (also called the classical theory of concepts) is the school of thought in which it is believed that a proper explanation of a theory consists of all the concepts used by that theory being well-defined. This approach has been criticized for its dismissal of the importance of ostensive definitions.


</doc>
<doc id="10000937" url="https://en.wikipedia.org/wiki?curid=10000937" title="Category (Kant)">
Category (Kant)

In Kant's philosophy, a category ( in the original or "Kategorie" in modern German) is a pure concept of the understanding ("Verstand"). A Kantian category is a characteristic of the appearance of any object in general, before it has been experienced. Kant wrote that "They are concepts of an object in general…." Kant also wrote that, "…pure cоncepts [Categories] of the undеrstanding which apply to objects of intuition in general…." Such a category is not a classificatory division, as the word is commonly used. It is, instead, the condition of the possibility of objects in general, that is, objects as such, any and all objects, not specific objects in particular.

The word comes from the Greek κατηγορία, "katēgoria", meaning "that which can be said, predicated, or publicly declared and asserted, about something." A category is an attribute, property, quality, or characteristic that can be predicated of a thing. "…I remark concerning the categories…that their logical employment consists in their use as predicates of objects." Kant called them "ontological predicates."

A category is that which can be said of everything in general, that is, of anything that is an object. John Stuart Mill wrote: "The Categories, or Predicaments—the former a Greek word, the latter its literal translation in the Latin language—were believed to be an enumeration of all things capable of being named, an enumeration by the "summa genera" (highest kind), i.e., the most extensive classes into which things could be distributed, which, therefore, were so many highest Predicates, one or other of which was supposed capable of being affirmed with truth of every nameable thing whatsoever."

Aristotle had claimed that the following ten predicates or categories could be asserted of anything in general: substance, quantity, quality, relation, action, affection (passivity), place, time (date), position, and state. These are supposed to be the qualities or attributes that can be affirmed of each and every thing in experience. Any particular object that exists in thought must have been able to have the Categories attributed to it as possible predicates because the Categories are the properties, qualities, or characteristics of any possible object in general. The Categories of Aristotle and Kant are the general properties that belong to all things without expressing the peculiar nature of any particular thing. Kant appreciated Aristotle's effort, but said that his table was imperfect because " … as he had no guiding principle, he merely picked them up as they occurred to him..."

The Categories do not provide knowledge of individual, particular objects. Any object, however, must have Categories as its characteristics if it is to be an object of experience. It is presupposed or assumed that anything that is a specific object must possess Categories as its properties because Categories are predicates of an object in general. An object in general does not have all of the Categories as predicates at one time. For example, a general object cannot have the qualitative Categories of reality and negation at the same time. Similarly, an object in general cannot have both unity and plurality as quantitative predicates at once. The Categories of Modality exclude each other. Therefore, a general object cannot simultaneously have the Categories of possibility/impossibility and existence/non–existence as qualities.

Since the Categories are a list of that which can be said of every object, they are related only to human language. In making a verbal statement about an object, a speaker makes a judgment. A general object, that is, every object, has attributes that are contained in Kant's list of Categories. In a judgment, or verbal statement, the Categories are the predicates that can be asserted of every object and all objects.

Kant believed that the ability of the human understanding (German: "Verstand", Greek: "dianoia" "διάνοια", Latin: "ratio") to think about and know an object is the same as the making of a spoken or written judgment about an object. According to him, "Our ability to judge is equivalent to our ability to think."
A judgment is the thought that a thing is known to have a certain quality or attribute. For example, the sentence "The rose is red" is a judgment. Kant created a table of the forms of such judgments as they relate to all objects in general.

This table of judgments was used by Kant as a model for the table of categories. Taken together, these twelvefold tables constitute the formal structure for Kant's architectonic conception of his philosophical system.

Categories are entirely different from the appearances of objects. According to Kant, in order to relate to specific phenomena, categories must be "applied" through time. The way that this is done is called a schema.

Arthur Schopenhauer, in his criticism of the Kantian philosophy, found many errors in Kant's use of the Categories of Quality, Quantity, Relation, and Modality. Schopenhauer also noted that in accordance with Kant's claim, non-human animals would not be able to know objects. Animals would only know impressions on their sense organs, which Kant mistakenly calls perception.




</doc>
<doc id="2381958" url="https://en.wikipedia.org/wiki?curid=2381958" title="Conceptual model">
Conceptual model

A conceptual model is a representation of a system, made of the composition of concepts which are used to help people know, understand, or simulate a subject the model represents. It is also a set of concepts. Some models are physical objects; for example, a toy model which may be assembled, and may be made to work like the object it represents.

The term "conceptual model" may be used to refer to models which are formed after a conceptualization or generalization process. Conceptual models are often abstractions of things in the real world whether physical or social. Semantic studies are relevant to various stages of concept formation. Semantics is basically about concepts, the meaning that thinking beings give to various elements of their experience.

The term "conceptual model" is normal. It could mean "a model of concept" or it could mean "a model that is conceptual." A distinction can be made between "what models are" and "what models are made of". With the exception of iconic models, such as a scale model of Winchester Cathedral, most models are concepts. But they are, mostly, intended to be models of real world states of affairs. The value of a model is usually directly proportional to how well it corresponds to a past, present, future, actual or potential state of affairs. A model of a concept is quite different because in order to be a good model it need not have this real world correspondence. In artificial intelligence conceptual models and conceptual graphs are used for building expert systems and knowledge-based systems; here the analysts are concerned to represent expert opinion on what is true not their own ideas on what is true.

Conceptual models (models that are conceptual) range in type from the more concrete, such as the mental image of a familiar physical object, to the formal generality and abstractness of mathematical models which do not appear to the mind as an image. Conceptual models also range in terms of the scope of the subject matter that they are taken to represent. A model may, for instance, represent a single thing (e.g. the "Statue of Liberty"), whole classes of things (e.g. "the electron"), and even very vast domains of subject matter such as "the physical universe." The variety and scope of conceptual models is due to the variety of purposes had by the people using them.
Conceptual modeling is the activity of formally describing some aspects of the physical and social world around us for the purposes of understanding and communication."

A conceptual model's primary objective is to convey the fundamental principles and basic functionality of the system which it represents. Also, a conceptual model must be developed in such a way as to provide an easily understood system interpretation for the model's users. A conceptual model, when implemented properly, should satisfy four fundamental objectives.


The conceptual model plays an important role in the overall system development life cycle. Figure 1 below, depicts the role of the conceptual model in a typical system development scheme. It is clear that if the conceptual model is not fully developed, the execution of fundamental system properties may not be implemented properly, giving way to future problems or system shortfalls. These failures do occur in the industry and have been linked to; lack of user input, incomplete or unclear requirements, and changing requirements. Those weak links in the system design and development process can be traced to improper execution of the fundamental objectives of conceptual modeling. The importance of conceptual modeling is evident when such systemic failures are mitigated by thorough system development and adherence to proven development objectives/techniques.

As systems have become increasingly complex, the role of conceptual modelling has dramatically expanded. With that expanded presence, the effectiveness of conceptual modeling at capturing the fundamentals of a system is being realized. Building on that realization, numerous conceptual modeling techniques have been created. These techniques can be applied across multiple disciplines to increase the user's understanding of the system to be modeled. A few techniques are briefly described in the following text, however, many more exist or are being developed. Some commonly used conceptual modeling techniques and methods include: workflow modeling, workforce modeling, rapid application development, object-role modeling, and the Unified Modeling Language (UML).

Data flow modeling (DFM) is a basic conceptual modeling technique that graphically represents elements of a system. DFM is a fairly simple technique, however, like many conceptual modeling techniques, it is possible to construct higher and lower level representative diagrams. The data flow diagram usually does not convey complex system details such as parallel development considerations or timing information, but rather works to bring the major system functions into context. Data flow modeling is a central technique used in systems development that utilizes the structured systems analysis and design method (SSADM).

Entity-relationship modeling (ERM) is a conceptual modeling technique used primarily for software system representation. Entity-relationship diagrams, which are a product of executing the ERM technique, are normally used to represent database models and information systems. The main components of the diagram are the entities and relationships. The entities can represent independent functions, objects, or events. The relationships are responsible for relating the entities to one another. To form a system process, the relationships are combined with the entities and any attributes needed to further describe the process. Multiple diagramming conventions exist for this technique; IDEF1X, Bachman, and EXPRESS, to name a few. These conventions are just different ways of viewing and organizing the data to represent different system aspects.

The event-driven process chain (EPC) is a conceptual modeling technique which is mainly used to systematically improve business process flows. Like most conceptual modeling techniques, the event driven process chain consists of entities/elements and functions that allow relationships to be developed and processed. More specifically, the EPC is made up of events which define what state a process is in or the rules by which it operates. In order to progress through events, a function/ active event must be executed. Depending on the process flow, the function has the ability to transform event states or link to other event driven process chains. Other elements exist within an EPC, all of which work together to define how and by what rules the system operates. The EPC technique can be applied to business practices such as resource planning, process improvement, and logistics.

The dynamic systems development method uses a specific process called JEFFF to conceptually model a systems life cycle. JEFFF is intended to focus more on the higher level development planning that precedes a project's initialization. The JAD process calls for a series of workshops in which the participants work to identify, define, and generally map a successful project from conception to completion. This method has been found to not work well for large scale applications, however smaller applications usually report some net gain in efficiency.

Also known as Petri nets, this conceptual modeling technique allows a system to be constructed with elements that can be described by direct mathematical means. The petri net, because of its nondeterministic execution properties and well defined mathematical theory, is a useful technique for modeling concurrent system behavior, i.e. simultaneous process executions.

State transition modeling makes use of state transition diagrams to describe system behavior. These state transition diagrams use distinct states to define system behavior and changes. Most current modeling tools contain some kind of ability to represent state transition modeling. The use of state transition models can be most easily recognized as logic state diagrams and directed graphs for finite-state machines.

Because the conceptual modeling method can sometimes be purposefully vague to account for a broad area of use, the actual application of concept modeling can become difficult. To alleviate this issue, and shed some light on what to consider when selecting an appropriate conceptual modeling technique, the framework proposed by Gemino and Wand will be discussed in the following text. However, before evaluating the effectiveness of a conceptual modeling technique for a particular application, an important concept must be understood; Comparing conceptual models by way of specifically focusing on their graphical or top level representations is shortsighted. Gemino and Wand make a good point when arguing that the emphasis should be placed on a conceptual modeling language when choosing an appropriate technique. In general, a conceptual model is developed using some form of conceptual modeling technique. That technique will utilize a conceptual modeling language that determines the rules for how the model is arrived at. Understanding the capabilities of the specific language used is inherent to properly evaluating a conceptual modeling technique, as the language reflects the techniques descriptive ability. Also, the conceptual modeling language will directly influence the depth at which the system is capable of being represented, whether it be complex or simple.

Building on some of their earlier work, Gemino and Wand acknowledge some main points to consider when studying the affecting factors: the content that the conceptual model must represent, the method in which the model will be presented, the characteristics of the model's users, and the conceptual model languages specific task. The conceptual model's content should be considered in order to select a technique that would allow relevant information to be presented. The presentation method for selection purposes would focus on the technique's ability to represent the model at the intended level of depth and detail. The characteristics of the model's users or participants is an important aspect to consider. A participant's background and experience should coincide with the conceptual model's complexity, else misrepresentation of the system or misunderstanding of key system concepts could lead to problems in that system's realization. The conceptual model language task will further allow an appropriate technique to be chosen. The difference between creating a system conceptual model to convey system functionality and creating a system conceptual model to interpret that functionality could involve two completely different types of conceptual modeling languages.

Gemino and Wand go on to expand the affected variable content of their proposed framework by considering the focus of observation and the criterion for comparison. The focus of observation considers whether the conceptual modeling technique will create a "new product", or whether the technique will only bring about a more intimate understanding of the system being modeled. The criterion for comparison would weigh the ability of the conceptual modeling technique to be efficient or effective. A conceptual modeling technique that allows for development of a system model which takes all system variables into account at a high level may make the process of understanding the system functionality more efficient, but the technique lacks the necessary information to explain the internal processes, rendering the model less effective.

When deciding which conceptual technique to use, the recommendations of Gemino and Wand can be applied in order to properly evaluate the scope of the conceptual model in question. Understanding the conceptual models scope will lead to a more informed selection of a technique that properly addresses that particular model. In summary, when deciding between modeling techniques, answering the following questions would allow one to address some important conceptual modeling considerations.


Another function of the simulation conceptual model is to provide a rational and factual basis for assessment of simulation application appropriateness.

In cognitive psychology and philosophy of mind, a mental model is a representation of something in the mind, but a mental model may also refer to a nonphysical external model of the mind itself.

A metaphysical model is a type of conceptual model which is distinguished from other conceptual models by its proposed scope; a metaphysical model intends to represent reality in the broadest possible way. This is to say that it explains the answers to fundamental questions such as whether matter and mind are one or two substances; or whether or not humans have free will.

Conceptual Models and semantic models have many similiarities, however the way they are presentend, the level of flexibility and the use are different.
Conceptual models have a certain purpose in mind, hence the core semantic concepts are pre-defined in a so-called meta model. This enables a pragmatic modelling but reduces the flexibility, as only the pre-defined semantic concepts can be used. Samples are flow charts for process behaviour or organisational structure for tree behaviour.

Semantic models are more flexible and open, and therefore more difficult to model. Potentially any semantic concept can be defined, hence the modelling support is very generic. Samples are terminologies, taxonomies or ontologies.

In a concept model each concept has a unique and distinguishable graphical representation, whereas semantic concepts are by default the same. 
In a concept model each concept has pre-defined properties that can be populated, whereas semantic concepte are related to concepts that are interpreted as properties.
In a concept model operational semantic can be built-in, like the processing of a sequence, whereas a semantic model needs explicit semantic definition of the sequence.

The decision if a concept model or a semantic model is used, depends therefore on the "object under survey", the intended goal, the necessary flexibility as well as how the model is interpreted. In case of human-interpretation there may be a focus on graphical concept models, in case of machine interpretation there may be the focus on semantic models.

An epistemological model is a type of conceptual model whose proposed scope is the known and the knowable, and the believed and the believable.

In logic, a model is a type of interpretation under which a particular statement is true. Logical models can be broadly divided into ones which only attempt to represent concepts, such as mathematical models; and ones which attempt to represent physical objects, and factual relationships, among which are scientific models.

Model theory is the study of (classes of) mathematical structures such as groups, fields, graphs, or even universes of set theory, using tools from mathematical logic. A system that gives meaning to the sentences of a formal language is called a model for the language. If a model for a language moreover satisfies a particular sentence or theory (set of sentences), it is called a model of the sentence or theory. Model theory has close ties to algebra and universal algebra.

Mathematical models can take many forms, including but not limited to dynamical systems, statistical models, differential equations, or game theoretic models. These and other types of models can overlap, with a given model involving a variety of abstract structures.

A more comprehensive type of mathematical model uses a linguistic version of category theory to model a given situation. Akin to entity-relationship models, custom categories or sketches can be directly translated into database schemas. The difference is that logic is replaced by category theory, which brings powerful theorems to bear on the subject of modeling, especially useful for translating between disparate models (as functors between categories).

A scientific model is a simplified abstract view of a complex reality. A scientific model represents empirical objects, phenomena, and physical processes in a logical way. Attempts to formalize the principles of the empirical sciences use an interpretation to model reality, in the same way logicians axiomatize the principles of logic. The aim of these attempts is to construct a formal system for which reality is the only interpretation. The world is an interpretation (or model) of these sciences, only insofar as these sciences are true.

A statistical model is a probability distribution function proposed as generating data. In a parametric model, the probability distribution function has variable parameters, such as the mean and variance in a normal distribution, or the coefficients for the various exponents of the independent variable in linear regression. A nonparametric model has a distribution function without parameters, such as in bootstrapping, and is only loosely confined by assumptions. Model selection is a statistical method for selecting a distribution function within a class of them; e.g., in linear regression where the dependent variable is a polynomial of the independent variable with parametric coefficients, model selection is selecting the highest exponent, and may be done with nonparametric means, such as with cross validation.

In statistics there can be models of mental events as well as models of physical events. For example, a statistical model of customer behavior is a model that is conceptual (because behavior is physical), but a statistical model of customer satisfaction is a model of a concept (because satisfaction is a mental not a physical event).

In economics, a model is a theoretical construct that represents economic processes by a set of variables and a set of logical and/or quantitative relationships between them. The economic model is a simplified framework designed to illustrate complex processes, often but not always using mathematical techniques. Frequently, economic models use structural parameters. Structural parameters are underlying parameters in a model or class of models. A model may have various parameters and those parameters may change to create various properties.

A system model is the conceptual model that describes and represents the structure, behavior, and more views of a system. A system model can represent multiple views of a system by using two different approaches. The first one is the non-architectural approach and the second one is the architectural approach. The non-architectural approach respectively picks a model for each view. The architectural approach, also known as system architecture, instead of picking many heterogeneous and unrelated models, will use only one integrated architectural model.

In business process modelling the enterprise process model is often referred to as the "business process model". Process models are core concepts in the discipline of process engineering. Process models are:
The same process model is used repeatedly for the development of many applications and thus, has many instantiations.

One possible use of a process model is to prescribe how things must/should/could be done in contrast to the process itself which is really what happens. A process model is roughly an anticipation of what the process will look like. What the process shall be will be determined during actual system development.

Conceptual models of human activity systems are used in soft systems methodology (SSM), which is a method of systems analysis concerned with the structuring of problems in management. These models are models of concepts; the authors specifically state that they are not intended to represent a state of affairs in the physical world. They are also used in information requirements analysis (IRA) which is a variant of SSM developed for information system design and software engineering.

Logico-linguistic modeling is another variant of SSM that uses conceptual models. However, this method combines models of concepts with models of putative real world objects and events. It is a graphical representation of modal logic in which modal operators are used to distinguish statement about concepts from statements about real world objects and events.

In software engineering, an entity-relationship model (ERM) is an abstract and conceptual representation of data. Entity-relationship modeling is a database modeling method, used to produce a type of conceptual schema or semantic data model of a system, often a relational database, and its requirements in a top-down fashion. Diagrams created by this process are called entity-relationship diagrams, ER diagrams, or ERDs.

Entity-relationship models have had wide application in the building of information systems intended to support activities involving objects and events in the real world. In these cases they are models that are conceptual. However, this modeling method can be used to build computer games or a family tree of the Greek Gods, in these cases it would be used to model concepts.

A domain model is a type of conceptual model used to depict the structural elements and their conceptual constraints within a domain of interest (sometimes called the problem domain). A domain model includes the various entities, their attributes and relationships, plus the constraints governing the conceptual integrity of the structural model elements comprising that problem domain. A domain model may also include a number of conceptual views, where each view is pertinent to a particular subject area of the domain or to a particular subset of the domain model which is of interest to a stakeholder of the domain model.

Like entity-relationship models, domain models can be used to model concepts or to model real world objects and events.




</doc>
<doc id="38191512" url="https://en.wikipedia.org/wiki?curid=38191512" title="Concept-driven strategy">
Concept-driven strategy

A concept-driven strategy is a process for formulating strategy that draws on the explanation of how humans inquire provided by linguistic pragmatic philosophy. This argues that thinking starts by selecting (explicitly or implicitly) a set of concepts (frames, patterns, lens, principles, etc.) gained from our past experiences. These are used to reflect on whatever happens, or is done, in the future.

Concept-driven strategy therefore starts from agreeing and enacting a set of strategic concepts (organizing principles) that "works best" for an organisation. For example, a hospital might set its strategy as intending to be Caring, World Class, Local, Evidence Based, and Team Based. A University might set its strategy as intending to be Ranked, Problem Solving, Online, Equis, and Offering Pathways. A commercial corporation might set its strategy as intending to be Innovative, Global, Have Visible Supply Chains, Agile and Market Share Dominant. These strategic concepts make up its "Statement of Intent" (or Purpose).

Much of the strategic management literature mutates Peter Drucker's call for corporations to start the strategic management process by producing a statement of purpose, mission and objectives. This has been mutated into a call to start with a vision, mission and objectives statement. There is an alternative approach which focuses on the Statement of Purpose or Intent. Drucker's example for this statement for a commercial corporation was to state that the corporation's purpose was to create customers. That is, it was going to use the concept of 'customer creation' to coordinate and organise the cognition or mindset of those that worked for the organisation. This was why the corporation existed. Having one concept is now thought to be insufficient. George Armitage Miller's modified The Magical Number Seven, Plus or Minus Two and dialectic suggests a handful of concepts under tension would be preferable.

The Statement of Purpose, Statement of Intent or concept-driven approach to strategy formulation therefore focuses on setting and enacting a set strategic concepts. If a participatory approach is being used these concepts will be acquired through a process of collaboration with stakeholders. Once agreed the strategic concepts can be used to coordinate activities and act as a set of decision making criteria. The set of concepts that make up the Statement of Intent is then used to make sense of an unpredictable future across an organisation in a co-ordinated manner.

Linguistic pragmatism argues that our prior conceptions interpret our perception (sensory inputs). These conceptions are represented by concepts like running, smiling, justice, reasoning and agility. They are patterns of activity, experienced in our past and remembered. They can be named by those with language and so shared.

Bagginni explains pragmatic concepts using the classic example of whether the earth is flat or round.

Another example would be that we can think of the war in Iraqi differently by reflecting off the concepts of oil security, Imperialism, aggressive capitalism, liberation or democracy. 
The concept-driven approach to strategy formulation involves setting and using a set of linguistic pragmatic concepts.

The steps to formulating a participatory concept-driven strategy are:


Concept-driven strategy is the name given to a number of similar strategic thinking approaches.

Generally, the term 'concept-driven' is used to encourage a focus on the 'concepts' being used. See Concept learning or Management Concepts.

Some organisations produce a 'statement of intent' with little thought as to the concepts it contains. However, if it is a short list of concepts, high level objectives, principles, priorities or frames, then concept-driven strategy offers a philosophical basis for these statements.

Some organisations produce a 'strategic principles' statement which again is similar to a statement of intent and the same applies about the concepts approach offering a philosophical basis. The term 'strategic priorities' or 'strategic values' are often used in the same way as strategic principles.

The literature about 'corporate purpose' is also similar to that of strategic intent. Sometimes, purpose refers to present actions and intent to future ones. If purpose is expressed as a set of concepts, then the concepts approach again provides some philosophical basis.

There is a connection between 'systems thinking' and concept-driven strategy. The Churchman/Ackoff stream of systems thinking was interested in a developing generic system of concepts for thinking about problems. Rather than a generic set of concepts, the concept-driven approach uses whatever concepts stakeholders think work best for the future of their organisation.

There is a military planning approach called 'concept-led'. The military-like leadership seems to have moved the concepts from being drivers to be leaders. There seems to be very little difference otherwise.

In turbulent environments, concepts are thought 'more flexible than objectives' (goals, targets) as they provide why certain actions are preferable. The purpose and intent literature likes to distinguish itself from the objectives literature by saying purpose and intent provide the reasons for (why change), the driver for change. Objectives are where you end up. In complex dynamic situations, there may be many acceptable end points, many of which cannot be anticipated by planners. Arguably the only objective is to survive. How is explained in the statement of intent.

Perhaps strangely, there is a connection between 'metaphor', metaphoric criticism, or conceptual metaphor and concept-driven strategy. Pragmatic concepts are not images but most concepts relate to metaphors. For example, to say an organisation is like a machine, with cogs, or like an adaptive organism, is to use the concepts of machine and organism to reflect on organisations. Much of what has been written about the usefulness of metaphors in planning applies to concepts.

The term 'strategic frames' is not common given the extensive literature on frame analysis but frames and pragmatic concepts seem to be very similar. Amos Tversky defines a frame as a conception of outcomes.

The system of strategic concepts listed in a statement of intent, purpose, principles, frames or conceptual metaphor are organizing principle(s).

Also, as Karl Weick explains sensemaking as the process of conceptualising problems, concept-driven strategy might be thought of as a pragmatic means of sensemaking a strategy.




</doc>
<doc id="19777249" url="https://en.wikipedia.org/wiki?curid=19777249" title="Organizing principle">
Organizing principle

An organizing principle is a core assumption from which everything else by proximity can derive a classification or a value. It is like a central reference point that allows all other objects to be located, often used in a conceptual framework. Having an organizing principle might help one simplify and get a handle on a particularly complicated domain or phenomenon. On the other hand, it might create a deceptive prism that colors one's judgment.





</doc>
<doc id="1809875" url="https://en.wikipedia.org/wiki?curid=1809875" title="Notion (philosophy)">
Notion (philosophy)

A notion in philosophy is a reflection in the mind of real objects and phenomena in their essential features and relations. Notions are usually described in terms of scope and content. This is because notions are often created in response to empirical observations (or experiments) of covarying trends among variables.

"Notion" is the common translation for "Begriff" as used by Hegel in his Science of Logic (1816).

A primitive notion is used in logic or mathematics as an undefined term or concept at the foundation of an axiomatic system to be constructed. 

However, in philosophy the term "primitive notion" has historical content. For example, Gottfried Leibniz wrote "De Alphabeto Cogitationum Humanarum" (English: "An Alphabet for Human Thought"). Jaap Maat (2004) reviewed Leibniz for "Philosophical Languages of the 17th Century". According to Leibniz, "The alphabet of human thought is a catalogue of primitive notions, or those we cannot render clearer by any definitions." Maat explains, "a thing which is known without other intermediate notions can be considered to be primitive," and further, "a primitive notion is said to be conceived through itself".

Another example is in the "Meditations" of René Descartes:



</doc>
<doc id="42415226" url="https://en.wikipedia.org/wiki?curid=42415226" title="Conceptual combination">
Conceptual combination

Conceptual combination is a fundamental cognitive process by which two or more existing basic concepts are mentally synthesized to generate a composite, higher-order concept. The products of this process are sometimes referred to as "complex concepts." Combining concepts allows individuals to use a finite number of concepts which they already understand to construct a potentially limitless quantity of new, related concepts. It is an essential component of many abilities, such as perception, language, synthetic reasoning, creative thought and abstraction.

Conceptual combination is an important concept in the fields of cognitive psychology and cognitive science.

The mechanism by which conceptual combination occurs is debatable, both on cognitive and neurological levels. As such, multiple models have been developed or applied to better define how the process occurs.

Cognitive models attempt to functionally outline the mental computation involved in conceptual combination. 

Constraint theory stipulates that the concept that results from an attempt at conceptual combination is controlled by three constraints known as diagnosticity, plausibility and informativeness. "Diagnosticity" refers to the a complex concept's possession of the defining properties of its component simple concepts. Because such properties are diagnostic of the component concepts, at least some of them should be diagnostic of the higher-order representations constructed from those concepts. "Plausibility" refers to consistency with existing knowledge and prior experience. It is based on the assumption that a complex concept should be reasonably relevant to the context in which it is used. This assumption makes the most sense in a practical, linguistic context, particularly when a speaker is catering to the understanding of the listener. "Informativeness" is the property of having more meaning or properties than any individual component. If a complex concept were not distinguishable from any given component, it would be identical to that component. Because nothing can logically be both a component of something and the totality of something simultaneously, a complex concept must at least be the sum of its parts. Many argue that the interaction among component concepts should allow a complex concept to be greater than that sum. If multiple possible ways to structure or interpret a complex concept exist, the one which best satisfies or most satisfies these constraints is the one which will be used. The paradigm upon which constraint theory is based is computational, and therefore views the mind as a processor which operates on the basis of standard problem-solving protocols (i.e. algorithms and heuristics).

The spreading activation model is a model in connectionist theory sometimes designed to represent how concepts are activated in relation to one another. Though it is typically applied to information search processes like recognition, brainstorming, and recall, it can be used to explain how concepts are combined as well as connected.

Spreading activation models represent memory and knowledge as a network of interlinked concepts. Every concept manifests as a node within this network, with related nodes/concepts linked to one another with connections. Concepts that are more strongly associated with one another either in terms of content or an individual's past experience are correspondingly more strongly linked.

When one concept is employed in working memory, the corresponding node is also activated. This activation spreads through the node's links, making it easier to activate nodes to which the activated node is connected. This spreading activation stimulates the linked nodes, pressuring them to activate to an extent proportional to the strength of the connection between the stimulating node and the stimulated node. If sufficient net stimulation is accrued through a stimulated node's links, it will also activate. Thus, being connected to an activated node makes it easier for an inactive node to become active as well; concepts become more readily accessed when individuals are stimulated with related concepts first. This increase in ease of access is known as "priming."

Spreading activation models tend to imply that processing concepts occurs in series; that is, each concept is processed one-at-a-time, one after the other. As such, individuals tend to combine concepts more readily, easily, and quickly if they are more closely linked within the network of concepts. This implication, however, has caused spreading activation to come under a great deal of criticism, particularly with respect to how the concept is employed in feature theories.

The features and properties of complex concepts are generally assumed to be derived from the simple concepts that compose them. One popularly discussed model involves a two-stage serial process. In the initial stage, features from each of the component simple concepts are retrieved from memory through spreading activation. This allows a complex concept to accrue features with existing relationships with its component simple concepts. During this stage, the basic definition of what the complex concept is and/or means is generates. In the second stage, knowledge and reasoning are employed upon the features accrued in the previous stage to generate further features. For example, one might reason that the complex concept "white jacket," if worn in a blizzard, would make one difficult to see; it would follow that one should ascribe the property of "good for winter camouflage," despite the fact that this property is not closely attached to the component concepts "white" nor "jacket." This stage is especially useful when properties of complex concepts contradict those of their component concepts, such as the different colours of milk and chocolate milk.

This model, however, has come under criticism due to its inconsistency with empirical studies. If conceptual combination employed serial spreading activation, for instance, it should take longer to verify the properties of complex concepts, as they necessarily possess more concepts than their component simple concepts. Research has nonetheless shown that it takes less time to confirm complex concepts' properties than their components and about equal time to reject false properties for both. This occurred even when the properties of the complex concept contradicted those of the simple concepts. Likewise, when experiment participants are exposed to a set of features first, and then asked to verify whether or not they correspond to simple or complex concepts, the participants tend to provide correct verification answers for the complex concepts more quickly.

The neurological basis of conceptual combination has received considerably less attention than its cognitive basis. Nevertheless, research has revealed several specific brain regions that are intimately involved if not entirely responsible for neural processing involved in conceptual combination.

Of particular relevance is the left anterior temporal lobe. Studies have previously demonstrated an additive effect for stimulation in this subsection of neural cortex tissue. When experiment participants were verbally presented with certain simple concepts, the processing of the information causes electrical stimulation in the region. When the same participants were verbally presented with a single complex concept formed from the combination of the aforementioned simple concepts, the stimulation recorded was equivalent to the sum of the stimulation that resulted from each individual component simple concept. In other words, the stimulation caused by a complex concept is equivalent to the total stimulation caused by its component concepts. More recent data contradicts those results by indicating a multiplicative effect in which the activation caused by a complex concept is the product of the activation levels caused by its component concepts, rather than the sum.

Further support for the role of the left anterior temporal lobe has been previously established through neuropsychological studies. Semantic dementia is a disorder in which conceptual manipulation, including conceptual combination, is hindered. These indicate that the neural damage associated with semantic dementia occurs within this brain region. Unfortunately, neuropsychological studies that attempt to replicate this pattern have failed, leading uncertainty as to whether initial results were valid.

As language is the means by which concepts are communicated and expressed, the processed involved in linguistic expression and interpretation are heavily intertwined with combined concepts. Many theories of concept combination mechanisms, including constraint theory were developed within the context of language, and therefore make more sense when applied in a linguistic context. Study into the linguistic aspects of concept combination as has generally been focused on the interpretation mechanism.

A concept that can be expressed using a single word is called a "lexical concept." A lexical concept is usually treated as a basic concept, although it can just as easily be a complex concept.

Two lexical concepts are often used together as phrases to represent a combined concept of greater specificity. This is most readily seen in the use of adjectives to modify nouns and the use of adverbs to modify verbs and adjectives. Consider, for example, phrases such as "burnt toast," "eat roughly," and "readily loved." Multiple noun lexical concepts can also be used together in order to represent combined concepts. Through this process, a limited pool of nouns can be used to produce an exponentially larger pool of phrases such as "sound wave," "video game," and "sleeping pill."

In addition to constraint theory, there are two principal theories surrounding the mechanism by which noun-noun combinations are interpreted. The first of these is "dual-process theory." Dual-process theory proposed that there are two means by which people interpreted noun-noun phrases. "Relational interpretation" attempts to establish a relationship between the nouns and interprets the combined phrase in terms of that relationship. For example, one might relationally interpret the phrase "snake mouse" to refer to a mouse meant to be eaten by snakes, as the two concepts have a predatory relationship. "Property interpretation" identifies properties associated with the first noun and then applies them onto the second noun. In this case the phrase "snake mouse" might be interpreted as a mouse with poisonous fangs or an elongated body.

The second principal theory is known as the "Competition in Relations among Nominals" theory. It states that the assumed modification effect of a noun on its partner in a novel noun-noun combination is the one which it has been seen to employ most often in the past. For example, "chocolate cat" is usually interpreted as "a cat made of chocolate" rather than "a chocolate-eating cat" simply because the "made of" modifier is heavily conditioned to be associated with "chocolate."

Explanations of linguistic expression of complex concepts have been linked to spreading activation models. When an individual identifies a lexical concept through vision or hearing, the corresponding node in that individual's cognitive network is said to activate. This makes it easier for lexical concepts linked to the activated concept to be comprehended, as they are primed. This is consistent with current empirical data, which shows that when individuals are interpreting sentences, they process the linguistic content more quickly when several related words follow one another. In turn, it becomes easier for people to combine these related concepts together and understand them as a relationship, rather than two distinct entities. For example, consider the example, "John spread butter on a bagel." In this sentence, the lexical concepts "spread," "butter," and "bagel" are associated with one another and easy to combine into a mental representation of a breakfast scenario. Conversely, consider the example, "John baked a computer." Because "baked" and "computer" are not related lexical concepts, it takes more effort and time to build a mental representation of this unusual scenario.

However, spreading activation models of conceptual combination have been criticized in light of how humans have been observed to combined languages. Those who claim that the theory provides an insufficient account of linguistic conceptual combination refer to the ability of humans to readily understand lexical concept combinations with seemingly no apparent connection with one another. One example of this would be the sentence "John saw an elephant cloud." "Elephant" and "cloud" do not shared a close association, but it takes little effort to comprehend that the term "elephant cloud" refers to a cloud shaped like an elephant. This has led some to conclude that the combination of lexical concepts does not wholly rely on the simultaneous activation of linked lexical concepts alone. Rather, they claim that the process involves the use of existing nodes to generate entirely new concepts independent of their parent concepts.

Although many theories of novel noun-noun combination interpretation ignore the effect of social environment, some theorists have attempted to account for any contingencies social context may cause.

When lexical concept combinations are interpreted without the influence of social context, the interpretation carried out is termed "sense generation." This includes all processes that would normally occur excepting those dependent on a conversation partner. The "generation hypothesis" accordingly states that the interpretation mechanism of a noun-noun combination is essentially the same regardless of context. This does not rule out the possibility that social context can affect sense generation in some way, but it does assert that the basic structure of the process is unaffected. As seen above, debate as to what sense generation entails and how many sub-processes into which it should be divided is a contentious matter in cognitive science.

The "anaphor resolution hypothesis" instead asserts that before sense generation occurs, interpreters first search their memory of recent communication to see if the combination refers to something previously discussed. This process is termed "anaphor resolution'.' If a referent is identified, interpretation occurs without sense generation in light of that referent. Even if an explicit referent does not exist, anaphor resolution can help facilitate sense generation by providing more information that might hint at the combination's intended meaning.

The "dual-process hypothesis" not to be confused with dual-process theory, states that sense generation and anaphor resolution occur in parallel. Both processes begin to work once the noun-noun combination is presented. Proponents of this hypothesis disagree as to how the interpretation is eventually resolves. Some believe that whichever process reaches a conclusion first provides the answer. Others believe that both provide continuous input to a third, mediating process that eventually makes a decision based on input from both.

Creativity necessitates the employment of existing concepts in novel ways, and therefore requires conceptual combination. Surprisingly, this contribution seems to be limited. Conceptual combination is a significant contributor to convergent thinking, but not divergent thinking. For example, practice with generating new concepts through combination does not improve brainstorming. It does, however, assist in devising creative problem solving methods.

The psychological community's growing understanding of how concepts are manipulated has allowed educators to teach new concepts more effectively. Tools that are developed based on conceptual combination theory attempt to teach individual tasks, and then challenge students to exercise them together in order to promote both base subject skills and the critical thinking needed to apply them simultaneously to solve new problems. Máder & Vajda, for instance, developed a three-dimensional grid with cells of adjustable height which has been successfully used in numerous activities capable of improving the effectiveness of high school mathematics education.


</doc>
<doc id="5370" url="https://en.wikipedia.org/wiki?curid=5370" title="Category of being">
Category of being

In ontology, the different kinds or ways of being are called categories of being; or simply categories. To investigate the categories of being is to determine the most fundamental and the broadest classes of entities. A distinction between such categories, in making the categories or applying them, is called an ontological distinction.

The process of abstraction required to discover the number and names of the categories has been undertaken by many philosophers since Aristotle and involves the careful inspection of each concept to ensure that there is no higher category or categories under which that concept could be subsumed. The scholars of the twelfth and thirteenth centuries developed Aristotle's ideas, firstly, for example by Gilbert of Poitiers, dividing Aristotle's ten categories into two sets, primary and secondary, according to whether they inhere in the subject or not:
Secondly, following Porphyry’s likening of the classificatory hierarchy to a tree, they concluded that the major classes could be subdivided to form subclasses, for example, Substance could be divided into Genus and Species, and Quality could be subdivided into Property and Accident, depending on whether the property was necessary or contingent. An alternative line of development was taken by Plotinus in the second century who by a process of abstraction reduced Aristotle’s list of ten categories to five: Substance, Relation, Quantity, Motion and Quality. Plotinus further suggested that the latter three categories of his list, namely Quantity, Motion and Quality correspond to three different kinds of relation and that these three categories could therefore be subsumed under the category of Relation. This was to lead to the supposition that there were only two categories at the top of the hierarchical tree, namely Substance and Relation, and if relations only exist in the mind as many supposed, to the two highest categories, Mind and Matter, reflected most clearly in the dualism of René Descartes.

An alternative conclusion however began to be formulated in the eighteenth century by Immanuel Kant who realised that we can say nothing about Substance except through the relation of the subject to other things. In the sentence "This is a house" the substantive subject "house" only gains meaning in relation to human use patterns or to other similar houses. The category of Substance disappears from Kant's tables, and under the heading of Relation, Kant lists "inter alia" the three relationship types of Disjunction, Causality and Inherence. The three older concepts of Quantity, Motion and Quality, as Peirce discovered, could be subsumed under these three broader headings in that Quantity relates to the subject through the relation of Disjunction; Motion relates to the subject through the relation of Causality; and Quality relates to the subject through the relation of Inherence. Sets of three continued to play an important part in the nineteenth century development of the categories, most notably in G.W.F. Hegel's extensive tabulation of categories, and in C.S. Peirce's categories set out in his work on the logic of relations. One of Peirce's contributions was to call the three primary categories Firstness, Secondness and Thirdness which both emphasises their general nature, and avoids the confusion of having the same name for both the category itself and for a concept within that category.

In a separate development, and building on the notion of primary and secondary categories introduced by the Scholastics, Kant introduced the idea that secondary or "derivative" categories could be derived from the primary categories through the combination of one primary category with another. This would result in the formation of three secondary categories: the first, "Community" was an example that Kant gave of such a derivative category; the second, "Modality", introduced by Kant, was a term which Hegel, in developing Kant's dialectical method, showed could also be seen as a derivative category; and the third, "Spirit" or "Will" were terms that Hegel and Schopenhauer were developing separately for use in their own systems. Karl Jaspers in the twentieth century, in his development of existential categories, brought the three together, allowing for differences in terminology, as Substantiality, Communication and Will. This pattern of three primary and three secondary categories was used most notably in the nineteenth century by Peter Mark Roget to form the six headings of his Thesaurus of English Words and Phrases. The headings used were the three objective categories of Abstract Relation, Space (including Motion) and Matter and the three subjective categories of Intellect, Feeling and Volition, and he found that under these six headings all the words of the English language, and hence any possible predicate, could be assembled.

In the twentieth century the primacy of the division between the subjective and the objective, or between mind and matter, was disputed by, among others, Bertrand Russell and Gilbert Ryle. Philosophy began to move away from the metaphysics of categorisation towards the linguistic problem of trying to differentiate between, and define, the words being used. Ludwig Wittgenstein’s conclusion was that there were no clear definitions which we can give to words and categories but only a "halo" or "corona" of related meanings radiating around each term. Gilbert Ryle thought the problem could be seen in terms of dealing with "a galaxy of ideas" rather than a single idea, and suggested that category mistakes are made when a concept (e.g. "university"), understood as falling under one category (e.g. abstract idea), is used as though it falls under another (e.g. physical object). With regard to the visual analogies being used, Peirce and Lewis, just like Plotinus earlier, likened the terms of propositions to points, and the relations between the terms to lines. Peirce, taking this further, talked of univalent, bivalent and trivalent relations linking predicates to their subject and it is just the number and types of relation linking subject and predicate that determine the category into which a predicate might fall. Primary categories contain concepts where there is one dominant kind of relation to the subject. Secondary categories contain concepts where there are two dominant kinds of relation. Examples of the latter were given by Heidegger in his two propositions "the house is on the creek" where the two dominant relations are spatial location (Disjunction) and cultural association (Inherence), and "the house is eighteenth century" where the two relations are temporal location (Causality) and cultural quality (Inherence). A third example may be inferred from Kant in the proposition "the house is impressive or sublime" where the two relations are spatial or mathematical disposition (Disjunction) and dynamic or motive power (Causality). Both Peirce and Wittgenstein introduced the analogy of colour theory in order to illustrate the shades of meanings of words. Primary categories, like primary colours, are analytical representing the furthest we can go in terms of analysis and abstraction and include Quantity, Motion and Quality. Secondary categories, like secondary colours, are synthetic and include concepts such as Substance, Community and Spirit.

One of Aristotle’s early interests lay in the classification of the natural world, how for example the genus "animal" could be first divided into "two-footed animal" and then into "wingless, two-footed animal". He realised that the distinctions were being made according to the qualities the animal possesses, the quantity of its parts and the kind of motion that it exhibits. To fully complete the proposition "this animal is ..." Aristotle stated in his work on the Categories that there were ten kinds of predicate where ...

"... each signifies either substance or quantity or quality or relation or where or when or being-in-a-position or having or acting or being acted upon".

He realised that predicates could be simple or complex. The simple kinds consist of a subject and a predicate linked together by the "categorical" or inherent type of relation. For Aristotle the more complex kinds were limited to propositions where the predicate is compounded of two of the above categories for example "this is a horse running". More complex kinds of proposition were only discovered after Aristotle by the Stoic, Chrysippus, who developed the "hypothetical" and "disjunctive" types of syllogism and these were terms which were to be developed through the Middle Ages and were to reappear in Kant's system of categories.

"Category" came into use with Aristotle's essay "Categories", in which he discussed univocal and equivocal terms, predication, and ten categories:

Plotinus in writing his "Enneads" around AD 250 recorded that "philosophy at a very early age investigated the number and character of the existents ... some found ten, others less ... to some the genera were the first principles, to others only a generic classification of existents". He realised that some categories were reducible to others saying "why are not Beauty, Goodness and the virtues, Knowledge and Intelligence included among the primary genera?" He concluded that such transcendental categories and even the categories of Aristotle were in some way posterior to the three Eleatic categories first recorded in Plato's dialogue "Parmenides" and which comprised the following three coupled terms: 

Plotinus called these "the hearth of reality" deriving from them not only the three categories of Quantity, Motion and Quality but also what came to be known as "the three moments of the Neoplatonic world process":

Plotinus likened the three to the centre, the radii and the circumference of a circle, and clearly thought that the principles underlying the categories were the first principles of creation. "From a single root all being multiplies". Similar ideas were to be introduced into Early Christian thought by, for example, Gregory of Nazianzus who summed it up saying "Therefore Unity, having from all eternity arrived by motion at duality, came to rest in trinity".

In the "Critique of Pure Reason" (1781), Immanuel Kant argued that the categories are part of our own mental structure and consist of a set of "a priori" concepts through which we interpret the world around us. These concepts correspond to twelve logical functions of the understanding which we use to make judgements and there are therefore two tables given in the "Critique", one of the Judgements and a corresponding one for the Categories. To give an example, the logical function behind our reasoning from ground to consequence (based on the Hypothetical relation) underlies our understanding of the world in terms of cause and effect (the Causal relation). In each table the number twelve arises from, firstly, an initial division into two: the Mathematical and the Dynamical; a second division of each of these headings into a further two: Quantity and Quality, and Relation and Modality respectively; and, thirdly, each of these then divides into a further three subheadings as follows.
Table of Judgements

Mathematical
Dynamical

Table of Categories

Mathematical
Dynamical

Criticism of Kant's system followed, firstly, by Arthur Schopenhauer, who amongst other things was unhappy with the term "Community", and declared that the tables "do open violence to truth, treating it as nature was treated by old-fashioned gardeners", and secondly, by W.T.Stace who in his book "The Philosophy of Hegel" suggested that in order to make Kant's structure completely symmetrical a third category would need to be added to the Mathematical and the Dynamical. This, he said, Hegel was to do with his category of Notion.

G.W.F. Hegel in his "Science of Logic" (1812) attempted to provide a more comprehensive system of categories than Kant and developed a structure that was almost entirely triadic. So important were the categories to Hegel that he claimed "the first principle of the world, the Absolute, is a system of categories ... the categories must be the reason of which the world is a consequent".

Using his own logical method of combination, later to be called the Hegelian dialectic, of arguing from thesis through antithesis to synthesis, he arrived, as shown in W.T.Stace's work cited, at a hierarchy of some 270 categories. The three very highest categories were Logic, Nature and Spirit. The three highest categories of Logic, however, he called Being, Essence and Notion which he explained as follows:
Schopenhauer's category that corresponded with Notion was that of Idea, which in his "Four-Fold Root of Sufficient Reason" he complemented with the category of the Will. The title of his major work was "The World as Will and Idea". The two other complementary categories, reflecting one of Hegel's initial divisions, were those of Being and Becoming. At around the same time, Goethe was developing his colour theories in the "Farbenlehre" of 1810, and introduced similar principles of combination and complementation, symbolising, for Goethe, "the primordial relations which belong both to nature and vision". Hegel in his "Science of Logic" accordingly asks us to see his system not as a tree but as a circle.

Charles Sanders Peirce, who had read Kant and Hegel closely, and who also had some knowledge of Aristotle, proposed a system of merely three phenomenological categories: Firstness, Secondness, and Thirdness, which he repeatedly invoked in his subsequent writings. Like Hegel, C.S.Peirce attempted to develop a system of categories from a single indisputable principle, in Peirce's case the notion that in the first instance he could only be aware of his own ideas. 

Although Peirce's three categories correspond to the three concepts of relation given in Kant's tables, the sequence is now reversed and follows that given by Hegel, and indeed before Hegel of the three moments of the world-process given by Plotinus. Later, Peirce gave a mathematical reason for there being three categories in that although monadic, dyadic and triadic nodes are irreducible, every node of a higher valency is reducible to a "compound of triadic relations". Ferdinand de Saussure, who was developing "semiology" in France just as Peirce was developing "semiotics" in the US, likened each term of a proposition to "the centre of a constellation, the point where other coordinate terms, the sum of which is indefinite, converge".

Edmund Husserl (1962, 2000) wrote extensively about categorial systems as part of his phenomenology.

For Gilbert Ryle (1949), a category (in particular a "category mistake") is an important semantic concept, but one having only loose affinities to an ontological category.

Contemporary systems of categories have been proposed by John G. Bennett (The Dramatic Universe, 4 vols., 1956–65), Wilfrid Sellars (1974), Reinhardt Grossmann (1983, 1992), Johansson (1989), Hoffman and Rosenkrantz (1994), Roderick Chisholm (1996), Barry Smith (ontologist) (2003), and Jonathan Lowe (2006).





</doc>
<doc id="47792266" url="https://en.wikipedia.org/wiki?curid=47792266" title="Construction of Concept Map">
Construction of Concept Map

Concept is usually perceived as a regularity in events or objects, or in their records. While constructing a concept map, it is essential to keep in mind that the concept be built with reference to a focus question. Hence, initially, the focus question one seeks to answer is carefully chosen, as learners usually tend to deviate from this question relating only to domains, and thus fail to answer the question.

With the selected domain and the focus question, the next step is to identify the key concepts which apply to this domain. About 15 to 25 concepts are sufficient; they are usually ordered in a rank ordered list. Such a list should be established from the most general and inclusive concept for the particular chosen problem. That list will assist at least in the beginning of the construction of the concept map.

The list is referred to as a parking lot, since the list is constantly shuffled to build up the required network of the concept. Two or more concepts are connected to each other using linking words or phrases, which can only then complete a meaningful sentence. Another important characteristic of a concept map is its cross-links, as the relationship between two different domains used in the concept map. These help in a clear representation of the knowledge contained in the concept, and also give a clear background with specific examples. 


</doc>
<doc id="29358535" url="https://en.wikipedia.org/wiki?curid=29358535" title="Comply or explain">
Comply or explain

Comply or explain is a regulatory approach used in the United Kingdom, Germany, the Netherlands and other countries in the field of corporate governance and financial supervision. Rather than setting out binding laws, government regulators (in the UK, the Financial Reporting Council, in Germany, under the Aktiengesetz) set out a code, which listed companies may either comply with, or if they do not comply, explain publicly why they do not. The UK Corporate Governance Code, the German Corporate Governance Code (or Deutscher Corporate Governance Kodex) and the Dutch Corporate Governance Code 'Code Tabaksblat' () use this approach in setting minimum standards for companies in their audit committees, remuneration committees and recommendations for how good companies should divide authority on their boards.

The purpose of "comply or explain" is to "let the market decide" whether a set of standards is appropriate for individual companies. Since a company may deviate from the standard, this approach rejects the view that "one size fits all", but because of the requirement of disclosure of explanations to market investors, anticipates that if investors do not accept a company's explanations, then investors will sell their shares, hence creating a "market sanction", rather than a legal one. The concept was first introduced after the recommendations of the Cadbury Report of 1992.



</doc>
<doc id="1973470" url="https://en.wikipedia.org/wiki?curid=1973470" title="Fuzzy concept">
Fuzzy concept

A fuzzy concept is a concept of which the boundaries of application can vary considerably according to context or conditions, instead of being fixed once and for all. This means the concept is vague in some way, lacking a fixed, precise meaning, without however being unclear or meaningless altogether. It has a definite meaning, which can be made more precise only through further elaboration and specification - including a closer definition of the context in which the concept is used. The study of the characteristics of fuzzy concepts and fuzzy language is called "fuzzy semantics". The inverse of a "fuzzy concept" is a "crisp concept" (i.e. a precise concept).

A fuzzy concept is understood by scientists as a concept which is "to an extent applicable" in a situation. That means the concept has "gradations" of significance or "unsharp" (variable) boundaries of application. A fuzzy statement is a statement which is true "to some extent", and that extent can often be represented by a scaled value. The best known example of a fuzzy concept around the world is an amber traffic light, and indeed fuzzy concepts are widely used in traffic control systems. The term is also used these days in a more general, popular sense - in contrast to its technical meaning - to refer to a concept which is "rather vague" for any kind of reason.

In the past, the very idea of reasoning with fuzzy concepts faced considerable resistance from academic elites. They did not want to endorse the use of imprecise concepts in research or argumentation. Yet although people might not be aware of it, the use of fuzzy concepts has risen gigantically in all walks of life from the 1970s onward. That is mainly due to advances in electronic engineering, fuzzy mathematics and digital computer programming. The new technology allows very complex inferences about "variations on a theme" to be anticipated and fixed in a program.

The new neuro-fuzzy computational methods make it possible, to identify, to measure and respond to fine gradations of significance, with great precision. It means that practically useful concepts can be coded and applied to all kinds of tasks, even if, ordinarily, these concepts are never precisely defined. Nowadays engineers, statisticians and programmers often represent fuzzy concepts mathematically, using fuzzy logic, fuzzy values, fuzzy variables and fuzzy sets.

Problems of vagueness and fuzziness have probably always existed in human experience. The boundary between different things can appear blurry. Sometimes people have to think, when they are not in the best frame of mind to do it, or, they have to talk about something out there, which just isn't sharply defined. Across time, however, philosophers and scientists began to reflect about those kinds of problems, in much more systematic ways.

The ancient Sorites paradox first raised the logical problem of how we could exactly define the threshold at which a change in quantitative gradation turns into a qualitative or categorical difference. With some physical processes this threshold is relatively easy to identify. For example, water turns into steam at 100 °C or 212 °F (the boiling point depends partly on atmospheric pressure, which decreases at higher altitudes).

With many other processes and gradations, however, the point of change is much more difficult to locate, and remains somewhat vague. Thus, the boundaries between qualitatively different things may be "unsharp": we know that there are boundaries, but we cannot define them exactly.

According to the modern idea of the continuum fallacy, the fact that a statement is to an extent vague, does not automatically mean that it is invalid. The problem then becomes one of how we could ascertain the kind of validity that the statement does have.

The Nordic myth of Loki's wager suggested that concepts that lack precise meanings or precise boundaries of application cannot be usefully discussed at all. However, the 20th century idea of "fuzzy concepts" proposes that "somewhat vague terms" can be operated with, since we can explicate and define the variability of their application, by assigning numbers to gradations of applicability. This idea sounds simple enough, but it had large implications.

The intellectual origins of the species of fuzzy concepts as a logical category have been traced back to a diversity of famous and less well-known thinkers, including (among many others) Eubulides, Plato, Cicero, Georg Wilhelm Friedrich Hegel, Karl Marx and Friedrich Engels, Friedrich Nietzsche, Hugh MacColl, Charles S. Peirce, Max Black, Jan Łukasiewicz, Emil Leon Post, Alfred Tarski, Georg Cantor, Nicolai A. Vasiliev, Kurt Gödel, Stanisław Jaśkowski and Donald Knuth.

Across at least two and a half millennia, all of them had something to say about graded concepts with unsharp boundaries. This suggests at least that the awareness of the existence of concepts with "fuzzy" characteristics, in one form or another, has a very long history in human thought. Quite a few logicians and philosophers have also tried to "analyze" the characteristics of fuzzy concepts as a recognized species, sometimes with the aid of some kind of many-valued logic or substructural logic.

An early attempt in the post-WW2 era to create a theory of sets where set membership is a matter of degree was made by Abraham Kaplan and Hermann Schott in 1951. They intended to apply the idea to empirical research. Kaplan and Schott measured the degree of membership of empirical classes using real numbers between 0 and 1, and they defined corresponding notions of intersection, union, complementation and subset. However, at the time, their idea "fell on stony ground". J. Barkley Rosser Sr. published a treatise on many-valued logics in 1952, anticipating "many-valued sets". Another treatise was published in 1963 by Aleksandr A. Zinov'ev and others

In 1964, the American philosopher William Alston introduced the term "degree vagueness" to describe vagueness in an idea that results from the absence of a definite cut-off point along an implied scale (in contrast to "combinatory vagueness" caused by a term that has a number of logically independent conditions of application).

The German mathematician Dieter Klaua published a German-language paper on fuzzy sets in 1965, but he used a different terminology (he referred to "many-valued sets", not "fuzzy sets").

Two popular introductions to many-valued logic in the late 1960s were by Robert J. Ackermann and Nicholas Rescher respectively. Rescher’s book includes a bibliography on fuzzy theory up to 1965, which was extended by Robert Wolf for 1966-1974. Haack provides references to significant works after 1974. Bergmann provides a more recent (2008) introduction to fuzzy reasoning.

Usually the Iranian-born American computer scientist Lotfi A. Zadeh (1921-2017) is credited with inventing the specific idea of a "fuzzy concept" in his seminal 1965 paper on fuzzy sets, because he gave a formal mathematical presentation of the phenomenon that was widely accepted by scholars.<ref>Lotfi A. Zadeh, "Fuzzy sets". In: "Information and Control", Vol. 8, June 1965, pp. 338–353.



</doc>
<doc id="37673" url="https://en.wikipedia.org/wiki?curid=37673" title="Symbol">
Symbol

A symbol is a mark, sign or word that indicates, signifies, or is understood as representing an idea, object, or relationship. Symbols allow people to go beyond what is known or seen by creating linkages between otherwise very different concepts and experiences. All communication (and data processing) is achieved through the use of symbols. Symbols take the form of words, sounds, gestures, ideas or visual images and are used to convey other ideas and beliefs. For example, a red octagon may be a symbol for "STOP". On a map, a blue line might represent a river. Numerals are symbols for numbers. Alphabetic letters may be symbols for sounds. Personal names are symbols representing individuals. A red rose may symbolize love and compassion. The variable 'x', in a mathematical equation, may symbolize the position of a particle in space.

In cartography, an organized collection of symbols forms a legend for a map.

The word "symbol" derives from the Greek σύμβολον "symbolon", meaning "token, watchword" from σύν "syn" "together" and βάλλω "bállō" " "I throw, put." The sense evolution in Greek is from "throwing things together" to "contrasting" to "comparing" to "token used in comparisons to determine if something is genuine." Hence, "outward sign" of something. The meaning "something which stands for something else" was first recorded in 1590, in Edmund Spenser's "Faerie Queene".

Symbols are a means of complex communication that often can have multiple levels of meaning. Symbols are the basis of all human understanding and serve as vehicles of conception for all human knowledge. Symbols facilitate understanding of the world in which we live, thus serving as the grounds upon which we make judgments. In this way, people use symbols not only to make sense of the world around them, but also to identify and cooperate in society through constitutive rhetoric.

Human cultures use symbols to express specific ideologies and social structures and to represent aspects of their specific culture. Thus, symbols carry meanings that depend upon one's cultural background; in other words, the meaning of a symbol is not inherent in the symbol itself but is culturally learned.

In considering the effect of a symbol on the psyche, in his seminal essay "The Symbol without Meaning" Joseph Campbell proposes the following definition:
Later, expanding on what he means by this definition Campbell says:
Heinrich Zimmer gives a concise overview of the nature, and perennial relevance, of symbols.
In the book "Signs and Symbols", it is stated that

Semiotics is the study of signs, symbols, and signification as communicative behavior. Semiotics studies focus on the relationship of the signifier and the signified, also taking into account interpretation of visual cues, body language, sound, and other contextual clues. Semiotics is linked with both linguistics and psychology. Semioticians thus not only study what a symbol implies, but also how it got its meaning and how it functions to make meaning in society. Symbols allow the human brain continuously to create meaning using sensory input and decode symbols through both denotation and connotation.

An alternative definition of "symbol", distinguishing it from the term "sign" was proposed by Swiss psychoanalyst Carl Jung. In his studies on what is now called Jungian archetypes, a sign stands for something known, as a word stands for its referent. He contrasted a sign with a "symbol": something that is unknown and that cannot be made clear or precise. An example of a symbol in this sense is Christ as a symbol of the archetype called "self".

Kenneth Burke described "Homo sapiens" as a "symbol-using, symbol making, and symbol misusing animal" to suggest that a person creates symbols as well as misuses them. One example he uses to indicate what he means by the misuse of symbol is the story of a man who, when told that a particular food item was whale blubber, could barely keep from throwing it up. Later, his friend discovered it was actually just a dumpling. But the man's reaction was a direct consequence of the symbol of "blubber" representing something inedible in his mind. In addition, the symbol of "blubber" was created by the man through various kinds of learning.

Burke goes on to describe symbols as also being derived from Sigmund Freud's work on condensation and displacement, further stating that symbols are not just relevant to the theory of dreams but also to "normal symbol systems". He says they are related through "substitution", where one word, phrase, or symbol is substituted for another in order to change the meaning. In other words, if one person does not understand a certain word or phrase, another person may substitute a synonym or symbol in order to get the meaning across. However, upon learning the new way of interpreting a specific symbol, the person may change his or her already-formed ideas to incorporate the new information.

Jean Dalby Clift says that people not only add their own interpretations to symbols, they also create personal symbols that represent their own understanding of their lives: what she calls "core images" of the person. She argues that symbolic work with these personal symbols or core images can be as useful as working with dream symbols in psychoanalysis or counseling.

William Indick suggests that the symbols that are commonly found in myth, legend, and fantasy fulfil psychological functions and hence are why archetypes such as "the hero," "the princess" and "the witch" have remained popular for centuries.

Symbols can carry symbolic value in three primary forms: Ideological, comparative, and isomorphic. Ideological symbols such as religious and state symbols convey complex sets of beliefs and ideas that indicate "the right thing to do". Comparative symbols such as prestigious office addresses, fine art, and prominent awards indicate answers to questions of "better or worse" and "superior or inferior". Isomorphic symbols blend in with the surrounding cultural environment such that they enable individuals and organizations to conform to their surroundings and evade social and political scrutiny. Examples of symbols with isomorphic value include wearing professional dress during business meetings, shaking hands to greet others in the West, or bowing to greet others in the East. A single symbol can carry multiple distinct meanings such that it provides multiple types of symbolic value.

Paul Tillich argued that, while signs are invented and forgotten, symbols are born and die. There are, therefore, dead and living symbols. A living symbol can reveal to an individual hidden levels of meaning and transcendent or religious realities. For Tillich a symbol always "points beyond itself" to something that is unquantifiable and mysterious; symbols open up the "depth dimension of reality itself". Symbols are complex, and their meanings can evolve as the individual or culture evolves. When a symbol loses its meaning and power for an individual or culture, it becomes a dead symbol.
When a symbol becomes identified with the deeper reality to which it refers, it becomes idolatrous as the "symbol is taken for reality." The symbol itself is substituted for the deeper meaning it intends to convey. The unique nature of a symbol is that it gives access to deeper layers of reality which are otherwise inaccessible.

A symbol's meaning may be modified by various factors including popular usage, history, and contextual intent.

The history of a symbol is one of many factors in determining a particular symbol's apparent meaning. Consequently, symbols with emotive power carry problems analogous to false etymologies.

The context of a symbol may change its meaning. Similar five-pointed stars might signify a law enforcement officer or a member of the armed services, depending upon the uniform.

Symbols are used in cartography to communicate geographical information (generally as point, line, or area features). As with other symbols, visual variables such as size, shape, orientation, texture, and pattern provide meaning to the symbol. According to semiotics, map symbols are "read" by map users when they make a connection between the graphic mark on the map (the "sign"), a general concept (the "interpretant"), and a particular feature of the real world (the "referent"). Map symbols can thus be categorized by how they suggest this connection:


A symbolic action is an action that has no, or little, practical effect but symbolizes, or signals, what the actor wants or believes. The action conveys meaning to the viewers. Symbolic action may overlap with symbolic speech, such as the use of flag burning to express hostility or saluting the flag to express patriotism. In response to intense public criticism, businesses, organizations, and governments may take symbolic actions rather than, or in addition to, directly addressing the identified problems.




</doc>
<doc id="387403" url="https://en.wikipedia.org/wiki?curid=387403" title="Nonsense">
Nonsense

Nonsense is a communication, via speech, writing, or any other symbolic system, that lacks any coherent meaning. Sometimes in ordinary usage, nonsense is synonymous with absurdity or the ridiculous. Many poets, novelists and songwriters have used nonsense in their works, often creating entire works using it for reasons ranging from pure comic amusement or satire, to illustrating a point about language or reasoning. In the philosophy of language and philosophy of science, nonsense is distinguished from sense or meaningfulness, and attempts have been made to come up with a coherent and consistent method of distinguishing sense from nonsense. It is also an important field of study in cryptography regarding separating a signal from noise.

The phrase "Colorless green ideas sleep furiously" was coined by Noam Chomsky as an example of nonsense. However, this can easily be confused with poetic symbolism. The individual "words" make sense and are arranged according to proper grammatical rules, yet the result is nonsense. The inspiration for this attempt at creating verbal nonsense came from the idea of contradiction and seemingly irrelevant and/or incompatible characteristics, which conspire to make the phrase meaningless, but are open to interpretation. The phrase "the square root of Tuesday" operates on the latter principle. This principle is behind the inscrutability of the "kōan" "What is the sound of one hand clapping?", where one hand would presumably be insufficient for clapping without the intervention of another.

James Joyce's final novel "Finnegans Wake" also uses nonsense: full of portmanteau and strong words, it "appears" to be pregnant with multiple layers of meaning, but in many passages it is difficult to say whether any one human's interpretation of a text could be the intended or unintended one.

"Jabberwocky", a poem (of nonsense verse) found in "Through the Looking-Glass, and What Alice Found There" by Lewis Carroll (1871), is a nonsense poem written in the English language. The word "jabberwocky" is also occasionally used as a synonym of nonsense.

Nonsense verse is the verse form of literary nonsense, a genre that can manifest in many other ways. Its best-known exponent is Edward Lear, author of "The Owl and the Pussycat" and hundreds of limericks.

Nonsense verse is part of a long line of tradition predating Lear: the nursery rhyme "Hey Diddle Diddle" could also be termed a nonsense verse. There are also some works which "appear" to be nonsense verse, but actually are not, such as the popular 1940s song Mairzy Doats.

Lewis Carroll, seeking a nonsense riddle, once posed the question "How is a raven like a writing desk?". Someone answered him, "Because Poe wrote on both". However, there are other possible answers (e.g. "both have inky quills").

Lines of nonsense frequently figure in the refrains of folksongs, where nonsense riddles and knock-knock jokes are often encountered.

The first verse of "Jabberwocky" by Lewis Carroll;
The first four lines of "On the Ning Nang Nong" by Spike Milligan;
The first verse of "Spirk Troll-Derisive" by James Whitcomb Riley;
The first four lines of "The Mayor of Scuttleton" by Mary Mapes Dodge;
"Oh Freddled Gruntbuggly" by Prostetnic Vogon Jeltz; a creation of Douglas Adams

In the philosophy of language and the philosophy of science, nonsense refers to a lack of sense or meaning. Different technical definitions of meaning delineate sense from nonsense.

In Ludwig Wittgenstein's writings, the word "nonsense" carries a special technical meaning which differs significantly from the normal use of the word. In this sense, "nonsense" does not refer to meaningless gibberish, but rather to the lack of sense in the context of sense and reference. In this context, logical tautologies, and purely mathematical propositions may be regarded as "nonsense". For example, "1+1=2" is a nonsensical proposition. Wittgenstein wrote in Tractatus Logico Philosophicus that some of the propositions contained in his own book should be regarded as nonsense. Used in this way, "nonsense" does not necessarily carry negative connotations.

Starting from Wittgenstein, but through an original perspective, the Italian philosopher Leonardo Vittorio Arena, in his book "Nonsense as the meaning", highlights this positive meaning of nonsense to undermine every philosophical conception which does not take note of the absolute lack of meaning of the world and life. Nonsense implies the destruction of all views or opinions, on the wake of the Indian Buddhist philosopher Nagarjuna. In the name of nonsense, it is finally refused the conception of duality and the Aristotelian formal logic.

The problem of distinguishing sense from nonsense is important in cryptography and other intelligence fields. For example, they need to distinguish signal from noise. Cryptanalysts have devised algorithms to determine whether a given text is in fact nonsense or not. These algorithms typically analyze the presence of repetitions and redundancy in a text; in meaningful texts, certain frequently used words recur, for example, "the", "is" and "and" in a text in the English language. A random scattering of letters, punctuation marks and spaces do not exhibit these regularities. Zipf's law attempts to state this analysis mathematically. By contrast, cryptographers typically seek to make their cipher texts resemble random distributions, to avoid telltale repetitions and patterns which may give an opening for cryptanalysis.

It is harder for cryptographers to deal with the presence or absence of meaning in a text in which the level of redundancy and repetition is "higher" than found in natural languages (for example, in the mysterious text of the Voynich manuscript).

Scientists have attempted to teach machines to produce nonsense. The Markov chain technique is one method which has been used to generate texts by algorithm and randomizing techniques that seem meaningful. Another method is sometimes called the "Mad Libs" method: it involves creating templates for various sentence structures and filling in the blanks with noun phrases or verb phrases; these phrase-generation procedures can be looped to add recursion, giving the output the appearance of greater complexity and sophistication. Racter was a computer program which generated nonsense texts by this method; however, Racter's book, "The Policeman’s Beard is Half Constructed", proved to have been the product of heavy human editing of the program's output.





</doc>
<doc id="55063170" url="https://en.wikipedia.org/wiki?curid=55063170" title="Afro-pessimism">
Afro-pessimism

Afro-pessimism is a framework and critical idiom that describes the ongoing effects of racism, colonialism, and historical processes of enslavement including the Trans-Atlantic slave trade, and their impact on structural conditions as well as personal, subjective, and lived experience, and embodied reality. 

The term was first coined in 1990 in an article in "Jeune Afrique Economie" by Francophone Congolese author Sony Lab'ou Tansi. Writer and intellectual Frank B. Wilderson III developed the term in his political memoir, "Incognegro: A Memoir and Exile & Apartheid", about his time spent teaching and participating in the African National Congress in South Africa during apartheid. 

According to Tansi, "Afro-pessimism [is] a terrible word used to conceal the greatest mess of all time," which is the "tragedy" that Africa's position "dooms us to construct and build garbage economies in the depths of the most cruel, unbearable, and inhuman form of indignity that humans can swallow" (as translated by John Conteh-Morgan).

Wilderson, along with Hortense Spillers, Saidiya Hartman, Achille Mbembe, Jared Sexton, D. S. Marriott, and others who have contributed to afro-pessimist thought, cite the Martinician psychiatrist, philosopher, and writer Frantz Fanon as a foundational figure in the tradition of Afro-pessimism. 

Afro-pessimism has been constructed in many ways and with different aims. But Afro-pessimism is chiefly approached a transcendent position, not as a negative or disaffected political attitude in the sense that pessimism might seemingly connote. The Black radical tradition has drawn upon the term as a way to acknowledge the power, depth, and vitality of the resilience and radical imagination of people of African descent. Within this same critique, some have used Afro-pessimism to articulate the subject-position of renunciation, refusal, distancing, dread, doubt and abjection in response to the multitude and ongoing effects and historical traumas of colonialism. This includes the view that dismantling white supremacy would mean dismantling much of the social and political institutions of the modern world.

Discussions of Afro-pessimism have manifest in an online context, and have continued in Afro-pessimist approaches to art, poetics, and computing.

Afro-pessimist ideas have been part of ongoing conversations about pan-African identity, as an inclusionary concept of blackness among all people of African descent. Pan-African thought has drawn attention to the shared racial identity and also the particulars of the expression of African identity among the African Diaspora and peoples on the African continent. Pan-African thought has analyzed the ongoing struggles of African peoples, and the power of Afrocentricity as a move away from the colonialism and violence of Eurocentricity. The writings of Frantz Fanon, a Martinican psychiatrist, intellectual, and revolutionary, reflect pan-African and Afro-pessimistic approaches to decolonization and black liberation. 

The Pan-African movement négritude represents pessimism as a kind of realist recognition of the historical traumas of colonialism, from an existentialist position. A key figure in the movement, Aimé Césaire, uses pessimism to consider transcendence and a recognition of the breadth of the cultural imagination and perseverance of people of African descent.

Afro-pessimism has also been employed as a term describing a narrative in Western media and International relations theory that portrays post-colonial Africa as unlikely to achieve economic growth and democratic governance. This use of Afro-pessimism has nothing to with Wilderson's definition. This form of Afro-pessimism has been criticized as a Western construct regarding the ongoing portrayal of Africa and African people in Western media, overwhelmingly in terms of tragedy, doom, victimization, and victim-hood. Scholar Toussaint Nothias has characterized these discussions by the components, "essentialism, racialization, selectivity, ranking framework, and prediction." From this Afro-pessimistic perspective, news media that portray Africa and African people by the trope of victimhood, mirror the Eurocentric and ethnocentric of the Western media, language, images, and rhetoric. In this ways the media tends to victimize and exoticize Africa for its going struggles with poverty, health-crisis, famine, and lack of modern development. The victimization is then visible in the humanitarian and development projects, which sometimes use the language of "saving" African people from such "humanitarian disasters".




</doc>
<doc id="6880483" url="https://en.wikipedia.org/wiki?curid=6880483" title="Philosophy of mind">
Philosophy of mind

Philosophy of mind is a branch of philosophy that studies the ontology, nature, and relationship of the mind to the body. The mind–body problem is a paradigm issue in philosophy of mind, although other issues are addressed, such as the hard problem of consciousness, and the nature of particular mental states. Aspects of the mind that are studied include mental events, mental functions, mental properties, consciousness, the ontology of the mind, the nature of thought, and the relationship of the mind to the body.

Dualism and monism are the two central schools of thought on the mind–body problem, although nuanced views have arisen that do not fit one or the other category neatly. Dualism finds its entry into Western philosophy thanks to René Descartes in the 17th century. Substance dualists like Descartes argue that the mind is an independently existing substance, whereas property dualists maintain that the mind is a group of independent properties that emerge from and cannot be reduced to the brain, but that it is not a distinct substance.

Monism is the position that mind and body are not ontologically distinct entities (independent substances). This view was first advocated in Western philosophy by Parmenides in the 5th century BCE and was later espoused by the 17th-century rationalist Baruch Spinoza. Physicalists argue that only entities postulated by physical theory exist, and that mental processes will eventually be explained in terms of these entities as physical theory continues to evolve. Physicalists maintain various positions on the prospects of reducing mental properties to physical properties (many of whom adopt compatible forms of property dualism), and the ontological status of such mental properties remains unclear. Idealists maintain that the mind is all that exists and that the external world is either mental itself, or an illusion created by the mind. Neutral monists such as Ernst Mach and William James argue that events in the world can be thought of as either mental (psychological) or physical depending on the network of relationships into which they enter, and dual-aspect monists such as Spinoza adhere to the position that there is some other, neutral substance, and that both matter and mind are properties of this unknown substance. The most common monisms in the 20th and 21st centuries have all been variations of physicalism; these positions include behaviorism, the type identity theory, anomalous monism and functionalism.

Most modern philosophers of mind adopt either a reductive physicalist or non-reductive physicalist position, maintaining in their different ways that the mind is not something separate from the body. These approaches have been particularly influential in the sciences, especially in the fields of sociobiology, computer science (specifically, artificial intelligence), evolutionary psychology and the various neurosciences. Reductive physicalists assert that all mental states and properties will eventually be explained by scientific accounts of physiological processes and states. Non-reductive physicalists argue that although the mind is not a separate substance, mental properties supervene on physical properties, or that the predicates and vocabulary used in mental descriptions and explanations are indispensable, and cannot be reduced to the language and lower-level explanations of physical science. Continued neuroscientific progress has helped to clarify some of these issues; however, they are far from being resolved. Modern philosophers of mind continue to ask how the subjective qualities and the intentionality of mental states and properties can be explained in naturalistic terms.

The mind–body problem concerns the explanation of the relationship that exists between minds, or mental processes, and bodily states or processes. The main aim of philosophers working in this area is to determine the nature of the mind and mental states/processes, and how—or even if—minds are affected by and can affect the body.

Our perceptual experiences depend on stimuli that arrive at our various sensory organs from the external world, and these stimuli cause changes in our mental states, ultimately causing us to feel a sensation, which may be pleasant or unpleasant. Someone's desire for a slice of pizza, for example, will tend to cause that person to move his or her body in a specific manner and in a specific direction to obtain what he or she wants. The question, then, is how it can be possible for conscious experiences to arise out of a lump of gray matter endowed with nothing but electrochemical properties.

A related problem is how someone's propositional attitudes (e.g. beliefs and desires) cause that individual's neurons to fire and muscles to contract. These comprise some of the puzzles that have confronted epistemologists and philosophers of mind from at least the time of René Descartes.

Dualism is a set of views about the relationship between mind and matter (or body). It begins with the claim that mental phenomena are, in some respects, non-physical. One of the earliest known formulations of mind–body dualism was expressed in the eastern Sankhya and Yoga schools of Hindu philosophy (c. 650 BCE), which divided the world into purusha (mind/spirit) and prakriti (material substance). Specifically, the Yoga Sutra of Patanjali presents an analytical approach to the nature of the mind.

In Western Philosophy, the earliest discussions of dualist ideas are in the writings of Plato who maintained that humans' "intelligence" (a faculty of the mind or soul) could not be identified with, or explained in terms of, their physical body. However, the best-known version of dualism is due to René Descartes (1641), and holds that the mind is a non-extended, non-physical substance, a "res cogitans". Descartes was the first to clearly identify the mind with consciousness and self-awareness, and to distinguish this from the brain, which was the seat of intelligence. He was therefore the first to formulate the mind–body problem in the form in which it still exists today.

The most frequently used argument in favor of dualism appeals to the common-sense intuition that conscious experience is distinct from inanimate matter. If asked what the mind is, the average person would usually respond by identifying it with their self, their personality, their soul, or some other such entity. They would almost certainly deny that the mind simply is the brain, or vice versa, finding the idea that there is just one ontological entity at play to be too mechanistic, or simply unintelligible. Many modern philosophers of mind think that these intuitions are misleading and that we should use our critical faculties, along with empirical evidence from the sciences, to examine these assumptions to determine whether there is any real basis to them.

Another important argument in favor of dualism is that the mental and the physical seem to have quite different, and perhaps irreconcilable, properties. Mental events have a subjective quality, whereas physical events do not. So, for example, one can reasonably ask what a burnt finger feels like, or what a blue sky looks like, or what nice music sounds like to a person. But it is meaningless, or at least odd, to ask what a surge in the uptake of glutamate in the dorsolateral portion of the prefrontal cortex feels like.

Philosophers of mind call the subjective aspects of mental events "qualia" or "raw feels". There is something that it is like to feel pain, to see a familiar shade of blue, and so on. There are qualia involved in these mental events that seem particularly difficult to reduce to anything physical. David Chalmers explains this argument by stating that we could conceivably know all the objective information about something, such as the brain states and wavelengths of light involved with seeing the color red, but still not know something fundamental about the situation – what it is like to see the color red.

If consciousness (the mind) can exist independently of physical reality (the brain), one must explain how physical memories are created concerning consciousness. Dualism must therefore explain how consciousness affects physical reality. One possible explanation is that of a miracle, proposed by Arnold Geulincx and Nicolas Malebranche, where all mind–body interactions require the direct intervention of God.

Another possible argument that has been proposed by C. S. Lewis is the Argument from Reason: if, as monism implies, all of our thoughts are the effects of physical causes, then we have no reason for assuming that they are also the consequent of a reasonable ground. Knowledge, however, is apprehended by reasoning from ground to consequent. Therefore, if monism is correct, there would be no way of knowing this—or anything else—we could not even suppose it, except by a fluke.

The zombie argument is based on a thought experiment proposed by Todd Moody, and developed by David Chalmers in his book "The Conscious Mind". The basic idea is that one can imagine one's body, and therefore conceive the existence of one's body, without any conscious states being associated with this body. Chalmers' argument is that it seems possible that such a being could exist because all that is needed is that all and only the things that the physical sciences describe about a zombie must be true of it. Since none of the concepts involved in these sciences make reference to consciousness or other mental phenomena, and any physical entity can be by definition described scientifically via physics, the move from conceivability to possibility is not such a large one. Others such as Dennett have argued that the notion of a philosophical zombie is an incoherent, or unlikely, concept. It has been argued under physicalism that one must either believe that anyone including oneself might be a zombie, or that no one can be a zombie—following from the assertion that one's own conviction about being (or not being) a zombie is a product of the physical world and is therefore no different from anyone else's. This argument has been expressed by Dennett who argues that "Zombies think they are conscious, think they have qualia, think they suffer pains—they are just 'wrong' (according to this lamentable tradition) in ways that neither they nor we could ever discover!"
See also the problem of other minds.

Interactionist dualism, or simply interactionism, is the particular form of dualism first espoused by Descartes in the "Meditations". In the 20th century, its major defenders have been Karl Popper and John Carew Eccles. It is the view that mental states, such as beliefs and desires, causally interact with physical states.

Descartes' famous argument for this position can be summarized as follows: Seth has a clear and distinct idea of his mind as a thinking thing that has no spatial extension (i.e., it cannot be measured in terms of length, weight, height, and so on). He also has a clear and distinct idea of his body as something that is spatially extended, subject to quantification and not able to think. It follows that mind and body are not identical because they have radically different properties.

At the same time, however, it is clear that Seth's mental states (desires, beliefs, etc.) have causal effects on his body and vice versa: A child touches a hot stove (physical event) which causes pain (mental event) and makes her yell (physical event), this in turn provokes a sense of fear and protectiveness in the caregiver (mental event), and so on.

Descartes' argument crucially depends on the premise that what Seth believes to be "clear and distinct" ideas in his mind are necessarily true. Many contemporary philosophers doubt this. For example, Joseph Agassi suggests that several scientific discoveries made since the early 20th century have undermined the idea of privileged access to one's own ideas. Freud claimed that a psychologically-trained observer can understand a person's unconscious motivations better than the person himself does. Duhem has shown that a philosopher of science can know a person's methods of discovery better than that person herself does, while Malinowski has shown that an anthropologist can know a person's customs and habits better than the person whose customs and habits they are. He also asserts that modern psychological experiments that cause people to see things that are not there provide grounds for rejecting Descartes' argument, because scientists can describe a person's perceptions better than the person herself can.

Psychophysical parallelism, or simply parallelism, is the view that mind and body, while having distinct ontological statuses, do not causally influence one another. Instead, they run along parallel paths (mind events causally interact with mind events and brain events causally interact with brain events) and only seem to influence each other. This view was most prominently defended by Gottfried Leibniz. Although Leibniz was an ontological monist who believed that only one type of substance, the monad, exists in the universe, and that everything is reducible to it, he nonetheless maintained that there was an important distinction between "the mental" and "the physical" in terms of causation. He held that God had arranged things in advance so that minds and bodies would be in harmony with each other. This is known as the doctrine of pre-established harmony.

Occasionalism is the view espoused by Nicholas Malebranche as well as Islamic philosophers such as Abu Hamid Muhammad ibn Muhammad al-Ghazali that asserts that all supposedly causal relations between physical events, or between physical and mental events, are not really causal at all. While body and mind are different substances, causes (whether mental or physical) are related to their effects by an act of God's intervention on each specific occasion.

Property dualism is the view that the world is constituted of just one kind of substance – the physical kind – and there exist two distinct kinds of properties: physical properties and mental properties. In other words, it is the view that non-physical, mental properties (such as beliefs, desires and emotions) inhere in some physical bodies (at least, brains). How mental and physical properties relate causally depends on the variety of property dualism in question, and is not always a clear issue. Sub-varieties of property dualism include:


Dual aspect theory or dual-aspect monism is the view that the mental and the physical are two aspects of, or perspectives on, the same substance. (Thus it is a mixed position, which is monistic in some respects). In modern philosophical writings, the theory's relationship to neutral monism has become somewhat ill-defined, but one proffered distinction says that whereas neutral monism allows the context of a given group of neutral elements and the relationships into which they enter to determine whether the group can be thought of as mental, physical, both, or neither, dual-aspect theory suggests that the mental and the physical are manifestations (or aspects) of some underlying substance, entity or process that is itself neither mental nor physical as normally understood. Various formulations of dual-aspect monism also require the mental and the physical to be complementary, mutually irreducible and perhaps inseparable (though distinct).

This is a philosophy of mind that regards the degrees of freedom between mental and physical well-being as not necessarily synonymous thus implying an experiential dualism between body and mind. An example of these disparate degrees of freedom is given by Allan Wallace who notes that it is "experientially apparent that one may be physically uncomfortable—for instance, while engaging in a strenuous physical workout—while mentally cheerful; conversely, one may be mentally distraught while experiencing physical comfort". Experiential dualism notes that our subjective experience of merely seeing something in the physical world seems qualitatively different than mental processes like grief that comes from losing a loved one. This philosophy also is a proponent of causal dualism which is defined as the dual ability for mental states and physical states to affect one another. Mental states can cause changes in physical states and vice versa.

However, unlike cartesian dualism or some other systems, experiential dualism does not posit two fundamental substances in reality: mind and matter. Rather, experiential dualism is to be understood as a conceptual framework that gives credence to the qualitative difference between the experience of mental and physical states. Experiential dualism is accepted as the conceptual framework of Madhyamaka Buddhism.

Madhayamaka Buddhism goes even further, finding fault with the monist view of physicalist philosophies of mind as well in that these generally posit matter and energy as the fundamental substance of reality. Nonetheless, this does not imply that the cartesian dualist view is correct, rather Madhyamaka regards as error any affirming view of a fundamental substance to reality.In denying the independent self-existence of all the phenomena that make up the world of our experience, the Madhyamaka view departs from both the substance dualism of Descartes and the substance monism—namely, physicalism—that is characteristic of modern science. The physicalism propounded by many contemporary scientists seems to assert that the real world is composed of physical things-in-themselves, while all mental phenomena are regarded as mere appearances, devoid of any reality in and of themselves. Much is made of this difference between appearances and reality.
Indeed, physicalism, or the idea that matter is the only fundamental substance of reality, is explicitly rejected by Buddhism.In the Madhyamaka view, mental events are no more or less real than physical events. In terms of our common-sense experience, differences of kind do exist between physical and mental phenomena. While the former commonly have mass, location, velocity, shape, size, and numerous other physical attributes, these are not generally characteristic of mental phenomena. For example, we do not commonly conceive of the feeling of affection for another person as having mass or location. These physical attributes are no more appropriate to other mental events such as sadness, a recalled image from one's childhood, the visual perception of a rose, or consciousness of any sort. Mental phenomena are, therefore, not regarded as being physical, for the simple reason that they lack many of the attributes that are uniquely characteristic of physical phenomena. Thus, Buddhism has never adopted the physicalist principle that regards only physical things as real.

In contrast to dualism, monism does not accept any fundamental divisions. The fundamentally disparate nature of reality has been central to forms of eastern philosophies for over two millennia. In Indian and Chinese philosophy, monism is integral to how experience is understood. Today, the most common forms of monism in Western philosophy are physicalist. Physicalistic monism asserts that the only existing substance is physical, in some sense of that term to be clarified by our best science. However, a variety of formulations (see below) are possible. Another form of monism, idealism, states that the only existing substance is mental. Although pure idealism, such as that of George Berkeley, is uncommon in contemporary Western philosophy, a more sophisticated variant called panpsychism, according to which mental experience and properties may be at the foundation of physical experience and properties, has been espoused by some philosophers such as Alfred North Whitehead and David Ray Griffin.

Phenomenalism is the theory that representations (or sense data) of external objects are all that exist. Such a view was briefly adopted by Bertrand Russell and many of the logical positivists during the early 20th century. A third possibility is to accept the existence of a basic substance that is neither physical nor mental. The mental and physical would then both be properties of this neutral substance. Such a position was adopted by Baruch Spinoza and was popularized by Ernst Mach in the 19th century. This neutral monism, as it is called, resembles property dualism.

Behaviorism dominated philosophy of mind for much of the 20th century, especially the first half. In psychology, behaviorism developed as a reaction to the inadequacies of introspectionism. Introspective reports on one's own interior mental life are not subject to careful examination for accuracy and cannot be used to form predictive generalizations. Without generalizability and the possibility of third-person examination, the behaviorists argued, psychology cannot be scientific. The way out, therefore, was to eliminate the idea of an interior mental life (and hence an ontologically independent mind) altogether and focus instead on the description of observable behavior.

Parallel to these developments in psychology, a philosophical behaviorism (sometimes called logical behaviorism) was developed. This is characterized by a strong verificationism, which generally considers unverifiable statements about interior mental life pointless. For the behaviorist, mental states are not interior states on which one can make introspective reports. They are just descriptions of behavior or dispositions to behave in certain ways, made by third parties to explain and predict another's behavior.

Philosophical behaviorism has fallen out of favor since the latter half of the 20th century, coinciding with the rise of cognitivism. Cognitivists reject behaviorism due to several perceived problems. For example, behaviorism could be said to be counterintuitive when it maintains that someone is talking about behavior in the event that a person is experiencing a painful headache.

Type physicalism (or type-identity theory) was developed by John Smart and Ullin Place as a direct reaction to the failure of behaviorism. These philosophers reasoned that, if mental states are something material, but not behavioral, then mental states are probably identical to internal states of the brain. In very simplified terms: a mental state "M" is nothing other than brain state "B". The mental state "desire for a cup of coffee" would thus be nothing more than the "firing of certain neurons in certain brain regions".
Despite its initial plausibility, the identity theory faces a strong challenge in the form of the thesis of multiple realizability, first formulated by Hilary Putnam. For example, not only humans, but many different species of animals can experience pain. However, it seems highly unlikely that all of these diverse organisms with the same pain experience are in the identical brain state. And if this is the case, then pain cannot be identical to a specific brain state. The identity theory is thus empirically unfounded.

On the other hand, even granted the above, it does not follow that identity theories of all types must be abandoned. According to token identity theories, the fact that a certain brain state is connected with only one mental state of a person does not have to mean that there is an absolute correlation between types of mental state and types of brain state. The type–token distinction can be illustrated by a simple example: the word "green" contains four types of letters (g, r, e, n) with two tokens (occurrences) of the letter "e" along with one each of the others.
The idea of token identity is that only particular occurrences of mental events are identical with particular occurrences or tokenings of physical events. Anomalous monism (see below) and most other non-reductive physicalisms are token-identity theories. Despite these problems, there is a renewed interest in the type identity theory today, primarily due to the influence of Jaegwon Kim.

Functionalism was formulated by Hilary Putnam and Jerry Fodor as a reaction to the inadequacies of the identity theory. Putnam and Fodor saw mental states in terms of an empirical computational theory of the mind. At about the same time or slightly after, D.M. Armstrong and David Kellogg Lewis formulated a version of functionalism that analyzed the mental concepts of folk psychology in terms of functional roles. Finally, Wittgenstein's idea of meaning as use led to a version of functionalism as a theory of meaning, further developed by Wilfrid Sellars and Gilbert Harman. Another one, psychofunctionalism, is an approach adopted by the naturalistic philosophy of mind associated with Jerry Fodor and Zenon Pylyshyn.

What all these different varieties of functionalism share in common is the thesis that mental states are characterized by their causal relations with other mental states and with sensory inputs and behavioral outputs. That is, functionalism abstracts away from the details of the physical implementation of a mental state by characterizing it in terms of non-mental functional properties. For example, a kidney is characterized scientifically by its functional role in filtering blood and maintaining certain chemical balances. From this point of view, it does not really matter whether the kidney be made up of organic tissue, plastic nanotubes or silicon chips: it is the role that it plays and its relations to other organs that define it as a kidney.

Non-reductionist philosophers hold firmly to two essential convictions with regard to mind–body relations: 1) Physicalism is true and mental states must be physical states, but 2) All reductionist proposals are unsatisfactory: mental states cannot be reduced to behavior, brain states or functional states. Hence, the question arises whether there can still be a non-reductive physicalism. Donald Davidson's anomalous monism is an attempt to formulate such a physicalism. He "thinks that when one runs across what are traditionally seen as absurdities of Reason, such as akrasia or self-deception, the personal psychology framework is not to be given up in favor of the subpersonal one, but rather must be enlarged or extended so that the rationality set out by the principle of charity can be found elsewhere."

Davidson uses the thesis of supervenience: mental states supervene on physical states, but are not reducible to them. "Supervenience" therefore describes a functional dependence: there can be no change in the mental without some change in the physical–causal reducibility between the mental and physical without ontological reducibility.

Because non-reductive physicalist theories attempt to both retain the ontological distinction between mind and body and try to solve the "surfeit of explanations puzzle" in some way; critics often see this as a paradox and point out the similarities to epiphenomenalism, in that it is the brain that is seen as the root "cause" not the mind, and the mind seems to be rendered inert.

Epiphenomenalism regards one or more mental states as the byproduct of physical brain states, having no influence on physical states. The interaction is one-way (solving the "surfeit of explanations puzzle") but leaving us with non-reducible mental states (as a byproduct of brain states) – causally reducible, but ontologically irreducible to physical states. Pain would be seen by epiphenomenaliasts as being caused by the brain state but as not having effects on other brain states, though it might have effects on other mental states (i.e. cause distress).

Weak emergentism is a form of "non-reductive physicalism" that involves a layered view of nature, with the layers arranged in terms of increasing complexity and each corresponding to its own special science. Some philosophers hold that emergent properties causally interact with more fundamental levels, while others maintain that higher-order properties simply supervene over lower levels without direct causal interaction. The latter group therefore holds a less strict, or "weaker", definition of emergentism, which can be rigorously stated as follows: a property P of composite object O is emergent if it is metaphysically impossible for another object to lack property P if that object is composed of parts with intrinsic properties identical to those in O and has those parts in an identical configuration.

Sometimes emergentists use the example of water having a new property when Hydrogen H and Oxygen O combine to form HO (water). In this example there "emerges" a new property of a transparent liquid that would not have been predicted by understanding hydrogen and oxygen as gases. This is analogous to physical properties of the brain giving rise to a mental state. Emergentists try to solve the notorious mind–body gap this way. One problem for emergentism is the idea of "causal closure" in the world that does not allow for a mind-to-body causation.

If one is a materialist and believes that all aspects of our common-sense psychology will find reduction to a mature cognitive neuroscience, and that non-reductive materialism is mistaken, then one can adopt a final, more radical position: eliminative materialism.

There are several varieties of eliminative materialism, but all maintain that our common-sense "folk psychology" badly misrepresents the nature of some aspect of cognition. Eliminativists such as Patricia and Paul Churchland argue that while folk psychology treats cognition as fundamentally sentence-like, the non-linguistic vector/matrix model of neural network theory or connectionism will prove to be a much more accurate account of how the brain works.

The Churchlands often invoke the fate of other, erroneous popular theories and ontologies that have arisen in the course of history. For example, Ptolemaic astronomy served to explain and roughly predict the motions of the planets for centuries, but eventually this model of the solar system was eliminated in favor of the Copernican model. The Churchlands believe the same eliminative fate awaits the "sentence-cruncher" model of the mind in which thought and behavior are the result of manipulating sentence-like states called "propositional attitudes".

Some philosophers take an epistemic approach and argue that the mind–body problem is currently unsolvable, and perhaps will always remain unsolvable to human beings. This is usually termed New mysterianism. Colin McGinn holds that human beings are cognitively closed in regards to their own minds. According to McGinn human minds lack the concept-forming procedures to fully grasp how mental properties such as consciousness arise from their causal basis. An example would be how an elephant is cognitively closed in regards to particle physics.

A more moderate conception has been expounded by Thomas Nagel, which holds that the mind–body problem is currently unsolvable at the present stage of scientific development and that it might take a future scientific paradigm shift or revolution to bridge the explanatory gap. Nagel posits that in the future a sort of "objective phenomenology" might be able to bridge the gap between subjective conscious experience and its physical basis.

Each attempt to answer the mind–body problem encounters substantial problems. Some philosophers argue that this is because there is an underlying conceptual confusion. These philosophers, such as Ludwig Wittgenstein and his followers in the tradition of linguistic criticism, therefore reject the problem as illusory. They argue that it is an error to ask how mental and biological states fit together. Rather it should simply be accepted that human experience can be described in different ways—for instance, in a mental and in a biological vocabulary. Illusory problems arise if one tries to describe the one in terms of the other's vocabulary or if the mental vocabulary is used in the wrong contexts. This is the case, for instance, if one searches for mental states of the brain. The brain is simply the wrong context for the use of mental vocabulary—the search for mental states of the brain is therefore a category error or a sort of fallacy of reasoning.

Today, such a position is often adopted by interpreters of Wittgenstein such as Peter Hacker. However, Hilary Putnam, the originator of functionalism, has also adopted the position that the mind–body problem is an illusory problem which should be dissolved according to the manner of Wittgenstein.

The thesis of physicalism is that the mind is part of the material (or physical) world. Such a position faces the problem that the mind has certain properties that no other material thing seems to possess. Physicalism must therefore explain how it is possible that these properties can nonetheless emerge from a material thing. The project of providing such an explanation is often referred to as the "naturalization of the mental". Some of the crucial problems that this project attempts to resolve include the existence of qualia and the nature of intentionality.

Many mental states seem to be experienced subjectively in different ways by different individuals. And it is characteristic of a mental state that it has some experiential "quality", e.g. of pain, that it hurts. However, the sensation of pain between two individuals may not be identical, since no one has a perfect way to measure how much something hurts or of describing exactly how it feels to hurt. Philosophers and scientists therefore ask where these experiences come from. The existence of cerebral events, in and of themselves, cannot explain why they are accompanied by these corresponding qualitative experiences. The puzzle of why many cerebral processes occur with an accompanying experiential aspect in consciousness seems impossible to explain.

Yet it also seems to many that science will eventually have to explain such experiences. This follows from an assumption about the possibility of reductive explanations. According to this view, if an attempt can be successfully made to explain a phenomenon reductively (e.g., water), then it can be explained why the phenomenon has all of its properties (e.g., fluidity, transparency). In the case of mental states, this means that there needs to be an explanation of why they have the property of being experienced in a certain way.

The 20th-century German philosopher Martin Heidegger criticized the ontological assumptions underpinning such a reductive model, and claimed that it was impossible to make sense of experience in these terms. This is because, according to Heidegger, the nature of our subjective experience and its "qualities" is impossible to understand in terms of Cartesian "substances" that bear "properties". Another way to put this is that the very concept of qualitative experience is incoherent in terms of—or is semantically incommensurable with the concept of—substances that bear properties.

This problem of explaining introspective first-person aspects of mental states and consciousness in general in terms of third-person quantitative neuroscience is called the explanatory gap. There are several different views of the nature of this gap among contemporary philosophers of mind. David Chalmers and the early Frank Jackson interpret the gap as ontological in nature; that is, they maintain that qualia can never be explained by science because physicalism is false. There are two separate categories involved and one cannot be reduced to the other. An alternative view is taken by philosophers such as Thomas Nagel and Colin McGinn. According to them, the gap is epistemological in nature. For Nagel, science is not yet able to explain subjective experience because it has not yet arrived at the level or kind of knowledge that is required. We are not even able to formulate the problem coherently. For McGinn, on other hand, the problem is one of permanent and inherent biological limitations. We are not able to resolve the explanatory gap because the realm of subjective experiences is cognitively closed to us in the same manner that quantum physics is cognitively closed to elephants. Other philosophers liquidate the gap as purely a semantic problem. This semantic problem, of course, led to the famous "Qualia Question", which is: "Does Red cause Redness"?

Intentionality is the capacity of mental states to be directed towards ("about") or be in relation with something in the external world. This property of mental states entails that they have contents and semantic referents and can therefore be assigned truth values. When one tries to reduce these states to natural processes there arises a problem: natural processes are not true or false, they simply happen. It would not make any sense to say that a natural process is true or false. But mental ideas or judgments are true or false, so how then can mental states (ideas or judgments) be natural processes? The possibility of assigning semantic value to ideas must mean that such ideas are about facts. Thus, for example, the idea that Herodotus was a historian refers to Herodotus and to the fact that he was a historian. If the fact is true, then the idea is true; otherwise, it is false. But where does this relation come from? In the brain, there are only electrochemical processes and these seem not to have anything to do with Herodotus.

Philosophy of perception is concerned with the nature of perceptual experience and the status of perceptual objects, in particular how perceptual experience relates to appearances and beliefs about the world. The main contemporary views within philosophy of perception include naive realism, enactivism and representational views.

Humans are corporeal beings and, as such, they are subject to examination and description by the natural sciences. Since mental processes are intimately related to bodily processes, the descriptions that the natural sciences furnish of human beings play an important role in the philosophy of mind. There are many scientific disciplines that study processes related to the mental. The list of such sciences includes: biology, computer science, cognitive science, cybernetics, linguistics, medicine, pharmacology, and psychology.

The theoretical background of biology, as is the case with modern natural sciences in general, is fundamentally materialistic. The objects of study are, in the first place, physical processes, which are considered to be the foundations of mental activity and behavior. The increasing success of biology in the explanation of mental phenomena can be seen by the absence of any empirical refutation of its fundamental presupposition: "there can be no change in the mental states of a person without a change in brain states."

Within the field of neurobiology, there are many subdisciplines that are concerned with the relations between mental and physical states and processes: Sensory neurophysiology investigates the relation between the processes of perception and stimulation. Cognitive neuroscience studies the correlations between mental processes and neural processes. Neuropsychology describes the dependence of mental faculties on specific anatomical regions of the brain. Lastly, evolutionary biology studies the origins and development of the human nervous system and, in as much as this is the basis of the mind, also describes the ontogenetic and phylogenetic development of mental phenomena beginning from their most primitive stages. Evolutionary biology furthermore places tight constraints on any philosophical theory of the mind, as the gene-based mechanism of natural selection does not allow any giant leaps in the development of neural complexity or neural software but only incremental steps over long time periods.

The methodological breakthroughs of the neurosciences, in particular the introduction of high-tech neuroimaging procedures, has propelled scientists toward the elaboration of increasingly ambitious research programs: one of the main goals is to describe and comprehend the neural processes which correspond to mental functions (see: neural correlate). Several groups are inspired by these advances.

Computer science concerns itself with the automatic processing of information (or at least with physical systems of symbols to which information is assigned) by means of such things as computers. From the beginning, computer programmers have been able to develop programs that permit computers to carry out tasks for which organic beings need a mind. A simple example is multiplication. It is not clear whether computers could be said to have a mind. Could they, someday, come to have what we call a mind? This question has been propelled into the forefront of much philosophical debate because of investigations in the field of artificial intelligence (AI).

Within AI, it is common to distinguish between a modest research program and a more ambitious one: this distinction was coined by John Searle in terms of a weak AI and strong AI. The exclusive objective of "weak AI", according to Searle, is the successful simulation of mental states, with no attempt to make computers become conscious or aware, etc. The objective of strong AI, on the contrary, is a computer with consciousness similar to that of human beings. The program of strong AI goes back to one of the pioneers of computation Alan Turing. As an answer to the question "Can computers think?", he formulated the famous Turing test. Turing believed that a computer could be said to "think" when, if placed in a room by itself next to another room that contained a human being and with the same questions being asked of both the computer and the human being by a third party human being, the computer's responses turned out to be indistinguishable from those of the human. Essentially, Turing's view of machine intelligence followed the behaviourist model of the mind—intelligence is as intelligence does. The Turing test has received many criticisms, among which the most famous is probably the Chinese room thought experiment formulated by Searle.

The question about the possible sensitivity (qualia) of computers or robots still remains open. Some computer scientists believe that the specialty of AI can still make new contributions to the resolution of the "mind–body problem". They suggest that based on the reciprocal influences between software and hardware that takes place in all computers, it is possible that someday theories can be discovered that help us to understand the reciprocal influences between the human mind and the brain (wetware).

Psychology is the science that investigates mental states directly. It uses generally empirical methods to investigate concrete mental states like joy, fear or obsessions. Psychology investigates the laws that bind these mental states to each other or with inputs and outputs to the human organism.

An example of this is the psychology of perception. Scientists working in this field have discovered general principles of the perception of forms. A law of the psychology of forms says that objects that move in the same direction are perceived as related to each other. This law describes a relation between visual input and mental perceptual states. However, it does not suggest anything about the nature of perceptual states. The laws discovered by psychology are compatible with all the answers to the mind–body problem already described.

Cognitive science is the interdisciplinary scientific study of the mind and its processes. It examines what cognition is, what it does, and how it works. It includes research on intelligence and behavior, especially focusing on how information is represented, processed, and transformed (in faculties such as perception, language, memory, reasoning, and emotion) within nervous systems (human or other animal) and machines (e.g. computers). Cognitive science consists of multiple research disciplines, including psychology, artificial intelligence, philosophy, neuroscience, linguistics, anthropology, sociology, and education. It spans many levels of analysis, from low-level learning and decision mechanisms to high-level logic and planning; from neural circuitry to modular brain organisation. Rowlands argues that cognition is enactive, embodied, embedded, affective and (potentially) extended. The position is taken that the "classical sandwich" of cognition sandwiched between perception and action is artificial; cognition has to be seen as a product of a strongly coupled interaction that cannot be divided this way.

Most of the discussion in this article has focused on one style or tradition of philosophy in modern Western culture, usually called analytic philosophy (sometimes described as Anglo-American philosophy). Many other schools of thought exist, however, which are sometimes subsumed under the broad (and vague) label of continental philosophy. In any case, though topics and methods here are numerous, in relation to the philosophy of mind the various schools that fall under this label (phenomenology, existentialism, etc.) can globally be seen to differ from the analytic school in that they focus less on language and logical analysis alone but also take in other forms of understanding human existence and experience. With reference specifically to the discussion of the mind, this tends to translate into attempts to grasp the concepts of thought and perceptual experience in some sense that does not merely involve the analysis of linguistic forms.

Immanuel Kant's "Critique of Pure Reason", first published in 1781 and presented again with major revisions in 1787, represents a significant intervention into what will later become known as the philosophy of mind. Kant's first critique is generally recognized as among the most significant works of modern philosophy in the West. Kant is a figure whose influence is marked in both continental and analytic/Anglo-American philosophy. Kant's work develops an in-depth study of transcendental consciousness, or the life of the mind as conceived through universal categories of consciousness.

In Georg Wilhelm Friedrich Hegel's "Philosophy of Mind" (frequently translated as "Philosophy of Spirit" or Geist), the third part of his "Encyclopedia of the Philosophical Sciences", Hegel discusses three distinct types of mind: the "subjective mind/spirit", the mind of an individual; the "objective mind/spirit", the mind of society and of the State; and the "Absolute mind/spirit", the position of religion, art, and philosophy. See also Hegel's "The Phenomenology of Spirit". Nonetheless, Hegel's work differs radically from the style of Anglo-American philosophy of mind.

In 1896, Henri Bergson made in "Matter and Memory" "Essay on the relation of body and spirit" a forceful case for the ontological difference of body and mind by reducing the problem to the more definite one of memory, thus allowing for a solution built on the "empirical test case" of aphasia.

In modern times, the two main schools that have developed in response or opposition to this Hegelian tradition are phenomenology and existentialism. Phenomenology, founded by Edmund Husserl, focuses on the contents of the human mind (see noema) and how processes shape our experiences. Existentialism, a school of thought founded upon the work of Søren Kierkegaard, focuses on Human predicament and how people deal with the situation of being alive. Existential-phenomenology represents a major branch of continental philosophy (they are not contradictory), rooted in the work of Husserl but expressed in its fullest forms in the work of Martin Heidegger, Jean-Paul Sartre, Simone de Beauvoir and Maurice Merleau-Ponty. See Heidegger's "Being and Time", Merleau-Ponty's "Phenomenology of Perception", Sartre's "Being and Nothingness", and Simone de Beauvoir's "The Second Sex".

There are countless subjects that are affected by the ideas developed in the philosophy of mind. Clear examples of this are the nature of death and its definitive character, the nature of emotion, of perception and of memory. Questions about what a person is and what his or her identity consists of also have much to do with the philosophy of mind. There are two subjects that, in connection with the philosophy of the mind, have aroused special attention: free will and the self.

In the context of philosophy of mind, the problem of free will takes on renewed intensity. This is certainly the case, at least, for materialistic determinists. According to this position, natural laws completely determine the course of the material world. Mental states, and therefore the will as well, would be material states, which means human behavior and decisions would be completely determined by natural laws. Some take this reasoning a step further: people cannot determine by themselves what they want and what they do. Consequently, they are not free.

This argumentation is rejected, on the one hand, by the compatibilists. Those who adopt this position suggest that the question "Are we free?" can only be answered once we have determined what the term "free" means. The opposite of "free" is not "caused" but "compelled" or "coerced". It is not appropriate to identify freedom with indetermination. A free act is one where the agent could have done otherwise if it had chosen otherwise. In this sense a person can be free even though determinism is true. The most important compatibilist in the history of the philosophy was David Hume. More recently, this position is defended, for example, by Daniel Dennett.

On the other hand, there are also many incompatibilists who reject the argument because they believe that the will is free in a stronger sense called libertarianism. These philosophers affirm the course of the world is either a) not completely determined by natural law where natural law is intercepted by physically independent agency, b) determined by indeterministic natural law only, or c) determined by indeterministic natural law in line with the subjective effort of physically non-reducible agency. Under Libertarianism, the will does not have to be deterministic and, therefore, it is potentially free. Critics of the second proposition (b) accuse the incompatibilists of using an incoherent concept of freedom. They argue as follows: if our will is not determined by anything, then we desire what we desire by pure chance. And if what we desire is purely accidental, we are not free. So if our will is not determined by anything, we are not free.

The philosophy of mind also has important consequences for the concept of "self". If by "self" or "I" one refers to an essential, immutable nucleus of the "person", some modern philosophers of mind, such as Daniel Dennett believe that no such thing exists. According to Dennett and other contemporaries, the self is considered an illusion. The idea of a self as an immutable essential nucleus derives from the idea of an immaterial soul. Such an idea is unacceptable to modern philosophers with physicalist orientations and their general skepticism of the concept of "self" as postulated by David Hume, who could never catch himself "not" doing, thinking or feeling anything. However, in the light of empirical results from developmental psychology, developmental biology and neuroscience, the idea of an essential inconstant, material nucleus—an integrated representational system distributed over changing patterns of synaptic connections—seems reasonable.



</doc>
<doc id="59350035" url="https://en.wikipedia.org/wiki?curid=59350035" title="Mind in eastern philosophy">
Mind in eastern philosophy

The study of the mind in Eastern philosophy has parallels to the Western study of the Philosophy of mind as a branch of philosophy that studies the nature of the mind. Dualism and monism are the two central schools of thought on the mind–body problem in the Western tradition, although nuanced views have arisen that do not fit one or the other category neatly. Dualism is found in both Eastern and Western traditions (in the Sankhya and Yoga schools of Hindu philosophy as well as Plato) but its entry into Western philosophy was thanks to René Descartes in the 17th century. This article on mind in eastern philosophy deals with this subject from the standpoint of eastern philosophy which is historically strongly separated from the Western tradition and its approach to the Western philosophy of mind.

Substance Dualism is a common feature of several orthodox Hindu schools including the Sāṅkhya, Nyāya, Yoga and Dvaita Vedanta. In these schools a clear difference is drawn between matter and a non-material soul, which is eternal and undergoes samsara, a cycle of death and rebirth. The Nyāya school argued that qualities such as cognition and desire are inherent qualities which are not possessed by anything solely material, and therefore by process of elimination must belong to a non-material self, the atman. Many of these schools see their spiritual goal as moksha, liberation from the cycle of reincarnation.

In the Advaita Vedanta of the 8th century Indian philosopher Śaṅkara, the mind, body and world are all held to be the same unchanging eternal conscious entity called Brahman. Advaita, which means non-dualism, holds the view that all that exists is pure absolute consciousness. The fact that the world seems to be made up of changing entities is an illusion, or Maya. The only thing that exists is Brahman, which is described as Satchitananda (Being, consciousness and bliss). Advaita Vedanta is best described by a verse which states "Brahman is alone True, and this world of plurality is an error; the individual self is not different from Brahman."

Another form of monistic Vedanta is Vishishtadvaita (qualified non-dualism) as posited by the eleventh century philosopher Ramanuja. Ramanuja criticized Advaita Vedanta by arguing that consciousness is always intentional and that it is also always a property of something. Ramanuja's Brahman is defined by a multiplicity of qualities and properties in a single monistic entity. This doctrine is called "samanadhikaranya" (several things in a common substrate).

Arguably the first exposition of empirical materialism in the history of philosophy is in the Cārvāka school (also called Lokāyata). The Cārvāka school rejected the existence of anything but matter (which they defined as being made up of the four elements), including God and the soul. Therefore, they held that even consciousness was nothing but a construct made up of atoms. A section of the Cārvāka school believed in a material soul made up of air or breath, but since this also was a form of matter, it was not said to survive death.

Buddhist teachings describe that the mind manifests moment-to-moment as sense impressions and mental phenomena that are continuously changing. The moment-by-moment manifestation of the mind-stream has been described as happening in every person all the time, even in a scientist who analyses various phenomena in the world, or analyses the material body including the organ brain. The manifestation of the mind-stream is also described as being influenced by physical laws, biological laws, psychological laws, volitional laws, and universal laws.

A salient feature of Buddhist philosophy which sets it apart from Indian orthodoxy is the centrality of the doctrine of not-self (Pāli. anatta, Skt. anātman). The Buddha's not-self doctrine sees humans as an impermanent composite of five psychological and physical aspects instead of a single fixed self. In this sense, what is called ego or the self is merely a convenient fiction, an illusion that does not apply to anything real but to an erroneous way of looking at the ever-changing stream of five interconnected aggregate factors. The relationship between these aggregates is said to be one of dependent-arising (pratītyasamutpāda). This means that all things, including mental events, arise co-dependently from a plurality of other causes and conditions. This seems to reject both causal determinist and epiphenomenalist conceptions of mind.

Three centuries after the death of the Buddha (c. 150 BCE) saw the growth of a large body of literature called the Abhidharma in several contending Buddhist schools. In the Abhidharmic analysis of mind, the ordinary thought is defined as prapañca ('conceptual proliferation'). According to this theory, perceptual experience is bound up in multiple conceptualizations (expectations, judgments and desires). This proliferation of conceptualizations form our illusory superimposition of concepts like self and other upon an ever-changing stream of aggregate phenomena.
In this conception of mind no strict distinction is made between the conscious faculty and the actual sense perception of various phenomena. Consciousness is instead said to be divided into six sense modalities, five for the five senses and sixth for perception of mental phenomena. The arising of cognitive awareness is said to depend on sense perception, awareness of the mental faculty itself which is termed mental or 'introspective awareness' ("manovijñāna") and attention ("āvartana"), the picking out of objects out of the constantly changing stream of sensory impressions.

Rejection of a permanent agent eventually led to the philosophical problems of the seeming continuity of mind and also of explaining how rebirth and karma continue to be relevant doctrines without an eternal mind. This challenge was met by the Theravāda school by introducing the concept of mind as a factor of existence. This "life-stream" (Bhavanga-sota) is an undercurrent forming the condition of being. The continuity of a karmic "person" is therefore assured in the form of a mindstream (citta-santana), a series of flowing mental moments arising from the subliminal life-continuum mind (Bhavanga-citta), mental content, and attention.

The Sautrāntika school held a form of phenomenalism that saw the world as imperceptible. It held that external objects exist only as a support for cognition, which can only apprehend mental representations. This influenced the later Yogācāra school of Mahayana Buddhism. The Yogācāra school is often called the mind-only school because of its internalist stance that consciousness is the ultimate existing reality. The works of Vasubandhu have often been interpreted as arguing for some form of Idealism. Vasubandhu uses the dream argument and a mereological refutation of atomism to attack the reality of external objects as anything other than mental entities. Scholarly interpretations of Vasubandhu's philosophy vary widely, and include phenomenalism, neutral monism and realist phenomenology.

The Indian Mahayana schools were divided on the issue of the possibility of reflexive awareness ("svasaṃvedana"). Dharmakīrti accepted the idea of reflexive awareness as expounded by the Yogācāra school, comparing it to a lamp that illuminates itself while also illuminating other objects. This was strictly rejected by Mādhyamika scholars like Candrakīrti. Since in the philosophy of the Mādhyamika all things and mental events are characterized by emptiness, they argued that consciousness could not be an inherently reflexive ultimate reality since that would mean it was self-validating and therefore not characterized by emptiness. These views were ultimately reconciled by the 8th century thinker Śāntarakṣita. In Śāntarakṣita's synthesis he adopts the idealist Yogācāra views of reflexive awareness as a conventional truth into the structure of the two truths doctrine. Thus he states: "By relying on the Mind-Only system, know that external entities do not exist. And by relying on this Middle Way system, know that no self exists at all, even in that [mind]." 

The Yogācāra school also developed the theory of the repository consciousness ("ālayavijñāna") to explain continuity of mind in rebirth and accumulation of karma. This repository consciousness acts as a storehouse for karmic seeds (bija) when all other senses are absent during the process of death and rebirth as well as being the causal potentiality of dharmic phenomena. Thus according to B. Alan Wallace: 
No constituents of the body—in the brain or elsewhere—transform into mental states and processes. Such subjective experiences do not emerge from the body, but neither do they emerge from nothing. Rather, all objective mental appearances arise from the substrate, and all subjective mental states and processes arise from the substrate consciousness.

Tibetan Buddhist theories of mind evolved directly from the Indian Mahayana views. Thus the founder of the Gelug school, Je Tsongkhapa discusses the Yogācāra system of the Eight Consciousnesses in his "Explanation of the Difficult Points". He would later come to repudiate Śāntarakṣita's pragmatic idealism. 
According to the 14th Dalai Lama the mind can be defined "as an entity that has the nature of mere experience, that is, 'clarity and knowing'. It is the knowing nature, or agency, that is called mind, and this is non-material." The simultaneously dual nature of mind is as follows:
The 14th Dalai Lama has also explicitly laid out his theory of mind as experiential dualism which is described above under the different types of dualism.

Because Tibetan philosophy of mind is ultimately soteriological, it focuses on meditative practices such as Dzogchen and Mahamudra that allow a practitioner to experience the true reflexive nature of their mind directly. This unobstructed knowledge of one's primordial, empty and non-dual Buddha nature is called rigpa. The mind's innermost nature is described among various schools as pure luminosity or "clear light" ('od gsal) and is often compared to a crystal ball or a mirror. Sogyal Rinpoche speaks of mind thus:
"Imagine a sky, empty, spacious, and pure from the beginning; its essence is like this. Imagine a sun, luminous, clear, unobstructed, and spontaneously present; its nature is like this."

The central issue in Chinese Zen philosophy of mind is in the difference between the pure and awakened mind and the defiled mind. Chinese Chan master Huangpo described the mind as without beginning and without form or limit while the defiled mind was that which was obscured by attachment to form and concepts. The pure Buddha-mind is thus able to see things "as they truly are", as absolute and non-dual "thusness" (Tathatā). This non-conceptual seeing also includes the paradoxical fact that there is no difference between a defiled and a pure mind, as well as no difference between samsara and nirvana.

In the Shobogenzo, the Japanese philosopher Dogen argued that body and mind are neither ontologically nor phenomenologically distinct but are characterized by a oneness called "shin jin" (bodymind). According to Dogen, "casting off body and mind" ("Shinjin datsuraku") in zazen will allow one to experience things-as-they-are ("genjokoan") which is the nature of original enlightenment ("hongaku").



</doc>
<doc id="161999" url="https://en.wikipedia.org/wiki?curid=161999" title="Idea">
Idea

In philosophy, ideas are usually taken as mental representational images of some object. Ideas can also be abstract concepts that do not present as mental images. Many philosophers have considered ideas to be a fundamental ontological category of being. The capacity to create and understand the meaning of ideas is considered to be an essential and defining feature of human beings. In a popular sense, an idea arises in a reflexive, spontaneous manner, even without thinking or serious reflection, for example, when we talk about the "idea" of a person or a place. A new or original idea can often lead to innovation.

The word "idea" comes from Greek ἰδέα "idea" "form, pattern," from the root of ἰδεῖν "idein", "to see." 

One view on the nature of ideas is that there exist some ideas (called "innate ideas") which are so general and abstract that they could not have arisen as a representation of an object of our perception but rather were in some sense always present. These are distinguished from "adventitious ideas" which are images or concepts which are accompanied by the judgment that they are caused or occasioned by an external object.

Another view holds that we only discover ideas in the same way that we discover the real world, from personal experiences. The view that humans acquire all or almost all their behavioral traits from nurture (life experiences) is known as "tabula rasa" ("blank slate"). Most of the confusions in the way ideas arise is at least in part due to the use of the term "idea" to cover both the representation perceptics and the object of conceptual thought. This can be always illustrated in terms of the scientific doctrines of innate ideas, "concrete ideas versus abstract ideas", as well as "simple ideas versus complex ideas".

Plato in Ancient Greece was one of the earliest philosophers to provide a detailed discussion of ideas and of the thinking process (in Plato's Greek the word "idea" carries a rather different sense from our modern English term). Plato argued in dialogues such as the "Phaedo", "Symposium", "Republic", and "Timaeus" that there is a realm of ideas or forms ("eidei"), which exist independently of anyone who may have thoughts on these ideas, and it is the ideas which distinguish mere opinion from knowledge, for unlike material things which are transient and liable to contrary properties, ideas are unchanging and nothing but just what they are. Consequently, Plato seems to assert forcefully that material things can only be the objects of opinion; real knowledge can only be had of unchanging ideas. Furthermore, ideas for Plato appear to serve as universals; consider the following passage from the "Republic":
Descartes often wrote of the meaning of "idea" as an image or representation, often but not necessarily "in the mind", which was well known in the vernacular. Despite that Descartes is usually credited with the invention of the non-Platonic use of the term, he at first followed this vernacular use. In his "Meditations on First Philosophy" he says, "Some of my thoughts are like images of things, and it is to these alone that the name 'idea' properly belongs." He sometimes maintained that ideas were innate and uses of the term "idea" diverge from the original primary scholastic use. He provides multiple non-equivalent definitions of the term, uses it to refer to as many as six distinct kinds of entities, and divides "ideas" inconsistently into various genetic categories. For him knowledge took the form of ideas and philosophical investigation is the deep consideration of these entities.

In striking contrast to Plato's use of idea is that of John Locke. In his Introduction to An Essay Concerning Human Understanding, Locke defines "idea" as "that term which, I think, serves best to stand for whatsoever is the object of the understanding when a man thinks, I have used it to express whatever is meant by phantasm, notion, species, or whatever it is which the mind can be employed about in thinking; and I could not avoid frequently using it." He said he regarded the book necessary to examine our own abilities and see what objects our understandings were, or were not, fitted to deal with. In his philosophy other outstanding figures followed in his footsteps — Hume and Kant in the 18th century, Arthur Schopenhauer in the 19th century, and Bertrand Russell, Ludwig Wittgenstein, and Karl Popper in the 20th century. Locke always believed in "good sense" — not pushing things to extremes and on taking fully into account the plain facts of the matter. He considered his common-sense ideas "good-tempered, moderate, and down-to-earth."

As John Locke studied humans in his work “An Essay Concerning Human Understanding” he continually referenced Descartes for ideas as he asked this fundamental question: “When we are concerned with something about which we have no certain knowledge, what rules or standards should guide how confident we allow ourselves to be that our opinions are right?” A simpler way of putting it is how do humans know ideas, and what are the different types of ideas. An idea to Locke “can simply mean some sort of brute experience.” He shows that there are “No innate principles in the mind.”. Thus, he concludes that “our ideas are all experiential in nature.” An experience can either be a sensation or a reflection: “consider whether there are any innate ideas in the mind before any are brought in by the impression from sensation or reflection.” Therefore, an idea was an experience in which the human mind apprehended something.

In a Lockean view, there are really two types of ideas: complex and simple. Simple ideas are the building blocks for much more complex ideas, and “While the mind is wholly passive in the reception of simple ideas, it is very active in the building of complex ideas…” Complex ideas, therefore, can either be modes, substances, or relations. Modes are when ideas are combined in order to convey new information. For instance, David Banach gives the example of beauty as a mode. He says that it is the combination of color and form. Substances, however, is different. Substances are certain objects, that can either be dogs, cats, or tables. And relations represent the relationship between two or more ideas. In this way, Locke did, in fact, answer his own questions about ideas and humans.

Hume differs from Locke by limiting "idea" to the more or less vague mental reconstructions of perceptions, the perceptual process being described as an "impression." Hume shared with Locke the basic empiricist premise that it is only from life experiences (whether their own or others') that humans' knowledge of the existence of anything outside of themselves can be ultimately derived, that they shall carry on doing what they are prompted to do by their emotional drives of varying kinds. In choosing the means to those ends, they shall follow their accustomed associations of ideas. Hume has contended and defended the notion that "reason alone is merely the 'slave of the passions'." 

Immanuel Kant defines an "idea" as opposed to a "concept". "Regulative ideas" are ideals that one must tend towards, but by definition may not be completely realized. Liberty, according to Kant, is an idea. The autonomy of the rational and universal subject is opposed to the determinism of the empirical subject. Kant felt that it is precisely in knowing its limits that philosophy exists. The business of philosophy he thought was not to give rules, but to analyze the private judgements of good common sense.

Whereas Kant declares limits to knowledge ("we can never know the thing in itself"), in his epistemological work, Rudolf Steiner sees "ideas" as "objects of experience" which the mind apprehends, much as the eye apprehends light. In "Goethean Science" (1883), he declares, "Thinking ... is no more and no less an organ of perception than the eye or ear. Just as the eye perceives colors and the ear sounds, so thinking perceives ideas." He holds this to be the premise upon which Goethe made his natural-scientific observations.

Wundt widens the term from Kant's usage to include "conscious representation of some object or process of the external world". In so doing, he includes not only ideas of memory and imagination, but also perceptual processes, whereas other psychologists confine the term to the first two groups. One of Wundt's main concerns was to investigate conscious processes in their own context by experiment and introspection. He regarded both of these as "exact methods", interrelated in that experimentation created optimal conditions for introspection. Where the experimental method failed, he turned to other "objectively valuable aids", specifically to "those products of cultural communal life which lead one to infer particular mental motives. Outstanding among these are speech, myth, and social custom." Wundt designed the basic mental activity apperception — a unifying function which should be understood as an activity of the will. Many aspects of his empirical physiological psychology are used today. One is his principles of mutually enhanced contrasts and of assimilation and dissimilation (i.e. in color and form perception and his advocacy of "objective" methods of expression and of recording results, especially in language. Another is the principle of heterogony of ends — that multiply motivated acts lead to unintended side effects which in turn become motives for new actions.

C. S. Peirce published the first full statement of pragmatism in his important works "" (1878) and "" (1877). In "How to Make Our Ideas Clear" he proposed that a "clear idea" (in his study he uses concept and "idea" as synonymic) is defined as one, when it is apprehended such as it will be recognized wherever it is met, and no other will be mistaken for it. If it fails of this clearness, it is said to be obscure. He argued that to understand an idea clearly we should ask ourselves what difference its application would make to our evaluation of a proposed solution to the problem at hand. Pragmatism (a term he appropriated for use in this context), he defended, was a method for ascertaining the meaning of terms (as a theory of meaning). The originality of his ideas is in their rejection of what was accepted as a view and understanding of knowledge by scientists for some 250 years, i.e. that, he pointed, knowledge was an impersonal fact. Peirce contended that we acquire knowledge as "participants", not as "spectators". He felt "the real", sooner or later, is information acquired through ideas and knowledge with the application of logical reasoning would finally result in. He also published many papers on logic in relation to "ideas".

G. F. Stout and J. M. Baldwin, in the "Dictionary of Philosophy and Psychology", define "idea" as "the reproduction with a more or less adequate image, of an object not actually present to the senses." They point out that an idea and a perception are by various authorities contrasted in various ways. "Difference in degree of intensity", "comparative absence of bodily movement on the part of the subject", "comparative dependence on mental activity", are suggested by psychologists as characteristic of an idea as compared with a perception.

It should be observed that an idea, in the narrower and generally accepted sense of a mental reproduction, is frequently composite. That is, as in the example given above of the idea of a chair, a great many objects, differing materially in detail, all call a single idea. When a man, for example, has obtained an idea of chairs in general by comparison with which he can say "This is a chair, that is a stool", he has what is known as an "abstract idea" distinct from the reproduction in his mind of any particular chair (see abstraction). Furthermore, a complex idea may not have any corresponding physical object, though its particular constituent elements may severally be the reproductions of actual perceptions. Thus the idea of a centaur is a complex mental picture composed of the ideas of man and horse, that of a mermaid of a woman and a fish.

Diffusion studies explore the spread of ideas from culture to culture. Some anthropological theories hold that all cultures imitate ideas from one or a few original cultures, the Adam of the Bible, or several cultural circles that overlap. Evolutionary diffusion theory holds that cultures are influenced by one another but that similar ideas can be developed in isolation.

In the mid-20th century, social scientists began to study how and why ideas spread from one person or culture to another. Everett Rogers pioneered diffusion of innovations studies, using research to prove factors in adoption and profiles of adopters of ideas. In 1976, in his book "The Selfish Gene", Richard Dawkins suggested applying biological evolutionary theories to the spread of ideas. He coined the term "meme" to describe an abstract unit of selection, equivalent to the gene in evolutionary biology.

James Boswell recorded Samuel Johnson's opinion about ideas. Johnson claimed that they are mental images or internal visual pictures. As such, they have no relation to words or the concepts which are designated by verbal names.

To protect the cause of invention and innovation, the legal constructions of Copyrights and Patents were established. Patent law regulates various aspects related to the functional manifestation of inventions based on new ideas or incremental improvements to existing ones. Thus, patents have a direct relationship to ideas.

In some cases, authors can be granted limited legal monopolies on the manner in which certain works are expressed. This is known colloquially as copyright, although the term intellectual property is used mistakenly in place of "copyright". Copyright law regulating the aforementioned monopolies generally does not cover the actual ideas. The law does not bestow the legal status of property upon ideas per se. Instead, laws purport to regulate events related to the usage, copying, production, sale and other forms of exploitation of the fundamental expression of a work, that may or may not carry ideas. Copyright law is fundamentally different from patent law in this respect: patents do grant monopolies on ideas (more on this below).

A copyright is meant to regulate some aspects of the usage of expressions of a work, "not" an idea. Thus, copyrights have a negative relationship to ideas.

Work means a tangible medium of expression. It may be an original or derivative work of art, be it literary, dramatic, musical recitation, artistic, related to sound recording, etc. In (at least) countries adhering to the Berne Convention, copyright automatically starts covering the work upon the original creation and fixation thereof, without any extra steps. While creation usually involves an idea, the idea in itself does not suffice for the purposes of claiming copyright. 
Confidentiality and nondisclosure agreements are legal instruments that assist corporations and individuals in keeping ideas from escaping to the general public. Generally, these instruments are covered by contract law.




</doc>
<doc id="37080" url="https://en.wikipedia.org/wiki?curid=37080" title="Thought">
Thought

Thought encompasses an "aim-oriented flow of ideas and associations that can lead to a reality-oriented conclusion". Although thinking is an activity of an existential value for humans, there is no consensus as to how it is defined or understood.

Because thought underlies many human actions and interactions, understanding its physical and metaphysical origins and its effects has been a longstanding goal of many academic disciplines including philosophy, linguistics, psychology, neuroscience, artificial intelligence, biology, sociology and cognitive science.

Thinking allows humans to make sense of, interpret, represent or model the world they experience, and to make predictions about that world. It is therefore helpful to an organism with needs, objectives, and desires as it makes plans or otherwise attempts to accomplish those goals.

The word "thought" comes from Old English "þoht", or "geþoht", from stem of "þencan" "to conceive of in the mind, consider".

The word "thought" may mean:

Definitions may or may not require that thought

Definitions of thought may also be derived directly or indirectly from theories of thought.


The phenomenology movement in philosophy saw a radical change in the way in which we understand thought. Martin Heidegger's phenomenological analyses of the existential structure of man in "Being and Time" cast new light on the issue of thinking, unsettling traditional cognitive or rational interpretations of man which affect the way we understand thought. The notion of the fundamental role of non-cognitive understanding in rendering possible thematic consciousness informed the discussion surrounding artificial intelligence (AI) during the 1970s and 1980s.

Phenomenology, however, is not the only approach to thinking in modern Western philosophy. Philosophy of mind is a branch of philosophy that studies the nature of the mind, mental events, mental functions, mental properties, consciousness and their relationship to the physical body, particularly the brain. The mind–body problem, i.e. the relationship of the mind to the body, is commonly seen as the central issue in philosophy of mind, although there are other issues concerning the nature of the mind that do not involve its relation to the physical body.

The mind–body problem concerns the explanation of the relationship that exists between minds, or mental processes, and bodily states or processes. The main aim of philosophers working in this area is to determine the nature of the mind and mental states/processes, and how—or even if—minds are affected by and can affect the body.

Human perceptual experiences depend on stimuli which arrive at one's various sensory organs from the external world and these stimuli cause changes in one's mental state, ultimately causing one to feel a sensation, which may be pleasant or unpleasant. Someone's desire for a slice of pizza, for example, will tend to cause that person to move his or her body in a specific manner and in a specific direction to obtain what he or she wants. The question, then, is how it can be possible for conscious experiences to arise out of a lump of gray matter endowed with nothing but electrochemical properties. A related problem is to explain how someone's propositional attitudes (e.g. beliefs and desires) can cause that individual's neurons to fire and his muscles to contract in exactly the correct manner. These comprise some of the puzzles that have confronted epistemologists and philosophers of mind from at least the time of René Descartes.

The above reflects a classical, functional description of how we work as cognitive, thinking systems. However the apparently irresolvable mind–body problem is said to be overcome, and bypassed, by the embodied cognition approach, with its roots in the work of Heidegger, Piaget, Vygotsky, Merleau-Ponty and the pragmatist John Dewey.

This approach states that the classical approach of separating the mind and analysing its processes is misguided: instead, we should see that the mind, actions of an embodied agent, and the environment it perceives and envisions, are all parts of a whole which determine each other. Therefore, functional analysis of the mind alone will always leave us with the mind–body problem which cannot be solved.

A neuron (also known as a neurone or nerve cell) is an excitable cell in the nervous system that processes and transmits information by electrochemical signaling. Neurons are the core components of the brain, the vertebrate spinal cord, the invertebrate ventral nerve cord and the peripheral nerves. A number of specialized types of neurons exist: sensory neurons respond to touch, sound, light and numerous other stimuli affecting cells of the sensory organs that then send signals to the spinal cord and brain. Motor neurons receive signals from the brain and spinal cord that cause muscle contractions and affect glands. Interneurons connect neurons to other neurons within the brain and spinal cord. Neurons respond to stimuli, and communicate the presence of stimuli to the central nervous system, which processes that information and sends responses to other parts of the body for action. Neurons do not go through mitosis and usually cannot be replaced after being destroyed, although astrocytes have been observed to turn into neurons, as they are sometimes pluripotent.

Psychologists have concentrated on thinking as an intellectual exertion aimed at finding an answer to a question or the solution of a practical problem. Cognitive psychology is a branch of psychology that investigates internal mental processes such as problem solving, memory, and language. The school of thought arising from this approach is known as cognitivism, which is interested in how people mentally represent information processing. It had its foundations in the Gestalt psychology of Max Wertheimer, Wolfgang Köhler, and Kurt Koffka, and in the work of Jean Piaget, who provided a theory of stages/phases that describes children's cognitive development.

Cognitive psychologists use psychophysical and experimental approaches to understand, diagnose, and solve problems, concerning themselves with the mental processes which mediate between stimulus and response. They study various aspects of thinking, including the psychology of reasoning, and how people make decisions and choices, solve problems, as well as engage in creative discovery and imaginative thought. Cognitive theory contends that solutions to problems either take the form of algorithms: rules that are not necessarily understood but promise a solution, or of heuristics: rules that are understood but that do not always guarantee solutions. Cognitive science differs from cognitive psychology in that algorithms that are intended to simulate human behavior are implemented or implementable on a computer. In other instances, solutions may be found through insight, a sudden awareness of relationships.

In developmental psychology, Jean Piaget was a pioneer in the study of the development of thought from birth to maturity. In his theory of cognitive development, thought is based on actions on the environment. That is, Piaget suggests that the environment is understood through assimilations of objects in the available schemes of action and these accommodate to the objects to the extent that the available schemes fall short of the demands. As a result of this interplay between assimilation and accommodation, thought develops through a sequence of stages that differ qualitatively from each other in mode of representation and complexity of inference and understanding. That is, thought evolves from being based on perceptions and actions at the sensorimotor stage in the first two years of life to internal representations in early childhood. Subsequently, representations are gradually organized into logical structures which first operate on the concrete properties of the reality, in the stage of concrete operations, and then operate on abstract principles that organize concrete properties, in the stage of formal operations. In recent years, the Piagetian conception of thought was integrated with information processing conceptions. Thus, thought is considered as the result of mechanisms that are responsible for the representation and processing of information. In this conception, speed of processing, cognitive control, and working memory are the main functions underlying thought. In the neo-Piagetian theories of cognitive development, the development of thought is considered to come from increasing speed of processing, enhanced cognitive control, and increasing working memory.

Positive psychology emphasizes the positive aspects of human psychology as equally important as the focus on mood disorders and other negative symptoms. In "Character Strengths and Virtues", Peterson and Seligman list a series of positive characteristics. One person is not expected to have every strength, nor are they meant to fully capsulate that characteristic entirely. The list encourages positive thought that builds on a person's strengths, rather than how to "fix" their "symptoms".

The "id", "ego" and "super-ego" are the three parts of the "psychic apparatus" defined in Sigmund Freud's structural model of the psyche; they are the three theoretical constructs in terms of whose activity and interaction mental life is described. According to this model, the uncoordinated instinctual trends are encompassed by the "id", the organized realistic part of the psyche is the "ego", and the critical, moralizing function is the "super-ego".

The unconscious was considered by Freud throughout the evolution of his psychoanalytic theory to be a sentient force of will influenced by human desire and yet operating well below the perceptual conscious mind. For Freud, the unconscious is the storehouse of instinctual desires, needs, and psychic drives. While past thoughts and reminiscences may be concealed from immediate consciousness, they direct the thoughts and feelings of the individual from the realm of the unconscious.

For psychoanalysis, the unconscious does not include all that is not conscious, rather only what is actively repressed from conscious thought or what the person is averse to knowing consciously. In a sense this view places the self in relationship to their unconscious as an adversary, warring with itself to keep what is unconscious hidden. If a person feels pain, all he can think of is alleviating the pain. Any of his desires, to get rid of pain or enjoy something, command the mind what to do. For Freud, the unconscious was a repository for socially unacceptable ideas, wishes or desires, traumatic memories, and painful emotions put out of mind by the mechanism of psychological repression. However, the contents did not necessarily have to be solely negative. In the psychoanalytic view, the unconscious is a force that can only be recognized by its effects—it expresses itself in the symptom.

Social psychology is the study of how people and groups interact. Scholars in this interdisciplinary area are typically either psychologists or sociologists, though all social psychologists employ both the individual and the group as their units of analysis.

Despite their similarity, psychological and sociological researchers tend to differ in their goals, approaches, methods, and terminology. They also favor separate academic journals and professional societies. The greatest period of collaboration between sociologists and psychologists was during the years immediately following World War II. Although there has been increasing isolation and specialization in recent years, some degree of overlap and influence remains between the two disciplines.

The collective unconscious, sometimes known as collective subconscious, is a term of analytical psychology, coined by Carl Jung. It is a part of the unconscious mind, shared by a society, a people, or all humanity, in an interconnected system that is the product of all common experiences and contains such concepts as science, religion, and morality. While Freud did not distinguish between "individual psychology" and "collective psychology", Jung distinguished the collective unconscious from the personal subconscious particular to each human being. The collective unconscious is also known as "a reservoir of the experiences of our species".

In the "Definitions" chapter of Jung's seminal work "Psychological Types", under the definition of "collective" Jung references "representations collectives", a term coined by Lucien Lévy-Bruhl in his 1910 book "How Natives Think". Jung says this is what he describes as the collective unconscious. Freud, on the other hand, did not accept the idea of a collective unconscious.





</doc>
<doc id="2616799" url="https://en.wikipedia.org/wiki?curid=2616799" title="Illegalism">
Illegalism

Illegalism is an anarchist philosophy that developed primarily in France, Italy, Belgium and Switzerland during the early 1900s as an outgrowth of individualist anarchism. The illegalists embraced either openly or secretly criminality as a lifestyle. The illegalists use Max Stirner's Egoism as a justification for illegalism. However, not all illegalists are supporters of Max Stirner and his philosophy. Jules Bonnot and the Bonnot Gang have been described as illegalist by some. Illegalism does not specify the type of crime, though it is associated with theft and shoplifting.

Illegalism first rose to prominence among a generation of Europeans inspired by the unrest of the 1890s, during which Ravachol, Émile Henry, Auguste Vaillant and Caserio committed daring crimes in the name of anarchism, in what is known as propaganda of the deed.

Influenced by theorist Max Stirner's egoism, the illegalists in France broke from anarchists like Clément Duval and Marius Jacob who justified theft with a theory of individual reclamation ("la reprise individuelle"). Instead, the illegalists argued that their actions required no moral basis and illegal acts were taken not in the name of a higher ideal, but in pursuit of one's own desires. In Paris, this milieu was centred on the weekly papers "L'Anarchie" and the "Causeries Populaires" (regular discussion groups meeting in several different locations in and around the capital each week), both of which were founded by Albert Libertad and his associates.
After Peter Kropotkin along with others decided to enter labor unions after their initial reservations, there remained the anti-syndicalist anarchist-communists, who in France were grouped around Sebastien Faure's "Le Libertaire". From 1905 onwards, the Russian counterparts of these anti-syndicalist anarchist-communists become partisans of economic terrorism and illegal expropriations. Illegalism as a practice emerged and within it "[t]he acts of the anarchist bombers and assassins ("propaganda by the deed") and the anarchist burglars ("individual reappropriation") expressed their desperation and their personal, violent rejection of an intolerable society. Moreover, they were clearly meant to be exemplary, invitations to revolt". In another less dramatic sense, "[at] that time this term was used to indicate all those practices prohibited by law that were useful for resolving the economic problems of comrades: robbery, theft, smuggling, counterfeiting money and so on".

Such acts of rebellion which could be individual were in the long run seen as acts of rebellion which could ignite a mass insurrection leading to revolution. Proponents and activists of this tactic among others included Johann Most, Luigi Galleani, Victor Serge and Severino Di Giovanni. In Argentina, these tendencies flourished at the end of the 1920s and during the 1930s, "years of acute repression and of flinching of the once powerful workers movement—this was a desperation, though heroic, of a decadent movement".
France's Bonnot Gang was the most famous group to embrace illegalism. The Bonnot Gang ("La Bande à Bonnot") was a French criminal anarchist group that operated in France and Belgium during the Belle Époque from 1911 to 1912. Composed of individuals who identified with the emerging illegalist milieu, the gang utilized cutting-edge technology (including automobiles and repeating rifles) not yet available to the French police.

Originally referred to by the press as simply "The Auto Bandits", the gang was dubbed "The Bonnot Gang" after Jules Bonnot gave an interview at the office of "Petit Parisien", a popular daily paper. Bonnot's perceived prominence within the group was later reinforced by his high-profile death during a shootout with French police in Nogent-sur-Marne.

Following his arrest for harbouring members of the Bonnot Gang, Victor Serge, once a forceful defender of illegalism, became a sharp critic. In "Memoirs of a Revolutionary", he describes illegalism as "a collective suicide". Similarly, Marius Jacob reflected in 1948: "I don't think that illegalism can free the individual in present-day society... Basically, illegalism, considered as an act of revolt, is more a matter of temperament than of doctrine".

Illegalism has been updated by currents such as insurrectionary anarchism and post-left anarchy. In Spain and Latin America, a campaign called Yomango has appeared, which advocates shoplifting and thus updates individual reclamation.

Horst Fantazzini was an Italian-German individualist anarchist who pursued an illegalist lifestyle and practice until his death in 2001. He gained media notoriety mainly due to his many bank robberies through Italy and other countries. In 1999, the film based on his life "Ormai è fatta!" was released.




</doc>
<doc id="3908174" url="https://en.wikipedia.org/wiki?curid=3908174" title="Lovers' lane">
Lovers' lane

A lovers' lane is a secluded area where people kiss, make out, or sometimes engage in sexual activity. These areas range from parking lots in secluded rural areas to places with extraordinary views of a cityscape or other feature.

"Lovers' lanes" are typically found in cultures built around the automobile—lovers often make out in a car or van for privacy.

Lovers' lanes have existed for centuries, sometimes as places for secret meetings with a loved one or as a euphemism for red-light districts and other areas of prostitution.

The Oxford English Dictionary records use of the phrase "lovers' lane" from 1853.

There are several streets called "Lovers Lane", including those at Oriskany, New York; Whitmire, South Carolina; Manitou Springs, Colorado; Baton Rouge, Louisiana; Kersey, Pennsylvania; Boonville, New York; Greenfield, Massachusetts; Southborough, Massachusetts; Northfield, Vermont; Riverton, Utah; Steubenville, Ohio; Bowling Green, Kentucky; Portage, Michigan; Excelsior Springs, Missouri; Springfield, Missouri; Charlestown, New Hampshire; Sugar Hill, New Hampshire; Princeton, New Jersey; Slatington, Pennsylvania; Adliya, Bahrain; Dallas, Texas; Texarkana, Texas; Ravenna Township, Portage County, Ohio; Visalia, California; El Segundo, California, Milwaukee, Wisconsin; Ancaster, Ontario, Canada; Newark-on-Trent; Ludham (both in England) and Thurso, Scotland.


The bowdlerised version "Love Lane" is sometimes seen. Jowett Walk, Oxford, once had this name.

In 1963, a lovers' lane site at Fuller's Bridge, Sydney became notorious as the location of the bodies of CSIRO scientist Dr. Gilbert Stanley Bogle and Mrs. Margaret Olive Chandler, the wife of one of his colleagues. The cause of death, while indicative of poisoning, couldn't be definitively determined, and apart from Mrs. Chandler's husband, Geoffrey, who was considered the prime suspect by the New South Wales Police, no one to-date has been charged. The Bogle-Chandler case has baffled law enforcement and forensic experts up to present day.

Several of the Zodiac Killer's victims were murdered in lovers' lanes in northern California.

Several attacks perpetrated by the Son of Sam serial killer also took place in such settings.

Two Mercer University students were killed by Andy Cook at a lovers' lane location in Georgia on January 2, 1995.



</doc>
<doc id="1949108" url="https://en.wikipedia.org/wiki?curid=1949108" title="Fingersmith (slang)">
Fingersmith (slang)

Fingersmith or finger-smith is slang for a midwife or pickpocket.

Used in a 1977 short story, "The Hitchhiker" by Roald Dahl and as the title of Sarah Waters's 2002 novel: "Fingersmith".


</doc>
<doc id="6901997" url="https://en.wikipedia.org/wiki?curid=6901997" title="Lookout">
Lookout

A lookout or look-out is a person on a ship in charge of the observation of the sea for hazards, other ships, land, etc. Lookouts report anything they see and or hear. When reporting contacts, lookouts give information such as, bearing of the object, which way the object is headed, target angles and position angles and what the contact is. Lookouts should be thoroughly familiar with the various types of distress signals they may encounter at sea.

Lookouts have been traditionally placed in high on masts, in crow's nests and tops.

The International Regulations for Preventing Collisions at Sea (1972) says in part:

By analogy, the term "lookout" is also used to describe a person who accompanies criminals during the commission of a crime, and warns them of the impending approach of hazards: that is, police or eyewitnesses. Although lookouts typically do not actually participate in the crime, they can nonetheless be charged with aiding and abetting or with conspiracy, or as accomplices.


</doc>
<doc id="3931146" url="https://en.wikipedia.org/wiki?curid=3931146" title="Crime victim advocacy program">
Crime victim advocacy program

A Crime Victim Advocacy Program is a program to assist victims of crime through the criminal justice system. Such a program assists victim of a "General Crime", that is, as any crime committed that is "not" domestic or sexual in nature. Common examples of general crime are murder, robbery, identity theft, burglary, vandalism, hate crimes, assault, and threats.

Typically, victims of general crimes are an underserved group. Most victim advocacy programs focus on either DV (domestic violence) or SA (sexual assault). Survivors also advocate for improved court procedures and legal assistance for victims. Many crime victims are unfamiliar with the criminal justice system, due to recent immigration, language barriers, or ignorance.

A typical crime victim advocacy program is located in SW Washington state serving the counties of Clark, Wahkiakum, and Cowlitz. It was started in January 2006 for the express purpose of helping victims of general crime. Chris Knox runs the CVAP program in Clark County, from his office based in Vancouver, Washington.



</doc>
<doc id="12960037" url="https://en.wikipedia.org/wiki?curid=12960037" title="Smash and grab">
Smash and grab

A smash and grab is a particular form of burglary that involves smashing a barrier, usually a display window in a shop or a showcase, grabbing valuables, and then making a quick getaway, without concern for setting off alarms or creating noise. Typically, display windows and showcases that are in enclosed areas, such as shopping malls and office buildings, are less vulnerable to smash and grab raids than those on open streets – particularly where the streets are poorly lit or unobserved (such as premises in pedestrian subways or unstaffed transport facilities). Recent smash and grab crimes have also involved ramming a pickup truck through the walls of a convenience store or gas station in order to remove the ATM from the premises and recover the cash. Smash and grab raids can occur in many scenarios, both in broad daylight and at night, and the perpetrators can range from experienced thieves to impulsive vandals. 

The greatest cost of smash and grab raids can often be in replacing the windows or walls, which can sometimes far exceed the cost of the goods that are stolen.

There are several approaches to deterring smash and grab raiders. Shopkeepers can securely tether their goods, and make the tethering obvious to the onlooker. They can also avoid displaying goods of value in windows, an approach that has the disadvantage of reducing the attractiveness of the display to customers. Additionally, shopkeepers can strengthen window glass, to the extent that it can withstand, without breaking, being hit by the implements that smash and grab raiders are likely to use, such as hammers, bricks, and scaffolding poles.

Smash and grab raids became common in the 1930s, and were particularly prevalent in the 1940s, but decreased in frequency as shopkeepers took to strengthening their windows and/or fitting protective grilles. By the 1950s, forced entry to shops was being effected by using cars and grappling irons to pull window bars off windows, a precursor to the 1980s phenomenon of ram-raiding.


</doc>
<doc id="14754173" url="https://en.wikipedia.org/wiki?curid=14754173" title="Illegal taxicab operation">
Illegal taxicab operation

Illegal taxicabs, sometimes known as pirate taxis or gypsy cabs, are taxicabs and other for-hire vehicles that are not duly licensed or permitted by the jurisdiction in which they operate. Most major cities worldwide require taxicabs to be licensed, safety-inspected, insured as for-hire vehicles and use taxi meters and there may also be requirements that the taxi driver be registered or accredited. However, many unlicensed cabs are in operation. Illegal cabs may be marked taxi vehicles (sometimes referred to as "speedy cabs"), and others are personal vehicles used by an individual to offer unauthorized taxi-like services. Illegal cabs are prevalent in cities with medallion systems, which restrict the number of legal cabs in operation. Since their introduction in 2009, vehicles affiliated with the transportation network company Uber have been classified as illegal taxicabs in some jurisdictions.

A variety of terms are used in the industry to describe legal and illegal transportation providers. "Hacks" or "hackers" is a common term that originated with the "hackney horse", a breed of horse typically offered for hire in the 19th century. Other terms used are "livery cab", "car service", or "jitney cab".

The phrases vary by locality and often refer to different classes of licensed transportation providers. For example, in Philadelphia, a cab driver's license is called a "hacker's license", while in New York City, "livery cabs" are licensed for telephone dispatch only. In New York and Baltimore, licensed cabs are also called "hacks" and their medallions are often referred to as "hack licenses".

In mainland China, illegal cabs are referred to as "black taxies" or "black cars" (黑车), or alternatively "blue-plate cars" (蓝牌车), referring to the colour of the licence plates for private vehicles, rather than yellow for public service vehicles.

In Lagos, Nigeria, illegal cabs are usually referred to as "kabu kabu".

In Hong Kong, illegal cabs are usually referred to as "white card", due to the different licence plate appearance between commercial and non-commercial vehicles.

In Malaysia, illegal taxicabs are called "prebet sapu" (sweep privates).

In Mexico, illegal taxicabs are called "taxi pirata" (pirate taxi).

In Norway and Denmark, an illegal cab is called "pirattaxi" (pirate taxi).

In Sweden, an illegal taxicab is called "svarttaxi" (black taxi), and is short for black market taxi.

In Trinidad and Tobago, illegal taxis are referred to as ""PH" cars". This is because of the coding used on licence plates to distinguish private cars from taxis. On a private car's licence plate, the number begins with a "P" (for private), while on taxis the license plates begin with an "H" (for hired). Thus the slang "PH" indicates an informal blend of the two states.

In Algeria, they are referred to as "le clandestin".

In Jamaica, illegal taxis are referred to as "robots" or "robot taxis".

Unlicensed cabs may be found cruising the residential streets of a city, typically in the working-class neighborhoods. Sometimes, drivers will also wait at a location where taxi service is in demand, such as airport or train station arrival areas or shopping centers, asking arriving passengers if they need a ride. Unlicensed taxis often do not have meters, so the fare is usually agreed to at the beginning of the ride. The car itself is usually large, similar in feel to a licensed taxi.

In New York City, Baltimore, Philadelphia, and other cities use non-medallion car services (also called livery cabs) lawfully exist but are only supposed to respond to telephone dispatch. They cannot legally pick up street hails or enter taxi stands at airports. However, outside of the core Manhattan business district, livery cabs are ubiquitous and will respond to street hails. Some areas also have sedan services, which likewise respond to telephone dispatch.

There are also non-taxicab based unlicensed transportation providers. Examples include "dollar vans" plying city bus routes in New York City, and van services that offer rides between major cities. In some places, providing a ride in a personal vehicle as a part of another job, such as caregiving, may be legal, sometimes with regulation of certain factors, such as insurance coverage.

In some large American cities, and in Hong Kong, a medallion system is used to license cabs. The city issues a fixed number of medallions, and only medallion taxis are allowed to pick up fares. In general, this leads to medallions becoming ever more expensive—a New York City corporate medallion can sell for up to $1 million each. Medallions are transferable, and while some cab drivers own their own medallion, most must lease one on a daily or weekly basis from a fleet owner.

The medallion system has several effects upon the illegal transportation market. By acting as a barrier to entry to the taxi market, it has the consequence of creating a market for unlicensed cabs, especially in areas that tend to be underserved by medallion cabs. Taxi medallions tend to increase in value over time, and their owners and lessees tend to be very eager to protect their exclusive rights, for example, by lobbying for stricter enforcement against unlicensed cabs.

In America, there is significant anecdotal evidence that unlicensed cabs are mostly found in working-class neighborhoods of large cities.

In Baltimore, United States, supermarkets in working-class neighborhoods frequently have "courtesy drivers"} who, although not employed by the supermarket, have shown identification to management and are allowed to wait in front of the store for fares. Unlike licensed cab drivers, these courtesy drivers will also help to carry groceries up to one's apartment. "Hacking" in Baltimore has grown grass-roots style to a region-wide phenomenon, originating from "Hack Clubs", organizations usually operating in converted rowhouses where "hacks" made their cars available, distributed business cards with a central number, employed a "dispatcher", and hung around the rowhouse waiting in line for calls. This practice continues today, but hacking has evolved to the point where people nowadays just wag a finger toward the street, and wait for anyone to stop. This new way of getting around remains popular, despite being potentially dangerous, due to disillusionment with the city transit service, and the fact that licensed cabs seldom stop for fares in the most dangerous parts of town. There are plenty of willing drivers, and competition can be fierce. The fare is negotiated and paid upfront. Police maintain this is illegal, and sometimes enforce with $500 tickets, and a trip to the courthouse.

Unlicensed cabs are also found among the Amish of rural Pennsylvania. An Amish taxi is typically an illegal taxicab operation run on an informal basis by an individual who is not specifically running a taxi service, but who has been propositioned by an Amish person to transport them for shopping or business purposes. Old Order Amish do not drive, but will hire a van or taxi for trips for which they cannot use their traditional horse and buggy transportation.

In most rural locations with a low-density Amish population, it would be impractical for an Amish person to hire a commercial taxi from a metropolitan area since the taxi would have to drive long distances just to pick up the Amish person. It is therefore more convenient and less expensive to find an unlicensed non-Amish neighbor willing to act as a "taxi".

Normal individual automotive insurance is not intended to insure driving a vehicle for hire for business purposes. A paratransit license from the Pennsylvania Public Utility Commission (PUC) is required to operate an Amish Taxi legally in Pennsylvania. This applies to anyone who transports people for a fee. The vehicle cannot hold more than 15 passengers, and must display a PUC identification number on both sides of the vehicle.
Crowdsourced taxis are run by a transportation network company such as Lyft and Uber, which operates in 633 cities worldwide. These companies develop, market, and operate the mobile apps, which allows consumers to submit a trip request which is then routed to sharing economy drivers. Since Uber's launch, several other companies have emulated its business model, a trend that has come to be referred to as "Uberification".

Many governments and taxi companies have protested against Uber, alleging that its use of unlicensed, crowd-sourced drivers was unsafe and illegal. Uber operates and functions as a taxi service company for the public by dispatching drivers to provide transportation services to passengers who pay Uber mileage-based fees and surcharges through credit card information kept on file by Uber. The taxi industry has pushed to have Uber treated the same as taxi companies, who face public safety requirements under the law ranging from how old vehicles on the road can be to how much they can charge or how many passengers allowed per vehicle and how much insurance they must carry.



</doc>
<doc id="16064455" url="https://en.wikipedia.org/wiki?curid=16064455" title="Individual reclamation">
Individual reclamation

Individual reclamation () is a form of direct action, characterized by the individual theft of resources from the rich by the poor. Individual reclamation gained popular attention in the early 20th century as a result of the exploits of anarchists and outsiders, such as Ravachol and Clément Duval, who believed that such expropriations were ethical because of the exploitation of society by capitalists (see Anti-capitalism). Advocacy centered on France, Belgium, Great Britain, and Switzerland.

In 1840, Pierre Joseph Proudhon, a French anarchist, wrote "What Is Property?", a question to which he famously answered "property is theft". By this, Proudhon meant that legitimate private property could result only from an individual's labor and all other capital was, in effect, stolen. This economic world view converged in the minds of radicals with the Russian theorist Mikhail Bakunin's concept of propaganda of the deed, the use of physical violence against political enemies as a method of inspiring the masses.

A marginal sector of European individualist anarchism derived the idea of individual reclamation as a means of breaking down what they perceived as the robbery of the laboring class by capitalists, politicians and the church. The individual's expropriation was regarded as legitimate resistance against an unfair social order, an ethical right to even the distribution of wealth.

Well-known 19th century practitioners of individual reclamation included Ravachol and Clément Duval. A later generation of European anarchists, influenced by the anti-essentialism of Max Stirner, would eventually abandon the ethical framing of individual reclamation, proposing an ideology of illegalism and openly embracing criminality as a lifestyle. The most famous of these practitioners included the infamous Bonnot Gang of France.

In the 20th century, Lucio Urtubia, a Spanish practitioner of individual reclamation, stole millions from Citibank by forging traveler's checks. Between 1993 and 2007, Jaime Giménez Arbe robbed 36 banks in Spain, stealing more than €700,000 euros in what he described as an effort "to liberate the Spanish people" from the banking sector.




</doc>
<doc id="16145656" url="https://en.wikipedia.org/wiki?curid=16145656" title="Four Horsemen of the Infocalypse">
Four Horsemen of the Infocalypse

The Four Horsemen of the Infocalypse is a term for internet criminals, or the imagery of internet criminals.

A play on Four Horsemen of the Apocalypse, it refers to types of criminals who use the internet to facilitate crime and consequently jeopardize the rights of honest internet users. There does not appear to be an exact definition for who the Horsemen are, but they are usually described as terrorists, drug dealers, pedophiles, and organized crime. Other sources use slightly different descriptions but generally refer to the same types of criminals. The term was coined by Timothy C. May in 1988, who referred to them as "child pornographers, terrorists, drug dealers, etc." when discussing the reasons for limited civilian use of cryptography tools. Among the most famous of these is in the Cypherpunk FAQ, which states:

The term seems to be used less often in discussions about online criminal activity, but more often in discussions about the negative, or chilling effects such activity has had on regular users' daily experiences online.
It is also used frequently to describe the political tactic "Think of the children". A message from the same mailing list states:

The four supposed threats may be used all at once or individually, depending on the circumstances:aj

In 2013, the director of the Safe Internet League (a voluntary censorship group in Russia) claimed that pedophiles, perverts, drug dealers “and other creeps” were using the Tor anonymity software, as a reason why the software should be outlawed. This list did not mention terrorists or money-launderers directly, but did use the catch-all phrase "other creeps" that potentially includes them.

In 2015, the UK Conservative party claimed that their proposed “new communications data legislation will strengthen our ability to disrupt terrorist plots, criminal networks and organised child grooming gangs”, echoing the "child pornographers, terrorists, drug dealers, etc." quote of Timothy C. May.

Later in 2015, Gamma Group released a statement claiming that their surveillance technology is used "against terrorist threats, drug cartels, other major organised crime, and paedophile rings." as justification for concerns that it was being used to target opposition politicians and media groups in Uganda. With money-laundering treated as a major organised crime, this quote matches very closely with the list given in the Cypherpunk FAQ.




</doc>
<doc id="6571403" url="https://en.wikipedia.org/wiki?curid=6571403" title="Crime scene getaway">
Crime scene getaway

A crime scene getaway is the act of fleeing the location where one has broken the law. It is an act that the offender(s) may or may not have planned in detail, resulting in a variety of outcomes. A :crime scene is the "location of a crime; especially one at which forensic evidence is collected in a controlled manner." The "getaway" is any escape by a perpetrator from that scene, which may have been witnessed by eyewitnesses or law enforcement.

The crime scene getaway is the subject of several penal laws, as well as a "notion" in academic studies of criminology.

A perpetrator can escape a crime scene by running, riding a horse, riding a bicycle, riding a motorcycle, driving a getaway car, or riding with a getaway driver, among other methods. If motor vehicles are used for the getaway, then each vehicle is a new crime scene.

In some jurisdictions, the very act of making a go away from a crime scene is an inchoate criminal offense in itself, though it is generally viewed as natural behavior for a lawbreaker. For example, under New York law, "escape" is defined as escaping custody or detention; "unlawful fleeing a police in a motor vehicle" is a distinct crime.

Traditionally, for thousands of years, the standard method of escape from a crime scene was for the perpetrator merely to run away, faster than the constable on patrol, sheriff, or the night watchman. This was common even into the 20th century. For example, according to the Warren Commission report, Lee Harvey Oswald infamously walked, then ran away from the Texas Book Depository from where he shot President Kennedy on November 22, 1963. If another means of transportation becomes unavailable, the suspect may have to run.

Once humans domesticated horses, that animal became a favorite way to escape a crime scene. Jesse James and many old "Wild West" bank robbers and train robbers of the 19th century used horses to get way from the scene of their larceny.

The etymology of two common terms for peace officers in premodern times indicates that their major role may have been to prevent horse theft—or escape by horse. These are constable (from the Latin "comes stabuli" -- attendant to the stables), and marshall, a loanword from Old Norman French, which in turn is borrowed from Old Frankish *"marhskalk" "stable boy, keeper, servant", cognate with Germanic "*marha-" "horse" (cf. Engl. "mare") and "skalk-" "servant" (cf. Old Engl. "scealc" "servant, soldier").

A motor vehicle, commonly referred to as a getaway car, is frequently used by the offender to flee the scene of a crime. Getaway cars are prevalent in major crimes such as bank robberies and homicides. Very frequently, but not always, a getaway car is stolen and is abandoned soon after the crime, in the hope that the vehicle cannot be traced to the offender.

If the vehicle does not belong to the driver and is quickly abandoned, a trace may not be possible without examination of forensic evidence. In some cases, the offender may go to extreme measures to discard the getaway vehicle in order to hide his 'tracks' by dumping it in a river or secluded park, and/or setting it on fire; while this may not make solving the crime impossible, it can make the effort more difficult for law enforcement. The criminal investigation can be further complicated by the use of multiple getaway vehicles, which can confuse eyewitnesses, as well as creating multiple places to investigate: each vehicle is a new crime scene. In "Forensics for Dummies", the rookie is reminded: "At a minimum, the crime scene includes ... Areas from which the site can be entered, exited, or even escaped..."

Since a getaway vehicle often requires a getaway driver, this additional co-defendant creates problems in itself. First, having a second perpetrator involved creates yet another inchoate offence that the prosecutor can use in an indictment: conspiracy. Also, a co-conspirator may cooperate with police, either intentionally by 'turning state's evidence' by way of a plea bargain, or inadvertently by giving away information to persons outside the conspiracy. If the driver, who may have parked some distance away, unknowingly drives past the scene of the crime, the getaway vehicle itself may identify the occupants to the crime victim and police. This is especially true if the vehicle has unique markings or is an unusual model. Without a driver, the perpetrator may make errors due to the stress associated with the crime, or lack of ability to multi-task (such as leaving the car keys at the scene of the crime); a murderer needs to "think strategically" to get away with murder—to "mislead police, stage crime scenes and destroy evidence."

Taking a public bus or taxicab makes the driver an involuntary co-conspirator, yet also creates an eyewitness whose interest it is to cooperate with police.

Witnesses to the crime will often attempt to take note of the tags (registration plate) or other important details of the car and report this information to law enforcement. It may be possible to identify the offender if an officer spots the offender in possession of the vehicle prior to its abandonment. In one news story:
The earliest robbers known to have made such use of an automobile were the anarchist-inspired Bonnot Gang, active in Paris of the early 1910s. Later, the method was used by John Dillinger and Bonnie and Clyde, whose exploits got wide media attention and inspired many less-known robbers.

Under the M'Naghten rules for the insanity defense, the defendant must be not only mentally ill ("suffering from a mental disease or defect" is a typical formulation) but also unable to tell right from wrong. If the defendant runs away from the crime scene, there must thus be an awareness that the crime is wrong and so a jury would, under such factual circumstances, deny that defense.

"Clark v. Arizona" ruled that the defense is not a right and that its scope is limited by whether the defendant knew right from wrong.



</doc>
<doc id="17608461" url="https://en.wikipedia.org/wiki?curid=17608461" title="Wireless identity theft">
Wireless identity theft

Wireless identity theft, also known as contactless identity theft or RFID identity theft, is a form of identity theft described as "the act of compromising an individual’s personal identifying information using wireless (radio frequency) mechanics." Numerous articles have been written about wireless identity theft and broadcast television has produced several investigations of this phenomenon. According to Marc Rotenberg of the Electronic Privacy Information Center, wireless identity theft is "a pretty serious issue" and "the contactless (wireless) card design is inherently flawed".

Wireless identity theft is a relatively new technique of gathering an individual’s personal information from RF-enabled cards carried on a person in their access control, credit, debit, or government issued identification cards. Each of these cards carry a Radio frequency identification chip which responds to certain radio frequencies. When these "tags" come into contact with radio waves, they respond with a slightly altered signal. The response can contain encoded personal identifying information, including the card holder’s name, address, Social Security Number, phone number, and pertinent account or employee information.

Upon capturing (or ‘harvesting’) this data, one is then able to program other cards to respond in an identical fashion (‘cloning’). Many websites are dedicated to teaching people how to do this, as well as supplying the necessary equipment and software.

The financial industrial complex is migrating from the use of magnetic stripes on debit and credit cards which technically require a swipe through a magnetic card swipe reader. The number of transactions per minute can be increased, and more transactions can be processed in a shorter time, therefore making for arguably shorter lines at the cashier.

Academic researchers and ‘White-Hat’ hackers have analysed and documented the covert theft of RFID credit card information and been met with both denials and criticisms from RFID card-issuing agencies. Nevertheless, after public disclosure of information that could be stolen by low-cost jerry-rigged detectors which were used to scan cards in mailing envelopes (and in other studies also even via drive-by data attacks), the design of security features on various cards was upgraded to remove card owners’ names and other data. Additionally a number of completely unencrypted card designs were converted to encrypted data systems.

The issues raised in a 2006 report were of importance due to the tens of millions of cards that have already been issued. Credit and debit card data could be stolen via special low cost radio scanners without the cards being physically touched or removed from their owner’s pocket, purse or carry bag. Among the findings of the 2006 research study "Vulnerabilities in First-Generation RFID-Enabled Credit Cards", and in reports by other white-hat hackers:

In a related issue, privacy groups and individuals have also raised "Big Brother" concerns, where there is a threat to individuals from their aggregated information and even tracking of their movements by either card issuing agencies, other third party entities, and even by governments. Industry observers have stated that ‘"...RFID certainly has the potential to be the most invasive consumer technology ever."’

Credit card issuing agencies have issued denial statements regarding wireless identity theft or fraud and provided marketing information that either directly criticized or implied that:

After the release of the study results, all of the credit card companies contacted during the "New York Times"' investigative report said that they were removing card holder names from the data being transmitted with their new second generation RFID cards.

Certain official identification documents issued by the U.S. government, U.S. Passports, Passport Cards, and also enhanced driver’s licenses issued by States of New York and Washington, contain RFID chips for the purpose of assisting those policing the U.S. border. Various security issues have been identified with their use, including the ability of black hats to harvest their identifier numbers at a distance and apply them to blank counterfeit documents and cards, thus assuming those people’s identifiers.

Various issues and potential issues with their use have been identified, including privacy concerns. Although the RFID identifier number associated with each document is not supposed to include personal identification information, "...numbers evolve over time, and uses evolve over time, and eventually these things can reveal more information than we initially expect" stated Tadayoshi Kohno, an assistant professor of computer science, at University of Washington who participated in a study of such government issued documents.




</doc>
<doc id="62312" url="https://en.wikipedia.org/wiki?curid=62312" title="Forgery">
Forgery

Forgery is a white-collar crime that generally refers to the false making or material alteration of a legal instrument with the specific intent to defraud anyone (other than himself or herself). Tampering with a certain legal instrument may be forbidden by law in some jurisdictions but such an offense is not related to forgery unless the tampered legal instrument was actually used in the course of the crime to defraud another person or entity. Copies, studio replicas, and reproductions are not considered forgeries, though they may later become forgeries through knowing and willful misrepresentations. 

Forging money or currency is more often called counterfeiting. But consumer goods may also be "counterfeits" if they are not manufactured or produced by the designated manufacturer or producer given on the label or flagged by the trademark symbol. When the object forged is a record or document it is often called a false document.

This usage of "forgery" does not derive from metalwork done at a forge, but it has a parallel history. A sense of "to counterfeit" is already in the Anglo-French verb "forger", meaning "falsify".

A forgery is essentially concerned with a produced or altered object. Where the prime concern of a forgery is less focused on the object itself – what it is worth or what it "proves" – than on a tacit statement of criticism that is revealed by the reactions the object provokes in others, then the larger process is a hoax. In a hoax, a rumor or a genuine object planted in a concocted situation, may substitute for a forged physical object.

The similar crime of fraud is the crime of deceiving another, including through the use of objects obtained through forgery. Forgery is one of the techniques of fraud, including identity theft. Forgery is one of the threats addressed by security engineering.

In the 16th century, imitators of Albrecht Dürer's style of printmaking improved the market for their own prints by signing them "AD", making them forgeries. In the 20th century the art market made forgeries highly profitable. There are widespread forgeries of especially valued artists, such as drawings originally by Pablo Picasso, Paul Klee, and Henri Matisse.

A special case of double forgery is the forging of Vermeer's paintings by Han van Meegeren, and in its turn the forging of Van Meegeren's work by his son Jacques van Meegeren. 

In England and Wales and Northern Ireland, forgery is an offence under section 1 of the Forgery and Counterfeiting Act 1981, which provides:

"Instrument" is defined by section 8, "makes" and "false" by section 9, and "induce" and "prejudice" by section 10.

Forgery is triable either way. A person guilty of forgery is liable, on conviction on indictment, to imprisonment for a term not exceeding ten years, or, on summary conviction, to imprisonment for a term not exceeding six months, or to a fine not exceeding the statutory maximum, or to both.

For offences akin to forgery, see English criminal law#Forgery, personation, and cheating.

The common law offence of forgery is abolished for all purposes not relating to offences committed before the commencement of the Forgery and Counterfeiting Act 1981.

Forgery is not an official offence under the law of Scotland, except in cases where statute provides otherwise.

The Forgery of Foreign Bills Act 1803 was repealed in 2013.

In the Republic of Ireland, forgery is an offence under section 25(1) of the Criminal Justice (Theft and Fraud Offences) Act, 2001 which provides:

A person guilty of forgery is liable, on conviction on indictment, to imprisonment for a term not exceeding ten years, or to a fine, or to both.

Any offence at common law of forgery is abolished. The abolition of a common law offence of forgery does not affect proceedings for any such offence committed before its abolition.

Except as regards offences committed before the commencement of the Criminal Justice (Theft and Fraud Offences) Act, 2001 and except where the context otherwise requires, without prejudice to section 65(4)(a) of that Act, references to forgery must be construed in accordance with the provisions of that Act.

Forgery is an offence under sections 366, 367 and 368 of the Canadian Criminal Code. The offence is a hybrid offence, subject to a maximum prison sentence of:

Forgery is a crime in all jurisdictions within the United States, both state and federal. Most states, including California, describe forgery as occurring when a person alters a written document "with the intent to defraud, knowing that he or she has no authority to do so." The written document usually has to be an instrument of legal significance. Punishments for forgery vary widely. In California, forgery for an amount under $950 can result in misdemeanor charges and no jail time, while a forgery involving a loss of over $500,000 can result in three years in prison for the forgery plus a five-year "conduct enhancement" for the amount of the loss, yielding eight years in prison. In Connecticut, forgery in the Third Degree, which is a class B misdemeanor is punishable by up to 6 months in jail, a $1000 fine, and probation; forgery in the First Degree, which is a class C felony, is punishable by a maximum 10 years in prison, a fine of up to $10,000 fine, or both.

As to the effect, in the United Kingdom, of a forged signature on a bill of exchange, see section 24 of the Bills of Exchange Act 1882.

Before the invention of photography, people commonly hired painters and engravers to "re-create" an event or a scene. Artists had to imagine what to illustrate based on the information available to them about the subject. Some artists added elements to make the scene more exotic, while others removed elements out of modesty. In the 18th century, for example, Europeans were curious about what North America looked like and were ready to pay to see illustrations depicting this faraway place. Some of these artists produced prints depicting North America, despite many having never left Europe.






</doc>
<doc id="2348828" url="https://en.wikipedia.org/wiki?curid=2348828" title="Malice aforethought">
Malice aforethought

Malice aforethought is the "premeditation" or "predetermination" (with malice) required as an element of some crimes in some jurisdictions and a unique element for first-degree or aggravated murder in a few. Insofar as the term is still in use, it has a technical meaning that has changed substantially over time.

Malice aforethought is a translation of the Law French term "malice prépensée".

Malice aforethought was not an element of murder in early medieval English law cases. Both self-defence killings and deaths caused by misadventure were treated as murder by juries. Although pardons for self-defence became common after the Statute of Gloucester was passed in 1278, the jury in a 14th century case still found that a self-defence killing was felonious.

In the 12th century, any death by misadventure without a "presentment of Englishry" was sufficient for a jury finding of murder, even in cases where there was no suspect and the victim's identity is unknown. The murder fine was levied in these cases under the Laws of Henry until 1267, when the fine for death by misadventure was abolished by the Statute of Marlborough during the baronial reform movement. The primary meaning of "murdurum" continued to be murder fine until the fine was abolished by the Engleschrie Act of 1340.

The first statutory mention of malice aforethought dates to the reign of Richard II in 1389. In 1390 Parliament defined murder as "death of a man slain by await, assault, or mallice prepensed". Henceforth, juries were instructed to consider whether a felony had been committed with malice aforethought. A 1403 jury instruction recorded in a 16th-century manuscript written by Edward Stillingfleet reads: "Also you will inquire about all sorts of homicides both of those who lie in wait through malice aforethought [par malice devant pourpense] in the peace of homes and other places [and who] murder people and of those who slay men through a hot-blooded mêlée [chaude melle]".

Some scholars have identified concepts from Anglo Saxon law as the origin for malice aforethought, but the connection is disputed. The Anglo Saxon legal concept of "forsteal" included lying in wait and ambush, but it remains unclear whether or not premeditation or intent were requirements for murder during this early period. It has been argued that "forsteal" became "agwait purpense" in medieval English law, which was also called "agwait premeditatus" in Latin.

In 1552 malice aforethought is applied as a requirement for murder in Thomas Buckler's Case. Malice aforethought emerges as an ill-defined concept from the writings of Blackstone, Joseph Chitty and their predecessors, Matthew Hale and Edward Coke.

After the Norman conquest, common law courts began to distinguish murders from homicides that occur during sudden brawls. Over centuries, this distinction evolved into an early form of the doctrine of provocation that distinguishes murder from voluntary manslaughter. By the time the Statute of Stabbing was passed in 1604, judges had started to consider whether provocation was sufficient in "heat of the blood" cases. During the 17th century, this was more clearly articulated in subsequent cases and gradually developed into the common law categorical test for provocation. The Statute of Stabbing had removed the benefit of clergy for cases where there was a killing without provocation.

Malice aforethought was the "mens rea" element of murder in 19th-century America, and remains as a relic in those states with a separate first-degree murder charge.

As of 1891, Texas courts were overwhelmed with discussing whether "malice" needs to be expressed or implied in the judge's jury instructions. However, the 1970s revision of the Texas Penal Code states that a murder must be committed "intentionally or knowingly" in Texas.

In English law, the "mens rea" requirement of murder is either an intention to kill or an intention to cause grievous bodily harm. In "R v Moloney" [1985], Lord Bridge held that intent is defined in the "mens rea" requirement of murder 'means intent' so the jury should simply use the term "intent" legally as they would in normal parlance. Furthermore, he held that for the defendant to have the "mens rea" of murder, there must be something more than mere foresight or knowledge that death or serious injury is a "natural" consequence of the current activities: there must be clear evidence of an intention. This element of intention is fulfilled when the defendant's motive or purpose was to cause death or serious bodily harm (also known as 'direct intent') but also when the defendant's motive or purpose was not to cause death or grievous bodily harm but (as held by Lord Steyn in "R v Woollin") death or serious bodily harm was a 'virtual certainty' of the defendant's act, and the defendant appreciated that to be so (also known as 'oblique intent.')

In most common law jurisdictions, the American Law Institute's Model Penal Code, and in the various U.S. state statutes, which have codified homicide definitions, the term has been abandoned or substantially revised. The four states of mind that are now recognized as constituting "malice aforethought" in murder prosecutions are as follows:

Since there are 4 different states of mind of malice aforethought, it can be hard to find the differences. It is easiest to break these categories up by premeditation, or express malice and reckless endangerment, or implied malice. Intent to kill or to inflict serious bodily injury would be considered express. This does not mean that the accused made a plan far in advanced, but it could even be in the moment of the crime. If the person did the action knowing it would hurt or kill the other person, there was express malice involved, which is a form of malice aforethought.

As stated above, malice aforethought does not require that the person accused premeditated to hurt a person, but that they knew their actions could lead to someone's harm. This is implied malice, which requires that a person knowingly did an act that they knew was dangerous, and acted without concern for other people's safety. Intention can also be found where the perpetrator acts with gross recklessness showing lack of care for human life, commonly referred to as "depraved-heart murder", or during the commission of or while in flight from a felony or attempted felony (termed felony murder).

Notably, the principle of transferred intent causes an accused who intended to kill one person but inadvertently killed another instead to remain guilty of murder. The intent to kill the first person suffices.

Malice aforethought is no longer regarded as a necessary "mens rea" element to prove a murder conviction. The term is a catch-all phrase that encompasses all the states of mind that are sufficient "mens rea" for murder. Most Australian jurisdictions require some degree of actual awareness of the resulting consequences of the accused's own actions to justify a murder conviction. The High Court of Australia affirmed that there is a spectrum of "mens rea" ranging from intention to kill to reckless indifference that would be relevant in securing a murder conviction. However, the High Court ruled that it was not necessary to prove malice aforethought in a manslaughter conviction. The Full Court of the Supreme Court of Victoria distinguished between the two classes of manslaughter. They were manslaughter by reckless indifference and manslaughter by criminal negligence in "R v Nydam" in which malice aforethought was definitively ruled out as an element in a charge of manslaughter by criminal negligence.


</doc>
<doc id="8957449" url="https://en.wikipedia.org/wiki?curid=8957449" title="Work-at-home scheme">
Work-at-home scheme

A work-at-home scheme is a get-rich-quick scam in which a victim is lured by an offer to be employed at home, very often doing some simple task in a minimal amount of time with a large amount of income that far exceeds the market rate for the type of work. The true purpose of such an offer is for the perpetrator to extort money from the victim, either by charging a fee to join the scheme, or requiring the victim to invest in products whose resale value is misrepresented.

Work-at-home schemes have been around for decades, with the classic "envelope stuffing" scam originating in the United States during the Depression in the 1920s and 1930s. In this scam, the worker is offered entry to a scheme where they can earn $2 for every envelope they fill. After paying a small $2 fee to join the scheme, the victim is sent a flyer template for the self-same work-from-home scheme, and instructed to post these advertisements around their local area – the victim is simply "stuffing envelopes" with flyer templates that perpetuate the scheme. Originally found as printed adverts in newspapers and magazines, variants of this scam have expanded into more modern media, such as television and radio adverts, and forum posts on the Internet.

In some countries, law enforcement agencies work to fight work-at-home schemes. In 2006, the United States Federal Trade Commission established Project False Hopes, a federal and state law enforcement sweep that targets bogus business opportunity and work at home scams. The crackdown involved more than 100 law enforcement actions by the FTC, the Department of Justice, the United States Postal Inspection Service, and law enforcement agencies in eleven states.

Legitimate work-at-home opportunities do exist, and many people do their jobs in the comfort of their own homes, but anyone seeking such an employment opportunity should be wary of accepting a home employment offer. A 2007 report in the United States suggested that about 97% of work-at-home offers were scams. Many legitimate jobs at home require some form of post-high-school education, such as a college degree or certificate, or trade school, and some experience in the field in an office or other supervised setting. Additionally, many legitimate at-home jobs are not like those in schemes are portrayed to be, as they are often performed at least some of the time in the company's office, require more self discipline than a traditional job, and have a higher risk of firing.

Common types of work found in work-at-home schemes include:

Some adverts offer legitimate forms of work that really do exist, but exaggerate the salary and understate the effort that will have to be put into the job, or exaggerate the amount of work that will be available. Many such ads do not even specify the type of work that will be performed. Some similar schemes do not advertise work that would be performed at home, but may instead offer occasional, sporadic work away from home for large payments, paired with a lot of free time. Some common offers fitting this description are acting as extras, mystery shopping (which in reality requires hard work, is paid close to minimum wage, and most importantly, does not require an up-front fee to join) and working as a nanny.

Signs of a work-at-home scam versus a legitimate job may include:

The consequences of falling for a work-at-home scheme may be as follows:



</doc>
<doc id="22529331" url="https://en.wikipedia.org/wiki?curid=22529331" title="Lonely hearts killer">
Lonely hearts killer

A lonely hearts killer (or want-ad killer) is a criminal who commits murder by contacting a victim who has either posted advertisements to or answered advertisements via newspaper classified ads and personal or lonely hearts ads.

The actual motivations of these criminals are varied. By definition, a killing will have taken place inasmuch as the suspected, accused, or convicted perpetrator has been dubbed a want-ad or lonely hearts killer. However, the crime may have involved a simple robbery gone wrong, an elaborate insurance fraud scheme, sexual violence, or any of several other ritualized pathological impulses (e.g. necrophilia, mutilation, cannibalism, etc.). Sometimes murder is not the (original) intent, but becomes a by-product of rape or other struggle; in some cases, murder is committed simply to cover up the original crime. Some, on the other hand, are serial killers who utilize this method of targeting victims, either exclusively, or when it suits them.

The following accused and convicted murderers and serial killers are known to have used want ads, personal ads, and/or matrimonial bureaus to contact their victims:


The theme of the want-ad killer or lonely hearts murderer has been popular in fiction. Examples of dramatic treatments of this theme are listed in chronological order of publication or release:




</doc>
<doc id="1460619" url="https://en.wikipedia.org/wiki?curid=1460619" title="United Nations Office on Drugs and Crime">
United Nations Office on Drugs and Crime

The United Nations Office on Drugs and Crime (UNODC; French: "Office des Nations unies contre la drogue et le crime") is a United Nations office that was established in 1997 as the Office for Drug Control and Crime Prevention by combining the United Nations International Drug Control Program (UNDCP) and the Crime Prevention and Criminal Justice Division in the United Nations Office at Vienna. It is a member of the United Nations Development Group and was renamed the United Nations Office on Drugs and Crime in 2002. In 2016–2017 it has an estimated biannual budget of US$700 million.

The agency, employing between 1,500 and 2,000 people worldwide, has its headquarters in Vienna (Austria), with 21 field offices and two liaison offices in Brussels and in New York City. The United Nations Secretary-General appoints the agency's Executive Director. Yuri Fedotov, the former Russian Ambassador to the United Kingdom, has held this position since his appointment in 2010, when he succeeded Antonio Maria Costa in his personal capacity, and also as Director-General of the United Nations Office at Vienna.

UNODC incorporates the secretariat of the International Narcotics Control Board (INCB).

UNODC was established to assist the UN in better addressing a coordinated, comprehensive response to the interrelated issues of illicit trafficking in and abuse of drugs, crime prevention and criminal justice, international terrorism, and political corruption. These goals are pursued through three primary functions: research, guidance and support to governments in the adoption and implementation of various crime-, drug-, terrorism-, and corruption-related conventions, treaties and protocols, as well as technical/financial assistance to said governments to face their respective situations and challenges in these fields.

The office aims long-term to better equip governments to handle drug-, crime-, terrorism-, and corruption-related issues, to maximise knowledge on these issues among governmental institutions and agencies, and also to maximise awareness of said matters in public opinion, globally, nationally and at community level. Approximately 90% of the Office's funding comes from voluntary "contributions", mainly from governments.

These are the main themes that UNODC deals with: Alternative Development, anti-corruption, Criminal Justice, Prison Reform and Crime Prevention, Drug Prevention, -Treatment and Care, HIV and AIDS, Human Trafficking and Migrant Smuggling, Money Laundering, Organized Crime, Piracy, Terrorism Prevention.

The World Drug Report is a yearly publication that presents a comprehensive assessment of the international drug problem, with detailed information on the illicit drug situation. It provides estimates and information on trends in the production, trafficking and use of opium/heroin, coca/cocaine, cannabis and amphetamine-type stimulants. The Report, based on data and estimates collected or prepared by Governments, UNODC and other international institutions, attempts to identify trends in the evolution of global illicit drug markets.

Through the World Drug Report, UNODC aims to enhance Member States' understanding of global illicit drug trends and increase their awareness of the need for the more systematic collection and reporting of data relating to illicit drugs.

United Nations Conventions and their related Protocols underpin all the operational work of UNODC.

The Convention is a legally binding instrument that entered into force on 29 September 2003, through which States parties commit to taking a series of measures against transnational organized crime. States that ratify the convention has the duty of creation of domestic offences to combat the problem, the adoption of new, sweeping frameworks for mutual legal assistance, extradition, law enforcement cooperation, technical assistance and training. The convention signifies an important stage in dealing with transnational crime by recognizing the seriousness of the problem that the crime poses, and gaining understanding from the member states of the importance of a cooperative measure. The convention is complemented by three different protocols: 


The Protocol to Prevent, Suppress and Punish Trafficking in Persons, especially Women and Children aims to provide a convergence in the states' domestic offences in the investigation and the persecution process. Another objective of the protocol is to protect the victims of trafficking in persons with full respect.

The Protocol against the Smuggling of Migrants by Land, Sea and Air is concerned with the aggravating problem of organized crime groups for smuggling persons. The protocol aims to combat and prevent transnational smuggling as well as to promote cooperative measures for enhancing protective measures for victims.

The Protocol against the Illicit Manufacturing of and Trafficking in Firearms, their Parts and Components and Ammunition was adopted to prevent and provide a cooperative measure for illicit manufacturing of and trafficking in firearms, their parts and components and ammunition. By adopting the protocol, the member states commit to adopt domestic criminal offences for illegal manufacturing, providing governmental licensing ammunition, and keeping track of the ammunition.

In its resolution 55/61, the General Assembly recognized that an effective international legal instrument against corruption, independent of the United Nations Convention against Transnational Organized Crime was desirable. The text of the Convention was negotiated during seven sessions held between 21 January 2002 and 1 October 2003. The Convention was adopted by the General Assembly on 31 October 2003.
In 2003, the United Nations adopted the UN Convention against Corruption (UNCAC). The Convention came into force in December 2005. As of 9 November 2012, 140 countries had signed and 164 countries (States Parties) had ratified the UNCAC. UNODC serves as the Secretariat for the Conference of the States Parties (CoSP) to the UNCAC.

UNODC, as the custodian of UNCAC, is also one of the main initiators of the establishment of the International Anti-Corruption Academy (IACA), whose main function is to, among other things, facilitate more effective implementation of the UNCAC.

There are three drug related treaties that guide UNODC's drug related programs. These are: The Single Convention on Narcotic Drugs of 1961 as amended by the 1972 Protocol ; the Convention on Psychotropic Substances of 1971 and the United Nations Convention Against Illicit Traffic in Narcotic Drugs and Psychotropic Substances of 1988.

These three major international drug control treaties are mutually supportive and complementary. An important purpose of the first two treaties is to codify internationally applicable control measures in order to ensure the availability of narcotic drugs and psychotropic substances for medical and scientific purposes, and to prevent their diversion into illicit channels. They also include general provisions on trafficking and drug abuse.

UNODC launches campaigns to raise awareness of drugs and crime problems. On 26 June every year, UNODC marks the International Day against Drug Abuse and Illicit Trafficking. 
On 9 December every year, UNODC commemorates the International Anti-Corruption Day.

The United Nations Office on Drugs and Crime (UNODC) started this international campaign to raise awareness about the major challenge that illicit drugs represent to society as a whole, and especially to the young. The goal of the campaign is to mobilize support and to inspire people to act against drug abuse and trafficking. The campaign encourages young people to put their health first and not to take drugs.

The United Nations Office on Drugs and Crime (UNODC) has teamed up with the United Nations Development Program (UNDP) to run this campaign as a focus on how corruption hinders efforts to achieve the internationally agreed upon MDGs, undermines democracy and the rule of law, leads to human rights violations, distorts markets, erodes quality of life and allows organized crime, terrorism and other threats to human security to flourish.

Young people aged 15 to 24 account for an estimated 40 per cent of new adult (15+) HIV infections worldwide. In some parts of the world, and in some marginalized sub-groups, the most frequent modes of HIV transmission for these young people are unsafe injecting drug use and unsafe sexual activities.

Because young people are also often more likely to use drugs, The United Nations Office on Drugs and Crime (UNODC) targets this population with a campaign to raise awareness about drug use and its connection to the spread of HIV and AIDS. The slogan: "Think Before You Start ... Before You Shoot ... Before You Share" is used to provoke young people to consider the implications of using drugs, and particularly injecting drugs.

The Blue Heart Campaign seeks to encourage involvement and action to help stop trafficking in persons. The campaign also allows people to show solidarity with the victims of human trafficking by wearing the Blue Heart. The use of the blue UN colour demonstrates the commitment of the United Nations to combat this crime.

In 2007, the five largest donors to UNODC's budget in descending order were: European Union, Canada, United States, the UN itself, and Sweden. According to the Transnational Institute this explains why, until recently, UNODC did not promote harm reduction policies like needle exchange and Heroin-assisted treatment. (This despite the actions of United Nations bodies (i.e. WHO and UNAIDS), who support these policies.) UNODC promotes other methods for drug use prevention, treatment and care that UNODC sees as "based on scientific evidence and on ethical standards".
The UNODC has been criticized by human rights organizations such as Amnesty international for not promoting the inclusion of adherence to international human rights standards within its project in Iran. Amnesty states that in Iran there are "serious concerns regarding unfair trials and executions of those suspected of drug offences in Iran.

UNODC has signed a partnership with the controversial Rule of Law and Anti-Corruption Center, which was founded by Ali Bin Fetais Al-Marri, the General-Prosecutor of Qatar.

Ali Bin Fetais Al-Marri has been accused of ill-gotten gains, corruption and support for Al-Qaeda terrorists by several media. He has also defended the life imprisonment of a Qatari poet and human rights campaigner.

In June 2012, Mohammad Reza Rahimi the Iranian Vice President made some controversial remarks during a speech at a UNODC Drugs and Crime conference in Tehran.

He then went on to blame the Talmud, a key Jewish religious text, for the expansion of illegal drugs around the world and said that it teaches to "destroy everyone who opposes the Jews."

Rahimi was widely condemned for his controversial remarks:




</doc>
<doc id="24978923" url="https://en.wikipedia.org/wiki?curid=24978923" title="Gene theft">
Gene theft

In bioethics and law, gene theft or DNA theft is the act of acquiring the genetic material of another human being without his or her permission, often from a public place. The DNA may be harvested from a wide variety of common objects such as discarded cigarettes, used coffee cups, and hairbrushes. This genetic material can then be used for purposes such as establishing paternity, proving genealogical connections or even unmasking private medical conditions.

Great Britain criminalized the acquisition of DNA without consent in 2006 at the urging of the Human Genetics Commission. Australia's legislature debated a two-year jail sentence for such theft in 2008.

In the United States, eight states currently have criminal or civil prohibitions on such nonconsensual appropriation of genetic materials. In Alaska, Florida, New Jersey, New York and Oregon, individuals caught swiping DNA face fines or short jail sentences. Lawsuits against "gene snatchers" are permitted in Minnesota, New Hampshire and New Mexico. In jurisdictions where such nonconsentual taking of DNA is illegal, exceptions are generally made for law enforcement.

Many bioethicists believe that such conduct is an unethical invasion of human privacy. Professor Jacob Appel has warned that criminals may acquire the capability to copy DNA of innocent people and deposit it at crimes scenes, endangering the blameless and undermining a key tool of forensic investigation." However, others defend the appropriation of genetic material on the grounds that doing so may further human knowledge in productive ways One particularly controversial case which received widespread attention in the media was that of Derrell Teat, a wastewater coordinator, who sought to acquire without consent the DNA of a man who was allegedly the last male descendant of her great-great-great grandfather’s brother. Another prominent case was a United States paternity suit involving film producer Steve Bing and billionaire investor Kirk Kerkorian.



</doc>
<doc id="18556316" url="https://en.wikipedia.org/wiki?curid=18556316" title="Contaminated currency">
Contaminated currency

Most banknotes have traces of cocaine on them; this has been confirmed by studies done in several countries. In 1994, the U.S. 9th Circuit Court of Appeals determined that in Los Angeles, out of every four banknotes, on average more than three are tainted by cocaine or another illicit drug.

Additionally, paper money in other parts of the world show a similar drug contamination, and studies indicate that they might even serve as a vector of disease, though researchers disagree over how easily diseases are transmitted this way.
Several theories have been suggested to explain this contamination beyond the predictable contamination due to handling during drug deals and the use of rolled up notes for snorting drugs. After the initial contamination, the substance is "infected to" other notes in close contact, often stacked together, in enclosed environments common in financial institutions.

In a study reported in "Forensic Science International", A.J. Jenkins, at the Office of the Cuyahoga County Coroner (Cleveland, OH), the author reports the analysis of ten randomly collected one-dollar bills from five cities, and tested for cocaine, heroin, 6-acetylmorphine (also called "6-AM"), morphine, codeine, methamphetamine, amphetamine and phencyclidine (PCP). Bills were then immersed in acetonitrile for two hours prior to extraction and subjected to Gas chromatography-mass spectrometry (GC-MS) analysis. Results demonstrated that "92% of the bills were positive for cocaine with a mean amount of 28.75 ± 139.07 micrograms per bill, a median of 1.37 μg per bill, and a range of 0.01-922.72 μg per bill. Heroin was detected in seven bills in amounts ranging from 0.03 to 168.5 μg per bill: 6-AM and morphine were detected in three bills; methamphetamine and amphetamine in three and one bills, respectively, and PCP was detected in two bills in amounts of 0.78 and 1.87 μg per bill. Codeine was not detected in any of the one-dollar bills analyzed". The study confirmed that although paper currency was most often contaminated with cocaine, other drugs of abuse may also be detected in bills.

Another study, conducted at Argonne National Laboratory, found that four out of five dollar bills in Chicago suburbs contain traces of cocaine. Previous studies have found similar contamination rates in other cities. But the Argonne study is the first to demonstrate that if you handle contaminated bills, you won't wind up with drugs on your hands. "It's virtually impossible for cocaine to rub off", Argonne chemist Jack Demirgian said. This estimate of contamination could be as high as 94%, according to Bill and Rich Sones of the Chicago Sun-Times.

This was confirmed by Ronald K. Siegel in his book, "Intoxication: Life in Pursuit of Artificial Paradise", who noted the figure as well. Another study by the "Journal of Analytical Toxicology" is more conservative, noting a still substantial contamination of 80% of US currency by cocaine.

It was uncovered in the "Sacramento Bee" that while the initial source of the contamination comes from money used in the Illegal drug trade in circulation, the U.S. Federal Reserve unwittingly spreads the substance to clean currency by mixing the notes together. The "Journal of Analytical Toxicology" confirms this assessment, noting that counting machines (in addition to simple proximity) are the agents of transfer.

The discovery that cocaine is so prevalent in U.S. banknotes has a legal application that reactions by drug-sniffing dogs is not immediately cause for arrest of persons or confiscation of banknotes. (The drug content is too low for prosecution but not too low to trigger response to drug-sniffing dogs.), though this has been contested legally in a number of U.S. states as a standard of what constitutes 'unusual' levels of contamination remains to be achieved ("see below").

In addition to traces of illicit drugs, a recent study of currency within New York City have shown that various contagious microbes from skin and oral commenals are also transferred onto paper bank notes, including Propionibacterium acnes, Staphylococcus epidermidis and Micrococcus luteus. Other microbes detected not associated with humans included Lactococcus lactis and Streptococcus thermophilus, microbes typically associated with dairy production and fermentation. The study went on to prove that viable microbes could be isolated and cultured from paper currency. An earlier study conducted in western Ohio, in which "One-dollar bills were collected from the general community in western Ohio to survey for bacterial contamination. Pathogenic or potentially pathogenic organisms were isolated from 94% of the bills. These results suggest a high rate of bacterial contamination of one-dollar bills."

Forensic scientists have said that around 80% of all British banknotes contain traces of drugs. A 1999 study found even higher levels of contamination in the London area; of 500 notes tested, only four had no traces of cocaine. Most of the banknotes showed only low levels of contamination, suggesting they had merely been in contact with contaminated notes, but 4% of the notes in the study showed higher levels, which the researchers suggested was the result of either being handled by people under the influence of cocaine (which is excreted in skin oils), or by being used directly to snort the drug.

There are drug levels above which banknotes need to be taken out of circulation, and over £15 million worth of notes are destroyed annually for this reason. The destruction is more often done as a precaution than because the money poses a serious health hazard.

Cocaine is the drug most commonly found on banknotes. Heroin and ecstasy are found less often, though the frequency of ecstasy contamination rose in the years leading up to 2002. Joe Reevy of Mass Spec Analytical, a company which analyses confiscated banknotes for the police, pointed out that heroin and ecstasy degrade more rapidly than cocaine, and that a single note which had been used to snort cocaine could subsequently contaminate many others when placed in a sorting machine, to explain the frequency of cocaine contamination.

Money recovered from police raids on the drugs trade are often heavily contaminated. In one raid in 2002, £465,000 was found which had been stored in a room where heroin was being prepared, and was so heavily contaminated that officers were advised not to touch it without protective equipment.

Prior studies found that the level of contamination - i.e., the concentration of the contaminants - was different between those notes suspected to be used in the drug trade and those of proximity transfer levels. Subsequent tests have confirmed this determination, and serve as the basis for court cases against drug dealers, since the basic level of drug contamination remains fairly constant throughout the UK, despite factors that might immediately be thought to affect levels, like rural or urban environments, rich or poor or areas with high or low crime rates.

The contamination of paper money is not limited to simply that of cocaine and other illicit drugs. Health officials in the UK warn that a silent Hepatitis-C epidemic could be brewing. Drug users with hepatitis who share with others the rolled paper note (or straw) used to snort cocaine can facilitate the transfer of the disease to thousands. As drug users are frequently impaired, they can easily fail to notice small traces of blood on these rolled banknotes. This is considered to be of particular concern, as eight out of ten carriers are unaware of their status (as hepatitis can lie dormant for decades), and have little in the way of access to regular healthcare . This higher risk for contracting hepatitis-C has also been noted by the American National Institutes of Health (NIH). Without treatment, hepatitis-C can lead to chronic liver disease.

The British Department of Health estimates that there are over 200,000 people infected with hepatitis C in Britain, but the number might be much higher.
Charles Gore, the chief executive of the Hepatitis C Trust, said: "Estimates show that around 5,000 new cases of hepatitis C are diagnosed every year - but they are mainly through chance. Because so many are undiagnosed we can't tell what kind of problem we are looking at. When 5,000 banknotes were tested in London in 2000, 99% of them had traces of cocaine on them. That tells us that there is potentially a massive problem in diagnosis and people's awareness of how easily hepatitis C can be contracted."

Professor Graham Foster, of St Mary's Hospital, London, said: "Sharing banknotes or straws is a significant risk factor that people need to be more aware of. Although the risk of contracting hepatitis C through snorting is lower than through sharing a needle, it is still there."

Similar contaminations have been found on euro banknotes from Ireland, Spain, and Germany with the cocaine concentration being almost 100 times higher on the Spanish banknotes than on the German. Additionally, Germany had noted the unusual occurrences of German euros cracking and disintegrating after being withdrawn from ATMs, later explained as being caused by the sulfates used in the production of methamphetamine mixing with human sweat to form sulfuric acid, which breaks down the paper the euros are printed on. Most of the crystal methamphetamine present in Germany comes from Eastern Europe, and has a high level of sulfates.

The longevity of most modern currency has also given rise to various fallacies regarding the transmission of bacteriological agents with paper banknotes. In early 2003, China placed banknotes under quarantine amid fears that SARS could be spread by the notes. Notes were held for 24 hours—the presumed lifespan of the virus. No evidence indicates that banknotes were an infection vector in the 2002–2004 SARS outbreak.

Contamination of bills is one factor that influenced Australia to introduce polymer banknotes for general circulation in 1992. Australia now also prints polymer currency for almost two dozen other countries, including Israel, Malaysia, Mexico and Romania.



</doc>
<doc id="12841199" url="https://en.wikipedia.org/wiki?curid=12841199" title="Baton (law enforcement)">
Baton (law enforcement)

A baton or truncheon is a roughly cylindrical club made of wood, rubber, plastic or metal. It is carried as a compliance tool and defensive weapon by law-enforcement officers, correctional staff, security guards and military personnel. In many cultures, they are highly symbolic of law enforcement and are rarely used with the intention to kill.

A baton or truncheon may be used in many ways as a weapon. It can be used defensively to block; offensively to strike, jab, or bludgeon; and it can aid in the application of armlocks. The usual striking or bludgeoning action is not produced by a simple and direct hit, as with an ordinary blunt object, but rather by bringing the arm down sharply while allowing the truncheon to pivot nearly freely forward and downward, so moving its tip much faster than its handle. Batons are also used for non-weapon purposes such as breaking windows to free individuals trapped in a vehicle, or turning out a suspect's pockets during a search (as a precaution against sharp objects).

Some criminals use batons as weapons because of their simple construction and easy concealment. The use or carrying of batons or improvised clubs by people other than law enforcement officers is restricted by law in many countries.

Other names for a baton are a truncheon, cosh, billystick, billy club, nightstick, or stick.

In the Victorian era, police in London carried truncheons about one-foot long called "billy clubs". According to the "Online Etymology Dictionary", this name is first recorded in 1848 as slang for a burglars' crowbar. The meaning "policeman's club" is first recorded 1856. The truncheon acted as the policeman's 'Warrant Card' as the Royal Crest attached to it indicated the policeman's authority. This was always removed when the equipment left official service (often with the person who used it). Earlier on the word was used in vulgar Latin ("bastο"—a stick helping walking, from "basta"—hold).

The Victorian original has since developed into the several varieties available today. The typical truncheon is a straight stick made from wood or a synthetic material, approximately in diameter and long, with a fluted handle to aid in gripping. Truncheons are often ornamented with their organizations' coats of arms. Longer truncheons are called "riot batons" because of their use in riot control. Truncheons probably developed as a marriage between the club or military mace and the staff of office/sceptre.

Straight batons of rubber have a softer impact. Some of the kinetic energy bends and compresses the rubber and bounces off when the object is struck. Rubber batons are not very effective when used on the subject's arms or legs, and can still cause injury if the head is struck. That is why most police departments have stopped issuing them. The Russian police standard-issue baton is rubber, except in places such as Siberia, where it can be cold enough that the rubber may become brittle and break if struck. The traffic baton is red to make it more visible as a signaling aid in directing traffic. In Russia traffic batons are striped in black and white for the same reason, and in Sweden they are white. Until the mid-1990s, British police officers carried traditional wooden truncheons of a sort that had changed little from Victorian times. Since the late 1990s, the collapsible baton is issued except for public order duties, where a fixed, acrylic baton is used. Side-handled batons were issued for a while, but fell out of favour.

In New York, the police used to use two kinds of batons depending on the time. The one for daytime was called a day-stick and was 11 inches in length. Another baton, that was used at night, was 26 inches long and called a night-stick, which is the origin of the word "nightstick". The night-stick was longer so it could provide extra protection which was thought to be necessary at night.

In modern police training, the primary targets are large nerve clusters, such as the common peroneal nerve in the mid-thigh and large, easily targetable muscle groups, such as the quadriceps and biceps. The baton is swung in fast, "snapping" strikes to these areas, sometimes only making contact with the tip. Taken together, these are intended to impair the subject's ability to continue advancing (by striking the leg) or attack (by striking the arm) by causing transitory neurapraxia (temporary muscle pain, spasm and paralysis due to nerve injury). Modern systems strictly prohibit hitting the skull, sternum, spine, or groin unless such an attack is conducted in defense of life, with many jurisdictions considering this deadly force.

Before the 1970s, a common use of the police baton was to strike a suspect's head with a full-force overhand motion in order to stun them or knock them unconscious by cerebral concussion, similar to the pre-baton practice of buffaloing with the handle of a revolver. However, this practice had two major liabilities. First, there was a high risk and incidence of death or permanent injury, as the difference in force between that required to concuss a suspect into non-resistance and that which would fracture their skull tends to be narrow and unpredictable. Second, there were problems with reliability, as resistance to cerebral concussion varies widely between individuals, and head strikes that didn't disable the suspect were found to merely escalate the encounter. Officer Arthur Lamb, a well-known trainer on the baton once stated:

As a result, civil lawsuits and claims of police brutality resulted in revised training for officers. 

Hand-held impact weapons have some advantages over newer less-lethal weapons. Batons are less expensive than Tasers to buy or to use, and carry none of the risk of cross-contamination of OC aerosol canisters such as pepper spray in confined areas (in houses, if police use pepper spray, the officers may get the spray in their eyes accidentally). Tasers and OC canisters have limited ammunition, whereas batons use none. Like Tasers and pepper spray, batons are referred to as "less-lethal" rather than "non-lethal". That is, these weapons are not designed to be fatal, but they can be. The baton is considered to have a greater risk of lethality than most less-lethal weapons, and so is higher on the use of force continuum than Tasers or OC. While all police weapons can potentially be taken from an officer and used against them, this risk is even greater with batons, as they can being grabbed and pulled away by a suspect if the officer improperly brandishes or swings them.

Batons in common use by police around the world include many different designs, such as fixed-length straight batons, blackjacks, fixed-length side-handle batons, collapsible straight batons, and other more exotic variations. All types have their advantages and disadvantages. The design and popularity of specific types of baton have evolved over the years and are influenced by a variety of factors. These include inherent compromises in the dual (and competing) goals of control effectiveness and safety (for both officer and subject).

A straight, fixed-length baton (also commonly referred to as a "straightstick") is the oldest and simplest police baton design, known as far back as ancient Egypt. It consists of little more than a long cylinder with a molded, turned or wrapped grip, usually with a slightly thicker or tapering shaft and rounded tip. They are often made of hardwood, but in modern times are available in other materials such as aluminium, acrylic, and dense plastics and rubber. They range in size from short clubs less than a foot in length to long "riot batons" commonly used in civil disturbances or by officers mounted on horseback.

Straightsticks tend to be heavier and have more weight concentrated in the striking end than other designs. This makes them less maneuverable, but theoretically would deliver more kinetic energy on impact. Most agencies have replaced the straightstick with other batons because of inconvenience to carry, and a desire for their officers to look less threatening to the community they serve. Despite having been replaced by side-handle and expandable batons in many (if not most) law enforcement agencies, straightsticks remain in use by many major departments in the US, such as the Baltimore, Denver, Sacramento, Long Beach, Santa Ana, Philadelphia, San Francisco, and Riverside Police Departments. They also are used by NYPD Auxiliary Police officers, as well as many Military Police forces around the world.

Side-handle batons (sometimes referred to as T-batons or nightsticks) are batons with a short side handle at a right angle to the shaft, about six inches from one end. The main shaft is typically in length. They are derived from the tonfa, an Okinawan kobudō weapon, and are used with a similar technique (although tonfa are usually used in pairs, whereas side-handle batons are not). The best-known example is the Monadnock PR-24; "PR-24" has become a genericized trademark within the law enforcement and security communities for this type of product.

It can be held by:


Side-handle batons are made in both fixed and collapsible models and may be constructed from a range of materials including wood, poly-carbonate, epoxy, aluminium, or a combination of materials. Some side-handle batons are one-piece design; the side-handle component and primary shaft are permanently fused together during manufacturing. One-piece designs are potentially stronger than two-piece designs, and have no risk of having a locking screw loosen from its threads. Other side-handle batons are two-piece in design (common among cheaper makes); the side-handle component is screwed into the primary shaft. The side handle may be removed from the shaft by the end-user, converting the side-handle into a straight baton.

The advantages of a side-handle baton over a straight baton are numerous:


Side-handle batons have a few disadvantages:


Side-handle batons have been involved in high-profile incidents of alleged police brutality, such as in New Zealand's 1981 Springbok Tour and the Rodney King beating.

An expandable baton (also referred to variously as a collapsible baton, telescopic <nowiki>[</nowiki>or telescoping<nowiki>]</nowiki> baton, tactical baton, spring cosh, ASP, Extendable, or extendo <nowiki>[</nowiki>slang<nowiki>]</nowiki>) is typically composed of a cylindrical outer shaft containing telescoping inner shafts (typically 2 or 3, depending on the design) that lock into each other when expanded. The shafts are usually made of steel, but lightweight baton models may have their shafts made from other materials such as aluminium alloy.

Expandable batons may have a solid tip at the outer end of the innermost shaft; the purpose of the solid tip is to maximize the power of a strike when the baton is used as an impact weapon. Expandable batons are made in both straight and side-handle configurations, but are considerably more common in the straight configuration. The best-known example of the straight expandable baton is the ASP Baton, from Armament Systems and Procedures; so much so that it has become a genericized trademark within the law enforcement and security communities for this type of product.

Depending on the holster or scabbard design, it may be possible to carry an expandable baton in either collapsed or expanded position, which would be helpful if an officer needed to holster an expanded baton and it was not possible or convenient to collapse it at the time. An expandable baton is opened by being swung in a forceful manner while collapsed, using inertia to extend and lock the segments by friction. Some mechanical-lock versions can also be opened by simply pulling the segments apart. Depending on the design, expandable batons may be collapsed either by being brought down (inverted) on a hard surface, or by depressing a button lock and manually collapsing the shafts. Additionally, the baton, in collapsed configuration, may be used as a control device against non-compliant subjects in conjunction with pain-compliance control techniques, such as to remove a driver refusing to exit his or her vehicle. It can be used as a large kubotan.

The expandable baton is provided to most officers in the British police forces, the idea being that should violence suddenly escalate, the baton can be easily deployed but can be stowed neatly away so as not to affect movement due to its mounting point on the officer's clothing. It is also commonly used in the UK and many other countries as a means of gaining entry quickly to a vehicle that contains offenders. In such a situation the baton is deployed and, due to the solid end of the device, is used to strike the side windows or windscreen of the vehicle to either gain entry or to stop the driver seeing where they are going in circumstances where the officer has hit the screen while the vehicle is still in motion.

The advantages of a collapsible baton over a fixed baton are numerous:


Expandable batons have some disadvantages:


The terms blackjack, cosh, and sap refer to any of several short, easily concealed club weapons consisting of a dense (often lead) weight attached to the end of a short shaft, used as a bludgeon. These weapons work by transferring kinetic energy to the dense core, via the handle, during the swing. When directed at the head, it works by concussing the brain without cutting the scalp. This is meant to stun or knock out the subject, although head strikes have a high risk of causing a permanent, disabling brain injury or being fatal.

The terminology used to refer to these weapons varies and can be imprecise, and depends on the source and time period. In some contexts, these terms are used loosely to refer to any small, dense bludgeon, including those that are improvised.

A late 19th-century type is a wooden shaft about one foot long, with a leather- or macrame-covered lead ball as the head. This weapon is referred to by some sources as a "sap" (derived from "sapling" due to its wood handle), or euphemistically as a "life-preserver." The term "cosh" may also originate with this weapon, being derived from the Romani word "kašt", meaning "stick" or "piece of wood." The term "blackjack" referring to a hand weapon is of unknown etymology, and the earliest text reference is 1889.
A type used by sailors in the 19th and early 20th century was weighted with a heavy lead ball at one or both ends of a piece of baleen, which is then wrapped in woven or plaited marline or codline and then varnished over. Some carefully made examples were likely to have been used by a boatswain or ship's master-at-arms or ship's mate as a badge of office and discipline-enforcer, so some modern sources call this weapon a "bosun's cosh." The term "blackjack" is sometimes applied by early 20th-century maritime sources to a lead weight knotted or woven into the end of a short piece of rope that serves as a handle, though most sources would consider this weapon a type of slungshot.
In the 20th Century, newer designs emerged that are shorter and predominately made of stitched or braided leather, with a flexible spring inside the handle. The slight flexibility and resilience of the handle gives these small clubs a whip-like action. Law enforcement sources from the mid-20th century prefer to divide these into two categories: "Blackjacks", which have a mostly cylindrical striking head, and "saps" which have a flat, usually oval-shaped head. In common usage, these terms have become interchangeable, so a "sap" of this kind is sometimes more precisely called a "flat sap, slap jack" or "beavertail sap" to differentiate it. The sap's flat profile makes it easier to carry in a pocket and spreads its impact out over a broader area, making it less likely to break bone. However, it can also be used to strike with the edge for more focused impact, though this was discouraged by most police departments for precisely this reason. There are several variants of these weapons that use different materials, such as steel instead of lead for the weight, or plastic for the covering. Some variants use powdered metal or even sand for the weight inside the head, usually called a "soft sap," which reduces the likelihood of bone fractures.
Blackjacks and saps were popular among law enforcement for a time due to their low profile, small size, and usability at very close range, such as when grappling with a suspect. Besides the head, they were also used on the elbows, wrists, shins, collarbone, and groin. The flat sap, in particular, could be used to strike large muscle groups with the edge. In the early days of use, they were favored for their ability stun or knock a suspect unconscious with a blow to the head. By the late 1960s head-strikes with impact weapons in general were strongly discouraged by most police departments and trainers because of the risk of death or permanent injury, as well as its questionable effectiveness. By the 1990s virtually all modern police departments had phased them out from their issued equipment, and most banned their use entirely.

Stun batons are an unusual modern variation designed to administer an electric shock in order to incapacitate the target. They consist of an insulated handle and guard, and a rigid shaft usually a foot or more in length for delivering a shock. Many designs function like an elongated stun gun or a cattle prod, requiring the tip to be held against the target and then manually triggering a shock by a switch in the handle. Some more sophisticated designs carry a charge along the shaft's entire surface, administering a shock on contact. This later design is especially useful in preventing the officer from having his weapon grabbed and taken away by an assailant.

Most batons of this design were not intended to be used as impact weapons and will break if used in this way, though a few were built to withstand occasional lighter impacts. They are rarely issued to patrol officers in modern times due to their price and the other associated problems with electroshock weapons.

The jitte was a Japanese Edo period police weapon consisting of a round or octagonal metal rod about long with a hook-like guard above the handle. It was used in a similar manner to modern police batons and it continued to be issued in Japan to some police departments until the early 20th century. The jitte eventually inspired an early form of expandable baton called a "tokushu keibo" in the 1960s.

A homemade blackjack can be made using several techniques. Putting a bar of soap, rocks or some wet sand in a sock, then tying off the end makes a blackjack out of common items.

Some non-purpose-built items have been used by law enforcement over the centuries as impact weapons. Examples are:


Although the Kel-Lite in the 1970s appears to have been the third flashlight designed specifically to be useful as an emergency defensive weapon, the best-known example is the large, metal D-cell Maglite, still in use by some law enforcement and security personnel. Use of such flashlights as a club or baton is generally officially discouraged by the manufacturers and law enforcement officials, but its use is an option. As with all police weapons, there have been many allegations of misuse, such as in the Malice Green beating in Detroit. The use of flashlights as improvised impact weapons is subject to the same use of force regulations as the use of purpose-designed impact weapons like batons.

Police officers may often choose to use such flashlights because they are viewed primarily as illumination devices; thus, if a police officer carries one in his hands during nighttime encounters with potentially violent subjects, it would be less likely to escalate the situation (by making the subject feel threatened) than if the officer were to be equipped with a baton or pepper spray canister instead. This permits the officer to appear less threatening while having an impact weapon in hand and ready for instantaneous action, should the situation indeed turn violent.

Characteristic of a flashlight used as a baton or club is the grip employed. Flashlights are commonly held with the bulb end pointing from the thumb side of the hand, such that it is pointing outward from the body when held palm upward. When wielded as a club, the bulb end points inward when the hand is palm upward, and the grip is closely choked to the bulb end. Another advantage to using a flashlight as a club is that in poorly lit situations it can be used to initially dazzle the eyes of an opponent. Law enforcement officers often deliberately shine flashlight beams into the eyes of suspects at night to cause temporary night-blindness as a preemptive defensive measure, whether or not the individual is likely to behave violently.

Batons are legal for sworn law enforcement and military in most countries around the world. However, the legality of civilian carry for purpose-built batons varies greatly by country, and by local jurisdictions.

There are no restrictions about batons to the general public, but private security guards can only carry wooden or rubber batons (no length is specified) according to Law 7102/83. They may also carry electric shock batons if they have a Less-Lethal Certification course. There is a general belief in Brazil that rubber batons are less prone to break bones than the wooden ones.

There is no law that prohibits batons; except for spring-loaded batons, which are defined as a prohibited weapon under a regulation entitled "Regulations Prescribing Certain Firearms and other Weapons, Components and Parts of Weapons, Accessories, Cartridge Magazines, Ammunition and Projectiles as Prohibited or Restricted" (also capable of being referred to by its registration number: SOR 98–462). However, it is a crime under section 90 of the Criminal Code to carry any weapon, including a baton, in a concealed fashion.

According to Cap 217 (Weapons Ordinance), Laws of Hong Kong, any person who has possession of any prohibited items commits an offence, which includes expandable batons.

In the Republic of Ireland, telescopic truncheons are classified as illegal offensive weapons.
All types of batons can be owned but not carried in public spaces by private citizens according to law (1988:254).

Straight, side-handled (PR-24) and friction-lock batons were added to the list of offensive weapons in 2004, which prohibited their manufacture, sale, hire, offering for sale or hire, lending or giving to any other person under Section 141 Criminal Justice Act 1988. The telescopic truncheon - defined as being a truncheon which extends automatically by hand pressure applied to a button, spring or other device in or attached to its handle - was banned in the original 1988 order.

They are not prohibited from possession in a private place such as a home, closed off building site, behind a sales counter, etc., but obviously an explanation would be needed to show how the item was lawfully acquired post 1988 or 2004, depending on the type of baton.

Legality is determined by the laws of the individual states. Some such as Vermont or Arizona allow for legal carry in the absence of unlawful behavior or criminal intent. Others such as California have general prohibitions against the carrying of all "club" weapons by non-law enforcement. Such jurisdictions will sometimes make exceptions for persons employed as security guards or bodyguards, will provide for permits to be obtained for legal carry, or make exceptions for persons who complete an appropriate training course.




</doc>
<doc id="884309" url="https://en.wikipedia.org/wiki?curid=884309" title="Confiscation">
Confiscation

Confiscation (from the Latin "confiscare" "to consign to the "fiscus", i.e. transfer to the treasury") is a legal form of seizure by a government or other public authority. The word is also used, popularly, of spoliation under legal forms, or of any seizure of property as punishment or in enforcement of the law.

As a punishment, it differs from a fine in that it is not primarily meant to match the crime but rather reattributes the criminal's ill-gotten spoils (often as a complement to the actual punishment for the crime itself; still common with various kinds of contraband, such as protected living organisms) to the community or even aims to rob them of their socio-economic status, in the extreme case reducing them to utter poverty, or if he or she is condemned to death even denies them inheritance to the legal heirs.

Meanwhile, limited confiscation is often in function of the crime, the rationale being that the criminal must be denied the fruits of their fault, while the crime itself is rather punished in some other, independent way, such as physical punishments or even a concurring fine.

Often, police will auction items confiscated via police auction or asset forfeiture and keep the proceeds. Theoretically, it is possible for owners to buy back confiscated items. 

In airports, potentially dangerous items (such as hazardous chemicals, weapons, and sharp objects) are usually confiscated at inspections. Other items, such as certain food, may also be confiscated, depending on importation laws. Depending on the nature of the items, some may be returned at the end of the flight, while most are discarded or auctioned off. The musical comedian Anna Russell had an Irish harp confiscated by the U.S. Customs Service.

Originally, in Roman law, confiscation was the seizure and transfer of private property to the "fiscus" (treasury) by the emperor; hence the appropriation, under legal authority, of private property to the state.

In modern English law, confiscation embraces forfeiture in the case of goods, and escheat in the case of lands, for crime or in default of heirs (see also Eminent domain). Goods may also be confiscated by the state for breaches of statutes relating to customs, excise or explosives. In the United Kingdom a confiscation order is a court order made under part 2 (England & Wales), part 3 (Scotland) or part 4 (Northern Ireland) of the Proceeds of Crime Act 2002 requiring a convicted defendant to pay a specified sum of money to the state by a specified date.

During the American Revolution, customs racketeering became a serious problem. By harshly enforcing customs laws, particularly the more obscure regulations, corrupt customs officials could seize property almost with impunity. This caused significant conflict between the United States and Great Britain.

In the United States among the "war measures" during the American Civil War, acts were passed in 1861 and 1862 confiscating, respectively, property used for "insurrectionary purposes" and the property generally of those engaged in rebellion.

There was from the late 1980s onwards a resurgence of interest in confiscation as crime prevention tool, which went hand in hand with the interest in the criminalization of money laundering. A number of international instruments, starting with the 1988 Vienna Convention, have strongly suggested the enactment of legal provisions enabling confiscation of proceeds of crime. The 40 recommendations of the FATF have also stated its importance as a crime prevention tool.

A further trend has been the reversal of the burden of proof for the purpose of facilitating confiscation. To the surprise of many, it is actually quite legal for law enforcement agencies to take property from people who haven't been convicted of a crime yet as civil asset forfeiture, a practice which brings in millions of dollars of revenue each year, disproportionately affecting people without means or access to a lawyer. 




</doc>
<doc id="10948731" url="https://en.wikipedia.org/wiki?curid=10948731" title="Ecclesiastical crime">
Ecclesiastical crime

An ecclesiastical crime is a crime ("delictum") related to the clergy where the crime is against canon law. Compare civil law.

The crime of Simony is the ecclesiastical crime of paying for offices or positions in the hierarchy of a church. The crimes of Schism and Heresy are also ecclesiastical crimes.

Older examples include "perjury", the breaking of a promissory oath (contractual promises made by oath or pledge of faith), and this was treated as an ecclesiastical crime. Some crimes have or have had both an ecclesiastical and a civil element to the crime; suicide and witches are counted here.

The term is also specifically used today for misappropriation of donation monies. In the International Bulletin of Missionary Research, January 2009, David B. Barrett, Todd M. Johnson, Peter F Crossing, study titled, Christian World Communions: Five Overviews of Global Christianity, AD 1800–2025 they show that "Ecclesiastical crime" is growing at 5.77% per annum and in mid-2009 is estimated to be USD$27 billion on a total "Giving to Christian causes" of USD$410 Billion. Unchecked this crime will be valued at USD$65 Billion by 2025



</doc>
<doc id="27416933" url="https://en.wikipedia.org/wiki?curid=27416933" title="Anatomy murder">
Anatomy murder

An anatomy murder (sometimes called burking in British English) is a murder committed in order to use all or part of the cadaver for medical research or teaching. It is not a medicine murder because the body parts are not believed to have any medicinal use in themselves. The motive for the murder is created by the demand for cadavers for dissection, and the opportunity to learn anatomy and physiology as a result of the dissection. Rumors concerning the prevalence of anatomy murders are associated with the rise in demand for cadavers in research and teaching produced by the Scientific Revolution. During the 19th century, the sensational serial murders associated with Burke and Hare and the London Burkers led to legislation which provided scientists and medical schools with legal ways of obtaining cadavers. Rumors persist that anatomy murders are carried out wherever there is a high demand for cadavers. These rumors, like those concerning organ theft, are hard to substantiate, and may reflect continued, deep-held fears of the use of cadavers as commodities.

Dissection as a way of acquiring medical knowledge existed since the ancient world, but during the Renaissance, increasingly widespread clandestine practices of post-mortem dissection led to fears that victims, especially the poor and outcast, would be murdered for their cadavers. During his years at the University of Padua, Andreas Vesalius made it clear that he had taken human remains from graveyards and ossuaries for his classic anatomical text "De humani corporis fabrica". Both he and his successor, Gabriele Falloppio, were rumored to have practiced human vivisection, although these rumors were not substantiated; however, Falloppio himself reported that he was asked by the judicial authorities to carry out an execution on a condemned criminal, whose cadaver he then dissected. During the 18th century, prominent British obstetrician William Smellie was accused of obtaining cadavers for his illustrated textbook on childbirth through murder. In 1751, Helen Torrence and Jean Waldie were convicted of murdering John Dallas, aged 8 or 9, and selling his cadaver to medical students in Edinburgh.

The great expansion in medical education in Great Britain in the early 19th century as a result of the Napoleonic Wars led to increased demand for cadavers for dissection. Body-snatching became more widespread, and local communities reacted by setting guards around graveyards. In 1828, Parliament convened a select committee to examine the means by which cadavers were obtained for medical schools. Ironically, this was the same period when the most notorious of the anatomy murders were carried out by William Burke and William Hare. They killed 16 people over the course of a year, selling the cadavers to the anatomist Robert Knox. Two years later, the London Burkers, John Bishop and Thomas Williams, murdered a boy identified as Carlo Ferrari and attempted to sell his cadaver to a London surgeon.

The most recent account of anatomy murders was in 1992, when a Colombian activist, Juan Pablo Ordoñez, claimed that 14 poor residents of Barranquilla, Colombia, had been killed to provide cadavers for the local medical school. One of the alleged victims managed to escape from his assailants and his account was publicized by the international press.

The difficulty of prosecuting cases of anatomy murders arises because of the difficulty of obtaining evidence. The victims are generally marginal and do not have anyone to report their disappearance. The cadavers, which may show evidence of homicide, are destroyed by dissection. Those dissecting the bodies may believe that they have been obtained legitimately, or may have a vested interest in keeping their practices quiet.

For these reasons, legislation from the 19th century on has focused on removing the motive for murder by providing legal sources of cadavers for medical research and teaching. In Great Britain, the Anatomy Act of 1832 provided for cheap, legal cadavers by turning over the bodies of those who died in caretaker institutions to medical schools. Although there were public protests at using the bodies of the poor as raw material for medical students, proponents of the Act were able to use fear of burking in order to get it passed. The Massachusetts Anatomy Act of 1831 was also inspired by the anatomy murders.

It is clear that the legislation reduced the demand for illegally obtained cadavers and may have acted as a deterrent against grave-robbing, as the latter practice persisted in localities without adequate provision for cadavers to dissect. It is likely, however, that the main deterrent against anatomy murders was the increasing sophistication of forensic science from the 19th century onward.





</doc>
<doc id="28091516" url="https://en.wikipedia.org/wiki?curid=28091516" title="False lien">
False lien

A false lien is document that purports to describe a lien, but which has no legal basis, based upon false, fictitious, or fraudulent statements or representations. The filing of false liens has been used as a tool of harassment in "paper terrorism", often against government officials. The practice was pioneered by the Posse Comitatus. The Bureau of Prisons has responded by treating lien documents and personal information (such as Social Security Numbers) of federal agents, judges, etc. as contraband in federal prisons.

The U.S. Congress has criminalized the filing of false liens, and the U.S. Sentencing Guidelines treat the filing of a false lien against a government official as equally serious as threatening the government officials of the United States. Various U.S. states have been developing ways of combating false liens.


</doc>
<doc id="28107588" url="https://en.wikipedia.org/wiki?curid=28107588" title="Crime control">
Crime control

Crime control refers to methods taken to reduce crime in a society. Penology often focuses on the use of criminal penalties as a means of deterring people from committing crimes and temporarily or permanently incapacitating those who have already committed crimes from re-offending. Crime prevention is also widely implemented in some countries, through government police and, in many cases, private policing methods such as private security and home defense. However, the police or security deployment may not necessarily be the best way to prevent a crime from happening.


</doc>
<doc id="28140106" url="https://en.wikipedia.org/wiki?curid=28140106" title="Preemptive arrest">
Preemptive arrest

A preemptive arrest is one in which a person is arrested prior to committing a crime. Preemptive arrests are sometimes viewed with suspicion as being contrary to the principles of a democracy.

This practice is distinct from an arrest on a charge of conspiracy to commit a crime, which for example in the United States federal system is itself a crime. A conspiracy charge in this system must be proven beyond a reasonable doubt, and requires that two or more parties have agreed to or planned to commit a crime and have taken concrete action to advance this plot.


</doc>
<doc id="1899598" url="https://en.wikipedia.org/wiki?curid=1899598" title="Children used by adults in the commission of crime">
Children used by adults in the commission of crime

The use, procuring or offering of a child by others for illegal activities, including the trafficking or production of drugs, is one of the "predefined worst forms of child labour" in terms of the International Labour Organization's Worst Forms of Child Labour Convention, adopted in 1999.

It is also known as Children used by adults in the commission of crime (CUBAC).

In terms of the Worst Forms of Child Labour Recommendation ratifying countries should ensure that CUBAC is a criminal offence, and also provide for other criminal, civil or administrative remedies to ensure the effective enforcement of such national legislation (Article III(12) to (14)). 



</doc>
<doc id="24727303" url="https://en.wikipedia.org/wiki?curid=24727303" title="Gang population">
Gang population

Reports on the number of people involved in criminal gangs, by locale.

There were at least 30,000 gangs and 800,000 gang members active across the USA in 2007. About 900,000 gang members lived "within local communities across the country," and about 147,000 were in U.S. prisons or jails in 2009. By 1999, Hispanics accounted for 47% of all gang members, Blacks 31%, Whites 13%, and Asians 6%.

The Latin Kings have organized chapters in over 41 US states, most notably Illinois, and several Latin American and European countries, including: Mexico, Spain, Dominican Republic, Canada, Italy, Ecuador, Peru, Puerto Rico, Portugal, Brazil, United Kingdom and others.

The Chicago Crime Commission publication "The Gang Book 1012" gave the statistic that Chicago has more gang members than any other city in the United States: 150,000. The city had 532 murders in 2012, however, it saw a decrease to 403 murders in 2013, but up to 762 in 2016. Not all murders are gang-related, but the [Chicago Police Department] states that 80% of all shootings and murders in the city are gang-related, which means that most violence in the city is gang upon gang violence.

Los Angeles has held the nickname "gang capital America" since 1930 because approximately 120,000 gang members reside in the city, and tens of thousands more in surrounding Los Angeles County.

There are between 25,000 and 50,000 gang members in Central America’s El Salvador.

The Mexican drug cartels have as many as 100,000 foot soldiers, many of them in the Los Angeles area.

The Yakuza are among the largest organized crime organizations in the world. In Japan, as of 2005, there are some 86,300 known members.

Hong Kong's Triads include up to 160,000 members in the 21st century. It was estimated that in the 1950s, there were 300,000 Triad members in Hong Kong. The Chinese government claims that police have eliminated 1,221 triad-style gangs across China since a crackdown was launched in 2006. More than 87,300 suspects have been arrested.

The FBI estimates the size of the four Italian organized crime groups to be approximately 25,000 members and 250,000 affiliates worldwide.


By country:




</doc>
<doc id="1924818" url="https://en.wikipedia.org/wiki?curid=1924818" title="Incident book">
Incident book

An incident book is a book used for recording injuries, crimes, and other incidents; they are included in British police boxes, hospitals, and other locations in which an incident is to be reported or treated.


</doc>
<doc id="438847" url="https://en.wikipedia.org/wiki?curid=438847" title="Fire marshal">
Fire marshal

A Fire Marshal or fire commissioner, in the United States and Canada, is often a member of a state, provincial or territorial government, but may be part of a building department or a separate department altogether. Fire marshals' duties vary but usually include fire code enforcement or investigating fires for origin and cause. Fire marshals may be sworn law-enforcement officers and are often experienced firefighters. In larger cities with substantially developed fire departments the local fire departments are sometimes delegated some of the duties of the fire marshal. 
A fire marshal's duties vary by location. Fire marshals may carry a weapon, wear a badge, wear a uniform or plain clothes, can drive marked or unmarked cars, and make arrests pertaining to arson and related offenses, or, in other localities, may have duties entirely separate from law enforcement, including building- and fire-code-related inspections. In many areas, the fire marshal is responsible for enforcing laws concerning flammable materials.

In Ontario, the Office of the Fire Marshal of Ontario (OFM), part of the Ministry of Community and Social Services, provides support to municipal fire departments, sets training requirements for firefighters, and advises the government on legislation. The Fire Marshal is responsible for investigating the origins of fires.

Office of State Fire Marshal (SFM); purpose; qualifications – to promote public health and safety and to reduce hazards to life, limb and property, the office of SFM is established within the department. The office shall perform its duties by performing inspections and fire investigations, by providing public education and by adopting fire protection codes. The person appointed as SFM shall have extensive experience in the field of fire prevention and fire protection including administrative experience in such capacity.

Deputy fire marshals and assistants

The SFM may hire deputy fire marshals and appoint as assistant fire inspectors any of the fire chiefs of a city, town, county, volunteer fire company or protective district to act within their area of jurisdiction or upon the recommendation of the fire chief appoint other assistant fire inspectors if needed to function within the jurisdiction. The SFM may also appoint other assistant fire inspectors as are necessary in areas which are not under the jurisdiction of a fire chief.

Powers and duties; arson investigators

The SFM shall:

1) Assist in the enforcement of state laws and ordinances of cities and counties relating to fire prevention and fire protection; and enforce compliance with the fire code adopted by the state fire safety committee throughout the state except in any city having a population of one hundred thousand persons or more which has in effect a nationally recognized fire code, whether modified or unmodified, and which has enacted an ordinance to assume such jurisdiction from the state fire safety committee. Such cities do not have authority that supersedes and are not exempt from the state fire safety committee's established fire code in state or county owned buildings and public schools wherever located throughout the state.

2) Cooperate and coordinate with other state agencies in the administration of the state fire code, and establish a regularly scheduled fire safety inspection program for all state and county owned public buildings and all public and private school buildings wherever located throughout the state, except for private school buildings in cities with a population of one hundred thousand or more persons according to the last decennial census.

3) Inspect as necessary all other occupancies located throughout this state, except family dwellings having fewer than five residential dwelling units and occupancies located in cities with a population of one hundred thousand or more persons according to the last decennial census.

4) At the written request of county or municipal authorities, make and provide to them a written report of the examination made by the SFM of any fire within their jurisdiction.

5) Compile, update as necessary and make available to the public a fully indexed and cross-referenced list of all rules adopted by state agencies and departments and agencies and departments of political subdivisions of this state relating to the control of all hazardous materials as defined in § 28-5201 and all federal regulations relating to the control of hazardous materials as defined in § 28-5201 for which there is no state regulation.

6) Establish and maintain a library of all rules and regulations identified, and support the regulated industry's request for information through research or referral to the agency adopting the specific rule for technical information or other assistance as circumstances dictate.

7) Administer the arson detection reward fund established by § 41-2167.

The SFM and the state are not liable for damages caused by information which is omitted from the rules and federal regulations compiled.

All plans and specifications for new construction, remodeling, alterations and additions for state, county and public school buildings and grounds shall be submitted to the director for review and approval by the SFM prior to construction. The plans and specifications shall be reviewed and approved or disapproved within sixty days of submission. No construction shall commence until the plans have been approved and a permit has been issued.

The SFM may:

The primary duty of investigators is the investigation, detections and apprehension of persons who have violated or are suspected of violating any provision of Arizona title 13, chapter 17. A person designated as an arson investigator, while engaged in arson investigation in this state, possesses and may exercise law enforcement powers of peace officer of this state. This subsection does not grant any powers of peace officers of this state to arson investigators other than those necessary for the investigation, detection and apprehension authority granted by this subsection. Any individual designated as an arson investigator shall have law enforcement training under Arizona § 41-1822.

Inspection; consent; search warrant

A. The fire marshal or his designated representative may investigate fire damage and shall carry out periodic inspection programs of buildings and premises to examine or inspect for fire hazards.

B. In carrying out such inspections or investigations the fire marshal or his designated representative shall identify himself to the owner or tenant of such building or premises and seek the consent of such owner or tenant to carry out such inspection. If such consent is refused, or it is not possible to reasonably obtain consent, the fire marshal or his designated representative shall obtain a search warrant for such building or property in compliance with the provisions of title 13, chapter 38, article 8.

C. When the fire marshal is assisting a local fire department in an investigation of fire damage, the authority of the local fire department to investigate such fire damage shall be deemed to include the fire marshal or his designated representative.

Like most states, Californian Fire marshals are typically associated with a city or region's local fire department. Yet, California has two additional authorities that hold the official designations of Fire Marshal. One is the California Department of Forestry and Fire Protection (CAL FIRE). It is tasked with the building code enforcement of all structures and occupancies within the state. They have the authority to issue building permits, conduct building inspections and investigate code violations. California Fire marshals are designated peace officers. The person heading this office is officially designated as the State Fire Marshal.

The second authority designated as Fire Marshals is the Office of Statewide Health Planning and Development (OSHPD) who is the state building official for all California hospitals. They are tasked with the structural, electrical and fire/life safety reliability of all hospital construction in the state. This responsibility is paramount in California due to the frequency and intensity of earthquake seismic activity it experiences.

The Florida Division of State Fire Marshal (SFM) is located within the Department of Financial Services, where Florida’s Chief Financial Officer (CFO) also serves as Florida’s State Fire Marshal.

The SFM office serves local fire departments who request assistance with conducting fire investigations and provides fire training colleges throughout the state. It is headquartered in Tallahassee, with numerous field offices located across the state.

The investigators working for the SFM office are sworn law enforcement officers, with powers to make arrests, conduct searches and seizures, serve summonses, and carry firearms. These law enforcement officers conduct complex investigations and have the ability to make arrests statewide. Investigators conduct thousands of fire related investigations each year, with approximately 45% being determined to be arson in 2009. Florida SFM investigators make arrest in 18% of the arson fires investigated, which is above the national average of 16%. Fire investigations are complex and potentially dangerous.

The Florida SFM Forensic Laboratory receives and examines over 10,000 evidence submissions every year. These submissions come from fire departments, police departments, sheriff’s offices and SFM investigators. The crime laboratory offers a wide variety of services to include examination of fire debris, explosives analysis, image reproduction and forensic video analysis. The forensic experts in the laboratory conduct consultations with investigators, prosecutors, and other attorneys on analyses and general aspects of forensic science. These consultations are often in preparation for expert witness testimony in criminal court.

The Florida SFM office issues over 3,000 basic fire fighter certifications every year. There are thirty five (35) certified training centers located across the state and the Florida State Fire College. The State Fire College trains over six thousand students per year in a wide variety of certification and professional development programs to include Pump Operator, Fire Officer, Fire Investigator, HAZMAT, etc.

The Florida SFM is responsible for inspecting over 14,000 state owned buildings every year. SFM code enforcement and inspection activities also reach over 16,000 public and private buildings; to include prisons, universities, public schools, thousands of fuel-fired boiler systems, hundreds of construction mining sites and explosive storage locations each year.

The Florida Fire Incident Reporting Section collects over 1,800,000 fire and emergency reports per year. These local fire department and fire service reports are combined with the other states reports in the National Fire Incident Reporting System (NFIRS) for use by the fire services in analysis and trends. The Florida reports are also used to form the basis for the SFM Annual Report "Florida Fires".

The SFM has authority to implement rules that conform to the standards of fire safety and the need to protect Floridians from fire hazards. Additionally, the SFM shall adopt and administer rules prescribing standards for the safety and health of occupants of educational and ancillary facilities pursuant to ss. 633.022, 1013.12, 1013.37, and 1013.371.

In any county that does not employ or appoint a local fire official, the State Fire Marshal shall assume the duties of the local fire official with respect to fire safety inspections of educational property required under s. 1013.12(2)(b), and the State Fire Marshal may take necessary corrective action as authorized under s. 1013.12(5).

New York City's Bureau of Fire Investigation, a division of the FDNY, currently employs about 100 fire marshals and 40 supervising fire marshals. The position of fire marshal is a promotional civil service title and all officers have served several years as active firefighters. Unlike many other jurisdictions, the New York City fire marshals are armed police officers with full powers of arrest who generally work in pairs and investigate serious fires with the New York City Police Department. New York City Fire Marshals undergo comprehensive police training to include annual weapons qualification at Camp Smith. Investigations are conducted in cooperation with the New York City Police Department, with whom they have a close relationship. Most New York City fire marshals are former New York City Police officers. In a typical year they are assigned about 4,000 fires within the five boroughs of the city. New York Fire Marshals often receive special training at the FBI academy in Quantico, Virginia, as well as attending investigative classes conducted by the NYPD and explosives training classes sponsored by the federal government in Socorro, New Mexico. Under New York State Consolidated Laws Article 35.00 section 35.20 "deadly physical force may be used in order to terminate or prevent commission of arson."

The city's first fire marshal, George H. Sheldon, was appointed in 1873, eight years after the reorganization of the fire department into a career department in 1865. Robert O. Lowery became the first African-American fire marshal in 1946. Lowery would ultimately rise to the top of the department, being appointed the city's fire commissioner in 1965.

Fire marshals have conducted a number of significant investigations, including the Triangle Shirtwaist Factory fire of 1911. They investigate insurance fraud involving arson, and more recently, potential terrorism. They also function as expert witnesses in arson cases. At times New York fire marshals work undercover and conduct surveillance operations. They also coordinate with federal, state and local law enforcement because arsonists are frequently involved in other criminal activity as well, and some investigations, like the 1993 bombing of the World Trade Center, require multiple agencies' skills.

The first line of duty NYC fire marshal deaths were from the September 11, 2001 attacks when Marshals Ronald Paul Bucca and James Devery, disregarding danger, rushed into the World Trade Center to assist in the rescue of civilians trapped within the towers. Devery led a wounded woman to safety, but Bucca, badge 317, a decorated Vietnam combat war veteran, died on the 78th floor of the south tower, one floor below the aircraft impact. The pair had worked on the 1993 investigation at the same site.

Professional training outside the state at the FBI Academy at Quantico, Virginia and other locations for New York City Marshals was made possible through federal counter-terror grants, subsequent to 9/11, actively supported by Mayor Mike Bloomberg.

New York State Executive Law, article 6c, sec 159, created an arson control board that mandated every jurisdiction prepare an arson control plan and a strong coordinated arson control program to include certification of investigators in compliance with NFPA 921 and NFPA 1033. A state standard of level I and level II fire investigator certification was developed. New York City Fire Marshal's training exceeds the requirements of level II.

There are two levels of Fire Marshals in Pennsylvania, the state police fire marshal and the local fire marshal. The State Fire Marshal had been an independent office until powers and duties were transferred to the State Police in 1919. In 1927, the state (commonwealth) created the local fire marshal position underneath the state police, via an act of April 27, 1927 (P.L. 450, No. 291).

The Pennsylvania State Police (PSP) Fire Marshals are usually considered the final investigative authority for fires deemed exceptionally costly (over $1,000,000) or where a death has occurred. The local fire marshal notifies PSP Fire Marshals when he or she considers their involvement necessary. State law authorizes and identifies the local fire marshal as an "Assistant to the State Police Fire Marshal". Local fire marshals are selected for their positions by the local fire chief or municipality. The State Police Commissioner (Colonel) then appoints them to the PSP office.

Local fire marshals are authorized to investigate fires, obtain and execute search documents, take evidence, and detain and question in the process of establishing origin and cause. This process may or may not result in affecting an arrest or prosecution. Both levels of Fire Marshals often testify in civil and criminal court proceedings, and respond and collaborate with insurance investigators. Along with state law, many municipalities have assigned local law enforcement officer (LEO) status to their respective fire marshals due to the nature of the service, requirements to detain, question or arrest, enforce fire safety related laws, and to protect themselves during potential high-risk investigations. (Some of the largest methamphetamine labs in the U.S. have been found in Pennsylvania during local fire marshal’s investigations.)

All municipalities and fire districts require fundamental fire training and substantial fire fighting experience, followed by progressive continuing fire investigation education supplied by the Pennsylvania State Police. Municipalities who have granted specific LEO status usually require either PA Act 120 or PA Act 235 training in addition.

The Virginia State Fire Marshal's Office is part of the Virginia Department of Fire Programs; the current marshal is Charles E. Altizer, P.E. The mission of the office is to provide safety to life and property from fire for the citizens of the Commonwealth. To do this, the Office:

Many of Virginia’s larger urban localities have their own local fire official. For example, Fairfax County's Office of the Fire Marshal has over 100 employees who are trained and certified to enforce a variety of fire prevention regulations including portions of the Uniform Statewide Building Code. The Office, which is the Fire Prevention Division of the Fire & Rescue Department’s Business Services Bureau, functions under the command of a Deputy Fire Chief, who is responsible for oversight of all aspects of the Office's mission, including supervision of the Fire Prevention Services (FPS) and Hazardous Materials & Investigative Services (HMIS) sections, each commanded by a Battalion Fire Chief. The mission is to prevent the inception or recurrence of fire and hazardous conditions by providing fire prevention and hazardous materials-related educational, enforcement, inspection, investigative, plans review, and technical services to the businesses, industries, residents, and visitors of Fairfax County and the towns of Clifton, Herndon, and Vienna.

The Washington State Fire Marshal's Office is a Bureau within the Washington State Patrol. The Office of the State Fire Marshal provides services including incident reporting, data collection, code review, construction plan fire safety, fireworks and supervision of sprinkler installation.

The American definition of a fire marshal should not be confused with that used in the United Kingdom. Fire marshals (sometimes known as "fire wardens") are civilians trained to assist in fire evacuation procedures at businesses and other organizations, usually employees.

There is no direct equivalent to a US fire marshal in the United Kingdom. The enforcement and Investigation role are carried out by two separate professionals known as Fire Investigators and Fire Inspectors.

Fire Investigators are highly trained and experienced firefighters or fire officers, who investigate cases of arson and other fire incidents where the cause of the fire is unclear or disputed. Fire investigations can also be carried out by Police Scenes of Crime Officers. Fire Investigators do not fulfill a direct law enforcement role, but instead act as expert witnesses in any prosecutions brought forward by the Police or Fire Service.

The enforcement of fire safety legislation is undertaken by Fire Safety Inspectors, or Fire Safety Officers as they are sometimes known.

UK Fire Officers do not have powers of arrests, but can place subjects under caution and prosecute anyone who has failed to comply with fire safety law. They also have the authority to close unsafe premises and investigate any actual perceived fire safety offence. They have substantial powers of entry. Most Fire Inspectors are experienced firefighters / fire officers, but there are also several civilian fire inspectors.



</doc>
<doc id="2623876" url="https://en.wikipedia.org/wiki?curid=2623876" title="Public security">
Public security

Public security is the function of governments which ensures the protection of citizens, persons in their territory, organizations, and institutions against threats to their well-being – and to the prosperity of their communities.

To meet the increasing challenges in the public security area, responsible public institutions and organisations can tap into their own intelligence to successfully address possible threats in advance. They optimise their internal structures, use synergies, and carefully balance costs and benefits of their measures.

Public safety organizations include law enforcement, fire and emergency medical services. The public safety issues a municipality, county, state, or federal jurisdiction might grapple with include narcotic use, trespassing, burglary, harassment, juvenile delinquency, unauthorized living, noise, littering, inappropriate social behavior, inebriation, and other quality of life issues. Generally organizations are involved in the prevention of and protection from events that could endanger the safety of the general public from significant danger, injury, or property damage, such as crimes or disasters (natural or human-made).

Organised crime and international terrorism are hardly deterred by geographical, linguistic, or financial barriers. Competence and administrative hurdles play into their hands.

The latter has largely contributed to public security becoming an important political and economic issue, nationally as well as internationally. Politics, public organisations and businesses closely collaborate to guarantee public security and maintain a stable environment for economic prosperity.

Although public security significantly contributes to the attractiveness of a location, the productivity of its people, and hence the overall success of an economy, the sector frequently suffers from low budgets, limited resources, and inadequate information systems. Large events, pandemics, severe accidents, environmental disasters, and terrorism attacks pose additional threats to public security and order.

The police, federal police and border authorities nonetheless need to warrant the security of the country as a fundamental prerequisite for the domestic political ability to act. The quality and scope of potential threats have changed significantly, and the tasks and general framework for the police, federal police and border authorities have changed accordingly.




There are five sub-sectors within public security:

Police Services:


Emergency services include:

Judicial services include:

Interior services include:







</doc>
<doc id="4118738" url="https://en.wikipedia.org/wiki?curid=4118738" title="Facial composite">
Facial composite

A facial composite is a graphical representation of one or more eyewitnesses' memory of a face, as recorded by a composite artist. Facial composites are used mainly by police in their investigation of (usually serious) crimes. These images are used to reconstruct the suspect's face in hope of identifying them.

Construction of the composite was originally performed by a trained artist, through drawing, sketching, or painting, in consultation with a witness or crime victim. Subsequently, techniques were devised for use by those less artistically skilled, employing interchangeable templates of separate facial features. The first such mechanical system, called "Identikit", was introduced in the U.S. in 1959; it used drawings of facial features on transparent acetate sheets that could be superimposed on one another to produce the composite image. (A later version of Identikit is made by Smith & Wesson.) In 1970, a system called "Photofit", which aimed for greater realism by using actual photographs of facial features, was introduced in the U.K.

In the last two decades, a number of computer based facial composite systems have been introduced; amongst the most widely used systems are SketchCop FACETTE Face Design System Software, "Identi-Kit 2000", FACES, E-FIT and PortraitPad. In the U.S. the FBI maintains that hand-drawing is its preferred method for constructing a facial composite. Many other police agencies, however, use software, since suitable artistic talent is often not available.

Until quite recently, the facial composite systems used by international police forces were exclusively based on a construction methodology in which individual facial features (eyes, nose, mouth, eyebrows, etc.) are selected one at a time from a large database and then electronically 'overlaid' to make the composite image. Such systems are often referred to as feature-based since they essentially rely on the selection of individual features in isolation. However, after a long period of research and development work conducted largely within British universities, systems based on a rather different principle are finding increasing use by police forces. These systems may be broadly described as holistic or global in that they primarily attempt to create a likeness to the suspect through an evolutionary mechanism in which a witness's response to groups of complete faces (not just features) converges towards an increasingly accurate image. Three such systems have come from academic beginnings, EFIT-V from the University of Kent; EvoFIT from the University of Stirling, the University of Central Lancashire (UCLan) and the University of Winchester; and ID from the University of Cape Town, South Africa. GFE is an experimental evolutionary face compositing system using image gradient instead of luminance to represent faces, which seems to produce better quality composites.

A general review of research into the evaluation of mechanical template techniques may be found in Davies and Valentine (2006). A review of research into more modern 'feature' and 'recognition' systems, and into methods for improving the effectiveness of composites, may be found in Frowd et al. (2008) and (2009).

The systems used in the UK have been subjected to a number of academic studies. These have typically shown that E-FIT and PRO-fit produce composites that are correctly named, either immediately or a few hours after construction, about 20% of the time (see Brace et al. (2000), Bruce et al. (2002), Davies et al. (2000) and Frowd et al. (2005)). When witnesses in these studies are required to wait two days before constructing a composite, which matches real use more closely, naming falls to a few percent at best (e.g. Frowd et al. [2005] and [2007]). The reason for the low level of naming from these systems appears to be that witnesses are unable to accurately construct the internal features of the face after long delays, the region that is important for recognition by another person later (Frowd et al. [2007]).

Evolutionary systems show a marked improvement in accuracy. In academic trials, research on a fairly-recent version of the EvoFIT system has shown correct naming levels of about 30% after a 2-day delay (see Frowd et al., 2010). Using more-recent construction techniques, the performance increased to 45% correct naming (Frowd et al., 2012). Using the very latest system, interview and enhancement techniques, naming of an EvoFIT composite is 74% correct (Frowd et al., 2013). Appropriately, the system does appear to behave more like a face recognition than a face recall system (Frowd et al., 2011) Accompanying the development of EvoFIT have been new approaches in the type of interview administered to eyewitnesses prior to face construction (e.g. Frowd et al., 2012). Similarly in extensive field use EFIT-V has shown a 40% naming rate over an 18-month period with 1000 interviews. The EvoFIT system has been similarly evaluated in formal police field-trials. These evaluations have reported a much higher naming rate for EvoFIT composites but, using the latest interview techniques, a suspect arrest rate of 60%. This latest police field trial has also indicated that an EvoFIT directly leads to the arrest of a suspect and then a conviction in 29% of cases. There have been many notable successes - for example, in this investigation, EvoFIT has directly led to the arrest of a serial rapist.

While the classic use of the facial composite is the citizen recognizing the face as an acquaintance, there are other ways where a facial composite can prove useful. The facial composite can contribute in law enforcement in a number of ways:


Facial composites of various types have been used extensively in those television programs which aim to reconstruct major unsolved crimes with a view to gaining information from the members of the public, such as "America's Most Wanted" in the US and "Crimewatch" in the UK.

These notable cases had facial composites assist in identifying the perpetrator:


</doc>
<doc id="20216813" url="https://en.wikipedia.org/wiki?curid=20216813" title="Conflicts involving Critical Mass">
Conflicts involving Critical Mass

There have been many conflicts during Critical Mass events since the founding of the worldwide bicycling advocacy event in 1992. The conflicts have resulted in injuries, property damage, and arrests, and both bicyclists and motorized vehicle drivers have been victims. Critics say that Critical Mass, held primarily in large metropolitan cities, is a deliberate attempt to obstruct automotive traffic and disrupt normal city functions, when individuals taking part refuse to obey traffic laws, while participants variously consider it a celebration of cycling, of cyclists' rights, and a practical re-imagining of urban space.

On May 11, 2007, an incident occurred in Berkeley, California, when an elderly motorist stopped at an intersection with dozens of bicycles crossing. Activists claim that the driver shouted, while bicyclists were in the intersection, "I'm sick of you people!" Police have not determined who had the right-of-way. The driver attempted to drive through the intersection. The motorist and his wife, two witnesses, and the police all claimed that the cyclists threw their bicycles under the vehicle. This was disputed by other witnesses. Critical Mass participants then rocked the vehicle, pounded the hood, and broke the windshield while verbally abusing the elderly couple. Approximately $3,000 worth of damage was done to the bicycles. Berkeley police did not make any arrests in the incident.

On May 30, 2003, in Buffalo, New York, during an incident known locally as "Critical Massacre," police stopped two cyclists for "failure to yield to an emergency vehicle." Several people were allegedly attacked by police. Nine cyclists were arrested and three were later convicted, including a journalist.

Chicago Police Department officers are often seen riding with Critical Mass participants, and squad cars block intersections to provide safe passage to Critical Mass cyclists. However, on August 31, 2007, seven riders were arrested on charges of obstructing traffic and disobeying police, and were held overnight. According to some of those arrested, they were released late at night or early in the morning. On multiple occasions, Critical Mass participants attempted to ride on Lake Shore Drive, a road off limits to cyclists. Police prevented participants riding on Lake Shore Drive, by blocking entrance ramps with squad cars when Critical Mass riders approach the road.

At dusk on March 28, 2008, in Honolulu, Hawaii, police collided with a young woman on a bicycle while trying to stop another bicyclist for traffic infractions. The young woman fell and hit her head on the ground, sustaining injuries requiring hospitalization. While no arrests were made, the police did issue citations and confiscate bicycles.

Due to the gradual increase of cyclists participating in Critical Mass, as well as complaints from motorists and concerns for safety, Houston Police Department officers helped direct the October 2013 Critical Mass ride in Houston, Texas by controlling intersections on the bike route. In January 2014, after two months of providing free security and safe passage through heavy intersections, the Houston Police Department began considering options to charge the group for providing security for the event, citing similarities to providing security for funeral processions through the city limits. Some Critical Mass riders have spoken out in protest of paying a fee to utilize extra security and escorting through busy intersections, while many others support paying fees for extra security to keep the ride safe, which has led to increased discussions between the city and group for additional alternatives to the building conflicts.

In London on September 2005, a few weeks after the 7 July 2005 bombings, Metropolitan Police required the organisers to provide a route six days before the event and placed strict restrictions on riders under threat of arrest. The threat was retracted when politicians and cyclist groups objected. In October 2005, the ride had close to 1,200 participants, significantly more than usual. A long stop in Parliament Square, part of the government's exclusion area in the Serious Organised Crime and Police Act 2005, led to a slow and cumbersome ride.

One participant sought a declaration from the High Court of England and Wales that police need not be notified about the rides, in a "friendly action" in which neither side sought damages. The High Court agreed, exempting Critical Mass from notification under Section 11 of the Public Order Act 1986. The ruling was reversed on appeal. In 2008, Friends of the Earth, who supported the legal action, said the case would be appealed to England's highest legal authority, the House of Lords, on the grounds that, after 11 years, Critical Mass is "commonly or customarily held." In October 2008, the House of Lords ruled in favour of the Critical Mass participant.

During the 2012 Summer Olympics, cyclists were arrested on opening day after police claim they ignored regulations in place during the Olympics. Jenny Jones of the Green Party and the Greater London Assembly has questioned the police actions, calling them "out of all proportion to common sense" and "tragically unnecessary." A Critical Mass website asked riders to be "peacefully assertive" during the monthly ride, while police claim they asked riders to keep to the south of the River Thames. When the riders got close to the Olympic Park, police began to cordon off the area and arrest riders. In total, 182 people were arrested, of whom 4 were charged, and 178 were bailed pending further inquiries. The action led to 5 of the 182 people arrested being convicted in court.

On the August 31, 2007, ride in Minneapolis, Minnesota, a confrontation occurred between cyclists and the police. The police presence included undercover officers, three marked squad cars, a state patrol helicopter, and unmarked vehicles. The ride had been linked with weekend protests of the following year's Republican National Convention. After the arrest of a cyclist for "riding in a snake-like manner," cyclists began chanting "Let him go!" and "What's the charge?" The police called for backup, and dozens of police officers responded, using mace and tasers. Minneapolis police arrested 19 participants, including three minors. The adults were arrested on suspicion of rioting, a gross misdemeanor.

On May 27, 2011, in Minsk, Belarus, police forces aided by special units transported 13 cyclists to the police station for violation of traffic rules and for not following orders to disband. Detained participants were fingerprinted and fined, then released.

On April 30, 2016 two cyclists were arrested during a Critical Mass action. As of September 2016, one was released and the other is facing trial.

Police in New York City have claimed that Critical Mass bicyclists blocking intersections to allow bikes to pass may delay emergency vehicles in the gridlock.

During the US 2004 Republican National Convention, police arrested 250 riders after the ride caused "massive disruptions" in the city. Many court cases resulted regarding the legality of the ride, whether police have the right to arrest cyclists and seize bicycles, and whether the event needs a permit. In December 2004, a federal judge dismissed New York City's injunction against Critical Mass as a "political event." On March 23, 2005, the city filed a lawsuit seeking to prevent Time's Up!, a direct action environmental group, from promoting or advertising Critical Mass rides. The lawsuit also stated that Time's Up! and the public could not ride or gather at a Critical Mass bike ride, claiming a permit was required.

During a bicycle rally on July 25, 2008, NYPD patrolman Patrick Pogan pushed rider Christopher Long off his bicycle. In a criminal complaint, Pogan wrote that he had ordered Long to stop because he was weaving in and out of traffic, forcing vehicles to swerve or stop, and generally disrupting the normal flow of traffic. In addition, Pogan wrote that he suffered lacerations on his arms because Long steered his bike into him and knocked him down, and when he tried to place Long under arrest, Long began flailing, kicking and screaming, "You are pawns in the game!" Long spent the next day in police custody on charges of attempted assault, resisting arrest and disorderly conduct.

Within days, members of the rally's sponsoring organization Time's Up! posted a video of the incident on YouTube. The video went viral and received over 400,000 hits within five days. Critical Mass activists claimed it supported their claims that the police department has demonstrated a pattern of arresting participants in the rally on false charges. Witnesses also disputed Pogan's account, saying that Long was the one to receive injuries, traffic was stopped for the rally, and that Pogan had simply scanned the group of cyclists to find one he could take down.

The union that represents NYPD officers said Pogan was just doing his job to protect the public from a reckless bike rider, and Pogan's father — himself a retired NYPD detective — defended him, saying "You gotta do what you gotta do to make an arrest." The prosecutor's office dismissed the charges against Long. NYPD placed Pogan, who had spent only three weeks as a police officer, on a desk assignment while the city investigated the incident.

On December 16, 2008, Pogan appeared in court and pleaded not guilty to felony charges of falsifying business records and filing a false instrument, and misdemeanor charges of third-degree assault, second-degree harassment and making a punishable false written statement. After the indictment, the police department suspended Pogan and, two months later, Pogan resigned as the department prepared to fire him. His attorney said that his defense would center on the department's training procedures and claims that events occurring off-camera needed to be taken into account.

On July 8, 2009, it was reported that Long, then a Hoboken, NJ, resident, was suing the New York Police Department for $1.5 million, alleging that Pogan falsified his arrest report in order to legitimize his assault on Long.

During his trial in April 2010, Pogan acknowledged that the video looked "very extreme." He testified that he had anticipated a collision with Long, since the rider lowered his right shoulder as the officer approached. Jurors found Pogan not guilty of harassment and assault and acquitted him of four of the seven counts of which he had been charged. He was found guilty of filing a criminal complaint that contained false statements concerning the cyclist. Pogan received no jail time but, because he is a convicted felon, he is not eligible to become a New York City police officer in the future. Long said in an interview that he was pleased with the verdict, in part because it would prevent Pogan from becoming a New York City police officer again.

On February 25, 2011, an automobile driver deliberately collided with around 20 cyclists that were participating in a Critical Mass event in Rua José do Patrocinio in Porto Alegre, southern Brazil. Out of approximately 150 people that were taking part in the event, dozens of bicycles were damaged, 15 people were injured and eight were transported to the emergency room. While the driver left the scene of the incident, demonstrators remained on the street, demanding that the driver be found and arrested. The driver was later identified as 47-year-old Ricardo José Neis. After Neis gave his statement to the police, his attorney, Luis Fernando Coimbra Albino, stated that the Neis was acting in self-defense after several cyclists threatened him and his son and assaulted his car. According to witnesses present at the event, Neis was acting violently behind the bicycles and hit the rear wheels of two different cyclists, and any contact from the cyclists on his car was meant as a sign asking him to slow the vehicle down. Witnesses also reported that Neis had two different transversal roads he could have taken to avoid waiting for the cyclists to proceed. On March 1, 2011, Neis attempted to transfer from a hospital to a psychiatric clinic, but this request was rejected by court officials. He was held in the hospital under police custody, but was later released and indicted under 17 counts of attempted murder. One of the most severely injured cyclists, 23-year-old Ricardo Mattes Ambus, was readmitted to the hospital on March 3, 2011, due to an intracranial haematoma.

During the following week, between February 28 and March 6, 2011, many protests in support of Critical Mass Porto Alegre were organized in several major cities in South America and around the world. In response, local cyclists organized the World Bike Forum in Porto Alegre to raise awareness of violence in traffic against cyclists. The first Forum took place during the anniversary of the incident.

On November 24, 2016, Ricardo Neis was sentenced to 12 years and 9 months in jail for attempted murder and aggravated assault.

On the night of July 25, 1997, in San Francisco, the ride attracted 5,000 participants, which resulted in congested traffic, confrontations with motorists, and arrests. Interest and tension had been growing for several weeks due to increased rhetoric from then-Mayor Willie Brown regarding cracking down on the event. The local newspapers published a city-approved route after the mayor withdrew his threat to have bicyclists arrested for not obtaining a parade permit. Because of the large turnout, it was difficult if not impossible for cyclists to follow the sanctioned route. Riders instead found themselves engaged in verbal and physical altercations with motorists and police, as well as among themselves. Two officers reported injuries in confrontations with bike riders. Local media reported that "about 250" bicyclists were arrested, most for disrupting traffic, and a few for being drunk in public, battery, and outstanding warrants.

On the March 2007 ride in San Francisco, a rider was arrested on felony (later reduced to misdemeanor) charges in San Francisco's Tenderloin neighborhood for denting a limousine using a bicycle lock. The driver told police he got out of his car to talk to two cyclists who allegedly blocked his path. After exchanging words with one of the cyclists, the driver said he grabbed one of the bicycles and tried to pull it out of the way. He then got back into his limo to go around the riders, but before he could move, he said, another cyclist ran into the side of his car, then punched the hood with a U-shaped lock. The cyclist told police he only hit the limousine after the driver gunned his engine. During the incident, one of the limousine's tires was slashed and the driver's keys were stolen.

Towards the end of the ride, near the Japan Center and Western Addition neighborhoods, a mother from Redwood City, California, traveling with her two young daughters in the vehicle, tried to drive through the mass of riders. A witness claimed to have observed the driver strike a cyclist and flee before cyclists chased and surrounded her vehicle. The driver denied striking a cyclist and alleged that hundreds of cyclists surrounded her minivan while she and her 11- and 13-year-old daughters were inside, banged on her car, scratched the paint, and threw a bicycle through the rear window of the vehicle, causing $5,300 in damages.

In April 2007, San Francisco Mayor Gavin Newsom requested that Critical Mass riders police themselves. "It does the bicycle-advocacy community no good to have people that are aggressive and dispirit the entire movement," Newsom said. "I would encourage the bicycle coalition to say, 'Look, we don't put up with this, enough is enough.' "

In November 2009, Stanley Roberts of KRON 4 News recorded several Critical Mass confrontations between bicyclists and vehicles at Van Ness and O'Farrell Streets. An old Critical Mass website advised riders not to be confrontational and block traffic, but in footage filmed by Roberts, bicyclists engaged in confrontational arguments with motorists and blocked roads to vehicular traffic.

In August 2015, KQED posted an article on a Critical Mass confrontation between a bicyclist and a female Zipcar driver in the San Francisco Marina District. 39 year old Ian Hespelt was arrested a few days later by the San Francisco Police Department's bicycle patrol at AT&T Park during the Billy Joel concert. Hespelt was charged with four felonies including assault, vandalism, maliciously throwing a substance at a vehicle and false imprisonment. Hespelt was also wanted in Washington state on a felony drug charge warrant.

Two riders were arrested during the June 2006 ride in Seattle, Washington, after a fight with two undercover detectives whom the cyclists confused for gang members. Witnesses disputed the claim made by the sheriff's office that the detectives identified themselves. The King County Sheriff's Office decided not to press felony charges in the case, saying there were too many issues over the circumstances surrounding the allegations.

On July 25, 2008, Critical Mass prevented a motorist from driving from a curbside parking space into cyclists in Seattle's Critical Mass on East Aloha. The motorist made statements to Seattle police that he drove away, hitting bicycles and riders (one of them an attorney), and told the press that he "freaked out and overreacted" when bicyclists threatened to tip his vehicle. According to some witnesses, the motorist drove into at least two cyclists and tried to flee.

A group of riders caught the vehicle, broke its rear windshield, slashed the tires, and assaulted the motorist when he got out. Damage to the car was estimated at $1,500. The motorist was struck in the back of his head by a bike lock and later hospitalized. Two cyclists were arrested for vandalism to the car. Seattle police did not charge the motorist.

On July 27, 2007, in Vilnius, Lithuania, police took five participants into custody, including two minors, for not following orders to disband.

In Walnut Creek, California, on June 20, 2008, a car bumped into the rear wheel of a Critical Mass rider. An argument ensued among the driver and passenger of the car and the cyclist involved, after which the passenger and driver of the car assaulted the cyclist. The police arrived and arrested the passenger and driver of the automobile involved in the assault.

On June 21, 2002, in Warsaw, Poland, the Critical Mass event was stopped by a cordon of fully armed riot police on Plac Konstytucji (Constitution Square), who demanded their dispersal and detained some of the participants. Other Critical Mass participants responded with a sit-in protest, blocking an important traffic junction, and then tried to evade the blockade by taking different routes to Plac Zamkowy (Castle Square), the Critical Mass rally point. This event was widely reported by the media and, as a result, the Warsaw municipality decided to legalize future events, rather than escalate the conflict. Beginning in September 2002, Critical Mass events in Warsaw are organized in full cooperation with the police force. Once a year in August, beginning in 2007, a special Critical Mass is organized in cooperation with the city officials to commemorate the Warsaw Uprising.

On March 28, 2013, in Buenos Aires, Argentina, a taxi driver ran over a group of Critical Mass riders, injuring 2 cyclists, before fleeing from the scene.


</doc>
<doc id="36183638" url="https://en.wikipedia.org/wiki?curid=36183638" title="Crime preparation">
Crime preparation

Crime preparations are acts or actions performed by criminal offenders during any period of time before the actual crime is committed and range from mere intent to overt action.

In some jurisdictions, the very act of preparing for a crime is a criminal offense in itself, though it is generally viewed as being natural behavior for lawbreakers. The preparations that criminals take prior to their illegal actions are very often prosecuted as inchoate offenses, described in law as the crime of preparing for or seeking to commit another crime. The most common examples of an inchoate offense are conspiracy and the possession of tools necessary to execute the crime or crimes. "Inchoate offense" has been defined as "Conduct deemed criminal without actual harm being done, provided that the harm that would have occurred is one the law tries to prevent."

Since criminals often to do act randomly to lead into their crimes, they often conspire and prepare greatly the executions of their action, their getaways, and their success in not being found out. Law enforcement and investigators in the field of forensic psychology describe these activities as most often being performed by the "organized offender".

In criminal law, a conspiracy is an agreement between two or more persons to break the law at some time in the future. Criminal law in some countries or for some conspiracies may require that at least one overt act must also have been undertaken in furtherance of that agreement, to constitute an offense. There is no limit on the number participating in the conspiracy and, in most countries, no requirement that any steps have been taken to put the plan into effect (compare attempts which require proximity to the full offence). For the purposes of concurrence, the "actus reus" is a continuing one and parties may join the plot later and incur joint liability and conspiracy can be charged where the co-conspirators have been acquitted or cannot be traced. Finally, repentance by one or more parties does not affect liability but may reduce their sentence.
An example can be: "The two gangsters conspired to rob the bank down the street".

It is the action or instance of soliciting; petition; proposal. In criminal law, it most commonly refers to either the act of offering goods or services, or the act of attempting to purchase such goods or services. Legal status may be specific to the time and/or place where solicitation occurs.
An example can be: "The bank robber solicited the help of an accomplice".

This can involve the criminal's act of casing or keeping the surveillance of a victim or place or item that would be involved in the crime. 
An example can be: "For a day the bank robber cased the bank down the street so that he could plan when and how he would rob it".

The possession of tools used to facilitate a crime and clothing used to conceal the identity of the offender is usually prosecuted as 'possession of burglary tools'.
An example can be: "The bank robber packed a crow bar, lock picks, and a saw to be used to break into the bank and its vault. Before he ventured towards the bank, the robber put on sunglasses and a ski mask to hide his face, and he slid on a pair of leather gloves to hide his fingerprints".



</doc>
<doc id="23868651" url="https://en.wikipedia.org/wiki?curid=23868651" title="Pin prick attack">
Pin prick attack

A pin prick attack is a hypothetical assault on another person with a needle or syringe tainted with the blood of somebody carrying a blood-borne disease, such as HIV. Although there have been numerous cases of people being attacked with needles and syringes, the idea that people infected with AIDS have deliberately attempted to infect others in this manner is generally considered an urban legend.

Although fanciful tales of so-called "needle men" or white slavers, who supposedly injected unsuspecting young girls with morphine before carrying them away into a life of prostitution, had been around since the 1930s, the legend probably has its roots in a 1989 incident where ten teenage girls were arrested and later charged with stabbing numerous women with pins in the Upper West Side area of New York City. Coming near the height of the 1980s HIV scares, this led to a great deal of panic amongst the local community although health officials were keen to stress that the chances of anybody contracting the virus in this way were practically zero, and nobody affected in the attacks subsequently tested positive for HIV.

The rise of the Internet in the 1990s led to the rise of numerous urban legends concerning the pin prick attack, which could be quickly spread via email and discussion forums and which soon assumed a standardised form. The email would take the form of a warning to others that a young person had been visiting a cinema or a night club when the person felt a slight prick on his or her arm. Not taking any notice, the person would carry on with his or her leisure activity, and it was only later that the person would find stuck to his or her clothes or in his or her pocket a badge or sticker carrying the slogan "welcome to the AIDS club", followed a few months later with a positive HIV test. These rumours bear similarities to the so-called AIDS Mary legends of the 1980s, whereby a man would enjoy a one-night stand with a stranger at his house and awaken the next morning to find the stranger gone and the words "Welcome to the AIDS Club" written in red lipstick on his bathroom mirror. However, the American Center for Disease Control has stressed on numerous occasions that it has yet to confirm a single case of HIV as being transmitted in this fashion and has dismissed such emails as a hoax. The motive behind such emails appears to be little more than a scare story intended to frighten the recipient into staying away from leisure establishments by playing on the public fear of AIDS and the notion that an individual could be infected with a killer disease through no fault of one's own.

A pin prick attack leading to the deliberate transmission of HIV occurred at the Long Bay Jail in Sydney on July 22, 1990, when prison officer Geoffrey Pearce was attacked by HIV-infected prisoner Graham Farlow, who stabbed him with a syringe full of his own infected blood. Despite immediate medical attention and the "one in 200" chance of being infected, Pearce tested positive for the disease a few months later, and died of an AIDS related illness in 1997 at age 28.

In 1992, Brryan Jackson was injected with a syringe of HIV-infected blood by his father. Jackson was diagnosed with AIDS that same year.

In 1998, Richard J. Schmidt, a physician in Lafayette, Louisiana, was convicted of attempted murder after injecting a former lover, Janice Trahan, with AIDS and Hepatitis C-tainted blood, claiming to be giving her a vitamin shot. Trahan developed both Hep-C and HIV as a result.




</doc>
<doc id="11676740" url="https://en.wikipedia.org/wiki?curid=11676740" title="Crime &amp; Investigation">
Crime &amp; Investigation

Crime & Investigation (stylized as Crime + Investigation) is an American pay television channel that is owned by A&E Networks, a joint venture between the Hearst Communications and the Disney Media Networks division of The Walt Disney Company.

The network airs mostly off-network reruns of crime dramas such as "24", "Nash Bridges", and "Hack", and the A&E crime documentary shows "SWAT", "Uncovered", "The First 48", "American Justice", "The Big House" and "Vanished With Beth Holloway".


</doc>
<doc id="24457106" url="https://en.wikipedia.org/wiki?curid=24457106" title="Race and crime">
Race and crime

Race is one of the correlates of crime receiving attention in academic studies, government surveys, media coverage, and public concern. Several causes of racial disparities in treatment by the criminal justice system have been tested by experts in the sociological field. A majority of their results find that a lack of financial means and low social status are likely factors motivating minorities to commit crime. Additionally, blacks and other ethnic minorities are often sentenced to more time in prison than their white counterparts.

The term racial disparity as it relates to crime can be defined as the proportion of a racial or ethnic group within the criminal justice system exceeding the proportion of such a group within the general population. People of color are more likely to be racially profiled, stopped, and harassed by the police. Racial disparities in the US criminal justice system worsened after 1980 following various political developments. The Nixon, Reagan and Bush administrations are credited for directing what is known as the War on Drugs. In 1986, the U.S. Congress passed laws that created a 100 to 1 sentencing disparity for the trafficking "or possession" of crack when compared to penalties for "trafficking" of powder cocaine, which had been widely criticized as discriminatory against minorities, mostly blacks, who were more likely to use crack than powder cocaine. Statistics from 1998 show that there were wide racial disparities in arrests, prosecutions, sentencing and deaths. African-American drug users made up for 35% of drug arrests, 55% of convictions, and 74% of people sent to prison for drug possession crimes. Nationwide, African-Americans were sent to state prisons for drug offenses 13 times more often than other races, even though they only supposedly comprised 13% of regular drug users.

Racial disparity in commission of violent crime is commonly attributed to the social status and financial means of minorities. Poverty is one factor correlated with an increase in criminal activity. The correlation between poverty and criminal activity has been shown to be independent of race, with the disproportionate number of minorities in poverty being a major reason for their disproportionately high levels of criminal activity. Research shows that childhood exposure to violence also significantly increases the likelihood of engagement in violent behavior.When studies control for childhood exposure to violence, black and white males in the United States are equally likely to engage in violent behavior. However, according to the Department of justice, black children are four times more likely to incarcerated in youth facilities than whites. . Among American teens, black-white differences in violence are accounted for by differences in family income and socialization with deviant peers in school.

Research suggests that police practices, such as racial profiling, over-policing in areas populated by minorities and in-group bias may result in disproportionately high numbers of racial minorities among crime suspects in Sweden, Italy, and England and Wales.In fact, according to the Racial Disparity Audit conducted by the Prime Minister, in 2017 minorities living in Wales and England were more than 3.5 times more likely to be arrested than whites. Likewise, this same group was far more likely to be the victims of crime with their white counterparts only having a 15 percent likelihood. Research also suggests that there may be possible discrimination by the judicial system, which contributes to a higher number of convictions for racial minorities in Sweden, the Netherlands, Italy, Germany, Denmark and France.

Research suggests that police practices, such as racial profiling, over-policing in areas populated by minorities and in-group bias may result in disproportionately high numbers of racial minorities among crime suspects. Research also suggests that there may be possible discrimination by the judicial system, which contributes to a higher number of convictions for racial minorities. A 2012 study found that "(i) juries formed from all-white jury pools convict black defendants significantly (16 percentage points) more often than white defendants, and (ii) this gap in conviction rates is entirely eliminated when the jury pool includes at least one black member." Research has found evidence of in-group bias, where "black (white) juveniles who are randomly assigned to black (white) judges are more likely to get incarcerated (as opposed to being placed on probation), and they receive longer sentences." In-group bias has also been observed when it comes to traffic citations, as black and white cops are more likely to cite out-groups. A 2016 paper by Roland G. Fryer, Jr, found that while there are no racial differences in lethal use of police force, blacks and Hispanics are significantly more likely to experience non-lethal use of force. Reports by the Department of Justice have also found that police officers in Baltimore, Maryland, and Ferguson, Missouri, systemically stop, search (in some cases strip-searching) and harass black residents. A January 2017 report by the DOJ also found that the Chicago Police Department had "unconstitutionally engaged in a pattern of excessive and deadly force" and that police "have no regard for the sanctity of life when it comes to people of color".

In criminal sentencing, medium to dark-skinned African Americans are likely to receive sentences 2.6 years longer than those of whites or light-skinned African Americans. When a white victim is involved, those with more "black" features are likely to receive a much more severe punishment." This is especially true in the case of women, as a 2017 study by Villanova found that lesser sentences were given to defendants who were "pretty." 

A 2013 report by the American Civil Liberties Union found that blacks were "3.73 times more likely than whites to be arrested for marijuana possession", even though "blacks and whites use drugs, including marijuana, at similar rates." Additionally, in 2015, the National Survey on Drug Use and Health reported that African Americans composed 12.5 percent of the illicit drug users, yet 33 percent of them are incarcerated in state facilities. 

A 2016 analysis by the "New York Times" "of tens of thousands of disciplinary cases against inmates in 2015, hundreds of pages of internal reports and three years of parole decisions found that racial disparities were embedded in the prison experience in New York." Blacks and Latinos were sent more frequently to solitary and held there for longer durations than whites. The New York Times analysis found that the disparities were the greatest for violations where the prison guards had lots of discretion, such as disobeying orders, but smaller for violations that required physical evidence, such as possessing contraband.

A 2016 report by the "Sarasota Herald-Tribune" found that Florida judges sentence black defendants to far longer prison sentences than whites with the same background. For the same drug possession crimes, blacks were sentenced to double the time of whites. Blacks were given longer sentences in 60 percent of felony cases, 68 percent of the most serious first-degree crimes, 45 percent of burglary cases and 30 percent of battery cases. For third-degree felonies (the least serious types of felonies in Florida), white judges sentenced blacks to twenty percent more time than whites, whereas black judges gave more balanced sentences.




</doc>
<doc id="348729" url="https://en.wikipedia.org/wiki?curid=348729" title="Juvenile delinquency">
Juvenile delinquency

Juvenile delinquency, also known as "juvenile offending", is the act of participating in unlawful behavior as minors (juveniles, i.e. individuals younger than the statutory age of majority). Most legal systems prescribe specific procedures for dealing with juveniles, such as juvenile detention centers and courts, with it being common that juvenile systems are treated as civil cases instead of criminal, or a hybrid thereof to avoid certain requirements required for criminal cases (typically the rights to a public trial or to a jury trial). A juvenile delinquent in the United States is a person who is typically below 18 (17 in Georgia, New York, Michigan, Missouri, North Carolina, New Hampshire, 
Texas, and Wisconsin) years of age and commits an act that otherwise would have been charged as a crime if they were an adult. Depending on the type and severity of the offense committed, it is possible for people under 18 to be charged and treated as adults.

In recent years a higher proportion of youth have experienced arrests by their early 20s than in the past. Some scholars have concluded that this may reflect more aggressive criminal justice and zero-tolerance policies rather than changes in youth behavior. Juvenile crimes can range from status offenses (such as underage smoking/ drinking), to property crimes and violent crimes. Youth violence rates in the United States have dropped to approximately 12% of peak rates in 1993 according to official US government statistics, suggesting that most juvenile offending is non-violent.

However, juvenile offending can be considered to be normative adolescent behavior. This is because most teens tend to offend by committing non-violent crimes, only once or a few times, and only during adolescence. Repeated and/or violent offending is likely to lead to later and more violent offenses. When this happens, the offender often displays antisocial behavior even before reaching adolescence.

Juvenile delinquency, or offending, is often separated into three categories:

According to the developmental research of Moffitt (2006), there are two different types of offenders that emerge in adolescence. One is the repeat offender, referred to as the life-course-persistent offender, who begins offending or showing antisocial/aggressive behavior in adolescence (or even in childhood) and continues into adulthood; and the age specific offender, referred to as the adolescence-limited offender, for whom juvenile offending or delinquency begins and ends during their period of adolescence. Considering that most teenagers tend to show some form of antisocial or delinquent behavior during adolescence, it is important to account for these behaviors in childhood in order to determine whether they will be life-course-persistent offenders or adolescence-limited offenders. Although adolescence-limited offenders tend to drop all criminal activity once they enter adulthood and show less pathology than life-course-persistent offenders, they still show more mental health, substance abuse, and financial problems, both in adolescence and adulthood, than those who were never delinquent.

The two largest predictors of juvenile delinquency are:


Other factors that may lead a teenager into juvenile delinquency include poor or low socioeconomic status, poor school readiness/performance and/or failure, peer rejection, or attention deficit hyperactivity disorder (ADHD). There may also be biological factors, such as high levels of serotonin, giving them a difficult temper and poor self-regulation, and a lower resting heart rate, which may lead to fearlessness. Delinquent activity, particularly the involvement in youth gangs, may also be caused by a desire for protection against violence or financial hardship, as the offenders view delinquent activity as a means of surrounding themselves with resources to protect against these threats. Most of these influences tend to be caused by a mix of both genetic and environmental factors. Some research indicates that changes in the weather can increase the likelihood of children exhibiting deviant behavior.

Individual psychological or behavioral risk factors that may make offending more likely include low intelligence, impulsiveness or the inability to delay gratification, aggression, lack of empathy, and restlessness. Other risk factors that may be evident during childhood and adolescence include, aggressive or troublesome behavior, language delays or impairments, lack of emotional control (learning to control one's anger), and cruelty to animals.

Children with low intelligence are more likely to do badly in school. This may increase the chances of offending because low educational attainment, a low attachment to school, and low educational aspirations are all risk factors for offending in themselves. Children who perform poorly at school are also more likely to be truant, and the status offense of truancy is linked to further offending. Impulsiveness is seen by some as the key aspect of a child's personality that predicts offending. However, it is not clear whether these aspects of personality are a result of "deficits in the executive functions of the brain" or a result of parental influences or other social factors. In any event, studies of adolescent development show that teenagers are more prone to risk-taking, which may explain the high disproportionate rate of offending among adolescents.

Family factors that may have an influence on offending include: the level of parental supervision, the way parents discipline a child, particularly harsh punishment, parental conflict or separation, criminal parents or siblings, parental abuse or neglect, and the quality of the parent-child relationship. Children who develop behavioral problems early in life are at greater risk for continual life long antisocial behavior, criminal activity and violence. Some have suggested that having a lifelong partner leads to less offending.

Juvenile Delinquency, which basically is the rebellious or unlawful activities by kids in their teens or pre-teens, is caused by four main risk factors namely; personality, background, state of mind and drugs. These factors may lead to the child having low IQ and may increase the rate of illiteracy.

Children brought up by single parents are more likely to start offending than those who live with both parents. It is also more likely that children of single parents may live in poverty, which is strongly associated with juvenile delinquency. However once the attachment a child feels towards their parent(s) and the level of parental supervision are taken into account, children in single parent families are no more likely to offend than others. Conflict between a child's parents is also much more closely linked to offending than being raised by a lone parent.

If a child has low parental supervision they are much more likely to offend. Many studies have found a strong correlation between a lack of supervision and offending, and it appears to be the most important family influence on offending. When parents commonly do not know where their children are, what their activities are, or who their friends are, children are more likely to truant from school and have delinquent friends, each of which are linked to offending. A lack of supervision is also connected to poor relationships between children and parents. Children who are often in conflict with their parents may be less willing to discuss their activities with them.

Adolescents with criminal siblings are only more likely to be influenced by their siblings, and also become delinquent; the sibling is older, of the same sex/gender, and warm. Cases where a younger criminal sibling influences an older one are rare. An aggressive, non-loving/warm sibling is less likely to influence a younger sibling in the direction of delinquency, if anything, the more strained the relationship between the siblings, the less they will want to be like, and/or influence each other.

Peer rejection in childhood is also a large predictor of juvenile delinquency. Although children are rejected by peers for many reasons, it is often the case that they are rejected due to violent or aggressive behavior. This rejections affects the child's ability to be socialized properly, which can reduce their aggressive tendencies, and often leads them to gravitate towards anti-social peer groups. This association often leads to the promotion of violent, aggressive and deviant behavior. "The impact of deviant peer group influences on the crystallization of an antisocial developmental trajectory has been solidly documented." Aggressive adolescents who have been rejected by peers are also more likely to have a "hostile attribution bias", which leads people to interpret the actions of others (whether they be hostile or not) as purposefully hostile and aggressive towards them. This often leads to an impulsive and aggressive reaction. Hostile attribution bias however, can appear at any age during development and often lasts throughout a persons life.

Children resulting from unintended pregnancies are more likely to exhibit delinquent behavior. They also have lower mother-child relationship quality.

There are a multitude of different theories on the causes of crime; most, if not all, of are applicable to the causes of juvenile delinquency.

Classical criminology stresses that the causes of crime lie within the individual offender, rather than in their external environment. For classicists, offenders are motivated by rational self-interest, and the importance of free will and personal responsibility is emphasized. Rational choice theory is the clearest example of this idea. Delinquency is one of the major factors motivated by rational choice.

Current positivist approaches generally focus on the culture. A type of criminological theory attributing variation in crime and delinquency over time and among territories to the absence or breakdown of communal institutions (e.g. family, school, church and social groups.) and communal relationships that traditionally encouraged cooperative relationships among people.

Strain theory is associated mainly with the work of Robert Merton. He felt that there are institutionalized paths to success in society. Strain theory holds that crime is caused by the difficulty those in poverty have in achieving socially valued goals by legitimate means. As those with, for instance, poor educational attainment have difficulty achieving wealth and status by securing well paid employment, they are more likely to use criminal means to obtain these goals.
Merton's suggests five adaptations to this dilemma:
A difficulty with strain theory is that it does not explore why children of low-income families would have poor educational attainment in the first place. More importantly is the fact that much youth crime does not have an economic motivation. Strain theory fails to explain violent crime, the type of youth crime that causes most anxiety to the public.

The theory of Differential association also deals with young people in a group context, and looks at how peer pressure and the existence of gangs could lead them into crime. It suggests young people are motivated to commit crimes by delinquent peers, and learn criminal skills from them. The diminished influence of peers after men marry has also been cited as a factor in desisting from offending. There is strong evidence that young people with criminal friends are more likely to commit crimes themselves. However it may be the case that offenders prefer to associate with one another, rather than delinquent peers causing someone to start offending. Furthermore there is the question of how the delinquent peer group became delinquent initially.

Labeling theory is a concept within Criminology that aims to explain deviant behavior from the social context rather than looking at the individual themselves. It is part of Interactionism criminology that states that once young people have been labeled as criminal they are more likely to offend. The idea is that once labelled as deviant a young person may accept that role, and be more likely to associate with others who have been similarly labelled. Labelling theorists say that male children from poor families are more likely to be labelled deviant, and that this may partially explain why there are more working class young male offenders.

Social control theory proposes that exploiting the process of socialization and social learning builds self-control and can reduce the inclination to indulge in behavior recognized as antisocial. The four types of control can help prevent juvenile delinquency are:

Direct: by which punishment is threatened or applied for wrongful behavior, and compliance is rewarded by parents, family, and authority figures.
Internal: by which a youth refrains from delinquency through the conscience or superego.
Indirect: by identification with those who influence behavior, say because his or her delinquent act might cause pain and disappointment to parents and others with whom he or she has close relationships.
Control through needs satisfaction, i.e. if all an individual's needs are met, there is no point in criminal activity.

Juvenile delinquents are often diagnosed with different disorders. Around six to sixteen percent of male teens and two to nine percent of female teens have a conduct disorder. These can vary from oppositional-defiant disorder, which is not necessarily aggressive, to antisocial personality disorder, often diagnosed among psychopaths. A conduct disorder can develop during childhood and then manifest itself during adolescence.

Juvenile delinquents who have recurring encounters with the criminal justice system, or in other words those who are life-course-persistent offenders, are sometimes diagnosed with conduct disorders because they show a continuous disregard for their own and others safety and/or property. Once the juvenile continues to exhibit the same behavioral patterns and turns eighteen he is then at risk of being diagnosed with antisocial personality disorder and much more prone to become a serious criminal offender. One of the main components used in diagnosing an adult with antisocial personality disorder consists of presenting documented history of conduct disorder before the age of 15. These two personality disorders are analogous in their erratic and aggressive behavior. This is why habitual juvenile offenders diagnosed with conduct disorder are likely to exhibit signs of antisocial personality disorder early in life and then as they mature. Some times these juveniles reach maturation and they develop into career criminals, or life-course-persistent offenders. "Career criminals begin committing antisocial behavior before entering grade school and are versatile in that they engage in an array of destructive behaviors, offend at exceedingly high rates, and are less likely to quit committing crime as they age."

Quantitative research was completed on 9,945 juvenile male offenders between the ages of 10 and 18 in Philadelphia, Pennsylvania in the 1970s. The longitudinal birth cohort was used to examine a trend among a small percentage of career criminals who accounted for the largest percentage of crime activity. The trend exhibited a new phenomenon among habitual offenders. The phenomenon indicated that only 6% of the youth qualified under their definition of a habitual offender (known today as life-course persistent offenders, or career criminals) and yet were responsible for 52% of the delinquency within the entire study. The same 6% of chronic offenders accounted for 71% of the murders and 69% of the aggravated assaults. This phenomenon was later researched among an adult population in 1977 and resulted in similar findings. S. A. Mednick did a birth cohort of 30,000 males and found that 1% of the males were responsible for more than half of the criminal activity. The habitual crime behavior found among juveniles is similar to that of adults. As stated before most life-course persistent offenders begin exhibiting antisocial, violent, and/or delinquent behavior, prior to adolescence. Therefore, while there is a high rate of juvenile delinquency, it is the small percentage of life-course persistent, career criminals that are responsible for most of the violent crimes.

Delinquency prevention is the broad term for all efforts aimed at preventing youth from becoming involved in criminal, or other antisocial, activity.

Because the development of delinquency in youth is influenced by numerous factors, prevention efforts need to be comprehensive in scope. Prevention services may include activities such as substance abuse education and treatment, family counseling, youth mentoring, parenting education, educational support, and youth sheltering. Increasing availability and use of family planning services, including education and contraceptives helps to reduce unintended pregnancy and unwanted births, which are risk factors for delinquency. Education is the great equalizer, opening doors to lift themselves out of poverty... Education also promotes economic growth, national productivity and innovation, and values of democracy and social cohesion. Prevention through education aides the young people to interact more effectively in social contexts, therefore diminishing need for delinquency.

It has been noted that often interventions may leave at-risk children worse off then if there had never been an intervention. This is due primarily to the fact that placing large groups of at risk children together only propagates delinquent or violent behavior. "Bad" teens get together to talk about the "bad" things they've done, and it is received by their peers in a positive reinforcing light, promoting the behavior among them. A well-known intervention treatment that has not increased the prevention of juvenile delinquency is the Scared Straight Treatment. “The harmful effects of Scared Straight and boot-camp programs may be attributable to juvenile offenders’ vicarious exposure to criminal role models, to the increased resentment engendered in them by confrontational interactions, or both”. This suggests that exposure to criminals could create a sense of idealization and defeat the entire purpose of scared straight treatment. Also, this treatment doesn’t acknowledge the psychological troubles that the teenager may be experiencing. As mentioned before, peer groups, particularly an association with antisocial peer groups, is one of the biggest predictors of delinquency, and of life-course-persistent delinquency. The most efficient interventions are those that not only separate at-risk teens from anti-social peers, and place them instead with pro-social ones, but also simultaneously improve their home environment by training parents with appropriate parenting styles, parenting style being the other large predictor of juvenile delinquency.

Two UK academics, Stephen Case and Kevin Haines, among others, criticized risk factor research in their academic papers and a comprehensive polemic text, "Understanding Youth Offending: Risk Factor Research, Policy and Practice".

The robustness and validity of much risk factor research is criticized for:

Juveniles who commit sexual crimes refer to individuals adjudicated in a criminal court for a sexual crime. Sex crimes are defined as sexually abusive behavior committed by a person under the age of 18 that is perpetrated "against the victim's will, without consent, and in an aggressive, exploitative, manipulative, and/or threatening manner". It is important to utilize appropriate terminology for juvenile sex offenders. Harsh and inappropriate expressions include terms such as "pedophile, child molester, predator, perpetrator, and mini-perp" These terms have often been associated with this group, regardless of the youth’s age, diagnosis, cognitive abilities, or developmental stage. Using appropriate expressions can facilitate a more accurate depiction of juvenile sex offenders and may decrease the subsequent aversive psychological affects from using such labels. In the Arab Gulf states [sic], homosexual acts are classified as an offense, and constitute one of the primary crimes for which juvenile males are charged.

Examining prevalence data and the characteristics of juvenile sex offenders is a fundamental component to obtain a precise understanding of this heterogeneous group. With mandatory reporting laws in place, it became a necessity for providers to report any incidents of disclosed sexual abuse. Longo and Prescott indicate that juveniles commit approximately 30-60% of all child sexual abuse. The Federal Bureau of Investigation Uniform Crime Reports indicate that in 2008 youth under the age of 18 accounted for 16.7% of forcible rapes and 20.61% of other sexual offenses. Center for Sex Offender Management indicates that approximately one-fifth of all rapes and one-half of all sexual child molestation can be accounted for by juveniles.

The Office of Juvenile Justice and Delinquency Prevention indicates that 15% of juvenile arrests occurred for rape in 2006, and 12% were clearance (resolved by an arrest). The total number of juvenile arrests in 2006 for forcible rape was 3,610 with 2% being female and 36% being under the age of 15 years. This trend has declined throughout the years with forcible rape from 1997–2006 being −30% and from 2005 to 2006 being −10%. The OJJDP reports that the juvenile arrest rate for forcible rape increased from the early 1980s through the 1990s and at that time it fell again. All types of crime rates fell in the 1990s. The OJJDP also reported that the total number of juvenile arrests in 2006 for sex offenses (other than forcible rape) was 15,900 with 10% being female and 47% being under the age of 15. There was again a decrease with the trend throughout the years with sex offenses from 1997 to 2006 being −16% and from 2005 to 2006 being −9%.

Barbaree and Marshall indicate that juvenile males contribute to the majority of sex crimes, with 2–4% of adolescent males having reported committing sexually assaultive behavior, and 20% of all rapes and 30–50% of all child molestation are perpetrated by adolescent males. It is clear that males are over-represented in this population. This is consistent with Ryan and Lane’s research indicating that males account for 91-93% of the reported juvenile sex offenses. Righthand and Welch reported that females account for an estimated 2–11% of incidents of sexual offending. In addition, it reported by The Office of Juvenile Justice and Delinquency Prevention that in the juvenile arrests during 2006, African American male youth were disproportionately arrested (34%) for forcible rape. In one case in a foster home a 13-year-old boy raped a 9-year-old boy by having forced anal sex with him, in a court hearing the 9-year-old boy said he has done this multiple times, that the 13-year-old boy was charged for sexual assault.

Sexual crimes committed by juveniles are not just an issue in the United States. Studies from the Netherlands show that out of 3200 sex offenders recorded by police in 2009, 672 of those were juveniles, approximately 21 percent of sexual offenders. The study also points out the male to female ratio of sexual predators.

In 2009, a U.S. congressman proposed legislature that would create an International Sex Offender Registry. The bill was introduced due to the fact that because laws differ in different countries someone who is on the sex offender registry in the U.S. who may be barred from living certain places and doing certain activities has free range in other less developed countries. This can lead to child sex tourism, when a sexual predator will go to less developed countries and prey on young boys and girls. Karne Newburn in his article, The Prospect of an International Sex Offender Registry, pointed out some serious flaws in the proposed bill, such as creating safety issues within the communities for the sex offenders placed on the registry. Newburn suggested instead of creating an International Sex Offender Registry from the U.S. model the U.S. join other countries in a dialogue on creating an effective model. As of now no registry exists. Despite this there is still interest in creating some sort of international registry.


<nowiki> ~~~~Adrianecohen (10/31/18 12:58am) </nowiki>



</doc>
<doc id="3095914" url="https://en.wikipedia.org/wiki?curid=3095914" title="Stranger danger">
Stranger danger

"Stranger danger" is the idea or warning that all strangers can potentially be dangerous. It is an example of a moral panic that people experience regarding anyone that they are unfamiliar with in society. The phrase is intended to encapsulate the danger associated with adults who children do not know. The phrase has found widespread usage and many children will hear it during their childhood lives. Many books, films and public service announcements have been devoted to helping children remember this advice. The concept has been criticized for ignoring that most child abductions and harm result not from strangers, but rather from someone the child knows.

Although there are other dangers such as kidnapping for ransom, the main threat with which stranger danger campaigns are concerned is child sexual abuse. Portrayals in the news media have tended to reinforce public fears of strangers as potential paedophiles, despite sexual abuse of children being more likely to occur in families. In recent years, the emphasis of such campaigns has shifted somewhat, in order to reflect the risk of abuse by persons known to the child.

Although there are other dangers such as kidnapping for ransom, the main threat with which stranger danger campaigns are concerned is sexual abuse. In recent years, the emphasis of such campaigns has shifted somewhat, in order to reflect the risk of abuse by persons known to the child. Common phrases children will hear include:

Some proponents of stranger danger propose telling children that it is safe to talk to strangers in circumstances where the child is in danger, such as if the child is lost or injured. In such circumstances, avoiding potentially helpful strangers could, itself, be dangerous. Conversely, other proponents of stranger danger warnings propose teaching children never to approach others without parental permission. This admonishment extends to not entering a car, even if the child recognizes the driver.

In addition to stranger danger warnings, programs from the Federal Bureau of Investigation, local law enforcement agencies and other organizations offer free fingerprinting services usually done in schools, child care centers, shopping malls, fairs, and festivals. Parents/guardians are provided with child identification sheets to use in cases of child abduction and other emergencies. Child identification sheets include the child's fingerprints, photo and other personal data. Neither the FBI nor any other law enforcement agency retains this information. DNA samples are also provided to parents.

In the wake of the July 2011 murder of Leiby Kletzky, New York City Councilman David Greenfield said he would propose "Leiby's Law", a bill under which businesses could volunteer to be designated as safe places for children who are lost or otherwise in trouble. Employees would undergo background checks and business owners would put a green sticker in their store windows so children would know the business is a safe place to get help. On August 16, 2011, the Brooklyn District Attorney’s office announced a similar program called "Safe Stop". As of August 2011, 76 stores had signed up to display a green "Safe Haven" sticker in their windows to help lost children.

Media stories have often exaggerated the risk of "stranger danger" by emphasizing rare and isolated incidents. Especially regarding child sexual abuse, the greatest risk comes from members of the child's family. Nevertheless, "stranger danger" is more likely to be the focus of news headlines and education campaigns.

According to the U.S. Department of Justice, most missing children are runaways, and 99% of abducted children are taken by relatives, typically a noncustodial father. In response to these statistics, the National Center for Missing and Exploited Children has reversed their campaign focusing on "stranger danger". 

Constantly warning children of possible danger in the form of strangers has also been criticised for unnecessarily spreading mistrust, especially when considering that (for example) in the US, about 800,000 children are reported at least temporarily missing every year, yet only 115 "become victims of what is viewed as classic stranger abductions". Only 10 percent of the child victimizers in violent crimes are strangers, and sex offenses are the crimes least likely to involve strangers as perpetrators.

A 2002 study looked at the nearly 800,000 minors who had been reported missing over a one-year period. Many were runaways. About 25 percent were family abductions, about 7 percent were nonfamily abductions, and only 115 — about 1 in 10,000 of all children reported missing — were "'stereotypical kidnappings,' defined in one study as 'a nonfamily abduction perpetrated by a slight acquaintance or stranger in which a child is detained overnight, transported at least 50 miles, held for ransom or abducted with the intent to keep the child permanently, or killed'". Journalist Stephen J. Dubner, co-author of "Freakonomics", referred to this statistic as an example of his point that "most people are pretty terrible at risk assessment. They tend to overstate the risk of dramatic and unlikely events at the expense of more common and boring (if equally devastating) events."

In circumstances where the child is in danger for other reasons, avoiding strangers (who might help) could in fact be dangerous itself, such as in the case of an 11-year-old Boy Scout who avoided rescue searchers because he feared they may want to "steal" him.

According to the University of New Hampshire's Crimes Against Children Research Center, "stranger danger" disproportionately increases fear of strangers in comparison to fear of abusers known to the child. This is because humans have to operate on the basis of trust and reciprocity with acquaintances and it is difficult to view acquaintances as threatening or to fear them.

The notion of "stranger danger" has been criticized for positioning children as passive objects of potential threat which allows adults to justify their means of controlling or isolating children. Gill Valentine argues that producing misleading or exaggerated messages about "stranger danger" results in the notion that public spaces are naturally adult spaces where children must be constantly protected.

Exaggerated fears of "stranger danger" have caused many parents to limit children's ability to be physically active, such as by exploring their neighborhood unsupervised; for example, fewer parents allow children to walk to school alone than in the past. This increased tendency to keep children indoors has resulted in an alleged nature deficit disorder in children.

In the United Kingdom, stranger danger has long been a key theme in the safety of children. The potential danger of a child being abused or killed by a stranger has been seen as a major factor in children having less freedom from the mid 20th century onwards, although factors including other crimes as well as increased road traffic (increasing the risk of being run over) have also been deemed as factors in parents becoming more protective of their children in more recent years.

The conviction of Ian Brady and Myra Hindley of the Moors Murders in 1966 was seen by many as the event which led to parents allowing their children less freedom - as well as making parents and children more alert of the fact that there are also dangerous women as well as dangerous men. The brother of one of Brady and Hindley's victims recalled many years later that his murdered brother had been regularly warned not to accept sweets or lifts from strange men, but had never been told not to speak to or go anywhere with a strange woman, as few people at the time were aware that a strange woman could be potentially as dangerous as a strange man. Although child murders already were frequently reported in Britain before the Moors Murders came to light, the fact that a woman was involved was obviously a factor in the case being so high profile in the media and public eye - and remained so in the years ahead, despite the vast number of other high profile murder cases which made the headlines. The first of Brady and Hindley's five known victims, Pauline Reade, was even a neighbour of Myra Hindley. The other four victims, however, were all unknown to Brady and Hindley. 

In more recent years, "stranger danger" killings of children including that of at least four young girls by Robert Black during the 1980s, and that of Sarah Payne in West Sussex in July 2000, may have led parents to become increasingly protective of their children — as well as prompting parents and teachers to make children more alert of the dangers of strangers. Black was a stranger who lured his victims from different parts of Britain while working as a lorry driver, while Sarah Payne's killer Roy Whiting was not known to the victim or to any of her family, who had confirmed this to the police when Sarah Payne was still missing and Whiting was first identified as a possible suspect.

However, statistics by government and police bodies have shown that "stranger danger" killings of children are incredibly rare, and that the overwhelming number of cases of child abuse and murder were committed by someone who was known to the child. The Soham Murders in Cambridgeshire, where two 10-year-old girls were found dead two weeks after their disappearance in August 2002, are a notable example — the killer of the girls, Ian Huntley, was known to both of his victims, and his role as a local school caretaker perhaps portrayed him as a man with a position of trust, who would not appear to be a likely danger to children whether known to them or not.

The police had even mentioned to the media while the girls were still missing that they may have been abducted by someone who was known to them. Huntley was arrested some 12 hours before the bodies of the two girls were found, although until this development the disappearance of the girls might have been judged by the majority of the public and the media as a typical "stranger danger" abduction. Subsequent child murders, including those of Tia Sharp in South London and April Jones (whose body has never been found) in Mid Wales during 2012, were also proven to have been committed by men who were known to the victim — in the case of Tia Sharp, the murderer was a family member.

There have also been cases of murder where the victim was an older child or teenager whose considerable amount of freedom (compared to the average younger child) made it impossible for the police to determine whether the killer was definitely known to the victim. A notable example is Amanda Dowler, the Surrey teenager who disappeared in March 2002 and whose remains were found in Hampshire six months later. Levi Bellfield, already serving life imprisonment for two other murders, was found guilty of her murder nearly a decade later, and police said that she may have known Bellfield as he was the step-father of one of her friends at school. In 2005, 15-year-old Rochelle Holness was murdered and dismembered by her distant neighbour John McGrady on a high-rise council estate in South London, but as with the case of Amanda Dowler, police were unable to confirm whether Rochelle Holness knew her killer.

Such is the rarity of "stranger danger" abductions and killings of children in the United Kingdom, that in May 2015 an online video portraying the dangers of strangers and potential abduction situations was in fact condemned by critics, due to these crimes being so rare. Indeed, the murder of Sarah Payne 15 years earlier may very well have been the most recent murder of a pre-teen child by a stranger in Britain.




</doc>
<doc id="37847649" url="https://en.wikipedia.org/wiki?curid=37847649" title="Crime concentration">
Crime concentration

A Crime concentration is a spatial area to which high levels of crime incidents are attributed. A crime concentration can be the result of homogeneous or heterogeneous crime incidents. "Hotspots" are the result of various crimes occurring in relative proximity to each other within predefined human geopolitical or social boundaries. Crime concentrations are smaller units or set of crime targets within a hotspot. A single or a conjunction of crime concentrations within a study area can make up a crime hotspot.

Some of the early works in crime analysis aimed to identify hotspots of crime within big regions. These regions could extend as large as states, counties, a group of counties, cities, neighborhoods and police beats. The aim of this approach was to focus on large areas, rather than specific addresses or locations hosting crime events as part of a larger environment. This is important because not all locations are equal generators of crime and not all provide equal opportunity for offenders to conduct criminal activity. Thus, crime concentrations are smaller groups of crime uniformly or randomly distributed within a hotspot's geographical domain; this is because not all hotspots have the same crime composition and patterns. In other words, a hotspot can be composed by multiple layers of crime intensity. Thus, each one has its own variations or rhythms of crime distribution. Therefore, it is each hotspot's composition that dictates what measures need to be employed as crime reduction strategies.

Hotspots are the foundation of crime concentrations because it is from the hotspot's earlier theories and studies that the analysis of crime concentration was derived. Hotspots can be expressed in the form of dots, lines or polygons and even shades of color as in the case of kernel density which estimates the likelihood of a crime event occurring within a given region; this is done through "crime mapping" which refers to the allocation of individual or multiple crime incidents on a map by utilizing a computer software package such as ArcMap 10.1, a Geographic information system. The different forms of hotspots and consequently crime concentrations are studied and explained by various theories and measured by several spatial and temporal analysis techniques. These techniques generally rely on statistical algorithms for the creation of surface maps. One of predominant theories that explains crime congregations is Crime opportunity theory. It explains that "rather than concentrations of offenders or the absence of social controls, opportunity theories suggest that analysts should look for concentrations of crime targets". Repeat victimization%20theory Victimisation victimization theory examines why some areas or targets are repeatedly victimized. Broken windows theory also explains that an area that becomes abandoned or if the guardians and managers cease to be in control of an establishment, then other guardians and managers become less motivated to enforce social controls, consequently allowing criminal activity to increase. Lastly, one of the most influential crime concentration theories is the Crime Place Theory because it focuses on criminal events on specific locations rather than a large view at the high crime density area.

Kernel density is a computer based analysis through the usage of geographic information systems employed for the purpose of measuring crime intensity. It takes the map of the area being studied as the basis for analysis then it proceeds to divide the total area or map into smaller grid cells. The size of those grid cells can be selected by the analyst accordingly to the research questions under study or the indented applications. Each cell grid has a center point. Also, it is necessary for the analyst to select a bandwidth. This bandwidth is essentially a search radius from the center of each map grid. When the analysis is run the bandwidth searches the number of crimes reported within each cell. A greater amount crimes located closer to the cell center indicate higher crime intensity. If cells are found to possess high crime intensity rates then they are assigned high values.

Every cell grid in the map is assigned a value. This results in a continues map, a map of a city under the jurisdiction of a given police department for example. This map portraits the crime incidents data or intensity in the form of shades of colors for each grid throughout the area of study. Every part of the map has cells thus every part of the map has intensity value. Therefore, after conducting the kernel density analysis, it can be determine if grid cells with high crime intensity values are clustered together and thus forming a crime hotspot. The cells that possess higher intensity values within the crime hotspots only show the crime density but cannot be further analyze in order to locate the spatial coverage of crime concentrations. The ability to manipulate cell and bandwidth sizes permits analyst to use kernel density for conducting analysis at a small scope level within a crime hotspot.

The "Hotspot Matrix" was pioneered by Jerry H. Ratcliffe. It is the analysis of hotspots; however, unlike conventional analysis, it is not limited to the examination of hotspots as a mere geographical location. In addition to the implementation of spatial analysis techniques such as kernel density, LISA or STAC; it uses an aoristic analysis for which "The basic premise is that if a time of an event is not known, then the start and end time can be used to estimate a probability matrix for each crime event for each hour of the day". Therefore, the hotspot matrix is the combination of both spatial and temporal characteristics pertaining to hotspots in order to determine crime concentration patterns within a high crime intensity area.

Ratcliffe divided the hotspot matrix as having spatial and temporal attributes. The spatial attributes of a hotspot are: Hotpoint referring to a specific place from which a high volume of crimes are generated. The Clustered is geographical characteristic and representation of hotspots where crimes are concentrated with greater density in various areas in the location being studied. Dispersed crimes are those that are distributed across the study region without formulating major clusters of crimes; it is the closest form of random distribution of crimes in a hotspot. Ratcliffe also introduced the idea of temporal characteristics of crime. Diffused are hotspots where crimes are likely to happen at any time and there is not a specific window of time for crime incidents. Focused describes a phenomenon where crimes are likely to occur within a hotspot through the day, week, month(s) with greater intensity over a set of small windows of time. Acute pertains to hotspots experiencing the vast majority of incidents in a very small time frame; crime incidents outside that time frame are still possible, but nearly nonexistent. These are the six broad categories attributed to the hotspot matrix. These categories can be utilized to identify the areas within administrative boundaries with greater crime intensities. It also facilitates the identification of the type hotspot in the region. After the major crime areas become known, consequently, they can be isolated by the analyst in order to examine them to a closer level.

Loyola Community Safety Project was assembled to investigate the potential relationship between taverns and other local licensed businesses whose primary or partial source of income rely the sales of alcoholic beverages in the area of Roger Park & Edgewater communities in the city of Chicago. This initiative was the result the collaboration of many community groups due to the increasing rates of drug and violent crimes in the region. The researchers had access to the equivalent of a "geodatabase", which essentially functions as a big folder with the capabilities of storing multiple files such as aerial photographs or any other file capable of depicting geographical information. This geodatabase was compiled from records of police departments and other community groups; it contained data in the form of street addresses of establishments that sell alcohol. This information was stored as software files on a computer; this enabled the analysis, the geocoding and the output of the community maps.

The researchers proceeded to compile a list of all businesses in the area of study holding a liquor sales license. The researchers limited themselves from defining Taverns as the source of the crimes. Instead, they included in their study population every business with a liquor license. This facilitated the inclusion of business that do not fit the category of a Tavern in areas with higher poverty levels, but nevertheless serve the same function.

The researchers initiated "geocoding" which associates an address in the real world to a map – both the addresses of the several types of liquor selling establishments and the crimes that had occurred in places where liquor beverages are sold. The crimes geocoded varied in nature and ranged from disorderly conduct to felonies. After the both crimes and establishments had been geocoded, the maps were overlaid. This facilitated the identification of liquor places with the greater number of crimes within their location or their vicinity.

Some of the limitations in the study were that a high level of coordinates did not match. This was because the raw data was collected by various agencies and for different purposes. The method of analysis was to calculate the hotspot ellipses through the implementation of Spatial and Temporal Analysis of Crime (STAC). Eck and Weisburb (1995) define the process of how STAC works “STAC hot spot area searches begin with individual pin map data and build areas that reflect the actual scatter of events, regardless of arbitrary or predefined boundaries. STAC finds the densest clusters of events in the map and calculates the standard deviational ellipse that best fits each cluster.” (p. 154). It was determined that the number of liquor stores and liquor related businesses were not randomly dispersed in the area. They were generally located in clusters along major roads. This supports the idea that hotspots may contain different arrangements of crime. After the hotspots were identified by the researchers, they continued to examine the hotspots arrangement and took a look at some specific address level crime concentrations. The study found that high concentrations of taverns or liquor stores do not necessarily produce high levels of crime. It concluded that there were places that were responsible for higher levels of crime than others. Therefore, not all crime concentrations are equally generators of crime. Some crime places have environmental cues that facilitate the occurrence and sustainment of crime victimization.

This study was designed to reduce youth violence and gun markets in Boston. This was a collaboration of Harvard University researchers, Boston Police Department, probation officers and other city employees that had some level of experience when dealing with young offenders or youth vulnerable to violence. The group initiated a multi-agency study under the perception that a high density of gangs were operating in the area of interest or the city of Boston. It was assumed that youth violence was the direct product of gangs involvement almost in every youth violence incident. Some gang members were interviewed and it was learned that many did not classify themselves as gangs or gang members.

Researchers with the help of gang and patrol officer identify the areas of operation pertaining to each gang or information was also acquired from gang members. Each area was highlighted on a printed map; this facilitated the identification of gang-controlled territory. The next step was to go on to hand "digitizing" the gang territories into a software based map. Through this process, it was discovered that the gang areas of operation were unevenly distributed. Gang territory accounted for less than 10% of Boston.

Data of violent crimes that were confirmed or likely to had been committed by gangs were geocoded and matched with the gang territorial map. This data was obtained from the Boston Police Department for the year of 1994. It is through geocoding and the overlapping the gang territorial map that major concentrations of crime were identified. The ratios of violence incidents were significantly higher under gang areas of operations in contrast to areas free of gang presence. However, not all gangs were equal generators crime or practitioners of the same criminal offenses. Additionally, STAC program was utilize to create hotspot ellipses in order to measure the crime distribution density. It reinforced the previous results that some gangs’ territory experience the higher rates of crime. The crime hotspots located in the regions could then be further analyzed for its unique crime concentration pattern.

The Center For Evidence-Based Crime Policy in George Mason University identifies the following randomized controlled trials of hot spot policing as very rigorous.

There are various methods for the identification and/or establishment of emerging geographical locations experiencing high levels of crime concentrations and hotspots. A commonly used method for this process is the implementation of kernel density; this method depicts the probability of an event occurring; in criminology it refers to crime incidents. This probability is often measured as a Mean and expressed in the form of density on a surface map. A disadvantage in this approach is that in order to obtain the different degrees of intensity, the map is subdivided into several grid cells. Therefore, the final map output have multiple cells with their own respective crime density degrees which facilitate the comparison between hotspots vs hotspots and places with relative low levels of crime. However, there is not finite line highlighting the begging and the exact end of each hotspot and its respective set or individual crime concentrations. This is assuming that the criminal incidents are not evenly distributed across the space within the hotspot. Also, every grid cell has the same crime density within it; therefore, it is difficult to know the exact crime pattern within each cell. One way in which the analysts can handle these set of potential deficiencies is by adjusting the grid cells size on the digital map so they can represent a smaller spatial area on the actual ground. Also, the kernel density map can be overlaid with a dot map for which the crime incidents have been geocoded. This method will enable the analysts to corroborate his/her results by having two analysis of the same area. The kernel density map can be used to identify the spatial area that constitutes the hotspot. After Zooming in to the map, the dot map will enable to identify the individual crime distribution pertaining to each hotspot or even to each cell. Ultimately, this allows for an analysis of blocks, street and specific locations and their spatial relationship to crimes in their surroundings.

A potential deficiency in crime concentration analysis and hotspot identification techniques is that crime analysts generally are limited to analyze data collected from their own law enforcement agency. The collection of this data is limited by administrative and geopolitical lines. Crimes are not contained within social boundaries. These boundaries might restrict the analyst from looking at the entire crime picture. Therefore, by only analyzing within a police department's jurisdiction the researcher might be unable to study the actual or miss the root of the crime concentration due to a partial access of the natural flow of crime that is not restricted by geographical lines.

It is important to know the limitations of each analysis techniques. Thus, it is fundamental to know that some techniques do not include temporal characteristics of crime concentrations or crime incidents. One of the future developments in the analysis of crime concentrations should be the inclusion of time at which the incidents occurred. This will enable to create a hotspot in motion rather than static pictures that only capture one moment in time or portraits all crime incidents as if there exist no difference between the time of each crime's occurrence.

Identification of hotspots and consequently crime concentrations enables law enforcing agencies to allocate their human and financial resources effectively. Detecting areas experiencing abnormally high crime densities provide empirical support to police chiefs or managers for the establishment and justification of policies and counter crime measures. It is through this method of crime analysis that areas with greater rates of victimization within a law enforcement's jurisdiction can received greater amounts of attention and therefore problem solving efforts.

The "crime analyst" can utilize one of the various spatial analytical techniques for spotting the crime concentration areas. After the spatial extend of these hot areas are defined, it is possible to formulate research questions, apply crime theories and opt the course(s) of action to address the issues being faced; therefore, preventing their potential spatial or quantitative proliferation. One example would be asking why a particular area is experiencing high levels of crime and others are not. This could lead the analyst to examine the hotspot at a much deeper level in order to become aware of the hotspot's inner crime incidents placement patterns, randomization or to examine the different clusters of crime. Because not all places are equal crime generators, individual facilities can be further analyzed in order to establish their relationship to other crimes in their spatial proximity. Similarly, every crime concentration analysis is essentially a snapshot of a given number of criminal acts distributed throughout a geographical area. Thus, crime concentrations analyses can be compared throughout different time periods such as specific days of the week, weeks, and dates of the month or seasons. For example, crime snapshots of block Z are compared every Friday over the course of 3 months. Through this comparison, it is determined that 85% of the Fridays during the length of the study; block Z experienced abnormally high levels of burglaries in one specific place in Block. Based on this, a "Crime prevention through environmental design" approach can be taken.

The analyst can then study the specific location and determine the factors that make that facility prone to repeat victimization and a crime facilitator. Also, the analyst could discover that there exist a relationship between the place on block Z and the crime offenders. Or it could be discovered that the place "managers" or "guardians" are not fulfilling their duties correctly. Therefore, neglecting the crime target and enabling crime flourishment. It is also possible, that the crime target's physical design and characteristics, plus the nature of the businesses it conducts regularly attract or provide actual and potential offenders in the area some crime opportunities.

In addition, objects taken from the premises as part of the burglaries might be easily accessible or promote low risks of being apprehended. This could be further fortified by or as the application of the crime opportunity theory. All of this is made possible due to identification of hotspot and their respective crime concentrations. Plus the further employment of Ratcliffe's hotspot matrix which depicts the crime concentration patterns within hotspots. Also, his perspective of zooming in to hotspot to examine specific crime generators in order to analyze their spatial and temporal relationship to other crimes in the area of study.




</doc>
<doc id="16205921" url="https://en.wikipedia.org/wiki?curid=16205921" title="Terroristic threat">
Terroristic threat

A terroristic threat is a threat to commit a crime of violence or a threat to cause bodily injury to another person and terrorization as the result of the proscribed conduct. Several U.S. states have enacted statutes which impose criminal liability for "terroristic threatening" or "making a terroristic threat."

Generally, a terroristic threat "is sufficiently specific where it threatens death or great bodily injury, and a threat is not insufficient simply because it does not communicate a time or precise manner of execution. Thus, a criminal statute prohibiting terroristic threatening serves to criminalize future, as well as present, death threats."

The courts have held that "a threat need not take any particular form or be expressed in any particular words, and may be made by innuendo or suggestion, and that the words uttered will not be considered in a vacuum but rather in light of all the circumstances." A number of courts have upheld convictions under a state criminal terroristic threat statute on the basis of a single or solitary threat, a conditional threat, or a threat that some third person will take action. In several states, courts have held that a "threatener's present inability to carry out his or her threats does not in itself remove the threats from the purview of terroristic threat or terroristic threatening statutes." However, "the courts recognized that one does not violate a terroristic threat or terroristic threatening statute by making idle talk or jests which do not have a reasonable tendency to create apprehension that the speaker will act according to the threat." 

The threat need not be communicated in person, but may be made by any means; courts have in a number of cases held that a terroristic threat statute may be violated by a threat may by telephone, by letter by communication with a third party, or by "a nonverbal, symbolic threat which in other respects satisfies the criminal elements specified in the terroristic threat statute" (such as the burning of a cross on the target's driveway).

The required "mens rea" element of the offense is generally "that the accused have made the threat with the intent or purpose of causing fear in the victim or in reckless disregard of the risk of causing such fear." At least one court has specified that the "proof of a terroristic threat is measured by an objective standard."

"American Law Reports" indicates that "the cases are in disagreement over the availability of voluntary intoxication as a defense in a terroristic threat or terroristic threatening prosecution, with intoxication being a defense where a specific criminal intent is an essential element of the offense, but not a defense where the offense is established without specific criminal intent."

Terroristic-threat statutes have generally been upheld by the courts against constitutional challenges raising claims that such laws violate the Free Speech Clause, are impermissibly vague, or overlap with a criminal assault statute.

Under the Model Penal Code, "a person is guilty of a felony of the third degree if he threatens to commit any crime of violence with purpose to terrorize another or to cause evacuation of a building, place of assembly, or facility of public transportation, or otherwise to cause serious public inconvenience, or in reckless disregard of the risk of causing such terror or inconvenience."

"Under California law, the elements of the completed crime of making threats with intent to terrorize are: (1) willfully threatening to commit a crime that will result in death or great bodily injury to another person, (2) specific intent that the statement be taken as a threat, (3) the threat was on its face and under the circumstances so unequivocal, unconditional, immediate, and specific as to convey to the person threatened a gravity of purpose and an immediate prospect of execution of the threat, (4) the threat caused the victim to be in sustained fear for his or her own safety or for his or her immediate family's safety, and (5) the victim's fear was reasonable under the circumstances."

In Texas, terroristic threats are prohibited under Chapter 22 of the Texas Penal Code:

Sec. 22.07. TERRORISTIC THREAT. (a) A person commits an offense if he threatens to commit any offense involving violence to any person or property with intent to:

 makes it a class C felony, punishable by 10 years imprisonment, for someone to willfully threaten to commit a crime that will result in death or great bodily harm; the threat is made with the specific intent that it be taken as a threat; the threat is so unequivocal, unconditional, and specific as to convey a gravity of purpose and immediate prospect of execution; the threat actually causes fear in the victim; and the fear is reasonable.



</doc>
<doc id="42626" url="https://en.wikipedia.org/wiki?curid=42626" title="Serial killer">
Serial killer

A serial killer is typically a person who murders three or more people, usually in service of abnormal psychological gratification, with the murders taking place over more than a month and including a significant period of time between them. Different authorities apply different criteria when designating serial killers. While most set a threshold of three murders, others extend it to four or lessen it to two. The Federal Bureau of Investigation (FBI) defines serial killing as "a series of two or more murders, committed as separate events, usually, but not always, by one offender acting alone".

Although psychological gratification is the usual motive for serial killing, and most serial killings involve sexual contact with the victim, the FBI states that the motives of serial killers can include anger, thrill-seeking, financial gain, and attention seeking. The murders may be attempted or completed in a similar fashion. The victims may have something in common, for example, demographic profile, appearance, gender or race. A serial killer is neither a mass murderer, nor a spree killer, although there may be conceptual overlaps between serial killers and spree killers.

The English term and concept of "serial killer" are commonly attributed to former FBI Special agent Robert Ressler who used the term "serial homicide" in 1974 in a lecture at Bramshill Police Academy in Britain. Author Ann Rule postulates in her book, "Kiss Me, Kill Me" (2004), that the English-language credit for coining the term goes to LAPD detective Pierce Brooks, who created the Violent Criminal Apprehension Program (ViCAP) system in 1985.

There is ample evidence the term was used in Europe and the United States earlier. The German term and concept were coined by criminologist Ernst Gennat, who described Peter Kürten as a ' ('serial-murderer') in his article "" (1930). The earliest usage attested of the specific term "serial killer" listed in the "Oxford English Dictionary" was from a 1960s German film article written by Siegfried Kracauer, about the German expressionist film "M" (1931), portraying a pedophilic '.

In his book, "" (2004), criminal justice historian Peter Vronsky notes that while Ressler might have coined the English term "serial homicide" within law in 1974, the terms "serial murder" and "serial murderer" appear in John Brophy's book "The Meaning of Murder" (1966). The Washington DC newspaper "Evening Star", in a 1967 review of the book: This use of ""serial" killer" to paraphrase Brophy's "serial murderer" does not appear to have been influential at the time.

In his more recent study, Vronsky states that the term "serial killing" first entered into broader American popular usage when published in "The New York Times" in the spring of 1981, to describe Atlanta serial killer Wayne Williams. Subsequently, throughout the 1980s, the term was used again in the pages of "The New York Times", one of the major national news publication of the United States, on 233 occasions. By the end of the 1990s, the use of the term had escalated to 2,514 instances in the paper.

When defining serial killers, researchers generally use "three or more murders" as the baseline, considering it sufficient to provide a pattern without being overly restrictive. Independent of the number of murders, they need to have been committed at different times, and are usually committed in different places. The lack of a cooling-off period (a significant break between the murders) marks the difference between a spree killer and a serial killer. The category has, however, been found to be of no real value to law enforcement, because of definitional problems relating to the concept of a "cooling-off period". Cases of extended bouts of sequential killings over periods of weeks or months with no apparent "cooling off period" or "return to normality" have caused some experts to suggest a hybrid category of "spree-serial killer".

In 2005, the FBI hosted a multi-disciplinary symposium in San Antonio, Texas, which brought together 135 experts on serial murder from a variety of fields and specialties with the goal of identifying the commonalities of knowledge regarding serial murder. The group also settled on a definition of serial murder which FBI investigators widely accept as their standard: "The unlawful killing of two or more victims by the same offender(s) in separate events." The definition does not consider motivation for killing nor define a cooling-off period.

Historical criminologists have suggested that there may have been serial murders throughout history, but specific cases were not adequately recorded. Some sources suggest that legends such as werewolves and vampires were inspired by medieval serial killers. In Africa, there have been periodic outbreaks of murder by "Lion" and "Leopard men".

Liu Pengli of China, nephew of the Han Emperor Jing, was made Prince of Jidong in the sixth year of the middle period of Jing's reign (144 BC). According to the Chinese historian Sima Qian, he would "go out on marauding expeditions with 20 or 30 slaves or with young men who were in hiding from the law, murdering people and seizing their belongings for sheer sport". Although many of his subjects knew about these murders, it was not until the 29th year of his reign that the son of one of his victims finally sent a report to the Emperor. Eventually, it was discovered that he had murdered at least 100 people. The officials of the court requested that Liu Pengli be executed; however, the emperor could not bear to have his own nephew killed, so Liu Pengli was made a commoner and banished.

In the 15th century, one of the wealthiest men in Europe and a former companion-in-arms of Joan of Arc, Gilles de Rais, sexually assaulted and killed peasant children, mainly boys, whom he had abducted from the surrounding villages and had taken to his castle. It is estimated that his victims numbered between 140 and 800. The Hungarian aristocrat Elizabeth Báthory, born into one of the wealthiest families in Transylvania, allegedly tortured and killed as many as 650 girls and young women before her arrest in 1610.

Members of the Thuggee cult in India may have murdered a million people between 1740 and 1840. Thug Behram, a member of the cult, may have murdered as many as 931 victims.

In his 1886 book, "Psychopathia Sexualis", psychiatrist Richard von Krafft-Ebing noted a case of a serial murderer in the 1870s, a Frenchman named Eusebius Pieydagnelle who had a sexual obsession with blood and confessed to murdering six people.

The unidentified killer Jack the Ripper, who has been called the first modern serial killer, killed at least five women, and possibly more, in London in 1888. He was the subject of a massive manhunt and investigation by the Metropolitan Police, during which many modern criminal investigation techniques were pioneered. A large team of policemen conducted house-to-house inquiries, forensic material was collected and suspects were identified and traced. Police surgeon Thomas Bond assembled one of the earliest character profiles of the offender.

The Ripper murders also marked an important watershed in the treatment of crime by journalists. While not the first serial killer in history, Jack the Ripper's case was the first to create a worldwide media frenzy. The dramatic murders of financially destitute women in the midst of the wealth of London focused the media's attention on the plight of the urban poor and gained coverage worldwide. Jack the Ripper has also been called the most infamous serial killer of all time, and his legend has spawned hundreds of theories on his real identity and many works of fiction.

H. H. Holmes was one of the first documented modern serial killers in the United States, responsible for the death of at least nine victims in the early 1890s. Here as well, the case gained notoriety and wide publicity through possibly sensationalized accounts in William Randolph Hearst's newspapers. At the same time in France, Joseph Vacher became known as "The French Ripper" after killing and mutilating 11 women and children. He was executed in 1898 after confessing to his crimes.

76% of all known serial killers in the 20th century were from the United States.

Some commonly found characteristics of serial killers include the following:

There are exceptions to these criteria, however. For example, Harold Shipman was a successful professional (a General Practitioner working for the NHS). He was considered a pillar of the local community; he even won a professional award for a children's asthma clinic and was interviewed by Granada Television's "World in Action" on ITV. Dennis Nilsen was an ex-soldier turned civil servant and trade unionist who had no previous criminal record when arrested. Neither was known to have exhibited many of the tell-tale signs. Vlado Taneski, a crime reporter, was a career journalist who was caught after a series of articles he wrote gave clues that he had murdered people. Russell Williams was a successful and respected career Royal Canadian Air Force Colonel who was convicted of murdering two women, along with fetish burglaries and rapes.

Many serial killers have faced similar problems in their childhood development. Hickey's Trauma Control Model explains how early childhood trauma can set the child up for deviant behavior in adulthood; the child's environment (either their parents or society) is the dominant factor determining whether or not the child's behavior escalates into homicidal activity.

Family, or lack thereof, is the most prominent part of a child's development because it is what the child can identify with on a regular basis. "The serial killer is no different from any other individual who is instigated to seek approval from parents, sexual partners, or others." This need for approval is what influences children to attempt to develop social relationships with their family and peers. "The quality of their attachments to parents and other members of the family is critical to how these children relate to and value other members of society."

Wilson and Seaman (1990) conducted a study on incarcerated serial killers, and what they concluded was the most influential factor that contributed to their homicidal activity. Almost all of the serial killers in the study had experienced some sort of environmental problems during their childhood, such as a broken home caused by divorce, or a lack of a parental figure to discipline the child. Nearly half of the serial killers had experienced some type of physical or sexual abuse, and more of them had experienced emotional neglect. When a parent has a drug or alcohol problem, the attention in the household is on the parents rather than the child. This neglect of the child leads to the lowering of their self-esteem and helps develop a fantasy world in which they are in control. Hickey's Trauma Control Model supports how the neglect from parents can facilitate deviant behavior, especially if the child sees substance abuse in action. This then leads to disposition (the inability to attach), which can further lead to homicidal behavior, unless the child finds a way to develop substantial relationships and fight the label they receive. If a child receives no support from anyone, then he or she is unlikely to recover from the traumatic event in a positive way. As stated by E. E. Maccoby, "the family has continued to be seen as a major—perhaps "the" major—arena for socialization".

There have been recent studies looking into the possibility that an abnormality with one's chromosomes could be the trigger for serial killers. Two serial killers, Bobby Joe Long and Richard Speck, came to attention for reported chromosomal abnormalities. Long had an extra X chromosome. Speck was erroneously reported to have an extra Y chromosome; in fact, his karyotype was performed twice and was normal each time. Hellen Morrison, an American forensic psychiatrist, said in an interview that while researchers have not identified a specific causal gene, the fact that the majority of serial killers are male leads researchers to believe there is "a change associated with the male chromosome make up."

Children who do not have the power to control the mistreatment they suffer sometimes create a new reality to which they can escape. This new reality becomes their fantasy that they have total control of and becomes part of their daily existence. In this fantasy world, their emotional development is guided and maintained. According to Garrison (1996), "the child becomes sociopathic because the normal development of the concepts of right and wrong and empathy towards others is retarded because the child's emotional and social development occurs within his self-centered fantasies. A person can do no wrong in his own world and the pain of others is of no consequence when the purpose of the fantasy world is to satisfy the needs of one person" (Garrison, 1996). Boundaries between fantasy and reality are lost and fantasies turn to dominance, control, sexual conquest, and violence, eventually leading to murder. Fantasy can lead to the first step in the process of a dissociative state, which, in the words of Stephen Giannangelo, "allows the serial killer to leave the stream of consciousness for what is, to him, a better place".

Criminologist Jose Sanchez reports, "the young criminal you see today is more detached from his victim, more ready to hurt or kill ... The lack of empathy for their victims among young criminals is just one symptom of a problem that afflicts the whole society." Lorenzo Carcaterra, author of "Gangster" (2001), explains how potential criminals are labeled by society, which can then lead to their offspring also developing in the same way through the cycle of violence. The ability for serial killers to appreciate the mental life of others is severely compromised, presumably leading to their dehumanization of others. This process may be considered an expression of the intersubjectivity associated with a cognitive deficit regarding the capability to make sharp distinctions between other people and inanimate objects. For these individuals, objects can appear to possess animistic or humanistic power while people are perceived as objects. Before he was executed, serial killer Ted Bundy stated media violence and pornography had stimulated and increased his need to commit homicide, although this statement was made during last-ditch efforts to appeal his death sentence. However, correlation is not causation (a disturbed physiological disposition, psychosis, lack of socialization, or aggressiveness may contribute to both fantasy creation and serial killing without fantasy creation generally contributing to serial killing for instance). There are exceptions to the typical fantasy patterns of serial killers, as in the case of Dennis Rader, who was a loving family man and the leader of his church.

The FBI's "Crime Classification Manual" places serial killers into three categories: "organized", "disorganized", and "mixed" (i.e., offenders who exhibit organized and disorganized characteristics). Some killers descend from being organized into disorganized as their killings continue, as in the case of psychological decompensation or overconfidence due to having evaded capture, or vice versa, as when a previously disorganized killer identifies one or more specific aspects of the act of killing as his/her source of gratification and develops a "modus operandi" structured around those.

Organized serial killers often plan their crimes methodically, usually abducting victims, killing them in one place and disposing of them in another. They often lure the victims with ploys appealing to their sense of sympathy. Others specifically target prostitutes, who are likely to go voluntarily with a stranger. These killers maintain a high degree of control over the crime scene and usually have a solid knowledge of forensic science that enables them to cover their tracks, such as burying the body or weighing it down and sinking it in a river. They follow their crimes in the news media carefully and often take pride in their actions, as if it were all a grand project. Often, organized killers have social and other interpersonal skills sufficient to enable them to develop both personal and romantic relationships, friends and lovers and sometimes even attract and maintain a spouse and sustain a family including children. Among serial killers, those of this type are in the event of their capture most likely to be described by acquaintances as kind and unlikely to hurt anyone. Ted Bundy and John Wayne Gacy are examples of organized serial killers. In general, the IQs of organized serial killers tend to be near normal range, with a mean of 94.7. Organized nonsocial offenders tend to be on the higher end of the average, with a mean IQ of 99.2.

Disorganized serial killers are usually far more impulsive, often committing their murders with a random weapon available at the time, and usually do not attempt to hide the body. They are likely to be unemployed, a loner, or both, with very few friends. They often turn out to have a history of mental illness, and their modus operandi (M.O.) or lack thereof is often marked by excessive violence and sometimes necrophilia or sexual violence. Disorganized serial killers have been found to have a slightly lower mean IQ than organized serial killers, at 92.8.

Some people with a pathological interest in the power of life and death tend to be attracted to medical professions or acquiring such a job. These kinds of killers are sometimes referred to as "angels of death" or angels of mercy. Medical professionals will kill their patients for money, for a sense of sadistic pleasure, for a belief that they are "easing" the patient's pain, or simply "because they can". Perhaps the most prolific of these was the British doctor Harold Shipman. Another such killer was nurse Jane Toppan, who admitted during her murder trial that she was sexually aroused by death. She would administer a drug mixture to patients she chose as her victims, lie in bed with them and hold them close to her body as they died.

Another medical profession serial killer is Genene Jones. It is believed she killed 11 to 46 infants and children while working at Bexar County Medical Center Hospital in San Antonio, Texas. She is currently serving a 99-year sentence for the murder of Chelsea McClellan and the attempted murder of Rolando Santos, and became eligible for parole in 2017 due to a law in Texas at the time of her sentencing to reduce prison overcrowding.

A 21st-century example is Canadian nurse Elizabeth Wettlaufer who murdered elderly patients in the nursing homes where she worked.

Female serial killers are rare compared to their male counterparts. Sources suggest that female serial killers represented less than one in every six known serial murderers in the United States between 1800 and 2004 (64 females from a total of 416 known offenders), or that around 15% of U.S. serial killers have been women, with a collective number of victims between 427 and 612. The authors of "Lethal Ladies", Amanda L. Farrell, Robert D. Keppel, and Victoria B. Titterington, state that "the Justice Department indicated 36 female serial killers have been active over the course of the last century." According to "The Journal of Forensic Psychiatry & Psychology", there is evidence that 16% of all serial killers are women.

Kelleher and Kelleher (1998) created several categories to describe female serial killers. They used the classifications of "", "angel of death", "sexual predator", "revenge", "profit or crime", "team killer", "question of sanity", "unexplained", and "unsolved". In using these categories, they observed that most women fell into the categories of black widow or team killer. Although motivations for female serial killers can include attention seeking, addiction, or the result of psychopathological behavioral factors, female serial killers are commonly categorized as murdering men for material gain, usually being emotionally close to their victims, and generally needing to have a relationship with the victim, hence the traditional cultural image of the "black widow." In describing murderer Stacey Castor, forensic psychiatrist James Knoll offered a psychological perspective on what defines a "black widow" type. In simple terms, he described it as a woman who kills two or more husbands or lovers for material gain. Though Castor was not officially defined as a serial killer, it is likely that she would have killed again.

One "analysis of 86 female serial killers from the United States found that the victims tended to be spouses, children or the elderly". Other studies indicate that since 1975, increasingly strangers are marginally the most preferred victim of female serial killers, or that only 26% of female serial killers kill for material gain only. Sources state that each killer will have her own proclivities, needs and triggers." A review of the published literature on female serial murder stated that "sexual or sadistic motives are believed to be extremely rare in female serial murderers, and psychopathic traits and histories of childhood abuse have been consistently reported in these women." A study by Eric W. Hickey (2010) of 64 female serial killers in the United States indicated that sexual activity was one of several motives in 10% of the cases, enjoyment in 11% and control in 14%, and that 51% of all U.S. female serial killers murdered at least one woman and 31% murdered at least one child. In other cases, women have been involved as an accomplice with a male serial killer as a part of a serial killing team. A 2015 study published in "The Journal of Forensic Psychiatry & Psychology" found that the most common motive for female serial killers was for financial gain and almost 40% of them had experienced some sort of mental illness.

Peter Vronsky in "Female Serial Killers" (2007) maintains that female serial killers today often kill for the same reason males do: as a means of expressing rage and control. He suggests that sometimes the theft of the victims' property by the female "black widow" type serial killer appears to be for material gain, but really is akin to a male serial killer's collecting of totems (souvenirs) from the victim as a way of exerting continued control over the victim and reliving it. By contrast, Hickey states that although popular perception sees "black widow" female serial killers as something of the Victorian past, in his statistical study of female serial killer cases reported in the United States since 1826, approximately 75% occurred since 1950.

The methods that female serial killers use for murder are frequently covert or low-profile, such as murder by poison (the preferred choice for killing). Other methods used by female serial killers include shootings (used by 20%), suffocation (16%), stabbing (11%), and drowning (5%). They commit killings in specific places, such as their home or a health-care facility, or at different locations within the same city or state. A notable exception to the typical characteristics of female serial killers is Aileen Wuornos, who killed outdoors instead of at home, used a gun instead of poison, killed strangers instead of friends or family, and killed for personal gratification. The most prolific female serial killer in all of history is allegedly Elizabeth Báthory. Countess Elizabeth Báthory de Ecsed (Báthory Erzsébet in Hungarian, August 7, 1560 – August 21, 1614) was a countess from the renowned Báthory family. Before her husband's death, Elizabeth took great pleasure in torturing the staff, by jamming pins under the servants fingernails or stripping servants and throwing them into the snow. After her husband's death, she and four collaborators were accused of torturing and killing hundreds of girls and young women, with one witness attributing to them over 600 victims, though the number for which they were convicted was 80. Elizabeth herself was neither tried nor convicted. In 1610, however, she was imprisoned in the Csejte Castle, where she remained bricked in a set of rooms until her death four years later.

A 2010 article by Perri and Lichtenwald addressed some of the misperceptions concerning female criminality. In the article, Perri and Lichtenwald analyze the current research regarding female psychopathy, including case studies of female psychopathic killers featuring Münchausen syndrome by proxy, cesarean section homicide, fraud detection homicide, female kill teams, and a female serial killer.

Juvenile serial killers are rare. There are three main categories that juvenile serial killers can fit into: primary, maturing, and secondary killers. There have been studies done to compare and contrast these three groups and to discover similarities and differences between them. Although these types of serial killers are less common, oftentimes adult serial killers may make their debut at an early age and it can be an opportunity for researchers to study what factors brought about the behavior. Though it is rare, the youngest felon on death row is in fact, a juvenile serial killer named Harvey Miguel Robinson.

The racial demographics regarding serial killers are often subject to debate. In the United States, the majority of reported and investigated serial killers are white males, from a lower-to-middle-class background, usually in their late 20s to early 30s. However, there are African American, Asian, and Hispanic (of any race) serial killers as well, and, according to the FBI, based on percentages of the U.S. population, whites are not more likely than other races to be serial killers. Criminal profiler Pat Brown says serial killers are usually reported as white because serial killers usually target victims of their own race, and argues the media typically focuses on "All-American" white and pretty female victims who were the targets of white male offenders; that crimes among minority offenders in urban communities, where crime rates are higher, are under-investigated; and that minority serial killers likely exist at the same ratios as white serial killers for the population. She believes that the myth that serial killers are always white might have become "truth" in some research fields due to the over-reporting of white serial killers in the media.

According to some sources, the percentage of serial killers who are African American is estimated to be between 13% and 22%. Another study has shown that 16% of serial killers are African American, what author Maurice Godwin describes as a "sizeable portion". A 2014 Radford/FGCU Serial Killer Database annual statistics report indicated that for the decades 1900–2010, the percentage of white serial killers was 52.1% while the percentage of African American serial killers was 40.3%. In a 2005 article Anthony Walsh, professor of criminal justice at Boise State University, argued a review of post-WWII serial killings in America finds that the prevalence of minority serial killers has typically been drastically underestimated in both professional research literature and the mass media. As a paradigmatic case of this media double standard, Walsh cites news reporting on white killer Gary Heidnik and African-American killer Harrison Graham. Both men were residents of Philadelphia, Pennsylvania; both imprisoned, tortured, and killed several women; and both were arrested only months apart in 1987. "Heidnik received widespread national attention, became the subject of books and television shows, and served as a model for the fictitious Buffalo Bill in "Silence of the Lambs"", writes Walsh, while "Graham received virtually no media attention outside of Philadelphia, Pennsylvania, despite having been convicted of four more murders than Heidnik".

The motives of serial killers are generally placed into four categories: "visionary", "mission-oriented", "hedonistic", and "power or control"; however, the motives of any given killer may display considerable overlap among these categories.

Visionary serial killers suffer from psychotic breaks with reality, sometimes believing they are another person or are compelled to murder by entities such as the Devil or God. The two most common subgroups are "demon mandated" and "God mandated".

Herbert Mullin believed the American casualties in the Vietnam War were preventing California from experiencing the Big One. As the war wound down, Mullin claimed his father instructed him via telepathy to raise the number of "human sacrifices to nature" in order to delay a catastrophic earthquake that would plunge California into the ocean. David Berkowitz ("Son of Sam") may also be an example of a visionary serial killer, having claimed a demon transmitted orders through his neighbor's dog and instructed him to commit murder. Berkowitz later described those claims as a hoax, as originally concluded by psychiatrist David Abrahamsen.

Mission-oriented killers typically justify their acts as "ridding the world" of certain types of people perceived as undesirable, such as the homeless, ex-cons, homosexuals, drug users, prostitutes, or people of different ethnicity or religion; however, they are generally not psychotic. Some see themselves as attempting to change society, often to cure a societal ill.

This type of serial killer seeks thrills and derives pleasure from killing, seeing people as expendable means to this goal. Forensic psychologists have identified three subtypes of the hedonistic killer: "lust", "thrill", and "comfort".

Sex is the primary motive of lust killers, whether or not the victims are dead, and fantasy plays a large role in their killings. Their sexual gratification depends on the amount of torture and mutilation they perform on their victims. The sexual serial murderer has a psychological need to have absolute control, dominance, and power over their victims, and the infliction of torture, pain, and ultimately death is used in an attempt to fulfill their need. They usually use weapons that require close contact with the victims, such as knives or hands. As lust killers continue with their murders, the time between killings decreases or the required level of stimulation increases, sometimes both.

Kenneth Bianchi, one of the "Hillside Stranglers", murdered women and girls of different ages, races and appearance because his sexual urges required different types of stimulation and increasing intensity. Jeffrey Dahmer searched for his perfect fantasy lover—beautiful, submissive and eternal. As his desire increased, he experimented with drugs, alcohol, and exotic sex. His increasing need for stimulation was demonstrated by the dismemberment of victims, whose heads and genitals he preserved, and by his attempts to create a "living zombie" under his control (by pouring acid into a hole drilled into the victim's skull). Dahmer once said, "Lust played a big part of it. Control and lust. Once it happened the first time, it just seemed like it had control of my life from there on in. The killing was just a means to an end. That was the least satisfactory part. I didn't enjoy doing that. That's why I tried to create living zombies with … acid and the drill." He further elaborated on this, also saying, "I wanted to see if it was possible to make—again, it sounds really gross—uh, zombies, people that would not have a will of their own, but would follow my instructions without resistance. So after that, I started using the drilling technique." He experimented with cannibalism to "ensure his victims would always be a part of him".

The primary motive of a thrill killer is to induce pain or terror in their victims, which provides stimulation and excitement for the killer. They seek the adrenaline rush provided by hunting and killing victims. Thrill killers murder only for the kill; usually the attack is not prolonged, and there is no sexual aspect. Usually the victims are strangers, although the killer may have followed them for a period of time. Thrill killers can abstain from killing for long periods of time and become more successful at killing as they refine their murder methods. Many attempt to commit the perfect crime and believe they will not be caught. Robert Hansen took his victims to a secluded area, where he would let them loose and then hunt and kill them. In one of his letters to San Francisco Bay Area newspapers in San Francisco, California, the Zodiac Killer wrote "[killing] gives me the most thrilling experience it is even better than getting your rocks off with a girl". Coral Watts was described by a surviving victim as "excited and hyper and clappin' and just making noises like he was excited, that this was gonna be fun" during the 1982 attack. Slashing, stabbing, hanging, drowning, asphyxiating, and strangling were among the ways Watts killed.

Material gain and a comfortable lifestyle are the primary motives of comfort killers. Usually, the victims are family members and close acquaintances. After a murder, a comfort killer will usually wait for a period of time before killing again to allow any suspicions by family or authorities to subside. They often use poison, most notably arsenic, to kill their victims. Female serial killers are often comfort killers, although not all comfort killers are female. Dorothea Puente killed her tenants for their Social Security checks and buried them in the backyard of her home. H. H. Holmes killed for insurance and business profits. Professional killers ("hitmen") may also be considered comfort serial killers. Richard Kuklinski charged tens of thousands of dollars for a "hit", earning enough money to support his family in a middle-class lifestyle (Bruno, 1993).

Some, like Puente and Holmes, may be involved in or have previous convictions for theft, fraud, non-payment of debts, embezzlement and other crimes of a similar nature. Dorothea Puente was finally arrested on a parole violation, having been on parole for a previous fraud conviction.

In 2016, the oldest prosecution and conviction of a suspected serial killer (Felix Vail) took place in Louisiana. He was convicted of murder 54 years after his wife's death in 1962, which had originally been ruled an accidental drowning, and which occurred only months after Vail took out two life insurance policies on her. He is a suspect in the disappearances of two other women – his girlfriend in 1973 and his second wife in 1984. The prosecutors were allowed to present evidence of the two disappearances under the Doctrine of chances.

The main objective for this type of serial killer is to gain and exert power over their victim. Such killers are sometimes abused as children, leaving them with feelings of powerlessness and inadequacy as adults. Many power- or control-motivated killers sexually abuse their victims, but they differ from hedonistic killers in that rape is not motivated by lust (as it would be with a lust murder) but as simply another form of dominating the victim. Ted Bundy is an example of a power/control-oriented serial killer. He traveled around the United States seeking women to control.

Many serial killers claim that a violent culture influenced them to commit murders. During his final interview, Ted Bundy stated that hardcore pornography was responsible for his actions. Others idolise figures for their deeds or perceived vigilante justice, such as Peter Kürten, who idolized Jack the Ripper, or John Wayne Gacy and Ed Kemper, who both idolized the actor John Wayne.

Killers who have a strong desire for fame or to be renowned for their actions desire media attention as a way of validating and spreading their crimes; fear is also a component here, as some serial killers enjoy causing fear. An example is Dennis Rader, who sought attention from the press during his murder spree.

Many movies, books, and documentaries have been created, detailing serial killers' lives and crimes. For example, the biographical movie "Bundy" (2002) focuses on serial killer Ted Bundy's personal life in college, leading up to his execution, and "Dahmer" (2002) tells the story of Jeffrey Dahmer.

Serial killers are also portrayed in fictional media, oftentimes as having substantial intelligence and looking for difficult targets, despite the contradiction with the psychological profile of serial killers.

Theories for why certain people commit serial murder have been advanced. Some theorists believe the reasons are biological, suggesting serial killers are born, not made, and that their violent behavior is a result of abnormal brain activity. Holmes and Holmes believe that "until a reliable sample can be obtained and tested, there is no scientific statement that can be made concerning the exact role of biology as a determining factor of a serial killer personality." The "Fractured Identity Syndrome" (FIS) is a merging of Charles Cooley's "looking glass self" and Erving Goffman's "virtual" and "actual social identity" theories. The FIS suggests a social event, or series of events, during one's childhood or adolescence results in a fracturing of the personality of the serial killer. The term "fracture" is defined as a small breakage of the personality which is often not visible to the outside world and is only felt by the killer.

"Social Process Theory" has also been suggested as an explanation for serial murder. Social process theory states that offenders may turn to crime due to peer pressure, family, and friends. Criminal behavior is a process of interaction with social institutions, in which everyone has the potential for criminal behavior. A lack of family structure and identity could also be a cause leading to serial murder traits. A child used as a scapegoat will be deprived of their capacity to feel guilt. Displaced anger could result in animal torture, as identified in the Macdonald triad, and a further lack of basic identity.

The "military theory" has been proposed as an explanation for why serial murderers kill, as some serial murderers have served in the military or related fields. According to Castle and Hensley, 7% of the serial killers studied had military experience. This figure may be a proportional under-representation when compared to the number of military veterans in a nation's total population. For example, according to the United States census for the year 2000, military veterans comprised 12.7% of the U.S. population; in England, it was estimated in 2007 that military veterans comprised 9.1% of the population. Though by contrast, about 2.5% of the population of Canada in 2006 consisted of military veterans.

There are two theories that can be used to study the correlation between serial killing and military training: "Applied learning theory" states that serial killing can be learned. The military is training for higher kill rates from servicemen while training the soldiers to be desensitized to taking a human life. "Social learning theory" can be used when soldiers get praised and accommodated for killing. They learn, or believe that they learn, that it is acceptable to kill because they were praised for it in the military. Serial killers want accreditation for the work that they have done.

In both military and serial killing, the offender or the soldier may become desensitized to killing as well as compartmentalized; the soldiers do not see enemy personnel as "human" and neither do serial killers see their victims as humans. The theories do not imply that military institutions make a deliberate effort to produce serial killers; to the contrary, all military personnel are trained to recognize when, where, and against whom it is appropriate to use deadly force, which starts with the basic "Law of Land Warfare", taught during the initial training phase, and may include more stringent policies for military personnel in law enforcement or security. They are also taught ethics in basic training.

In 2008, the Federal Bureau of Investigation (FBI) published a handbook titled "Serial Murder" which was the product of a symposium held in 2005 to bring together the many issues surrounding serial murder, including its investigation.

According to the FBI, identifying one, or multiple, murders as being the work of a serial killer is the first challenge an investigation faces, especially if the victim(s) come from a marginalized or high risk population and is normally linked through forensic or behavioral evidence (FBI 2008). Should the cases cross multiple jurisdictions, the law enforcement system in the United States is fragmented and thus not configured to detect multiple similar murders across a large geographic area (Egger 1998). The FBI suggests utilizing databases and increasing interdepartmental communication. Keppel (1989) suggests holding multi-jurisdictional conferences regularly to compare cases giving departments a greater chance to detect linked cases and overcome linkage blindness. One such collaboration, the "Radford/FGCU Serial Killer Database Project" was proposed at the 2012 FDIAI Annual Conference. Utilizing Radford's Serial Killer Database as a starting point, the new collaboration, hosted by FGCU Justice Studies, has invited and is working in conjunction with other Universities to maintain and expand the scope of the database to also include spree and mass murders. Utilizing over 170 data points, multiple-murderer methodology and victimology; researchers and Law Enforcement Agencies can build case studies and statistical profiles to further research the "Who, What, Why and How" of these types of crimes.

Leadership, or administration, should play a small or virtually non-existent role in the actual investigation past assigning knowledgeable or experienced homicide investigators to lead positions. The administration's role is not to run the investigation but to establish and reaffirm the primary goal of catching the serial killer, as well as provide support for the investigators. The FBI (2008) suggests completing Memorandums of Understanding to facilitate support and commitment of resources from different jurisdictions to an investigation. Egger (1998) takes this one step further and suggests completing mutual aid pacts, which are written agreements to provide support to each other in a time of need, with surrounding jurisdictions. Doing this in advance would save time and resources that could be used on the investigation.

Organization of the structure of an investigation is key to its success, as demonstrated by the investigation of Gary Ridgway, the Green River Killer. Once a serial murder case was established, a task force was created to track down and arrest the offender. Over the course of the investigation, for various reasons, the task force's organization was radically changed and reorganized multiple times – at one point including more than 50 full-time personnel, and at another, only a single investigator. Eventually, what led to the end of the investigation was a conference of 25 detectives organized to share ideas to solve the case.

The FBI handbook provides a description of how a task force should be organized but offers no additional options on how to structure the investigation. While it appears advantageous to have a full-time staff assigned to a serial murder investigation, it can become prohibitively expensive. For example, the Green River Task Force cost upwards of $2 million per year, and as was witnessed with the Green River Killer investigation, other strategies can prevail where a task force fails.
A common strategy, already employed by many departments for other reasons, is the conference, in which departments get together and focus on a specific set of topics. With serial murders, the focus is typically on unsolved cases, with evidence thought to be related to the case at hand.

Similar to a conference is an information clearing-house in which a jurisdiction with a suspected serial murder case collects all of its evidence and actively seeks data which may be related from other jurisdictions. By collecting all of the related information into one place, they provide a central point in which it can be organized and easily accessed by other jurisdictions working toward the goal of arresting an offender and ending the murders.

Already mentioned was the task force, FBI 2008, Keppel 1989 which provides for a flexible, organized, framework for jurisdictions depending on the needs of the investigation. Unfortunately due to the need to commit resources (manpower, money, equipment, etc.) for long periods of time it can be an unsustainable option.

In the case of the investigation of Aileen Wournos, the Marion County Sheriff coordinated multiple agencies without any written or formal agreement. While not a specific strategy for a serial murder investigation, this is certainly a best practice in so far as the agencies were able to work easily together toward a common goal.

Finally, once a serial murder investigation has been identified, utilization of an FBI Rapid Response Team can assist both experienced and inexperienced jurisdictions in setting up a task force. This is completed by organizing and delegating jobs, by compiling and analyzing clues, and by establishing communication between the parties involved.

During the course of a serial murder investigation it may become necessary to call in additional resources; the FBI defines this as Resource Augmentation. Within the structure of a task force the addition of a resource should be thought of as either long term, or short term. If the task force's framework is expanded to include the new resource, then it should be permanent and not removed. For short term needs, such as setting up road blocks or canvassing a neighborhood, additional resources should be called in on a short term basis. The decision of whether resources are needed short or long term should be left to the lead investigator and facilitated by the administration (FBI 2008). The confusion and counter productiveness created by changing the structure of a task force mid investigation is illustrated by the way the Green River Task Force's staffing and structure was changed multiple times throughout the investigation. This made an already complicated situation more difficult, resulting in the delay or loss of information, which allowed Ridgeway to continue killing (Guillen 2007). The FBI model does not take into account that permanently expanding a task force, or investigative structure, may not be possible due to cost or personnel availability. Egger (1998) offers several alternative strategies including; using investigative consultants, or experienced staff to augment an investigative team. Not all departments have investigators experienced in serial murder and by temporarily bringing in consultants, they can educate a department to a level of competence then step out. This would reduce the initially established framework of the investigation team and save the department the cost of retaining the consultants until the conclusion of the investigation.

The FBI handbook (2008) and Keppel (1989) both stress communication as paramount. The difference is that the FBI handbook (2008) concentrates primarily on communication within a task force while Keppel (1989) makes getting information out to, and allowing information to be passed back from patrol officers a priority. The FBI handbook (2008) suggest having daily e-mail or in person briefings for all staff involved in the investigation and providing periodic summary briefings to patrol officer and managers. Looking back on a majority of serial murderer arrests, most are exercised by patrol officers in the course of their every day duties and unrelated to the ongoing serial murder investigation (Egger 1998, Keppel 1989). Keppel (1989) provides examples of Larry Eyler, who was arrested during a traffic stop for a parking violation, and Ted Bundy, who was arrested during a traffic stop for operating a stolen vehicle. In each case it was uniformed officers, not directly involved in the investigation, who knew what to look for and took the direct action that stopped the killer. By providing up to date (as opposed to periodic) briefings and information to officers on the street the chances of catching a serial killer, or finding solid leads, are increased.

A serial murder investigation generates staggering amounts of data, all of which needs to be reviewed and analyzed. A standardized method of documenting and distributing information must be established and investigators must be allowed time to complete reports while investigating leads and at the end of a shift (FBI 2008). When the mechanism for data management is insufficient, leads are not only lost or buried but the investigation can be hindered and new information can become difficult to obtain or become corrupted. During the Green River Killer investigation, reporters would often find and interview possible victims or witnesses ahead of investigators. The understaffed investigation was unable to keep up the information flow, which prevented them from promptly responding to leads. To make matters worse, investigators believed that the journalists, untrained in interviewing victims or witnesses of crimes, would corrupt the information and result in unreliable leads (Guillen 2007).

Notorious and infamous serial killers number in the hundreds, and a subculture revolves around their legacies. That subculture includes the collection, sale, and display of serial killer memorabilia, dubbed "murderabilia" by one of the best-known opponents of collectors of serial killer remnants, Andrew Kahan. He is the director of the Mayor's Crime Victims Office in Houston and is backed by the families of murder victims and "Son of Sam laws" existing in some states that prevent murderers from profiting from the publicity generated by their crimes.

Such memorabilia includes the paintings, writings, and poems of these killers. Recently, marketing has capitalized even more upon interest in serial killers with the rise of various merchandise such as trading cards, action figures, and books such as "The Serial Killer Files: The Who, What, Where, How, and Why of the World's Most Terrifying Murderers" by Harold Schechter, and "The A-Z Encyclopedia of Serial Killers" by Schecter and David Everitt. Some serial killers attain celebrity status in the way they acquire fans, and may have previous personal possessions auctioned off on websites like eBay. A few examples of this are Ed Gein's 150-pound stolen gravestone and Bobby Joe Long's sunglasses.






</doc>
<doc id="28685" url="https://en.wikipedia.org/wiki?curid=28685" title="Squatting">
Squatting

Squatting is the action of occupying an abandoned or unoccupied area of land or a building, usually residential, that the squatter does not own, rent or otherwise have lawful permission to use.

Author Robert Neuwirth suggested in 2004 that there were one billion squatters globally. Yet, according to Kesia Reeve, "squatting is largely absent from policy and academic debate and is rarely conceptualised, as a problem, as a symptom, or as a social or housing movement."

Squatting can be related to political movements, such as anarchist, autonomist, or socialist. It can be a means to conserve buildings or simply to provide affordable housing.

In many of the world's poorer countries, there are extensive slums or shanty towns, typically built on the edges of major cities and consisting almost entirely of self-constructed housing built without the landowner's permission. While these settlements may, in time, grow to become both legalised and indistinguishable from normal residential neighbourhoods, they start off as squats with minimal basic infrastructure. Thus, there is no sewerage system, drinking water must be bought from vendors or carried from a nearby tap, and if there is electricity, it is stolen from a passing cable.

During the Great Recession and increased housing foreclosures in the late 2000s, squatting became far more prevalent in Western, developed nations.

Besides being residences, some squats are used as social centres or host give-away shops, pirate radio stations or cafés. In Spanish-speaking countries, squatters receive several names, such as "okupas" in Spain, Chile or Argentina (from the verb "ocupar" meaning "to occupy"), or "paracaidistas" in Mexico (meaning "parachuters", because they "parachute" themselves at unoccupied land).

Dutch sociologist Hans Pruijt separates types of squatters into five distinct categories:


In many countries, squatting is in itself a crime; in others, it is only seen as a civil conflict between the owner and the occupants. Property law and the state have traditionally favored the property owner. However, in many cases where squatters had "de facto" ownership, laws have been changed to legitimize their status. Squatters often claim rights over the spaces they have squatted by virtue of occupation, rather than ownership; in this sense, squatting is similar to (and potentially a necessary condition of) adverse possession, by which a possessor of real property without title may eventually gain legal title to the real property.

Anarchist Colin Ward comments: "Squatting is the oldest mode of tenure in the world, and we are all descended from squatters. This is as true of the Queen [of the United Kingdom] with her as it is of the 54 percent of householders in Britain who are owner-occupiers. They are all the ultimate recipients of stolen land, for to regard our planet as a commodity offends every conceivable principle of natural rights."

Others have a different view. UK police official Sue Williams, for example, has stated that "Squatting is linked to Anti-Social Behaviour and can cause a great deal of nuisance and distress to local residents. In some cases there may also be criminal activities involved."

The public attitude toward squatting varies, depending on legal aspects, socioeconomic conditions, and the type of housing occupied by squatters. In particular, while squatting of municipal buildings may be treated leniently, squatting of private property often leads to strong negative reaction on the part of the public and authorities. Squatting, when done in a positive and progressive manner, can be viewed as a way to reduce crime and vandalism to vacant properties, depending on the squatter's ability and willingness to conform to certain socioeconomic norms of the community in which they reside. Moreover, squatters can contribute to the maintenance or upgrading of sites that would otherwise be left unattended, the neglect of which would create (and has created) abandoned, dilapidated and decaying neighborhoods within certain sections of moderately to highly urbanized cities or boroughs, one such example being New York City's Lower Manhattan from roughly the 1970s to the post-9/11 era of the New Millennium.

Adverse possession is a method of acquiring title to property through possession for a statutory period under certain conditions. Countries where this principle exists include England and the United States, based on common law. However, some non-common law jurisdictions have laws similar to adverse possession. For example, Louisiana has a legal doctrine called acquisitive prescription, which is derived from French law.

The Zabbaleen settlement and the City of the Dead are both well-known squatter communities in Cairo, Egypt.

There are large squatter communities in Kenya, such as Kibera in Nairobi.

An estimated 1,000 people live in the Grande Hotel Beira in Mozambique.

Informal settlements in Zambia, particularly around Lusaka, are known as kombonis.

In South Africa, squatters tend to live in informal settlements or squatter camps on the outskirts of the larger cities, often but not always near townships. In the mid-1990s, an estimated 7.7 million South Africans lived in informal settlements: a fifth of the country's population. The number has grown rapidly in the post-apartheid era. Many buildings, particularly in the inner city of Johannesburg have also been occupied by squatters. Property owners or government authorities can usually evict squatters after following certain legal procedures including requesting a court order. 

In Durban, the city council routinely evicts without a court order in defiance of the law, and there has been sustained conflict between the city council and a shack dwellers' movement known as Abahlali baseMjondolo. The organisation has represetend the squatters in land occuations such as the Macassar Village in 2009 and Marikana in 2013. It has also fought against the KZN Slums Act.

There have been a number of similar conflicts between shack dwellers, some linked with the Western Cape Anti-Eviction Campaign, and the city council in Cape Town. One of the most high-profile cases was the eviction of squatters in the N2 Gateway homes in the suburb of Delft, where over 20 residents were shot, including a three-year-old child. There have been numerous complaints about the legality of the government's actions. Many of the families then squatted on Symphony Way, a main road in the township of Delft,before being forced to move to a camp called Blikkiesdorp.

In China, informal settlements are known as urban villages.

Israeli settlements are communities of Israeli citizens living in the Palestinian territories. The international community considers the settlements in occupied territory to be illegal,
In March 2018, Israeli settlers were evicted from a house they had illegally occupied in Hebron, a Palestinian city in the West Bank. The fifteen families had argued that they had bought the house, but the High Court of Justice ruled that they had to leave. The Israel Defense Forces declared the building a closed military zone and it was unclear if the Palestinian owners could regain possession. The settlers had already occupied the house and been evicted in 2012. In October 2018, Fatou Bensouda, the Chief Prosecutor of the International Criminal Court stated that Israel's planned demolition of Bedouin village Khan al-Ahmar could constitute a war crime.

Squatters in Malaysia live on both privately owned and government-owned land. Some squatters have lived on land owned by national electricity company Tenaga Nasional for over five decades.

In Thailand, although evictions have reduced their visibility or numbers in urban areas, many squatters still occupy land near railroad tracks, under overpasses, and waterways. Commercial squatting is common in Thailand, where businesses temporarily seize nearby public real estate (such as sidewalks, roadsides, beaches, etc) and roll out their enterprise, and at closing time they fold it in and lock it up, thus avoiding the extra cost of having to rent more property.

In Mumbai, there are an estimated 10 to 12 million inhabitants, and six million of them are squatters. The squatters live in a variety of ways. Some possess two- or three-story homes built out of brick and concrete which they have inhabited for years. Geeta Nagar is a squatter village based beside the Indian Navy compound at Colaba. Squatter Colony in Malad East has existed since 1962, and now, people living there pay a rent to the city council of 100 rupees a month. Dharavi is a community of one million squatters. The stores and factories situated there are mainly illegal and so are unregulated, but it is suggested that they do over $1 million in business every day.

Other squatters are pavement dwellers, with very few possessions.

Activists such as Jockin Arputham, Prema Gopalan and Sheela Patel are working for better living conditions for slum dwellers, through organisations such as Mahila Milan and Slum Dwellers International.

Squatting is a major issue in the Philippines especially but not exclusively in urban areas of the Philippines. Squatting gained notice right after World War II, when people whose homes were destroyed by war were left homeless. They built makeshift houses called "barong-barong" on abandoned private land.

In the late 20th century, the squatter population largely grew but the Philippine government has made separate attempts over the years to transfer some squatters to low-cost housing projects, such as projects in Tondo (in the former Smokey Mountain landfill), Taguig (BLISS Housing Project), and Rodriguez, Rizal.

Philippine law, and society more generally, distinguishes between squatters who squat because of poverty and "professional squatters" who squat in hopes of getting a payment to leave the property.

Philippine-based media and journalists refer squatters as "informal settlers."

Gecekondu (plural gecekondular) is a Turkish word meaning a house put up quickly without proper permissions, a squatter's house, and by extension, a shanty or shack. Gecekondu bölgesi is a neighborhood made of these informal settlements.

Shortly after the eviction of Gezi Park, Don Kişot (Quixote) was occupied and stated to be Istanbul's first occupied and self-managed social centre.

There are, or have been, several other political squats in İstanbul: Caferağa in Kadıköy was a squatted neighbourhood house evicted in December 2014. "Caferağa brings life, people, and productivity into that old rotting house" said local Turan Yildirim.

In Beşiktaş, a place was occupied on March 18, 2014 and named Berkin Elvan Student House after a 15-year-old boy who was shot during the Gezi protests and later died.

Atopya was squatted in Ankara in June 2014 by anarchists, who claimed it was the city's first political squat.

In many European countries, there are squatted houses used as residences and also larger squatted projects where people pursue social and cultural activities. An examples of the latter is a former military barracks called Metelkova in Slovenia.

Squat Milada in Prague, Czech Republic was occupied in 1997 and evicted in 2009. Its longevity was in part due to the building not existing in the Land Registry. Klinika was an occupied social centre between 2014 and 2019.

There was a big squatting movement in the newly formed state of Austria following the First World War. Famine was a significant problem for many people in Austria and the "Siedler" (settler) movement developed as these people tried to create shelter and a source of food for themselves. The Ernst Kirchweger Haus (EKH) in Vienna was squatted as a social centre in 1990 and legalised in 2008. Nowadays from time to time empty buildings are squatted and in the most instances given up after negotiations with the authorities. There are some exceptions like in 2014, when about 1,500 riot police officers, a tank-like police vehicle, a police water cannon and helicopters have been used to clear a building occupied by the group "Pizzeria Anarchia" in Vienna.

Christiania in Copenhagen, Denmark is an independent community of almost 900 people founded in 1971 on the site of an abandoned military zone. In Copenhagen, as in other European cities such as Berlin and Amsterdam, the squatter movement was large in the 1980s. It was a social movement, providing housing and alternative culture. A flashpoint came in 1986 with the Battle of Ryesgade. Another flashpoint came in 2007 when Ungdomshuset was evicted. While not technically a squat until 14 December 2006, it was a social centre used by squatters and people involved in alternative culture more generally. After a year of protests, the city council donated a new building.

In early twentieth century France, several artists who would later become world famous, such as Guillaume Apollinaire, Amedeo Modigliani and Pablo Picasso squatted at the Bateau-Lavoir, in Montmartre, Paris. Paris moved to legitimize some popular artist squats in the mid-2000s by purchasing and renovating the buildings for artist–residents. An example is Les Frigos. In the 2010s there have been several land squats protesting against large infrastructure projects. These are known collectively as Zone to Defend or ZAD (French: zone à défendre), with the most famous one being the ZAD de Notre-Dame-des-Landes.

Starting from December 2012, Greek Police initiated extensive raids in a number of squats in Athens, arresting and charging with offences all illegal occupants (mostly anarchists). Squats including Villa Amalia were evicted. A march in support of the 92 arrestees drew between 3,000 and 8,000 people. After Villa Amalia, Villa Skaramanga and then Villa Lela Karagianni were evicted. Lela Karagianni had been squatted since 1998 and was later reoccupied. The name came from the street, named for a Greek World War II resistance leader of that name. From 2015 onwards Athens has seen refugee squats in response to the European migrant crisis which are anarchist and self-organised. In 2019, several squats in Exarcheia were evicted by the Greek state. Some of the migrants evicted set up a camp outside the Parliament at Syntagma Square.

Squatting in Moldova started with Centro 73 in Chişinău in September 2010. This project was evicted soon after.
The oldest squat in Poland, Rozbrat, was created in 1994 in Poznań. There are also squats in Białystok, Gdańsk, Gliwice, Warsaw and Wrocław.

Geneva in Switzerland had 160 buildings illegally occupied and more than 2,000 squatters, in the middle of the 1990s. The RHINO ("Retour des Habitants dans les Immeubles Non-Occupés," in English: "Return of Inhabitants to Non-Occupied Buildings") was a 19-year-long squat in Geneva. It occupied two buildings on the Boulevard des Philosophes, a few blocks away from the main campus of the University of Geneva. The RHINO organisation often faced legal troubles, and Geneva police evicted the inhabitants on July 23, 2007. There were large riots in Zürich when the Binz occupation was evicted in 2013. The squatters moved to another building. 

In the 1970s, squatting in West German cities led to "a self-confident urban counterculture with its own infrastructure of newspapers, self-managed collectives and housing cooperatives, feminist groups, and so on, which was prepared to intervene in local and broader politics". The Autonomen movement protected squats against eviction and participated in radical direct action.

After the German reunification, many buildings were vacated due to the demise of former state-run enterprises and migration to the western parts of Germany, some of which were then occupied by squatters. In Berlin, the now-legalised squats are in desirable areas such as Mitte and Prenzlauer Berg. Before the reunification, squats in Berlin were mostly located in former West Berlin's borough of Kreuzberg. The squats were mainly for residential and social use. Squatting became known by the term "instandbesetzen", from "instandsetzen" ("renovating") and "besetzen" ("occupying").

Squatters moved into the former factory site of J.A. Topf & Söhne in Erfurt in April 2001 and remained there until they were evicted by police in April 2009. The firm made crematoria for Nazi concentration camps. The squatters ran culture programs which drew attention to the history of the company. The occupation was known simply as "Das Besetzte Haus" (the occupied house) and was one of the most well known actions of left-radicals of that period in Germany. A book about the occupation was published in 2012, titled "Topf & Söhne - Besetzung auf einem Täterort" (Topf & Söhne - Occupation of a crime scene).

Despite being illegal, squats exist in many of the larger cities. Examples are Au in Frankfurt and Rote Flora in Hamburg, although the last open squat of Berlin, Brunnenstraße183, was evicted in November 2009. Legalised housing project include Hafenstraße and Kiefernstraße.

Squatting can also take place for campaigning purposes, such as the Anatopia project, which protested against a Mercedes-Benz test track.

In Reykjavík, the capital of Iceland, there is a small tradition of squatting. In 1919, anarchists occupied a building and were quickly evicted.

Squatters occupied an empty house in downtown Reykjavík on Vatnsstigur street in April 2009. The squatters set up a freeshop and had plans for a social centre, but the occupation was quickly evicted by the police and 22 people were arrested.

Vatnsstigur 4 was briefly resquatted on May 7, 2009, in solidarity with the Rozbrat squat in Poland, which was threatened with eviction.

Also in 2009, a group of graffiti artists called the Pretty Boys occupied Hverfisgata 34. Their intention was to make a clandestine gallery and then when they were not evicted, they legalised the space and called it Gallery Bosnia.

When the Reykjavíkur Akademían (the Reykjavík Academy) was evicted at short notice from Hringbraut 121 in November 2011, it was occupied in protest. The space, which had hosted lectures and also Iceland’s trade union and anarchist libraries, was moved to another location but the occupiers were unhappy that the new use of the building would be a guest house for tourists. An art exhibition was organised, with a camera obscura, live music and shadow theatre.

The exact legal position of squatting in Ireland is ambiguous and the mechanisms for removing squatters from properties varies from case to case, sometimes going through the judicial process, other times not. Trespass and occupation of a property is not illegal, but as a definitive process for dealing with squatters does not exist, unlawful evictions do occur, sometimes with the support of the Garda Síochána (Irish Police). However certain 'squatters rights' do exist and can be invoked in the form of adverse possession. An occupant is entitled to legal possession of the title provided they are in continuous and uninterrupted occupation of the property for 12 years. To claim adverse possession the occupant must register an intent to claim the property with the land registry.

Squatting has no major tradition in Ireland, arguably in part due to the perceived strong position of the title holder. It has largely been confined to major cities but with the construction of Ghost estates across the country there has also been a rise in occupations of residential spaces in rural areas. There have been major housing movements and periods of squatting in Ireland, including the activities of the Dublin and Derry Housing Action Committees of the late 1960s and early 1970s. Each had a militant campaign which participated in dozens or hundreds of actions and protests in demand of better housing conditions.

In 2003 activists calling themselves 'Autonomous Community Spaces' entered 'Disco Disco' in Dublin's Parnell Square to turn the space in a social centre. They were violently evicted 24 hours later. From 2003 to 2004 the Magpie Squat was a residential space which housed activists in Dublin's Upper Leeson Street. It is also where the first meeting was held for the opening of what would become Dublin's first autonomous social centre Seomra Spraoi.

In 2010 activists from Occupy Cork squatted a National Asset Management Agency (NAMA) building in Cork city with the intention of using it as a community resource centre. It was vacated shortly after the occupation. In 2012 activists from Occupy Belfast squatted a Bank of Ireland building in Belfast city centre and used it as a social space. The occupation lasted several months before it was evicted.

Squatting has seen a recent surge in Dublin city with frequent occupations of spaces. With squatting becoming more public, Dublin hosted the 2014 'International Squatter Convergence', previously held in cities such as Dijon, Berlin and Brighton. Squatting also became popularised by the successful neighbourhood resistance to an attempted eviction of a large community used squatted space in Grangegorman in Dublin city in 2015. The news of the eviction attempt and eventual successful resistance spread across social media and international news. The squatted complex enjoyed widespread support in the area and was also publicly supported by the city's Lord Mayor, Christy Burke and by Irish Times journalist Una Mullally.

Since 2015 the building which once housed Neary's Hotel on Parnell St in Dublin's north inner city, was occupied and renamed The Barricade Inn by squatters.
In Italy, squatting has no legal basis, but there are many squats used as social centres. The first occupations of abandoned buildings began in 1968 with the left-wing movements Lotta Continua and Potere Operaio. Out of the breakup of these two movements was born Autonomia Operaia, which was composed of a Marxist–Leninist and Maoist wing and also an anarchist and more libertarian one. These squats had Marxist-Leninist (but also Stalinist and Maoist) ideals and came from the left wing of Autonomia. The militants of the Italian armed struggle (the New Red Brigades) were connected to these squats. There are many left-wing self-organised occupied projects across Italy such as Cascina Torchiera in Milan and Forte Prenestino in Rome.

Bussana Vecchia is a ghost town in Liguria which was abandoned in 1887 following an earthquake and subsequently squatted in the 1960s.

There are also far-right social centres such as CasaPound.

The Dutch use the term "krakers" to refer to people who squat houses with the aim of living in them (as opposed to people who break into buildings for the purpose of vandalism or theft). Squatting was criminalised in 2010.

There are still many residential squats in Dutch cities. There are also some squats in the countryside such as a squatted village called Ruigoord near Amsterdam. Fort Pannerden (a military fort built in 1869) was occupied in 2000 by people concerned about the state of the building. It was evicted on November 8, 2006, by a massive police operation which used military machinery and cost one million euros. The squatters then re-squatted the fort on November 26 and have since made a deal with the local council which owns the fort. The deal states that the squatters will receive a large piece of land near the fort to start a community in the rural area in between the city of Nijmegen and Arnhem. In exchange, the fort was handed over to local authorities, who will turn it into a museum, with help provided by the squatters that used to live in Fort Pannerden.

In the past, squats sometimes went through a process of legalisation. This is the case with the Poortgebouw in Rotterdam, which was squatted in 1980. In 1982, the inhabitants agreed to pay rent to the city council. The ORKZ () in Groningen, squatted in 1979, is an old Roman Catholic hospital, which was declared legal in the 1980s. In Amsterdam, OCCII, OT301 and Vrankrijk are examples of legalised spaces. The Grote Broek in Nijmegen was squatted in 1984 and legalised in the 2000s. The Vrijplaats Koppenhinksteeg in Leiden was occupied in 1968 and eventually evicted in 2010. There are also squats which refuse to legalise such as Anarres in Dordrecht (evicted in 2009), De Blauwe Aanslag in The Hague (evicted 2003), Het Slaakhuis (evicted) in Rotterdam, ADM (evicted) in Amsterdam and the Landbouwbelang and Villa Vendex in Maastricht.

Squatting gained a legal basis in the Netherlands in 1971, when the Supreme Court ruled that the concept of domestic peace ("huisvrede") (which means a house cannot be entered without the permission of the current user) also applied to squatters. Since then, the owner of the building must take the squatters to court (or take illegal action) in order to evict them. A law was passed in 1994 which made it illegal to squat a building which was empty for less than one year.

There were several moves to ban squatting in the past. In 1978, the Council of Churches launched a protest which scotched the idea. In June 2006, two ministers from the Dutch government (Sybilla Dekker and Piet Hein Donner) proposed a plan to make squatting illegal. Other ministers, such as Alexander Pechtold, were not in favor of this plan. Representatives of the four largest Dutch cities wrote a letter stating that it would not be in their interest to ban squatting. Squatters nationwide made banners and hung them on their squats in protest.

On June 1, 2010, the squatting ban was accepted by both houses of Parliament. Squatting in the Netherlands became illegal and punishable when a decree was sent out that the law would be enforced from the first of October.

The Dutch government assessed the effectiveness of the new law in 2015, releasing a report giving statistics on arrests and convictions between October 2010 and December 2014. During this time period, 529 people have been arrested for the act of occupying derelict buildings in 213 separate incidents. Of the 529 arrests, 210 were found guilty. Of those convicted, 39 people were imprisoned for the new offence.

Squatting of empty lots with shanty towns became popular in Spain in the 1960s and 1970s as a result of the shortage of urban accommodation during the rural exodus.
Gradually it was substituted by high-rise blocks (often built quickly and poorly).
It was revived in the mid-1980s during La Movida Madrileña, under the name of the "okupa" (an unofficial spelling applied to "ocupación") movement, when thousands of illegal squatted buildings were legalized. Influenced by the British Levellers, the movement's popularity rose again during the 1990s, once more due to a housing crisis, this time related to the 1992 Summer Olympics and the concomitant urban regeneration. Property speculation and house price inflation continue to catalyze "okupa" activism.
Related to the anarchist movement, "okupas" support the ideal of workers' self-management and create social centers, such as Patio Maravillas in Madrid, which carry out various grassroots activities. The "okupa" movement represents a highly politicized form of squatting, so much so that participants often claim they live in squats as a form of political protest first and foremost. The movement is involved in various other social struggles, including the alter-globalization movement. In 1996, during José María Aznar's presidency, the first specific legislation against squatting was passed and became the prelude to many squat evictions. In the barrio of Lavapiés in Madrid, the Eskalera Karakola was a feminist self-managed squat, which was active from 1996 to 2005 and participated in the nextGENDERation network. Other examples are the Escuela Popular de Prosperidad (La Prospe) o Minuesa.

As of 2007, there were approximately 200 occupied houses in Barcelona. At least 45 of these, as Infousurpa, a collective event calendar, mentions, are used as social and cultural centers – so-called "open houses". A number of popular rock groups have come out of this kind of venue, such as Sin Dios, Extremoduro, Kolumna Durruti, Refugio and Platero y Tú in Madrid and Ojos de Brujo and Gadjo in Barcelona. In 2014, the unsuccesful attempts to evict the long-running social center of Can Vies provoked major riots. Another long-running squat is Can Masdeu.

The Basque Country is another area where a high number of houses have been occupied. There are at least 46 squats, or "" ("youth's houses" in Basque). During the 1980s, a house was occupied by squatters in virtually every town, with the booming Basque punk rock thriving on the squatting movement, as it provided the badly needed premises for concerts, exhibitions, and other events. During the last 10 years, at least 15 "gaztetxes" have closed down, often following protests and clashes with the police. The eviction of Kukutza in Bilbao was met with largescale protests.

Parallelly there has been a not-ideologized current of Chabolismo (shanty towns) around big cities.
Initially settled by sedentarized Gitanos and Mercheros, they became known after the 1980s as selling points for heroin and other drugs.
As the Spanish nomads were transferred to public housing, the shanty towns became inhabited by poor immigrants, including Moroccans and Romanian Romas.
The Cañada Real Galiana is an example.

In England, squatting has a long historical tradition. The BBC states that squatting was "a big issue in the Peasants' Revolt of 1381 and again for the Diggers in the 17th Century [who] were peasants who cultivated waste and common land, claiming it as their rightful due" and that squatting was a necessity after the Second World War when so many were homeless. The BBC also reported in 2011 that the British government estimated that there were "20,000 squatters in the UK" and "650,000 empty properties".

On 1 September 2012, under Section 144 of the Legal Aid, Sentencing and Punishment of Offenders Act 2012, squatting in residential property was criminalised by the Government, punishable by up to six months in prison or a £5000 fine, or both. The same year saw the first successful prosecution for squatting, resulting in a 12-week jail sentence. However, squatting in a commercial building is still not a criminal offence.

Squatting is a criminal offence in Scotland, punishable by a fine or even imprisonment, see Trespass (Scotland) Act 1865. The owner or lawful occupier of the property has the right to evict squatters without notice or applying to the court for an eviction order, although when evicting, they cannot do anything that would break the law, for example, use violence.

The Forest Café in Edinburgh squatted its old premises in 2011 before moving to a new site.

There have been several road protest land squats such as Bilston Glen and Pollok Free State.

In 2010, a representative of the UK Bailiff Company claimed that the number of people squatting in Wales was at its highest for 40 years. The high number of businesses failing in urban Wales has led to squatting becoming a growing issue in large cities like Swansea and Cardiff. Experts said "the majority [of squatters] are forced into the lifestyle by financial pressures." Based on the internal database of UK Bailiff Company, there were 100 cases of squatting in 2009, the highest for 40 years, following trends estimated by the Advisory Service for Squatters that squatting has doubled in England and Wales since 1995.

As with England, from 1 September 2012, squatting in a residential building was made a criminal offence subject to arrest, fine and imprisonment. In December 2012 Cardiff Squatters Network was formed, to network together squatters citywide, and host "skill-share" workshops on squatting legally in commercial buildings.

In Canada, there are two systems to register the ownership of land. Under the land title system, squatter rights, formally known as adverse possession, were abolished. However, under the registry system, these rights have been preserved. If a person occupies land for the required period of time as set out in provincial limitation acts and, during that time, no legal action is taken to evict or in trespass, the ownership in the land goes from the legal owner to the squatter.

The Frances Street Squats in Vancouver were a row of six buildings squatted for nine months in 1990. They were evicted in a large operation and a film was subsequently made, called "The Beat of Frances Street".

In recent years there have been a number of public squats which have brought together the two main contemporary reasons for squatting – homelessness and activism. Examples are the Lafontaine squat in Overdale, a district of Montréal (2001), the Woodward's Squat in Vancouver (2002), the Infirmary Squat in Halifax (2002), the Pope Squat in Toronto (2002), the Seven Year Squat in Ottawa (2002), the Water Street Squat in Peterborough (2003) and the North Star hotel in Vancouver (2006). These were squats organised by anti-poverty groups which tended to have a short life expectancy.

The Woodward's building was a derelict department store which had stood empty for nine years. After being evicted from the building, two hundred squatters set up a tent city on the pavement outside. The action is credited with putting in motion the eventual redevelopment of the building.

The Peterborough Coalition Against Poverty (PCAP) publicly squatted 1130 Water Street, a building which stood empty after a fire. The group offered to repair the place and return it to its use as low-income housing. City officials agreed to the repairs and then the City Council voted to demolish the building. The cost of demolition was $8,900 and the cost of repairs had been projected to be $6,900.

The North Star hotel was temporarily squatted as a protest against emptiness by the Vancouver Anti-Poverty Committee.

In 2011, the 'Occupy Toronto squat team' squatted a basement at 238 Queen Street West and offered to take on a lease for 99 cents a year. They were evicted after eight hours.

In the United States, squatting laws vary from state to state and city to city. For the most part, it is rarely tolerated to any degree for long, particularly in cities. There have been a few exceptions, notably in 2002 when the New York City administration agreed to turn over eleven squatted buildings in the Lower East Side to an established non-profit group, on the condition that the apartments would later be turned over to the tenants as low-income housing cooperatives.

Community organizations have helped the homeless to take over vacant buildings not only as a place to live but also a part of larger campaign to shine a light on inequity in housing and advocate change in housing and land issues. Some of these include the Association of Community Organizations for Reform Now, Take Back the Land and Homes not Jails.

Squatters can be young people living in punk houses, low-income or homeless people, street gang members, or artists. During the Great Recession there were increasing numbers of people squatting foreclosed homes. There were also reports of people resquatting their own foreclosed homes.

Around many South American cities there are shanty towns. Sometimes, the authorities tear the houses down, but often, the squatters simply rebuild again. The houses are built out of whatever material can be scavenged from the local area or bought cheaply. As time goes by, the squatters start to form communities and become more established. The houses are rebuilt piece by piece with more durable materials. In some cases, a deal is reached with the authorities and connections for sewage, drinking water, cable television and electricity are made.

In Peru, the name given to the squatter settlements is pueblos jóvenes. In Colombia and Venezuela they are called 'invasiones' (as in "invading a property", as squatting can be related to a building or an empty lot) and in Argentina they are known as villa miseria.

In Chile the correct term used for the squatting is the similar term used in Spain "Casa Okupa". These houses share similar aspects with other squats around the world, such as being political and activist involved places, work as cultural and social centers and have their own subculture involve. They are normally associated with Anarchist Movement and they openly identify with the squatting movement, particularly the Movimiento Okupa in Spain. The mayor number of Casas Okupas are located in Valparaíso and Santiago de Chile.
It must not be confused with another different housing situation which term is "Tomas". These are particular situations of squatting that could be defined more like Shanty Towns, not necessarily involved with the Okupa movement.

In Brazil, some of the squatter communities are called favelas, and a famous example is Rocinha in Rio de Janeiro, estimated to be home of 100,000 people. Favelas are mostly inhabited by the poorest strata, and usually lack much infrastructure and public services, but in some cases, already have reached the structure needed for a city. They are equivalent to slums or shanty towns, and typically occupy unused land (instead of unused or abandoned buildings). There were 25 million people living in favelas all over Brazil, as of 2004.

In São Paulo the largest favela is Heliópolis, with over 200,000 inhabitants. However, its occupied area has been officially recognized as a regular neighborhood of the city. There are also a number of squatter buildings in the inner city, the most famous of which was a 22-story building called Prestes Maia, whose inhabitants were finally evicted by the police in 2007 after a long conflict with the city administration. Inspired both by this movement and increasing property speculation and gentrification, various occupations in buildings and unoccupied areas in big cities, led by groups such as the Homeless Workers' Movement (MTST) or Downtown Roofless Movement (MSTC).

The former Hotel Santos Dumont on Mauá Street in the Luz neighbourhood was occupied in 2007 after being derelict for 17 years. An estimated 1000 people were living in the building, paying a small amount every month to cover maintenance. The community expels people who fight, use drugs or abuse alcohol.

There are also rural squatter movements in Brazil, such as the Landless Workers' Movement (MST), which has an estimated 1.5 million members.

In the 19th century, the British government claimed to own all of Australia and tried to control land ownership. Wealthy farmers of livestock claimed land for themselves and thus were known as squatters.
This type of squatting is covered in greater detail at Squattocracy.
In more recent times, Australia has seen occupations in both Melbourne and Sydney. In the former, there was the 2016 Bendigo Street housing dispute and in the latter the Midnight Star squat.

In Europe, it is common for buildings to be squatted to be used as social centres. Cafés, bars, libraries, free shops, swaps shops and gyms have all been created, with many squats also holding parties and concerts. Social centers are often a combination of many things that happen in one space with the aim of creating a space for people to meet in a non-commercial setting, whether it be for a party, political workshop, to see a film, have a drink or have breakfast. There are many squatted social centers around the world, but they exist mainly in countries where squatting is legal. Examples include Ernst-Kirchweger-Haus in Austria, the RampART Social Centre in England, OT301 in the Netherlands and Ungdomshuset in Denmark (evicted on March 1, 2007, and demolished four days later).

Urban homesteading is a form of self-help housing where abandoned private properties in urban areas are taken over by the building's usually poor residents.

Sometimes this takes the form of squatting, which is not legal under many jurisdictions. Urban homesteading – in which residents rehabilitate the apartments through their own labor – may depart from squatting in some ways, especially philosophically.

While both groups may work initially with no permits, architectural plans or help from the government, self-help housing aims to manage the buildings cooperatively, and residents may work collaboratively with a non-profit organization or city government to legally obtain ownership of the building.

In some cases, urban homesteading is an organic phenomenon that evolves as a grassroots strategy of residents for dealing with a lack of affordable housing, or a sizable existence of abandoned, depressed, neglected or foreclosed housing stock. Some cities have used it as a solution to creating affordable housing.




</doc>
<doc id="33791438" url="https://en.wikipedia.org/wiki?curid=33791438" title="Outline of domestic violence">
Outline of domestic violence

The following outline is provided as an overview of and topical guide to domestic violence:

Domestic violence – pattern of abusive behaviors by one or both partners in an intimate relationship, such as marriage, dating, family, or cohabitation. It is also known as domestic abuse, spousal abuse, battering, family violence, and intimate partner violence (IPV).

Domestic violence can be described as all of the following:


Epidemiology of domestic violence – Domestic violence occurs across the world, in various cultures, and affects people across society, irrespective of economic status or gender.

The following table includes the forms of violence typically defined as part of Intimate partner violence, which is domestic violence in an intimate relationship by one's spouse or lover. It also includes a column for other family members or partners.

The rate of occurrence varies considerably based upon one's country, socio-economic class, culture, religion, family history and other factors.

Domestic violence affects people across society, irrespective of age, gender, sexual orientation, culture, religion or socio-economic status. Stop Abuse For Everyone (SAFE), a United States domestic violence organization, advocates for an "inclusive" model of domestic violence, focusing on groups that are "lacking in services", such as abused men, gay, lesbian, intersex, and transgender victims, and the elderly.

Some forms of domestic violence are unique to women victims:

Male victims of domestic abuse:

A large study, compiled by Martin S. Fiebert, shows that women are as likely to be abusive to men, but the men are less likely to be hurt. However, he noted, men are seriously injured in 38% of the cases in which "extreme aggression" is used. Fiebert additionally noted that his work was not meant to minimize the serious effects of men who abuse women. Women are far more likely to use weapons, such as throwing a plate or firing a gun. The National Institute of Justice (NIJ) contends that a national survey, supported by NIJ, the Centers for Disease Control and Prevention, and the Bureau of Justice Statistics that examined more serious assaults, does not support the conclusion of similar rates of male and female spousal assaults. This survey was conducted within a safety or crime context and found more partner abuse by men against women. A study published in the Violence & Victims Journal Vol. 1 concluded that a feminist analysis of Domestic Abuse was necessary to combat common misconceptions. The study found that 92% of women who used violence against their male partners were in self-defense, and that violence reciprocated by victims may be an integral part of abuse victimology.

Abuse in same-sex relationships is under-researched area of domestic violence, with a very wide range of prevalence estimates, and with fewer resources available for shelter and counseling.

Within a family, children may be victims of domestic child abuse in various ways:

A child may be affected by domestic violence even when the child is not the direct target:

Domestic violence can also be perpetrated by children against their parents:




The incidence of abuse may result in the following:




Some of the major academic researchers on domestic violence are:

Some of the most notable domestic violence activists are:









</doc>
<doc id="37321964" url="https://en.wikipedia.org/wiki?curid=37321964" title="American Market">
American Market

American Market (also known as Sitara Market) is a market located in Peshawar, Pakistan. It sells various types of electronic goods and is known for its low prices while being notorious for giving its visitors the opportunity to purchase firearms and accessories.

According to a local dealer, "the area has come to be known as the American Market because it sells US goods that have either been stolen and transported from Afghanistan, or from trucks captured from NATO transporting goods from Pakistan to Afghanistan." Even though being nicknamed the "American Market", this market sells "arms from the US, China, Russia, Iran and just about every other country you can think of" It was announced in January 2014, that a food park will be added to the Market, to include "quality and hygienic foods".


</doc>
<doc id="42049851" url="https://en.wikipedia.org/wiki?curid=42049851" title="Slashing (crime)">
Slashing (crime)

Slashing is a crime intended to cause bodily harm to a victim. A slashing is typically performed with a knife or other type of bladed or sharp object.

Cutting of the throat as to render the victim unable to breathe.

A street crime where a perpetrator permanently disfigures a victim by slicing into their face with a blade.

Boxer Nikita Thomas was involved in a street fight in Stapleton, Staten Island in which his face was severely slashed with a "007" flip-knife. The wound took 1000 stitches in total to close, with 200 on the outside of his face and 200 on the inside. He is left with a scar that stretches from top to bottom along his left cheek.

Actress and comedian Tina Fey has a scar a few inches long on the left side of her chin and cheek, the cause of which remained unexplained to the public until a 2008 "Vanity Fair" profile by Maureen Dowd. Dowd reported "...a faint scar runs across Tina Fey's left cheek, the result of a violent cutting attack by a stranger when Fey was five..." and subsequently in her autobiographical book, where she revealed "During the spring semester of kindergarten, I was slashed in the face by a stranger in the alley behind my house... When my face was slashed, my dad held me on his lap in the car to the hospital, applying direct pressure with the swift calm of a veteran and an ex-fireman. I looked up and asked him, ‘Am I going to die?’ ‘Don’t speak,’ he said."

Actor Tommy Flanagan was the victim of a slashing when he was mugged outside of a club he was working at in Scotland. The slashing on both of his cheeks left him with what is known as a "Glasgow smile".



</doc>
<doc id="42186654" url="https://en.wikipedia.org/wiki?curid=42186654" title="Assisting Offender">
Assisting Offender

An Assisting Offender is a suspected or convicted criminal in the United Kingdom, who has agreed to assist the investigation or prosecution of other criminals in return for some form of sentence reduction on their own criminal history.

In the United Kingdom the use of Assisting Offenders is enabled by the Serious Organised Crime and Police Act 2005 (SOCPA), the relevant sections of which came into force in 2006. The relevant sections are:

Section 71 of the SOCPA allows a Specified Prosecutor to grant an Assisting Offender immunity from prosecution.

Section 72 of the SOCPA allows a Specified Prosecutor to grant an undertaking to an Assisting Offender that information will not be used against that person. It is a form of limited immunity.

Section 73 of the SOCPA allows a Specified Prosecutor to sign an agreement with the Assisting Offender that the assistance of the offender will be brought to the attention of a Court in order to allow the court to pass a reduced sentence on the Assisting offender.

Section 74 of the SOCPA allows a Specified Prosecutor to seek a review of a previously sentenced prisoner who has entered an agreement to assist the prosecution or investigation of other criminals in exchange for a reduced sentence.

The 2005 legislation placed the use of so-called 'supergrasses' onto a statutory footing.

Assisting Offenders have been used in some notable cases with mixed results. In 2007 Rhys Jones was shot dead in Liverpool as part of a gang related incident. One of the suspects was later arrested in possession of a firearm and became an Assisting Offender giving evidence for the prosecution.
In Northern Ireland the use of Assisting Offenders was heavily criticised when the trial of 13 men for a range of terrorist crimes ended with only one conviction after a trial that had cost £11.5 million


</doc>
<doc id="45077521" url="https://en.wikipedia.org/wiki?curid=45077521" title="Justice Network">
Justice Network

Justice Network is an American digital multicast television network that is operated by Justice Network, LLC, a limited liability company, which is owned by Cooper Media. The network specializes in true crime, investigation and forensic science documentary programming aimed at adults – with a skew toward females – between the ages of 25 and 54.

The network, which broadcasts in 480i standard definition, is available in several large and mid-sized markets via digital subchannel affiliations with broadcast television stations, along with carriage of Justice Network-affiliated subchannels on cable television providers in most of its market coverage via existing carriage agreements for local broadcast stations.

The concept for the network was developed in 2013, when network founder Lonnie Cooper (a former executive at Bounce TV and chief executive officer of sports marketing firm CSE) had approached Steve Schiffman (who formerly served as president of National Geographic Channel) on a proposal for a new digital multicast network. Schiffman suggested to Cooper that the network should focus on crime- and investigation-related programming, an idea he suggested based on the popularity of the genre and the success of Investigation Discovery. Incidentally by that year, about half of the 50 highest-rated television programs as ranked by Nielsen were crime-related series.

The formation of Justice Network was announced on November 10, 2014, with the Gannett Company's television station group tapped as its charter affiliates, which then reached one third of the population. Besides featuring justice-oriented programming intended to entertain audiences, the network was also intent on taking an active role in combating crime by working with various law enforcement agencies to disseminate information about missing children and about fugitives accused of various felonies. Cooper assembled several top media executives to head the network at its launch with Schiffman as chief executive officer, Barry Wallach (former president of NBCUniversal Television Distribution) as head of distribution and John Ford (former president of Discovery Communications) as head of programming.

The network launched at 6:00 p.m. Eastern Time on January 20, 2015. On March 6, 2016, the network premiered its own original programs co-produced with TwoFour Productions and Zodiak Productions. In November 2017, Justice Network and the Justice Network, LLC parent entity were placed into a new corporate parent, Cooper Media, which was also founded to serve as the owner of its documentary- and history-themed sister network Quest (which launched on several Tegna-owned or -operated stations in January 2018).

Justice Network relies on an extensive library of crime and justice-related programming owned by the Turner Broadcasting System, A&E Networks, National Geographic Partners and Discovery Communications (encompassing 400 hours worth of episodes), including some series that originally aired on CourtTV/TruTV, A&E, History, National Geographic and Investigation Discovery. Much of the network's content is sourced through a syndication agreement with Turner Entertainment that was announced with the network on November 10, 2014. The network's decision to focus on crime-focused programming is based on various factors in addition to viewer interest in the genre, as it is intended to help tie into its public service mission, and because the genre is of relatively low cost to acquire and produce compared to other fact-based genres.

No originally produced programming appeared on Justice Network at its launch, although plans were put forth to start developing original content within the network's first year. Indeed, Justice Network would develop two original series that were co-produced by the network – "Killing Spree" (produced in conjunction with TwoFour Productions) and "Inside the Mind of a Serial Killer" (produced with Zodiak Productions) – that premiered on March 6, 2016.

In addition, the network airs 90 seconds of public service announcements per hour within its commercial breaks, which are produced through partnerships with Crime Stoppers USA, the National Center for Missing and Exploited Children and a number of law enforcement agencies. , this public service component, known as BeSAFE, has resulted in the capture of 101 fugitives and finding of 103 missing children. These PSAs consist of four different 30-second segments:
The PSAs are mainly tailored to the specific region of the local Justice Network affiliate, with additional information on the fugitives and missing children profiled available on the network's website. John Walsh, founder of the National Center for Missing and Exploited Children, serves as the network's on-air spokesperson and announcer of the PSA interstitials. John's son, National Center for Missing and Exploited Children child advocate Callahan Walsh, appears in the network's NCMEC safety and missing child profile PSAs, while Sgt. Ralph Woolfolk of the Atlanta Police Department (who, in his prior career as a child actor, was known for his role as Derek "Dee Dee" Parker in the 1990s Nickelodeon sitcom "My Brother and Me") appears in the network's "BeSAFE" PSA interstitials.

, Justice Network has current or pending affiliation agreements with television stations in 65 media markets (including 24 of the top 30), covering 57% of all households of at least one television set in the United States. The network is selective in the stations with which it affiliates, preferring those that maintain a local news department and community initiatives.

When its launch was announced, the network reached a charter affiliation agreement with the Gannett Company's broadcasting unit (now split into a separate company named Tegna as of June 29, 2015), which initially debuted the network on 22 of its television stations.

As a result of Live Well Network's initial plans to cease operations around the time of Justice Network's launch (later choosing to end national distribution of the former, and relegate it exclusively to ABC owned-and-operated stations owned by ABC Owned Television Stations in April 2015), some former LWN outlets owned by Gannett chose to become Justice Network affiliates at its launch. By August 2016, Justice Network had reached affiliation agreements with various other station groups including Hearst Television, Tribune Broadcasting, Media General, Gray Television and Univision Communications, which increased the network's national reach to encompass 57% of all U.S. television households. In September 2017, Univision began carrying the network on eleven additional Univision and UniMás owned-and-operated stations, expanding Justice Network's reach to 73% of the U.S.


</doc>
<doc id="1737582" url="https://en.wikipedia.org/wiki?curid=1737582" title="School violence">
School violence

School violence encompasses physical violence, including student-on-student fighting and corporal punishment; psychological violence, including verbal abuse; sexual violence, including rape and sexual harassment; many forms of bullying, including cyberbullying; and carrying weapons in school. It is widely held to have become a serious problem in recent decades in many countries, especially where weapons such as guns or knives are involved. It includes violence between school students as well as physical attacks by students on school staff.

A distinction is made between internalizing and externalizing behavior. Internalizing behaviors reflect withdrawal, inhibition, anxiety, and/or depression. Internalizing behavior has been found in some cases of youth violence although in some youth, depression is associated with substance abuse. Because they rarely act out, students with internalizing problems are often overlooked by school personnel. Externalizing behaviors refer to delinquent activities, aggression, and hyperactivity. Unlike internalizing behaviors, externalizing behaviors include, or are directly linked to, violent episodes. Violent behaviors such as punching and kicking are often learned from observing others. Just as externalizing behaviors are observed outside of school, such behaviors also observed in schools.

A number of other individual factors are associated with higher levels of aggressiveness. Compared to children whose antisocial conduct begins in adolescence, early starters have a worse prognosis in terms of future aggression and other antisocial activities. Lower IQ is related to higher levels of aggression. Other findings indicate that in boys early problematic motor skills, attentional difficulties, and reading problems predict later persistent antisocial conduct.

The home environment is thought to contribute to school violence. The Constitutional Rights Foundation suggests long-term exposure to gun violence, parental alcoholism, domestic violence, physical abuse of the child, and child sexual abuse teaches children that criminal and violent activities are acceptable. Harsh parental discipline is associated with higher levels of aggressiveness in youth. There is some evidence indicating that exposure to television violence and, to a lesser extent, violent video games is related to increased aggressiveness in children, which, in turn, may carry over into school.

Straus adduced evidence for the view that exposure to parental corporal punishment increases the risk of aggressive conduct in children and adolescents. Straus's findings have been contested by Larzelere and Baumrind. A meta-analysis of the vast literature on corporal punishment, however, indicates that corporal punishment is related to poorer outcomes in children and youth. The methodologically soundest studies indicate "positive, moderately sized associations between parental corporal punishment and children’s aggression." Gershoff found that the trajectory of mean effect sizes (the size of the effect of corporal punishment on children's problem behavior) was curvilinear with the largest mean effect size in middle school ("M" = 0.55; on average the mean of corporal punishment group was more than half a standard deviation higher than the mean of the non-punishment group) and slightly smaller effect sizes in grade school ("M" = 0.43) and high school ("M" = 0.45).

Gerald Patterson's social interactional model, which involves the mother's application and the child's counterapplication of "coercive" behaviors, also explains the development of aggressive conduct in the child. In this context, coercive behaviors include behaviors that are ordinarily punishing (e.g., whining, yelling, hitting, etc.). Abusive home environments can inhibit the growth of social cognitive skills needed, for example, to understand the intentions of others. Short-term longitudinal evidence is consistent with the view that a lack of social cognitive skills mediates the link between harsh parental discipline and aggressive conduct in kindergarten. Longer-term, follow-up research with the same children suggests that partial mediating effects last until third and fourth grade. Hirschi's (1969) control theory advances the view that children with weak affective ties to parents and school are at increased risk of engaging in delinquent and violent behavior in and out of school. Hirschi's cross-sectional data from northern California high-school students are largely consistent with this view. Findings from case-control and longitudinal studies are also consistent with this view.

Neighbourhoods and communities provide the context for school violence. Communities with high rates of crime and drug use teach youth the violent behaviors that are carried into schools. Children in violent neighborhoods tend to perceive that their communities are risky, and that these feelings of vulnerability carry over to the school environment. Dilapidated housing in the neighbourhood of the school has been found to be associated with school violence. Teacher assault was more likely to occur in schools located in high-crime neighbourhoods. Exposure to deviant peers is a risk factor for high levels of aggressivity. Research has shown that poverty and high population densities are associated with higher rates of school violence. Well controlled longitudinal research indicates that children's exposure to community violence during the early elementary school years increases the risk of aggression later in elementary school, as reported by teachers and classmates. Other, well controlled longitudinal research that utilized propensity score matching indicates that exposure to gun violence in early adolescence is related to the initiation of serious physical violence in later adolescence. Neighbourhood gangs are thought to contribute to dangerous school environments. Gangs use the social environment of the school to recruit members and interact with opposing groups, with gang violence carrying over from neighbourhoods into some schools. Alternatively, many children who grow up in violent neighborhoods learn to deliberately find and make "street-oriented" friends as an instrumental tactic used to avoid being victimized. Without the threat of violence, children more commonly develop friendships based on homophily, or shared traits.

Recent research has linked the school environment to school violence. Teacher assaults are associated with a higher percentage male faculty, a higher proportion of male students, and a higher proportion of students receiving free or reduced cost lunch (an indicator of poverty). In general, a large male population, higher grade levels, a history of high levels of disciplinary problems in the school, high student to teacher ratios, and an urban location are related to violence in schools. In students, academic performance is inversely related to antisocial conduct. The research by Hirschi and others, cited above in the section on the home environment, is also consistent with the view that lack of attachment to school is associated with increased risk of antisocial conduct.

The goal of prevention and intervention strategies is to stop school violence from occurring. According to the CDC, there are at least four levels at which violence-prevention programs can act: at the level of society in general, the school community, the family, and the individual.



Research on violence affecting children in schools is challenging for a variety of reasons.

When trying to measure the scope of violence in schools and to find out about the types of violence experienced by students, some key issues include: from what categories of the school community to collect the data; what data should be collected from each categories; and using which methods. For example, should there be studies or surveys where researchers ask students directly about violence in school, through self-reports about the violence they experienced as targets or perpetrators? Or should they be asked about incidents of violence that they have witnessed as bystanders? Should any of these questions be asked via self-administered questionnaires or questionnaires administered by researchers in schools? Does it make more sense to collect this data outside of schools, for example, through household surveys? Or through online surveys where students have access to the internet? Or is it better to rely on mechanisms for reporting incidents of violence in educational institutions when they are available, either in the schools themselves or outside schools (governmental hotlines, internet-based reporting systems, police and justice sectors, etc.)? What questions can be asked of children, using terminology that is easy to understand, age-appropriate and culturally sensitive?

In most countries there are strict rules related to research involving children, as they are under the age of consent. Therefore, requesting informed consent from the children in a study involves their parents and guardians. Asking children about violence, and particularly violence they have experienced themselves, can be traumatic. Finally, researching issues related to sexual orientation and gender identity/orientation in education and in relation to children has additional challenges. In some contexts it is not legal to discuss these issues either in schools or even outside of schools. Where it is legal, it may be considered as a very sensitive topic to be discussed with children and young people. Asking children and young people questions related to their sexual orientation and gender identity in the school setting is ethically questionable, as it could embarrass them and expose them to stigma and discrimination, unless questions are asked in strict confidence and anonymity is granted by independent researchers external to schools.



</doc>
<doc id="145043" url="https://en.wikipedia.org/wiki?curid=145043" title="Vice">
Vice

Vice is a practice, behaviour, or habit generally considered immoral, sinful, criminal, rude, taboo, depraved, or degrading in the associated society. In more minor usage, vice can refer to a fault, a negative character trait, a defect, an infirmity, or a bad or unhealthy habit (such as an addiction to smoking). Vices are usually associated with a transgression in a person's character or temperament rather than their morality. Synonyms for vice include fault, sin, depravity, iniquity, wickedness, and corruption.

The opposite of vice is virtue.

The modern English term that best captures its original meaning is the word "vicious", which means "full of vice". In this sense, the word "vice" comes from the Latin word "vitium", meaning "failing or defect".

Depending on the country or jurisdiction, vice crimes may or may not be treated as a separate category in the criminal codes. Even in jurisdictions where vice is not explicitly delineated in the legal code, the term "vice" is often used in law enforcement and judicial systems as an umbrella for crimes involving activities that are considered inherently immoral, regardless of the legality or objective harm involved.

In the United Kingdom, the term "vice" is commonly used in law and law enforcement to refer to criminal offences related to prostitution and pornography. In the United States, the term is also used to refer to crimes related to drugs, alcohol, and gambling.

A vice squad, also called a vice unit or a morality squad, is (though not always) a police division, whose focus is to restrain or suppress moral crimes. Though what is considered or accepted as a "moral" crime by society often varies considerably according to local laws or customs between nations, countries, or states, it often includes activities such as gambling, narcotics, pornography, and illegal sales of alcoholic beverages. Vice squads do not concentrate on more serious crimes like fraud and murder.

Religious police, for example islamic religious police units or sharia police in certain parts of the Arab-speaking world, are morality squads that also monitors for example dress codes, observance of store-closures during prayer time, consumption of unlawful beverages or foods, unrelated males and females socializing, and homosexual behavior.

Vices are those behaviors which are inherently harmful to oneself and society. 

In the Sarvastivadin tradition of Buddhism, there are 108 defilements, or vices, which are prohibited. These are subdivided into 10 bonds and 98 proclivities. The 10 bonds are the following:

Christians believe there are two kinds of vice:

The first kind of vice, though sinful, is believed less serious than the second. Vices recognized as spiritual by Christians include blasphemy (holiness betrayed), apostasy (faith betrayed), despair (hope betrayed), hatred (love betrayed), and indifference (scripturally, a "hardened heart"). Christian theologians have reasoned that the most destructive vice equates to a certain type of pride or the complete idolatry of the self. It is argued that through this vice, which is essentially competitive, all the worst evils come into being. In Christian theology, it originally led to the Fall of Man, and, as a purely diabolical spiritual vice, it outweighs anything else often condemned by the Church.

The Roman Catholic Church distinguishes between vice, which is a habit of sin, and the sin itself, which is an individual morally wrong act. Note that in Roman Catholicism, the word "sin" also refers to the state that befalls one upon committing a morally wrong act. In this section, the word always means the sinful act. It is the sin, and not the vice, that deprives one of God's sanctifying grace and renders one deserving of God's punishment. Thomas Aquinas taught that "absolutely speaking, the sin surpasses the vice in wickedness". On the other hand, even after a person's sins have been forgiven, the underlying habit (the vice) may remain. Just as vice was created in the first place by repeatedly yielding to the temptation to sin, so vice may be removed only by repeatedly resisting temptation and performing virtuous acts; the more entrenched the vice, the more time and effort needed to remove it. Saint Thomas Aquinas says that following rehabilitation and the acquisition of virtues, the vice does not persist as a habit, but rather as a mere disposition, and one that is in the process of being eliminated. Medieval illuminated manuscripts circulated with colorful schemas for developing proper attitudes, with scriptural allusions modelled on nature: the tree of virtues as blossoming flowers or vices bearing sterile fruit, The Renaissance writer Pietro Bembo is credited with reaffirming and promoting the Christian perfection of classical humanism. Deriving all from love (or the lack thereof) his schemas were added as supplements in the newly invented technology of printing by Aldus Manutius in his editions of Dante's Divine Comedy dating from early in the 16th century.

The poet Dante Alighieri listed the following seven deadly vices, associating them structurally as flaws in the soul's inherent capacity for goodness as made in the Divine Image yet perverted by the Fall:

The first three terraces of purgatory expiate the sins which can be considered to arise from love perverted, that is, sins which arise from the heart of the sinner being set upon something which is wrong in the eyes of God. Those being purged here must have their love set upon the right path. The fourth terrace of purgatory expiates the sins which can be considered to arise from love defective, that is, love which, although directed towards the correct subjects is too weak to drive the sinner to act as they should. Those being purged here must have their love strengthened so as to drive them correctly. The fifth, sixth, and seventh terraces of purgatory expiate the sins which can be considered to arise from love excessive, that is, love which although directed towards ends which God considers good is directed towards them too much for the sinner to gain bliss from them, and also so that the sinner is distracted from the love of other things of which God approves. Their love must be cooled to a more sensible level.

The Qur'an and many other Islamic religious writings provide prohibitions against acts that are seen as immoral.

Ibn abi Dunya, a 9th-century scholar and tutor to the caliphs, described seven "censures" (prohibitions against vices) in his writings:


In Sanskrit काम (lust) क्रोध (anger) लोभ (greed) मद(pride) मोह (temptation) मत्सर (jealousy)






</doc>
<doc id="50803" url="https://en.wikipedia.org/wiki?curid=50803" title="Victimless crime">
Victimless crime

A victimless crime is an illegal act that typically either directly involves only the perpetrator or occurs between consenting adults; because it is consensual in nature, there is arguably no true victim, i.e. aggrieved party.

Definitions of victimless crimes vary in different parts of the worlds and law systems, but usually include possession of any illegal contraband, recreational drug use, prostitution and prohibited sexual behavior between consenting adults (e.g. public sex), arms trafficking, smuggling and human smuggling, among other similar infractions. However, there is controversy surrounding this. Edwin Schur and Hugo Adam Bedau state in their book "Victimless Crimes: Two Sides of a Controversy" that "some of these laws produce secondary crime, and all create new 'criminals,' many of whom are otherwise law-abiding citizens and people in authority."

In politics, a lobbyist or an activist might use this phrase with the implication that the law in question should be abolished.

Victimless crimes are, in the harm principle of John Stuart Mill, "victimless" from a position that considers the individual as the sole sovereign, to the exclusion of more abstract bodies such as a community or a state against which criminal offenses may be directed.

Three characteristics can be used to identify whether a crime is victimless crime – if the act is excessive, is indicative of a distinct pattern of behavior, and its adverse effects impact only the person who has engaged in it – according to the University of Chicago's vice scholar, Jim Leitzel.

In theory, each polity determines for itself the laws it wants to have, so as to maximize the happiness of its citizens. As knowledge progresses and behavior changes, and values change as well, laws in most countries lag badly behind social changes. Once it is obvious to a vast majority that the law is unnecessary at best, the law, until it is repealed, will be prohibiting a victimless crime.

Many victimless crimes begin because of a desire to obtain illegal products or services that are in high demand. Criminal penalties thus tend to limit the supply more than the demand, driving up the black-market price and creating monopoly profits for those criminals who remain in business. This "crime tariff" encourages the growth of sophisticated and well-organized criminal groups. Organized crime in turn tends to diversify into other areas of crime. Large profits provide ample funds for bribery of public officials, as well as capital for diversification.

The War on Drugs is a commonly cited example of prosecution of victimless crime. The reasoning behind this is that drug use does not directly harm other people. It is argued that the criminalization of drugs leads to highly inflated prices for drugs. For example, Bedau and Schur found in 1974 that "In England the pharmacy cost of heroin [was] 0.06 cents per grain. In the United States street price [was] $30-90 per grain." This inflation in price is believed to drive addicts to commit crimes such as theft and robbery, which are thought to be inherently damaging to society, in order to be able to purchase the drugs on which they are dependent.

In addition to the creation of a black market for drugs, the War on Drugs is argued by proponents of legalization to reduce the workforce by damaging the ability of those convicted to find work. It is reasoned that this reduction of the workforce is ultimately harmful to an economy reliant on labor. The number of drug arrests increases every year. In a poll taken by the Bureau of Justice Statistics between 1980 and 2009, "[over a] 30-year period...[arrest] rates for drug possession or use doubled for whites and tripled for blacks."

Many activities that were once considered crimes are no longer illegal in some countries, at least in part because of their status as victimless crimes.

Two large categories of victimless crimes are sexual pleasure and recreational drug use (drug pleasure). On the first, 

Marijuana use is forbidden by law in Australia but is the most “widely used illicit drug” in the country, just as it is in countries such as the United States and New Zealand. Prohibition of alcohol in the United States, repealed in 1933, is considered a failed "social experiment" because many citizens ignored what it stipulated, turning to home-made spirits in lieu of licensed alcoholic drinks and resultantly making problems worse. In the United States today, tension over marijuana legalization is in response the current marijuana prohibition in most states, but there are efforts to legalize cannabis in many countries such as the United States and Australia, as its legalization has the potential to greatly increase revenue.

Prostitution is legal in many countries, though usually restricted. The Netherlands legalized prostitution in 1999, and was one of the first countries to do so. As of 2012, however, it has been considering policy changes to severely restrict it.

Adultery (sexual acts between a married person and a person other than the spouse) and fornication (sexual acts between unmarried people) have not been prosecuted in the United States for over 50 years, although the laws against them, like those against sodomy, are still on the books in several states. However, because sodomy laws were struck down as unconstitutional by the U.S. Supreme Court in "Lawrence v. Texas", the laws against fornication would also be unconstitutional as was recognized by the Supreme Court of Virginia in "Martin v. Ziherl".

The degradation of societal moral standards is a major concern among those who oppose the legalization of victimless crime. However, punishing citizens solely for their choice to engage in victimless acts declared by the law to be immoral is difficult. While the United States' typical response to crimes is retroactive, the illegality of victimless crimes is a more preventative approach to justice and is highly controversial.

Controversies over victimless crime deal mostly with the question of whether a crime can ever actually be victimless. With relation to drugs and their pathway to consumption, the impact of the drug trade and liability laws on drug dealers, their families, and other unforeseen actors may end in victimization. The possession of both adult and child pornography is also often considered to be a victimless crime, but the victimization of adults and children during its production is typically unacknowledged by those who hold that position.

In contrast, the argument that legal powers must be restrained to allow citizen autonomy, free from impediments in making voluntary, victimless choices that may or may not be perceived as morally wrong, also exists. With the incorporation of preventative law, such as sex offender registries and anti-social behavior orders, comes a loss of distinction between criminal and civil law because victimless crime is typically difficult to categorize and criminalize. This is problematic because it causes a distortion of traditional procedures found within the criminal and civil of aspects of United States law by enabling confusion and procedural interchangeability.




</doc>
<doc id="47270855" url="https://en.wikipedia.org/wiki?curid=47270855" title="Online Abuse Prevention Initiative">
Online Abuse Prevention Initiative

The Online Abuse Prevention Initiative (OAPI) is a non-profit organization whose aim is to study and combat abuse on the Internet.

The OAPI was founded in 2015 by Randi Lee Harper, with Crash Override Network's Zoë Quinn and Alex Lifschitz stated as serving on the inaugural board of directors. In March 2015 Quinn announced a formal partnership between the two organizations.

The stated goals of the OAPI are to study online abuse, and to reduce and mitigate it through technical measures and collaboration with tech companies. Its first public campaign was an open letter to ICANN, the organization responsible for coordinating the Internet's Domain Name System, opposing the latter's plans to end anonymity of WHOIS records for commercial websites. OAPI argues that ICANN's proposals will make it easier for abusers to physically endanger domain name registrants through doxxing and swatting, and that those marginalized for their race, gender, or sexual orientation are disproportionately at risk. The letter attracted signatures and support from over fifty organizations supporting online privacy or protection of at-risk communities, including the Electronic Frontier Foundation, The Tor Project, and the National Coalition Against Domestic Violence. The project is funded entirely by donors via Patreon.



</doc>
<doc id="15181251" url="https://en.wikipedia.org/wiki?curid=15181251" title="Crime in Italy">
Crime in Italy

Crime in Italy is combated by the spectrum of Italian law enforcement agencies.

In 2012, national murder rate was about 0.9 per 100,000 population, one of the lower rates in Western Europe. There were a total of 530 murders in Italy in 2012.

Many worldwide crime organizations originated in Italy, and its influence is widespread in Italian society, directly affecting a reported 22% of citizens and 14.6% of Italy's Gross Domestic Product. Public figures such as former Prime Minister Silvio Berlusconi have been charged with association in organized criminal acts. War against organized crime caused hundreds of murders, including judges (Giovanni Falcone and Paolo Borsellino) and lawyers (like Roberto Calvi).

There are several separate criminal organizations controlling territory and business activities: Sicilian "Cosa Nostra", Campanian "Camorra", Calabrese "'Ndrangheta" and Apulian "Sacra Corona Unita". More than 13 million people are involved into crime web. Their business involvement is on a European and global scale. Particularly in Naples an unusual high homicide rate and several drug addicted people have qualified the town as the most dangerous in West Europe.

Businesses, entrepreneurs, shopkeepers, and craftsmen in these regions are expected to pay a "protection money". There is rarely any possibility of escaping payment, and those not complying find their business premises and lives at risk. People not able to meet demands might find their business partly or completely taken over by organized crime.

In 2009, organized crime in Italy generated $189 billion in revenue.

Italy has a lower per capita rate of rape than most of the advanced Western countries in the European Union.

According to Police authorities data, the rate of sexual assaults per 100,000 inhabitants is significantly higher in the Northern region than in the Southern ones. In 2009, Lombardia and Emilia Romagna were the regions with the highest rate of sexual offences per 100.000 inhabitants (9.7); followed by Trentino Alto Adige and Tuscany (9.5); Piedmont and Liguria (8.6); Umbria (8.4). In this respect, all major Southern regions like Sicily (6.8); Calabria (6.5); Puglia (6.2); Campania (6,0) were the safest in the national territory, with the only exception of Friuli Venezia Giulia (5.1) in the North.

Fraud is a major contributor to Italy's crime rate, with some level of fraud appearing in all sectors of the economy since the country's founding in 1861. Notable cases of financial fraud include the collapse of Parmalat in the early years of the 21st century, and the Lockheed bribery scandal in the 1970s.
Insurance fraud also dramatically increases the cost of insurance in Italy, with 115,646 incidents of fraudulent claims in 2001 alone, with 3.28 percent of all claims in 2002 ascertained to have involved fraud. The percentage rose above ten percent in some of the southern provinces.

State employees have been perceived to have such a high rate of absenteeism, often feigning illness, that in 2008 the government introduced a law to harshly prosecute civil servants who are found to be making fraudulent claims about their health.
Fraudulent claims of ill health are not confined to state employees, with some physicians often willing to receive bribes to certify non-existent conditions so that citizens may receive disability benefits. A case was revealed in 2010 where in one quartiere of Naples alone, 400 people were found to be claiming mental illness although healthy.

Political corruption remains a major problem in Italy, particularly in Southern Italy including Calabria, parts of Campania and Sicily where corruption perception is at a high level. Political parties are ranked as the most corrupt institution in Italy, closely followed by public officials and Parliament, according to Transparency International's Global Corruption Barometer 2013.

Levels of crime are unevenly spread throughout the peninsula.

Traditionally, the areas most affected by high levels of violent crime have been the Southern regions heavily influenced by powerful criminal organizations: Sicily, Calabria, Campania and Apulia, where drug trade and gang feuds are common in marginalised areas in underdeveloped rural and urban settings alike.

Waste management problems affected Naples; Italian media have attributed the city's waste disposal issues to the activity of the Camorra organised crime network. In 2007, Silvio Berlusconi's government held senior meetings in Naples to demonstrate their intention to solve these problems. 
In December 2009 "waste emergency" officially finished.
In June 2012, allegations of blackmail, extortion and illicit contract tendering emerged in relation to the city's waste management issues.

Most regions in the center and north can be considered calmer and more organized, with lower levels of criminal activity. Regions such as Marche, Tuscany, Umbria in the centre and Piedmont, Trentino-Alto Adige/Südtirol, Liguria and Friuli Venezia Giulia present relatively low criminal indicators compared to other western countries.
But even in the north and center levels of crime are unequally spread. Cities such as Turin, Milan, Bologna, Genoa in the North frequently suffer a wide diversity of frequent offences ranging from extensive drug trade, homicides, etc.

The capital Rome presents medium to high levels of crime. But many areas of the Roman periphery are extensively dilapidated and crime-ridden to a much larger extent than northern and central European counterparts. Shantytowns on the outskirts of the city housing more than 4000 people are focuses of elevated criminal activity.

Petty crimes such as pick pocketing, car burglary, and purse snatching are serious problems, especially in large cities. Most reported thefts occur at crowded tourist sites, on public buses or trains, or at the major railway stations.



</doc>
<doc id="47642664" url="https://en.wikipedia.org/wiki?curid=47642664" title="BANCOOP case">
BANCOOP case

The BANCOOP case is the name used by the Brazilian press for the alleged use of BANCOOP (Housing Cooperative Bank of São Paulo) to benefit the slush funds of the Workers Party (PT), in 2002 and 2004. On October 28, 2010, Judge Patricia Inigo Funes e Silva, of the 5th Criminal Court of São Paulo, accepted the complaint against João Vaccari Neto and five other people involved in the case of embezzlement through BANCOOP.

Founded in 1996, by Representative Ricardo Berzoini (the current president of the Workers Party), BANCOOP had been investigated by prosecutors since 2007 for money laundering, overpricing and diversion of resources. The financial situation of the company provided evidence of the malpractice.

BANCOOP was one of the largest real estate developers in the state of São Paulo, with more than 15,000 members, and even received large financial contributions totaling more than R$40 million, since 2003, mostly through pension funds controlled by people linked to the PT. By 2010, it was estimated to have a deficit of more than R$100 million.

On March 10, 2010, the magazine Veja revealed that the Public Ministry of São Paulo would have had access to more than 8,000 pages of bank records of transactions carried out by BANCOOP between 2001 and 2008.

According to the publication, in 2002, contractors providing services to BANCOOP issued false invoices for BANCOOP. The directors of the contracting companies would then receive checks as payment for nonexistent services, and transferred the money to an employee in the Hélio Malheiro, who would then deposit this money at a branch of a major bank. During this time, the organization's president, Luiz Malheiro, gave the money to the union chair, João Vaccari Neto. The embezzled money was used to promote the slush fund for Lula's campaign in 2002.

In his statement made to the Public Ministry, the engineer responsible for the works of BANCOOP, Ricardo Luiz do Carmo, stated that he went to the union headquarters where he was instructed to collect money from contractors, who provided services for BANCOOP, for the Workers Party campaign PT in 2002.

In one of the cases, a business called Mirante / Mizu Artifacts provided concrete blocks to its sole customer, BANCOOP. In the first three months of operation, the company received R$900 million. Among the leaders of Mirante / Mizu included four directors of BANCOOP, including the then-president of the cooperative Luiz Malheiros. Luiz authorized deposits in the company's account, which had an account at the same branch as the cooperative. The prosecutors suspected that the cooperative used a network of companies contracted to supply the slush funds of the Workers Party in the 2002 election and for the enrichment of the cooperative leaders. Mirante / Mizu is one such company. In only the first five months of its existence, Mizu received more than R$1 million from BANCOOP. Some of the suspicious activities included R$432,000 in donations to the Workers Party, R$162,000 in the purchasing of apartments for BANCOOP, R$153,000 in profit-sharing, and R$27,000 injected into an NGO owned by Malheiros. In his testimony Ricardo Luiz Carmo claims to have seen an invoice in the amount of R$500,000 to Mizu for consultant work on a civil construction project. This fact surprised Ricardo because the contractors actually received much less.

In another case, the businessman Andi Gurczynska Roberto, who worked as security for the directors of BANCOOP, said in testimony to the CPI that BANCOOP had been sending notes to entities, in exchange for receiving 10X that value in the entities' accounts. The difference was caught and handed over to the then-president of the cooperative Luis Malheiro, and the other directors. According to Roberto, "It was commonly said that (the money) went to the PT."

In 2004, Luiz Malheiro sought Ricardo Berzoini, the then-labor minister, to explain that the cooperative was in need of additional financial resources. In December of that year, Using the brokerage firm Planner, the cooperative raised R$36.9 million from state pension funds.

According to the publication, in a small sampling of the cooperative's bank, there were cash withdrawals totaling R$31 million through checks issued by the cooperative itself, which showed a receipt by the cooperative or its own bank. The use of checks in this type of transaction is often used to hide the destination of the money. In other checks, R$10 million, between 2003 and 2005, was provided to four directors of the cooperative (the former president Luiz Eduardo Malheiro and former directors Alessandro Robson Bernardino, Marcelo Rinaldo and Tomas Edson Botelho Frag). The first three directors were killed in a car accident. The four were owners a firm called The Germany Empreiteira, whose sole client was the cooperative.

In the publication, the engineer Ricardo Luiz do Carmo, who was responsible for all construction of BANCOOP, stated that the notes, used by Germany Empreiteira, sent to BANCOOP, were overpriced by 20%.

Another person who received BANCOOP checks was Freud Godoy, the former security of President Lula's campaign, who received eleven checks totaling R$1.5 million, dating from the period 2005-2006. The checks were destined to Case Security Systems company, but the address only had a plaque with the firms name, and neighbors said that there was no indication that there was any activity there.

According to the lawyer Vernon Picazio Junior, about 8,500 families have suffered losses due to BANCOOP. Included that number are the injured families, or about 3,000 families, who arrived to receive the supposedly constructed buildings by BANCOOP. According to him, there has been no clarification of a fund of R$43 million, which was raised from the members for the purpose of constructing those buildings.

In the period that BANCOOP function, there was a deficit of R$135 million, with 2000 affiliates who had paid for property but had not yet received it.[6]

On October 19, 2010, Jose Carlos Blat, the Public Prosecutor of the state of São Paulo, presented a complaint to the 5th Criminal Court, accusing the former directors of the cooperative (Joao Vaccari Neto, Tomas Edson Botelho Fraga, Ana Maria Ernica, Henir de Oliveira, BANCOOP's lawyer, Leticia Achur Antonio and Helena Conceição Pereira Lage, the president of Germany Empreiteira) in larceny, attempted larceny, conspiracy, misrepresentation, and money laundering.

On October 28, 2010, Judge Patricia Inigo Funes e Silva, of the 5th Criminal Court of São Paulo, accepted the complaint. In addition, the judge ordered the disclosing of the banking and financial records of Vaccari and Ana Maria.[1]

On February 21, 2011, the Court of São Paulo decided to garnish the cooperative's headquarters. The decision was made as a way to try and pay the debts of the cooperative.

On March 13, 2012, in a unanimous decision, the 10th Private Law Chamber of the State Court of Justice ruled to pierce the corporate veil of BANCOOP, which in practice forces its leaders and former representatives (Ricardo Berzoini and Joao Vaccari Neto) to reimburse the cooperative in the amount relating to the damages that were suffered.

Justice of São Paulo summarily dismisses charges against former PT treasurer and member João Vaccari Neto and other defendants. According to judge Maria Priscilla Ernandes Veiga Oliveira, of 4ª Vara Criminal de São Paulo, prosecution charges were based on mere allegations, presented in a superficial way. 
Source: http://noblat.oglobo.globo.com/geral/noticia/2017/04/justica-absolve-vaccari-e-mais-11-em-caso-bancoop.html


</doc>
<doc id="3605313" url="https://en.wikipedia.org/wiki?curid=3605313" title="No-go area">
No-go area

A "no-go area" (or "no-go zone") is an area in a town barricaded off to civil authorities by a force such as a paramilitary, or an area barred to certain individuals or groups. The term has also been used to refer to areas:


Some types of no-go zones, such as military exclusion zones, border zones, or other declared exclusion zones, may have a legal basis. "De facto" no-go zones may arise in conjunction with inadequate local governance or tactical advantage. The boundaries of "de facto" no-go zones are volatile and responsive to changes in security and tactical advantage. No-go zone boundaries can be negotiated between hostile parties or declared unilaterally by one side of a conflict. Other no-go zones are undeclared or unofficial, making accurate boundary identification difficult. No-go zones in which rescue or security services are unavailable enable unrestricted lethal violence.

With no government enforcement from the British colonial government aside from a few raids by the Hong Kong Police, the Kowloon Walled City became a haven for crime and drugs. It was only during a 1959 trial for a murder that occurred within the Walled City that the Hong Kong government was ruled to have jurisdiction there. By this time, however, the Walled City was virtually ruled by the organised crime syndicates known as Triads. Beginning in the 1950s, Triad groups such as the 14K and Sun Yee On gained a stranglehold on the Walled City's countless brothels, gambling parlors, and opium dens. The Walled City had become such a haven for criminals that police would venture into it only in large groups.

See Rebel Zapatista Autonomous Municipalities

During the Mozambican War of Independence, the Mozambique Liberation Front (FRELIMO) set up and defended no-go "liberated zones" in the north of the country.

During the Troubles, the term was applied to urban areas in Northern Ireland where the Royal Ulster Constabulary (RUC) and British Army could not operate openly. Between 1969 and 1972, Irish nationalist/republican neighborhoods in Belfast and Derry were sealed off with barricades by residents. The areas were policed by vigilantes and both Official and Provisional factions of the Irish Republican Army (IRA) operated openly. The most notable no-go area was called Free Derry.

The areas' existence was a challenge to the authority of the British government. On 31 July 1972, the British Army demolished the barricades and re-established control in Operation Motorman. It was the biggest British military operation since the Suez Crisis. Although the areas were no longer barricaded, they remained areas where the British security forces found it difficult to operate and were regularly attacked. As a result, they entered only in armored convoys and in certain circumstances, such as to launch house raids. Police presence in these areas remained contentious into the 2000s and the main republican political party, Sinn Féin, refused to support the police. In 2007, however, the party voted to support the new Police Service of Northern Ireland (PSNI).

The Federally Administered Tribal Areas (FATA) were in actuality no-go areas for the Pakistani authorities, where the Pakistani police could not enter. The situation was changed temporarily with the United States invasion of Afghanistan in 2001, when the Pakistani government was supported by U.S. military forces. Currently FATA is no more a "no-go area" as it has been merged with the Khyber Pakhtunkhwa province.

The term "no-go area" has a military origin and was first used in the context of the Bush War in Rhodesia. The war was fought in the 1960s and 1970s between the army of the predominantly white minority Rhodesian government and communist-backed black nationalist groups.

The initial military strategy of the government was to seal the borders to prevent assistance to the guerrillas from other countries. However, with the end of Portuguese colonial rule in Angola and Mozambique, and especially the arrival of some 500,000 Cuban armed forces and tens of thousands of Soviet troops, this became untenable and the white minority government adopted an alternative strategy ("mobile counter offensive"). This involved defending only key economic areas, transport links ("vital asset ground"), and the white civilian population. The government lost control of the rest of the country to the guerilla forces, but carried out counter-guerilla operations including "free-fire attacks" in the so-called "no-go areas," where white civilians were advised not to go.

After the 1980 Turkish coup d'état, the Turkish communist guerillas established "liberated" no-go zones.

In 2013, the Venezuelan government negotiated with large criminal gangs on how to prevent violence and agreed to avoid policing gang territory in what were known as "peace zones", reinforcing criminal behaviors and making gang practices "de facto" law. According to InSight Crime, there are over a dozen mega-gangs in Venezuela, with some having up to 300 members.

The following are areas that have been described as no-go areas in recent years, though in some cases the characterization has been disputed.

In the wake of the 2015 Paris attacks, the Molenbeek municipality in Brussels was described in many media reports as a "no-go area", where gang violence and Islamic fundamentalism had fed on Molenbeek's marginalisation, despair and festering resentment of authority. In 2015 Belgium's home affairs minister said that the government did not "have control of the situation in Molenbeek" and that terrorists' links to this district were a "gigantic problem". Other academics, commentators, journalists and residents have contested the description of Molenbeek as a no-go zone.

Some slum areas (known as "favelas") in Brazil, most notably in Rio de Janeiro, are controlled by gangs with automatic weapons. Police and investigative reporters have been tortured and killed there, such as Tim Lopes in 2002. Attempts at clearing up such areas have led to security crises in Rio as well as in São Paulo.

An early usage of the term regarding Europe was in a 2002 opinion piece by David Ignatius in "The New York Times", where he wrote about France, "Arab gangs regularly vandalize synagogues here, the North African suburbs have become no-go zones at night, and the French continue to shrug their shoulders." La Courneuve, a municipality (commune) in the Paris region, was described by police as a no-go zone.

In 2010, Raphaël Stainville of French newspaper "Le Figaro" called certain neighborhoods of the southern city Perpignan "veritable lawless zones", saying they had become too dangerous to travel in at night. He added that the same was true in parts of Béziers and Nîmes. In 2012, , the mayor of the French city Amiens, in the wake of several riots, called the northern part of his city a lawless zone, where one could no longer order a pizza or call for a doctor. In 2014, Fabrice Balanche, a scholar of the Middle East, labelled the northern city of Roubaix, as well as parts of Marseille, "mini-Islamic states", saying that the authority of the state is completely absent there. American magazines "Newsweek" and "The New Republic" have also used the term to describe parts of France.

In January 2015, after the "Charlie Hebdo" shooting in Paris, various American media, including the news cable channels Fox News and CNN, described the existence of no-go zones across Europe and in France in particular. In some cases, the French areas termed "sensitive urban zones" were described as no-go zones. Both networks were criticized for these statements, and anchors on both networks later apologized for the characterizations. The mayor of Paris, Anne Hidalgo, said that she intended to sue Fox News for its statements.

A sociology paper published in 2009 said that right-wing extremists had been discussing the creation of no-go areas in Western Europe since the 1980s. It described attempts to create "national liberated zones" ("national befreite Zonen") in Germany: "'no-go-areas', which are areas dominated by neo-Nazis," attributing their appeal in the former DDR to "the unmet promises of modernisation and the poor socio-cultural conditions that offer no perspectives to young people". Whether or not Germany actually had no-go zones was disputed: the paper concluded "according to ... state officials, the police and other relevant institutions, [the phenomenon of no-go zones] does not actually exist ... by contrast, the national press in Germany, various civic associations, and also experts acknowledge and give examples of the existence of no-go areas."

In a 2011 interview, , then president of the German police union Gewerkschaft der Polizei (GdP), stated that in some areas police would always respond to alerts with more than two officers because of concerns of policemen to become target of crime themselves. In 2016, Rainer Wendt head of the smaller Deutsche Polizeigewerkschaft (DPolG) stated that areas exist where police "hardly dare to stop a car [...] Because they know that they'll be surrounded by 40 or 50 men". In 2017, Wendt warned that Germany faced a risk of "police-free zones in Germany".

In a February 2018 interview, German Chancellor Angela Merkel stated that there are no-go areas in Germany, saying, "There are such areas and one has to call them by their name and do something about them." This came in the context of arguing for a zero-tolerance policy in German policing. It appeared to be the first time that a German government politician had stated that no-go areas exist in the country.

In Kenya, the ongoing conflict in Somalia, where the terrorist organization al-Shabaab controls territory, has severely affected the security situation even on the Kenyan side of the border. There have been terrorist attacks and kidnappings in Kenya followed by a Kenyan intervention, Operation Linda Nchi, and police crackdowns. These have affected counties bordering Somalia and in Nairobi, the suburb of Eastleigh, which is inhabited mostly by Somalis. The U.S. government prohibits its personnel from traveling to the counties bordering Somalia: Mandera, Wajir and Garissa and Tana River County, Lamu county and Kilifi county north of Malindi. The area has been called a "no-go zone for travellers" because of terrorism and internal conflicts. Already in 2004, Eastleigh was described as a no-go zone for Kenyan authorities after dark. In 2012, in travel advisories issued by the U.S. and U.K. governments, Eastleigh was temporarily declared a no-go zone because of bombings and ongoing conflict.

The Israeli Defence Forces (IDF) maintains a border zone on the Gaza strip and declares "no-go zones", where they may use lethal force to enforce the security exclusion zone. An IDF spokesman said that "residents of the Gaza Strip are required not to come any closer than 300 meters from the security fence", although there is some allowance for farmers to approach up to 100 meters if they do so on foot only. The United Nations Office for the Coordination of Humanitarian Affairs said that the no-go zones include about 30% of the arable land in the Gaza strip, and a small number of residents farm in the exclusion zones despite the risk of military action. Unlike a legal border zone, the no-go zone is declared unilaterally in occupied territory, without acknowledgement or cooperation of Palestinian authorities, and as such can be considered a disputed no-go zone. It is considered unlawful by the Swedish organization Diakonia.

The Gaya Island is a location of an illegal Filipino colony, called "Kampung Lok Urai", with stilt houses girdling the beach. Both the Malaysian federal government and the Sabah state government do not officially recognise the settlement and the inhabitants as the inhabitants are known as illegal immigrants. It has a 6,000 floating population of largely Filipinos Suluk and Bajau. It is considered a dangerous, high crime or "no-go" area by the police and the locals.

The term "no-go zone" has been informally applied to high-crime neighborhoods in South African cities. In South Africa, the apartheid policy created segregated neighborhoods where whites risked being removed or victimized in black-only neighborhoods and vice versa. Because of the bantustan system, many urban inhabitants lived in the city illegally per apartheid laws. For example, in Cape Town, Cape Flats was a neighborhood where many of those evicted were relocated. It became a "no-go area" as it was controlled by criminal gangs. However, many of these areas have experienced significant gentrification; for example, Woodstock in Cape Town has experience significant urban renewal and cannot be described as a no-go zone anymore. Nevertheless, MiX Telematics uses the term "no-go zones" to warn drivers of the risk of carjacking and other crime in its proprietary Matrix vehicle tracking software.
In 2010, a housing complex comprising a number of city blocks in Atlantis, Western Cape were described as a "no-go zone for police conducting raids", and ambulances could not enter without police escort. In 2014, the situation had improved, and after convictions of several gang members, a police official said that "legislation concerning organised crime was beginning to work". In 2018, a gang war in Parkwood, Cape Town was reported to turn the area into a "no-go zone", although a minister visited the area to ensure policing continues.

Some urban areas in Sweden have been called no-go zones. The Swedish government states that "no-go zones", where "criminality and gangs have taken over and where the emergency services do not dare to go" do not exist. They acknowledge that there are areas "increasingly marred by crime, social unrest and insecurity".

A 2016 report from the Swedish Police mapped 53 "exposed" areas (Utsatta områden) and 15 "particularly exposed" areas. An "exposed area" was defined as an area with low socioeconomic status and high crime. A "particularly exposed" area was defined as an area nearby to an "exposed area" the inhabitants of which demonstrated the following qualities: 


Swedish police protocol differs for working in these areas. For example, the police bring certain equipment and work in pairs when in a "particularly exposed area".

In a 2017 interview with the conservative opinion magazine "Weekly Standard"'s , Gordon Grattidge, the head of the Swedish ambulance drivers' union, stated that there were some areas too dangerous for rescue workers to enter without police protection, using the English term "no-go zones" to describe them.

In March 2015, journalist Henrik Höjer discussed the rise of criminality, especially organized crime, in various neighborhoods within Sweden since the mid-1990s, especially in the city of Malmö. He interviewed a police officer and task force chief who referred to such areas as "no go areas" and wrote that gangs like to lay claim to an area by throwing stones at mailmen, police, firefighters and ambulances who enter the area.

In February 2016, a news crew for "Australia's 60 Minutes" working with anti-immigration activist Jan Sjunnesson reported having come under attack, including allegedly having stones thrown on them and a car running over the foot of a cameraman who was trying to prevent it from leaving in the immigrant-dominated district of Rinkeby of Stockholm. "60 Minutes" published the video, on which reporter Liz Hayes says "there are now 55 declared no-go zones in Sweden."

A 10-minute December 2016 film by FoxNews.com's Ami Horowitz, "Stockholm Syndrome", focused on violence by Muslim immigrants within Sweden, and included an interview with two policemen who seemed to confirm that there are no-go areas for police in Sweden. During the interview, one officer states, "If the police is chasing another car for some kind of crime, if they reach what we call 'no-go areas', the police won't go after it." The police officers later objected to the interview and said that their quotes had been taken out of context, and a videographer who worked on the film supported the officers' account, saying the video was cut together unethically. The documentary gained significant attention several months later when U.S. President Donald Trump indirectly alluded to it in a speech. The film as a whole, and its description of no-go areas, have both been disputed by sources within Sweden; the Swedish "The Local" quoted a police spokesperson as saying that, though there are areas "characterized by, among other things, the difficulty for the police to fulfill its duty", "There are no guidelines that the police should not visit these areas". The description of no-go zones was also disputed by several sources, including the interviewed policemen.

Around the time of the 2001 Oldham riots, BBC Radio 4 reporter Barnie Choudhury wrote "An investigation for "Today" has found disturbing evidence that Asian youths in parts of Oldham are trying to create no go areas for white people...It's not clear whether this is bravado but their message is blunt... white people keep out". 

In 2012, Professor Hamid Ghodse of the United Nations' International Narcotics Control Board included areas of Birmingham, Manchester and Liverpool as "no-go areas" run by drug traffickers, comparing them to Brazilian favelas. Local police forces denied the claims. In 2015 Donald Trump, in the early stages of his presidential campaign, stated on Twitter that the UK was trying to "disguise [its] massive Muslim problem", and retweeted an article which falsely claimed that the city of Birmingham was totally under Muslim control. These remarks were condemned by the mayor of Birmingham.

These claims, especially about London, continue to echo on social media typically accompanied by claims of "Sharia Law" being imposed in several neighbourhoods. Articles ridiculing these claims have appeared in the media. Other ironic responses have pointed out that no-go zones exist in London, including 10 Downing Street and Buckingham Palace.

The group Falmouth Hates Students have declared the town of Falmouth, Cornwall a no-go zone for students.

Articles have appeared in "The Atlantic" and "Business Week" magazines, Media Matters for America, and Snopes.com including criticism of the use term "no-go zone" to refer to areas claimed to operate under Sharia Law in Europe or the US.



</doc>
<doc id="10035514" url="https://en.wikipedia.org/wiki?curid=10035514" title="Intimate partner violence">
Intimate partner violence

Intimate partner violence (IPV) is domestic violence by a current or former spouse or partner in an intimate relationship against the other spouse or partner. IPV can take a number of forms, including physical, verbal, emotional, economic and sexual abuse. The World Health Organization (WHO) defines IPV as "... any behaviour within an intimate relationship that causes physical, psychological or sexual harm to those in the relationship, including acts of physical aggression, sexual coercion, psychological abuse and controlling behaviors."

The most extreme form of such violence may be termed "battering", "intimate terrorism", "coercive controlling violence", or simply "coercive control", in which one person is violent and controlling; this is generally perpetrated by men against women, and is the most likely of the types to require medical services and the use of a women's shelter. Subsequently, resistance to intimate terrorism, which is a form of self-defense and may be termed "violent resistance", is usually conducted by women. Studies on domestic violence against men suggest that men are less likely to report domestic violence perpetrated by their female intimate partners.

The most common but less injurious form of intimate partner violence is "situational couple violence" (also known as "situational violence"), which is conducted by individuals of both genders nearly equally, and is more likely to occur among younger couples, including adolescents (see teen dating violence) and those of college age. A last form of violence, in which both partners in the relationship engage in controlling and violent behavior, is called "mutual violent control".

Intimate partner violence occurs between two people in an intimate relationship. It may occur between heterosexual or homosexual couples and victims can be male or female. Couples may be dating, cohabiting or married and violence can occur in or outside of the home.

Studies in the 1990s showed that both men and women could be abusers or victims of domestic violence. Women are more likely to act violently in retaliation or self-defense and tend to engage in less severe forms of violence than men whereas men are more likely to commit long-term cycles of abuse than women.

The World Health Organization (WHO) defines intimate partner violence as "any behaviour within an intimate relationship that causes physical, psychological or sexual harm to those in the relationship". The WHO also adds controlling behaviors as a form of abuse.

According to a study conducted in 2010, 30% of women globally aged 15 and older have experienced physical and/or sexual intimate partner violence.

The WHO reported in 2013 that the incidence of women who had experienced physical or sexual abuse from an intimate partner in their lifetime was:

The U.S. Preventive Services Task Force (USPSTF) as of 2018 recommends screening women of reproductive age.

Some of the most studied IPV screening tools were the Hurt, Insult, Threaten, and Scream (HITS), the Woman Abuse Screening Tool/Woman Abuse Screening Tool-Short Form (WAST/WAST-SF), the Partner Violence Screen (PVS), and the Abuse Assessment Screen (AAS).

The HITS is a four-item scale rated on a 5-point Likert scale from 1 (never) to 5 (frequently). This tool was Initially developed and tested among family physicians and family practice offices, and since then has been evaluated in diverse outpatient settings. Internal reliability and concurrent validity are acceptable. Generally, sensitivity of this measure has found to be lower among men than among women.

The WAST is an eight-item measure (there is a short form of the WAST that consists of the first two items only). It was originally developed for family physicians, but subsequently has been tested in the emergency department. It has been found to have good internal reliability and acceptable concurrent validity.

The PVS is a three-item measure scored on a yes/no scale, with positive responses to any question denoting abuse. It was developed as a brief instrument for the emergency department.

The AAS is a five-item measure scored on a yes/no scale, with positive responses to any question denoting abuse. It was created to detect abuse perpetrated against pregnant women. The screening tool has been tested predominantly with young, poor women. It has acceptable test retest reliability.

The probably most widely used instrument in research on family violence is the Conflict Tactics Scale (CTS). Two versions have been developed from the original CTS: the CTS2 (an expanded and modified version of the original CTS) and the CTSPC (CTS Parent-Child).

Michael P. Johnson argues for four major types of intimate partner violence (also known as "Johnson's typology"), which is supported by subsequent research and evaluation, as well as independent researchers. Distinctions are made among the types of violence, motives of perpetrators, and the social and cultural context based upon patterns across numerous incidents and motives of the perpetrator. The United States Centers for Disease Control (CDC) also divides domestic violence into types.<ref name="10.2105/AJPH.2005.079020"></ref> Elaine Storkey in her comprehensive analysis, Scars Across Humanity IVP Academic 2018, argues that intimate partner violence is one aspect of a global manifestation of violence against women. Other examples she cites are selective abortion, female genital mutilation, early, enforced marriage, honour killings, rape, trafficking, prostitution and sexual violence in war.

Intimate terrorism, or coercive controlling violence (CCV), occurs when one partner in a relationship, typically a man, uses coercive control and power over the other partner, using threats, intimidation, and isolation. CCV relies on severe psychological abuse for controlling purposes; when physical abuse occurs it too is severe. In such cases, "[o]ne partner, usually a man, controls virtually every aspect of the victim's, usually a woman's, life." Johnson reported in 2001 that 97% of the perpetrators of intimate terrorism were men.

Intimate partner violence may involve sexual, sadistic control, economic, physical, emotional and psychological abuse. Intimate terrorism is more likely to escalate over time, not as likely to be mutual, and more likely to involve serious injury. The victims of one type of abuse are often the victims of other types of abuse. Severity tends to increase with multiple incidents, especially if the abuse comes in many forms. If the abuse is more severe, it is more likely to have chronic effects on victims because the long-term effects of abuse tend to be cumulative. Because this type of violence is most likely to be extreme, survivors of intimate terrorism are most likely to require medical services and the safety of shelters. Consequences of physical or sexual intimate terrorism include chronic pain, gastrointestinal and gynecological problems, depression, post-traumatic stress disorder, and death. Other mental health consequences are anxiety, substance abuse, and low-self esteem.

Abusers are more likely to have witnessed abuse as children than those who engage in situational couple violence.

Intimate terrorism batterers include two types: "Generally-violent-antisocial" and "dysphoric-borderline". The first type includes people with general psychopathic and violent tendencies. The second type includes people who are emotionally dependent on the relationship. Violence by an individual against their intimate partner is often done as a way for controlling the partner, even if this kind of violence is not the most frequent.

Violent resistance (VR), a form of self-defense, is violence perpetrated by victims against their partners who have exerted intimate terrorism against them. Within relationships of intimate terrorism and violent resistance, 96% of the violent resisters are women. VR can occur as an instinctive reaction in response to an initial attack or a defense mechanism after prolonged instances of violence. This form of resistance can sometimes become fatal if the victim feels as though their only way out is to kill their partner.

Situational couple violence, also called common couple violence, is not connected to general control behavior, but arises in a single argument where one or both partners physically lash out at the other. This is the most common form of intimate partner violence, particularly in the western world and among young couples, and involves members of both sexes nearly equally. Among college students, Johnson found it to be perpetrated about 44% of the time by women and 56% of the time by men.

Johnson states that situational couple violence involves a relationship dynamic "in which conflict occasionally gets 'out of hand,' leading usually to 'minor' forms of violence, and rarely escalating into serious or life-threatening forms of violence."

In situational couple violence, acts of violence by men and women occur at fairly equal rates, with rare occurrences of injury, and are not committed in an attempt to control a partner. It is estimated that approximately 50% of couples experience situational couple violence in their relationships.

Situational couple violence involves:


Mutual violent control (MVC) is rare type of intimate partner violence occurring when both partners act in a violent manner, battling for control.

The CDC divides domestic violence into two types: reciprocal, in which both partners are violent, and non-reciprocal violence, in which one partner is violent. Of the four types, situational couple violence and mutual violent control are reciprocal, while intimate terrorism is non-reciprocal. Violent resistance on its own is non-reciprocal, but is reciprocal when in response to intimate terrorism.

In the 1970s and 1980s, studies using large, nationally representative samples resulted in findings indicating that women were as violent as men in intimate relationships. This information diverged significantly from shelter, hospital, and police data, initiating a long-standing debate, termed "the gender symmetry debate". One side of this debate argues that mainly men perpetrate IPV (the gender asymmetry perspective), whereas the other side maintains that both genders perpetrate IPV at about equal rates (gender symmetry perspective). However, research on gender symmetry acknowledges asymmetrical aspects of IPV, which show that men use more violent and often deadly means of IPV. Older conflict tactics scale (CTS) methodology was criticized for excluding two important facets in gender violence: conflict-motivated aggression and control-motivated aggression. For example, women commonly engage in IPV as a form of self-defense or retaliation. Research has shown that the nature of the abuse inflicted by women upon male partners is different from the abuse inflicted by men, in that it is generally not used as a form of control and does not cause the same levels of injury or fear of the abusive partner. Scholars state these cases should not be generalized and each couple's specificities must be assessed.

While both women and men can be victims and perpetrators of IPV, the majority of such violence is inflicted upon women, who are also much more likely to suffer injuries as a result, in both heterosexual and same-sex relationships. Although men and women commit equivalent rates of unreported minor violence via situational altercation, more severe perpetration and domestic battery tends to be committed by men. This is based on newer CTS methodology as opposed to older versions that did not take into account the contexts in which violence takes place. A 2008 systematic review published in journal of "Violence and Victims" found that despite less serious altercation or violence being equal among both genders, more serious and violent abuse was perpetrated by men. It was also found that women's use of physical violence was more likely motivated by self-defense or fear whereas men's use of violence was motivated by control. A 2010 systematic review published in the journal of "Trauma Violence Abuse" found that the common motives for female on male IPV were anger, a need for attention, or as a response to their partner's violence. A 2011 review published in the journal of "Aggression and Violent behavior" found differences in the methods of abuse employed by men and women, suggesting that men were more likely to "beat up, choke or strangle" their partners, whereas women were more likely to "throw something at their partner, slap, kick, bite, punch, or hit with an object".

Researchers such as Michael S Kimmel have criticized CTS methodology in assessing relations between gender and domestic violence. Kimmel argued that the CTS excluded two important facets in gender violence: conflict-motivated aggression and control motivated aggression. The first facet is a form of family conflict (such as an argument) while the latter is using violence as a tool for control. Kimmel also argued that the CTS failed to assess for the severity of the injury, sexual assaults and abuse from ex-partners or spouses.

Women generally suffer more severe and long-lasting forms of partner abuse than men, and men generally have more opportunities to leave an abusive partner than women do. Researchers have found different outcomes in men and women in response to such abuse. A 2012 review from the journal "Psychology of Violence" found that women suffered from over-proportionate numbers of injuries, fear, and posttraumatic stress as a result of partner violence. The review also found that 70% of female victims felt frightened as a result of violence perpetrated by their partners whereas 85% of male victims expressed "no fear" in response to such violence. Lastly, IPV correlated with relationship satisfaction for women but it did not do so for men.

According to government statistics from the US Department of Justice, male perpetrators constituted 96% of federal prosecution on domestic violence. Another report by the US department of Justice on non-fatal domestic violence from 2003–2012 found that 76% of domestic violence was committed against women and 24% was committed against men. According to the United Nations Office on Drugs and Crime, the percentage of victims killed by their spouses or ex-spouses was 77.4% for women and 22.6% for men in selected countries across Europe.

Globally, men's perpetration of intimate partner violence against women often stems from conceptions of masculinity and patriarchy. Studies done in the United States, Nigeria, and Guatemala all support the idea of men reacting violently towards their partners when their masculinity is threatened by changing gender roles.

The theory that women perpetrate intimate partner violence (IPV) at roughly the same rate as men has been termed "gender symmetry." The earliest empirical evidence of gender symmetry was presented in the 1975 U.S. National Family Violence Survey carried out by Murray A. Straus and Richard J. Gelles on a nationally representative sample of 2,146 "intact families." The survey found 11.6% of men and 12% of women had experienced some kind of IPV in the last twelve months, while 4.6% of men and 3.8% of women had experienced "severe" IPV.

These unexpected results led Suzanne K. Steinmetz to coin the controversial term "battered husband syndrome" in 1977. Ever since the publication of Straus and Gelles' findings, other researchers into domestic violence have disputed whether gender symmetry really exists. Sociologist Michael Flood writes, "there is no 'gender symmetry' in domestic violence; there are important differences between men's and women's typical patterns of victimization; and domestic violence represents only a small proportion of the violence to which men are subject".

Other empirical studies since 1975 suggest gender symmetry in IPV. Empirical studies suggest rates of perpetration remain symmetrical for both minor and severe abuse. This result may be due to a bi-directional or reciprocal pattern of abuse, with one study concluding that 70% of assaults involve mutual acts of violence. A 2011 meta-analyses by Straus, of 200 studies, indicated that men and women commit IPV against each other at the same rate. One reason that data may appear to reflect that men and women equally commit intimate partner violence is that women frequently engage in violent resistance as a means of self-defense against their violent male partners. A 2010 systematic review of the literature on women's perpetration of IPV, however, found that distinguishing between self-defense and retaliation was difficult.

A 2013 review examined studies from five continents and the correlation between a country's level of gender inequality and rates of domestic violence. The authors found that when partner abuse is defined broadly to include emotional abuse, any kind of hitting, and who hits first, partner abuse is relatively even. They also stated if one examines who is physically harmed and how seriously, expresses more fear, and experiences subsequent psychological problems, domestic violence is significantly gendered toward women as victims.

Sexual violence by intimate partners varies by country and can reach as high as 25% of the women having been subject to forced sex. In some countries forced sex, or marital rape, often occurs with other forms of domestic violence, particularly physical abuse.

Due to the high prevalence and devastating consequences of IPV, approaches to decrease and prevent violence from re-occurring is of upmost importance. Initial police response and arrest is not always enough to protect victims from recurrence of abuse; thus, many states have mandated participation in batterer intervention programs (BIPs) for men who have been charged with assault against an intimate partner. Most of these BIPs are based on the Duluth Model and incorporate some cognitive behavioral techniques.

The Duluth model is one of the most common current interventions for IPV. It represents a psycho-educational approach that was developed by paraprofessionals from information gathered from interviewing battered women in shelters and using principles from feminist and sociological frameworks. One of the main components used in the Duluth Model is the 'power and control wheel,' which conceptualizes IPV as one form of abuse to maintain male privilege. Using the 'power and control wheel,' the goal of treatment is to achieve behaviors that fall on the 'equality wheel' by re-educate men and by replacing maladaptive attitudes held by men.

Cognitive behavioral therapy (CBT) techniques focus on modifying faulty or problematic cognitions, beliefs, and emotions to prevent future violent behavior and include skills training such as anger management, assertiveness, and relaxation techniques.

Overall, the addition of Duluth and CBT approaches results in a 5% reduction in IPV. This low reduction rate might be explained, at least in part, by the high prevalence of bidirectional violence as well as client-treatment matching versus “one-size-fits-all” approaches.

Achieving change through values-based behavior (ACTV) is a newly developed Acceptance and Commitment Therapy (ACT)-based program. Developed by domestic violence researcher Amie Zarling and colleagues at Iowa State University, the aim of ACTV is teach abusers "situational awareness"—to recognize and tolerate uncomfortable feelings – so that they can stop themselves from exploding into rage.

Initial evidence of the ACTV program has shown high promise: Using a sample 3,474 men who were arrested for domestic assault and court-mandated to a BIP (either ACTV or Duluth/CBT), Zarling and colleagues showed that compared with Duluth/CBT participants, significantly fewer ACTV participants acquired any new charges, domestic assault charges, or violent charges. ACTV participants also acquired significantly fewer charges on average in the 1 year after treatment than Duluth/CBT participants.

Some estimates show that as many as 50% of couples who experience IPV engage in some form of reciprocal violence. Nevertheless, most services address offenders and survivors separately. In addition, many couples who have experienced IPV decide to stay together. These couples may present to couples or family therapy. In fact, 37-58% of couples who seek regular outpatient treatment have experienced physical assault in the past year. In these cases, clinicians are faced with the decision as to whether they should accept or refuse to treat these couples. Although the use of conjoint treatment for IPV is controversial as it may present a danger to victims and potentially escalate abuse, it may be useful to others, such as couples experiencing situational couple violence. Scholars and practitioners in the field call for tailoring of interventions to various sub-types of violence and individuals served.

Behavioral couple's therapy (BCT) is cognitive-behavioral approach, typically delivered to outpatients in 15-20 sessions over several months. Research suggests that BCT can be effective in reducing IPV when used to treat co-occurring addictions, which is important work because IPV and substance abuse and misuse frequently co-occur.

Domestic conflict containment program (DCCP) is a highly structured skills-based program whose goal is to teach couples conflict containment skills.

Physical aggression couples treatment (PACT) is a modification of DCCP, which includes additional psychoeducational components designed to improve relationship quality, including such things as communication skills, fair fighting tactics, and dealing with gender differences, sex, and jealousy.

The primary goal of domestic violence focused couples treatment (DVFCT) is to end violence with the additional goal of helping couples improve the quality of their relationships. It is designed to be conducted over 18 weeks and can be delivered in either individual or multi-couple group format.




</doc>
<doc id="28307" url="https://en.wikipedia.org/wiki?curid=28307" title="Sin">
Sin

In a religious context, sin is an act of transgression against divine law. In Islamic ethics, Muslims see sin as anything that goes against the commands of Allah (God). Judaism regards the violation of any of the 613 commandments as a sin.

Sin can also be viewed as any thought or action that endangers the ideal relationship between an individual and God; or as any diversion from the perceived ideal order for human living. In Jainism, sin refers to anything that harms the possibility of the "jiva" (being) to attain "moksha" (supreme emancipation).

The word derives from "Old English "syn(n)", for original *"sunjō". The stem may be related to that of Latin '"sons", "sont-is"' guilty. In Old English there are examples of the original general sense, ‘offence, wrong-doing, misdeed'". The English Biblical terms translated as "sin" or "syn" from the Biblical Greek and Jewish terms sometimes originate from words in the latter languages denoting the act or state of missing the mark; the original sense of New Testament Greek "hamartia" "sin", is failure, being in error, missing the mark, especially in spear throwing; Hebrew "hata" "sin" originates in archery and literally refers to missing the "gold" at the centre of a target, but hitting the target, i.e. error. "To sin" has been defined from a Greek concordance as "to miss the mark".

In the Bahá'í Faith, humans are considered naturally good (perfect), fundamentally spiritual beings. Human beings were created because of God's immeasurable love. However, the Bahá'í teachings compare the human heart to a mirror, which, if turned away from the light of the sun (i.e. God), is incapable of receiving God's love.

There are a few differing Buddhist views on sin. American Zen author Brad Warner states that in Buddhism there is no concept of sin at all. The Buddha Dharma Education Association also expressly states "The idea of sin or original sin has no place in Buddhism."

Ethnologist Christoph von Fürer-Haimendorf explained,
However, Anantarika-kamma in Theravada Buddhism is a heinous crime, which through karmic process brings immediate disaster. In Mahayana Buddhism these five crimes are referred to as pañcānantarya (Pāli), and are mentioned in "The Sutra Preached by the Buddha on the Total Extinction of the Dharma", The five crimes or sins are:

The doctrine of sin is central to Christianity, since its basic message is about redemption in Christ. Christian hamartiology describes sin as an act of offence against God by despising his persons and Christian biblical law, and by injuring others. In Christian views it is an evil human act, which violates the rational nature of man as well as God's nature and his eternal law. According to the classical definition of St. Augustine of Hippo sin is "a word, deed, or desire in opposition to the eternal law of God."

Among some scholars, sin is understood mostly as legal infraction or contract violation of non-binding philosophical frameworks and perspectives of Christian ethics, and so salvation tends to be viewed in legal terms.

Other Christian scholars understand sin to be fundamentally relational—a loss of love for the Christian God and an elevation of self-love ("concupiscence", in this sense), as was later propounded by Augustine in his debate with the Pelagians. As with the legal definition of sin, this definition also affects the understanding of Christian grace and salvation, which are thus viewed in relational terms.

Original sin, also called ancestral sin, is a Christian belief in the state of sin in which humanity has existed since the fall of man, stemming from Adam and Eve's rebellion in Eden, namely the sin of disobedience in consuming the forbidden fruit from the tree of the knowledge of good and evil.

This condition has been characterized in many ways, ranging from something as insignificant as a slight deficiency, or a tendency toward sin yet without collective guilt, referred to as a "sin nature", to something as drastic as total depravity or automatic guilt of all humans through collective guilt.

The concept of original sin was first alluded to in the 2nd century by Irenaeus, Bishop of Lyon in his controversy with certain dualist Gnostics. Other church fathers such as Augustine also shaped and developed the doctrine, seeing it as based on the New Testament teaching of Paul the Apostle (Romans and 1 Corinthians ) and the Old Testament verse of Psalms . Tertullian, Cyprian, Ambrose and Ambrosiaster considered that humanity shares in Adam's sin, transmitted by human generation. Augustine's formulation of original sin after 412 CE was popular among Protestant reformers, such as Martin Luther and John Calvin, who equated original sin with concupiscence (or "hurtful desire"), affirming that it persisted even after baptism and completely destroyed freedom to do good. Before 412 CE, Augustine said that free will was weakened but not destroyed by original sin. But after 412 CE this changed to a loss of free will except to sin. Modern Augustinian Calvinism holds this later view. The Jansenist movement, which the Catholic Church declared to be heretical, also maintained that original sin destroyed freedom of will. Instead the Catholic Church declares "Baptism, by imparting the life of Christ's grace, erases original sin and turns a man back towards God, but the consequences for nature, weakened and inclined to evil, persist in man and summon him to spiritual battle." "Weakened and diminished by Adam's fall, free will is yet not destroyed in the race."

In Hinduism, sin ( "" "vice") describes actions that create negative karma by violating moral and ethical codes, which automatically brings negative consequences. This is somewhat similar to Abrahamic sin in the sense that "pāpa" is considered a crime against the laws of God, which is known as dharma, or moral order, and one's own self, but another term "aparadha" is used for grave offences.

However, the term "papa" cannot be taken in the literal sense as sin because there is no consensus regarding the nature of ultimate reality or God in Hinduism. Only, the Vedanta school being unambiguously theistic, whereas no anthropomorphic God exists in the rest of the five schools, Samkhya, Nyaya, Yoga, Vaisheshika, and Mīmāṃsā. The term "papa" however in the strictest sense refers to actions which bring about wrong/unfavourable consequences, not relating to a specific divine will in the absolute sense.

Sin is an important concept in Islamic ethics. Muslims see sin as anything that goes against the commands of Allah (God), a breach of the laws and norms laid down by religion. Islam teaches that sin is an act and not a state of being. It is believed that Allah weighs an individual’s good deeds and against his or her sins on the "Yawm ad-Din" (Day of Judgement) and punishes those individuals whose evil deeds outweigh their good deeds. These individuals are thought to be sentenced to afterlife in the fires of "jahannum" (Hell).

Islamic terms for sin include "dhanb" and "khaṭīʾa", which are synonymous and refer to intentional sins; "khiṭʾ", which means simply a sin; and "ithm", which is used for grave sins.

In Jainism, the word for sin is the Sanskrit word पाप ("paap"), which is the antithesis of पुण्य ("punya") meaning merit.

A "jiva" ("atman" or soul) accumulates karma if it resorts to violence, non-chastity, falsehood, stealing, and possessiveness, if it hurts anyone, causes someone to hurt anyone, or commends hurting anyone by thought, speech or action. A "jiva" ceases to accumulate karma if it resorts to the "ratnatraya" (triple gems of Jainism): "samyak gyan" (right knowledge), "samyak darshan" (right sight) and "samyak charitra" (right character). A "jiva" begins to shed the accumulated karma by resorting to penance, repentance, vows and by exterminating foes of lust, anger, attachment, aversion, ignorance and fallacy.

No "jiva" can achieve "moksha" (release from "samsara", the cycle of death and rebirth) without ceasing to accumulate karma and shedding the already accumulated karma entirely. Thus such a "jiva" is bound to remain in the worldly cycle of constant reincarnation, wherein it will keep taking rebirths, into any of the four broad types of living organisms, depending on the magnitude and nature of karma accumulated in previous birth(s). The four types are "dev" (beings of heaven, including deities), "manushya" (human), " tiryanch" (plants, animals, insects, etc.) and "naarki" (beings of hell).

During this cycle of getting born and dying for infinity, the "jiva" will have to then live the life of the organism he is and while living it, the "jiva" will again accumulate more karma. This will again lead to rebirth and again accumulating more karma. Thus, the cycle continues.

Jains believe that for complete liberation, not only the "sinful karma" but even the "meritorious karma" needs to be shed off. This means that a "jiva" can truly attain "moksha" only if the soul is completely and absolutely pure and devoid of any accumulation. For instance, sins may cause the "jiva" to be reborn in "naraka" (hell) and merits may cause it to be reborn in heaven. But heaven, like hell, is a part of worldly cycle of reincarnation and not supreme "moksha" of the soul. Thus, if a person hypothetically keeps performing only and exclusively good deeds in his life, he may still not attain "moksha", because he has not yet shed off previously accumulated sins through repentance and knowledge.

Jains believe that only a human "jiva" has the capacity and the will to attain "moksha". Hence the "jiva" should use this extremely rare opportunity of being born as a human to walk on the path that brings him closer to "moksha". In fact, Jains take the concept of avoiding sin so seriously that not only are they completely vegetarian but some devout Jains also abstain from eating underground grown food like potatoes, onions, etc. to avoid killing small organisms. Most of the Jains are also nonalcoholics and eat before sunset each day.

Judaism regards the violation of any of the 613 commandments as a sin. Judaism teaches that to sin is a part of life, since there is no perfect man and everyone has an inclination to do evil "from his youth". Sin has many classifications and degrees. Some sins are punishable with death by the court, others with death by heaven, others with lashes, and others without such punishment, but no sins committed with willful intentions go without consequence. Sins committed out of lack of knowledge are not considered sins, since a sin can't be a sin if the one who did it didn't know it was wrong. Unintentional sins are considered less severe sins.

Sins between people are considered much more severe in Judaism than sins between man and God. Yom Kippur, the main day of repentance in Judaism, can atone for sins between man and God, but not for sins between man and his fellow, that is until he has appeased his friend. Eleazar ben Azariah derived [this from the verse]: "From all your sins before God you shall be cleansed" (Book of Leviticus, 16:30) – for sins between man and God Yom Kippur atones, but for sins between man and his fellow Yom Kippur does not atone until he appeases his fellow.

When the Temple yet stood in Jerusalem, people would offer Karbanot (sacrifices) for their misdeeds. The atoning aspect of "karbanot" is carefully circumscribed. For the most part, "karbanot" only expiate unintentional sins, that is, sins committed because a person forgot that this thing was a sin or by mistake. No atonement is needed for violations committed under duress or through lack of knowledge, and for the most part, "karbanot" cannot atone for a malicious, deliberate sin. In addition, "karbanot" have no expiating effect unless the person making the offering sincerely repents of his or her actions before making the offering, and makes restitution to any person who was harmed by the violation.

Judaism teaches that all willful sin has consequences. The completely righteous suffer for their sins (by humiliation, poverty, and suffering that God sends them) in this world and receive their reward in the world to come. The in-between (not completely righteous or completely wicked), suffer for and repent their sins after death and thereafter join the righteous. The very evil do not repent even at the gates of hell. Such people prosper in this world to receive their reward for any good deed, but cannot be cleansed by and hence cannot leave "gehinnom", because they do not or cannot repent. This world can therefore seem unjust where the righteous suffer, while the wicked prosper. Many great thinkers have contemplated this.

In Mesopotamian mythology, Adamu (or Addamu/Admu, or Adapa) goes on trial for the "sin of casting down a divinity".
His crime is breaking the wings of the south wind.

Evil deeds fall into two categories in Shinto: "amatsu tsumi", "the most pernicious crimes of all", and "kunitsu tsumi", "more commonly called misdemeanors".






</doc>
<doc id="1000685" url="https://en.wikipedia.org/wiki?curid=1000685" title="Car chase">
Car chase

A car chase is the vehicular hot pursuit of suspects by law enforcers. The rise of the automotive industry in the 20th century increased car ownership, leading to a growing number of criminals attempting to evade police in their own vehicle or a stolen car. Car chases are often captured on news broadcast due to the video footage recorded by police cars and police and media helicopters participating in the chase. Car chases are also a popular subject with media and audiences due to their intensity, drama and the innate danger of high-speed driving.

Car chases occur when a suspect attempts to use a vehicle to escape from law enforcement attempting to detain or arrest him or her. The assumed offence committed may range from misdemeanours such as traffic infractions to felonies as serious as murder. When suspects realize they have been spotted by law enforcement, they attempt to lose their pursuer by driving away, sometimes at high speed. Generally, suspects whom police spot committing crimes for which long prison terms are likely upon conviction are much more likely to start car chases. In 2002, 700 pursuits were reported in the city of Los Angeles.

Los Angeles television station KCAL reported a quadrupling of ratings when police pursuits aired. Police officials have asked news media to reduce coverage of chases, claiming that they encourage suspects to flee and inciting gawkers to possibly get in the way of the pursuit, while the media responds that coverage of chases provides a public service and provide a deterrent to police brutality.

Police use a number of techniques to end chases, from pleading with the driver, waiting for the driver's vehicle to run out of fuel, or hoping the driver's vehicle becomes somehow disabled to more forceful methods such as boxing in the vehicle with police cruisers, ramming the vehicle, the PIT maneuver, shooting out the tires, or the use of spike strips, though all efforts, many of which pose risk to all involved as well as bystanders, will be aimed at avoiding danger to civilians. When available, a helicopter may be employed, which in some cases, may follow the vehicle from above while ground units may or may not be involved. The StarChase system as of summer 2009 was in use by the Arizona Department of Public Safety.

The February 2005 Macquarie Fields riots occurred in Sydney, Australia after a local driver crashed a stolen vehicle into a tree, killing his two passengers following a high-speed police pursuit. The death of university student Clea Rose following a police chase in Canberra sparked major recriminations over police pursuit policies. Ole Christian Bach was found shot and killed in Sweden in a presumed suicide after he had been followed in a car chase by Swedish undercover police.

Reality television has combined with the car chase genre in a number of television shows and specials featuring real footage, mostly taken from police cruisers and law enforcement or media helicopters of suspects fleeing police.

One notable, recorded police chase occurred when an M60 Patton tank was stolen by Shawn Nelson from an Army National Guard armory, on May 17, 1995. Nelson went on a rampage through San Diego, California, with the massive tank crushing multiple civilian vehicles before becoming stuck on a road divider. Police were able to get aboard the tank and open the hatch, killing the suspect when he would not surrender.

On June 4, 2004, welder Marvin Heemeyer went on a rampage in a heavily modified bulldozer in Granby, Colorado, wrecking 13 buildings including the town hall, the public library, a bank, a concrete batch plant, and a house owned by the town's former mayor, resulting in over $ 7 million in damage. The police were initially powerless, as none of their weapons could penetrate the suspect's vehicle. However, the bulldozer's engine failed and the machine became stuck, so Heemeyer committed suicide by gunshot.

On July 27, 2007, at exactly 12:46:20 p.m. MST in Phoenix, Arizona, two helicopters crashed in mid air. Both were AS-350 AStar helicopters from KNXV-TV (the area's ABC affiliate) and KTVK (an independent, but was the ABC affiliate until losing it to KNXV in 1995) news stations collided in mid-air above Steele Indian School Park in Phoenix, Arizona while covering a police pursuit. Four people were killed: KTVK pilot Scott Bowerbank and photographer Jim Cox; and pilot Craig Smith and photographer Rick Krolak of KNXV. No one on the ground was injured.

On September 28, 2012, Fox News aired a live police chase in Arizona which ended in the suspect exiting the vehicle and shooting himself after a short foot chase. Fox News was airing it in a five-second delay instead of a normal ten-second delay, which resulted in the shooting being aired on a live broadcast of the Fox Report. Shepard Smith soon apologized for the broadcast and vowed to never let it happen again.

High-speed car chases are recognized as a road safety problem, as vehicles not involved in the pursuit or pedestrians or street furniture may be hit by the elusive driver, who will often violate a number of traffic laws, often repeatedly, in their attempt to escape, or by the pursuing police cars. In the UK, it is estimated that 40 people a year are killed in road traffic incidents involving police, most as a result of a police pursuit. In the United States, chase-related deaths range between 300 and 400 people per year.

Kristie's Law is a proposed California law that would restrict immunity for damage (including injuries or deaths) caused by high-speed pursuits, where law enforcement agencies have established, but not followed, written pursuit policies.

In 2007, the United States Supreme Court held in "Scott v. Harris" (550 U.S. 372) that a "police officer's attempt to terminate a dangerous high-speed car chase that threatens the lives of innocent bystanders does not violate the Fourth Amendment, even when it places the fleeing motorist at risk of serious injury or death."

In most common law jurisdictions, the fireman's rule prevents police officers injured in such pursuits from filing civil lawsuits for monetary damages against the fleeing suspects, because such injuries are supposed to be an inherent risk of the job. Public outrage at such immunity has resulted in statutory exceptions. One example is California Civil Code Section 1714.9 (enacted 1982), which reinstates liability where the suspect knew or should have known that the police were present.

Policy on what circumstances justify a high-speed pursuit differ by jurisdiction. Some safety advocates want to restrict risky chases to violent felonies. Another option is to use technology to end or avoid the need for such chases. For example, vehicles can be tracked by aircraft or GPS tagging device like StarChase, allowing police agencies to reliably intercept suspects using stationary blockades, lower-speed vehicles, or when the vehicle is parked.

One particular hazard that is attendant to police pursuits is the problem of multiple law enforcement agencies becoming involved in a car chase that crosses municipal and jurisdictional boundaries. This is often complicated by radio communication incompatibility and policy differences in the various departments involved in a pursuit.

The city of Dallas, Texas was the first major city in the United States to adopt an "Inter-Jurisdictional Pursuit Policy" to address the problems inherent in car chases that involved more that one law enforcement agency. In August 1984, the Dallas Police Department's Planning and Research Division, under the command of Captain Rick Stone, began crafting a policy that more than twenty (20) local law enforcement agencies could agree to abide by when car chases crossed their borders. The result was a model policy that became the standard for use by police departments around the country.

In Europe, as many national borders no longer have border stations, car chases may sometimes cross national boundaries. States often have agreements in place where the police of one state can continue the chase across the national boundary.

In film and television, the term "car chase" refers to a scene involving one or more automobiles pursuing one another; the chase may or may not involve a police car. Car chases are a staple of the action movie genre, and feature-length films have been built entirely around car chases, often featuring high-powered, exotic vehicles. They are popular because they are fast moving scenes that generate a great deal of excitement and action, due to the speed of the vehicles involved, and the potential collisions and the debris resulting from the wreckage, while not being hugely expensive to stage.

Staging car chase sequences often requires numerous takes and destruction of several vehicles (whether intentional or mishap), giving an incentive for filmmakers to find ways to reduce costs. Hence it is common to use older vehicles that are 1–2 generations behind the current models on the market, since these can be second-hand acquisitions at low cost due to depreciation. There are some exceptions, if a high-profile vehicle (maybe but not necessarily a halo car) is used and/or if the vehicle manufacturer pays for product placement in a film production (serving as a technical adviser, donating vehicles to be used in filming); examples include the James Bond and Transporter franchises who use current and even concept vehicles.

Although car chases on film were staged as early as the motor vehicle itself — one of the earliest examples being "Runaway Match" directed by Alf Collins in 1903 — the consensus among historians and film critics is that the first modern car chase movie was 1968's "Bullitt". The revolutionary 10-minute-long chase scene in "Bullitt" was far longer and far faster than what had gone before, and placed cameras so that the audience felt as though they were inside the cars. Even during the most calamitous scenes, the star – Steve McQueen – could be clearly seen at the wheel of the vehicle.

"The French Connection" further increased the realism. While previous chases had obviously been filmed on closed roads, isolated highways, or Sunday mornings (including "Bullitt"), "The French Connection" placed the chase in the midst of busy New York traffic and pedestrians. The producer of both "Bullitt" and "The French Connection", Philip D'Antoni, went on to direct "The Seven-Ups" with yet another trademark chase sequence through New York featuring Roy Scheider from "The French Connection" as well as Bill Hickman, one of the drivers who had previously appeared in "Bullitt".

As time went on, so did the expectations of the movie car chase. Since "Bullitt", car chases featured in movies have become more advanced and arguably more entertaining. Car crashes have also formed an increasingly important role, with the destruction of any vehicle often coming as a delight to the viewer. An early example of a staged but startling accident in a movie chase can be found in the 1974 movie "McQ", which featured an incredible rollover, the first cannon rollover in fact, across a beach. The spectacle came at a cost, however, for stunt driver Hal Needham, who sustained multiple injuries after setting the explosives too high.

Eventually this resulted in movies which are not much more than a series of linked car chases, such as the 1974 film "Gone in 60 Seconds", which culminated in a 40-minute car chase scene with multiple crashes (some of them unplanned, real accidents) and a 30-foot-high, 128-feet-long airborne jump over crashed cars that block a road.

Arguably the most typical car chase is one in which a car is being pursued by police cars. In part because car chases are so common many movie makers try to introduce a new twists to them. One of the most famous variations is from "The French Connection" and involves a car chasing an elevated train. Chases involving buses, trucks, snowmobiles, trains, tanks, and virtually every other type of vehicle (with or without wheels) have appeared at some point.

Car chases can also be played for laughs. Films such as "The Blues Brothers", "The Keystone Kops", W.C. Fields comedies, "The Three Stooges", "It's a Mad, Mad, Mad, Mad World", "The Shaggy Dog", "No Deposit, No Return", "Freaky Friday", "The Gnome Mobile", "The Million Dollar Duck", "What's Up, Doc?", and many others have car chases that are used for comedy.

Probably the most complex type of car chase involves going the wrong way at high speed against moderately congested freeway traffic, most notably in "To Live and Die in L.A." and "Ronin" which, by no small coincidence, were directed by William Friedkin ("The French Connection") and John Frankenheimer ("French Connection II"), respectively.

Several films that feature complex large-scale chases involving a lot of vehicles in the pursuit include "The Blues Brothers", "The Transporter", "Raiders of the Lost Ark"," The Road Warrior", and "The Fast and the Furious" series. Another method of escalating a car chase scene is to have a character move from one vehicle to another and to fight in or on top of a moving vehicle as the Wachowskis employed very effectively in "The Matrix Reloaded".

A number of television shows have been built around the popularity of car chases, such as "CHiPs", "The Dukes of Hazzard", "Knight Rider", "Airwolf", and most recently, "Chase".

In more modern times, the use of computer-generated imagery is becoming increasingly popular, and, although costly, eliminates any danger level. While impressive at times, it is often argued that it eliminates the realism of the chase scene, which can then in turn damage the established thrill factor. Recent examples of this computer-generated imagery can be found in the Michael Bay films "Bad Boys II" and "The Island". An example of a lower budget film using computer-generated imagery in a car chase is "". "Driven" was particularly panned for its CGI car chase sequences. Such criticism has affected recent Hollywood productions; for example, films like "Ronin", "The Bourne Supremacy", "The Kingdom", and "The Dark Knight" all had actual live-action chases with minimal use of CGI, if at all.

In the action comedy film "Hot Fuzz", the scene in which Sergeant Angel chases the speeding car has been declared the shortest car chase in film history. The brevity of the scene, as acknowledged in interviews, was itself the joke.

Certain racing computer and video games with police cars have car chase (pursuit) racing/evasion modes. Notable examples of such games include the following:





</doc>
<doc id="50066201" url="https://en.wikipedia.org/wiki?curid=50066201" title="Women's fear of crime">
Women's fear of crime

Women's fear of crime refers to women's fear of being a victim of crime, independent of actual victimization. Although fear of crime is a concern for people of all genders, studies consistently find that women around the world tend to have much higher levels of fear of crime than men, despite the fact that in many places, and for most offenses, men's actual victimization rates are higher. Fear of crime is related to perceived risk of victimization, but is not the same; fear of crime may be generalized instead of referring to specific offenses, and perceived risk may also be considered a demographic factor that contributes to fear of crime. Women tend to have higher levels for both perceived risk and fear of crime.

In women's everyday lives, fear of crime can have negative effects, such as reducing their environmental mobility. Studies have shown that women tend to avoid certain behaviors, such as walking alone at night, because they are fearful of crime, and would feel more comfortable with these behaviors if they felt safer.

Social scientists have differing views on the causes of women's fear of crime. Some have argued that women's heightened fear of crime is due to women's higher levels physical vulnerability compared to men, although feminist work generally resists this generalization and often tries to relocate the cause to larger societal factors. It is nonetheless important that most women are aware of pervasive cultural view that women are more vulnerable than men, which may make them think they are more likely to be victimized and therefore contribute to their fear; in this way, it would be perceived vulnerability and not actual vulnerability that is the cause of women's fear. Some research has also suggested that women are in fact not much more fearful about crime than men, but that dominant cultural ideas about masculinity may make men reluctant to talk about their fear or report it in surveys.

Feminist discourse on fear of crime tends to explain women's higher levels of fear with the unequal gender structure in most societies, which places women beneath men within the power structure and thus puts them especially at risk for victimization by men. This theory refers to the oppressive social control of women, arguing that some crimes against women (such as rape) and the socialization that women receive to feel vulnerable and fear male violence are used by the patriarchy to assert male dominance and "keep women in their place."

As rape is by far the most gendered crime by victimization, some feminist scholars have suggested that fear of rape is the most important and most unique element of women's fear of crime, or even that women's fear of crime is in fact a generalized fear of rape. Proponents of this theory, often referred to as the "shadow of sexual assault hypothesis," often note that women tend to fear that rape will co-occur with other crimes, such as burglary, a fear that is not found among men. Some supporters of the theory also note that sexual harassment, which most women will experience in their lifetimes, especially contributes to the fear of rape; in some cases, women's rejection of unwanted sexual advances leads to threats, and even "benevolent" harassment may increase women's wariness and fear of men in public spaces.

The fear of rape, unlike other fears of specific crimes, is almost exclusive to women. Among women, it is also one of the strongest crime-related fears, and is the strongest crime-related fear for young women. Levels of fear of rape vary among women by age, race/ethnicity, residential area, and other factors, but are especially high for women who have been victims of rape in the past or know victims personally (the latter group may include a significant portion of women, with one study estimating that over half of women know rape victims). The fear of rape may also be related to the fear of murder, as women tend to overestimate the proportion of rape victims who are murdered during their attacks. Stigma and blame are also factors: what many feminists refer to as the "rape myth," the popular idea that women can be blamed for their rape and that women are responsible for preventing rape by the regulation of their behavior, often serves to support the fear of rape.

Although women as a whole demographic are more fearful of crime, specific subgroups of women may have higher levels of fear or be more likely to change their behavior because of it. In many studies, the demographics found to have the highest generalized fear of crime are single, older, urban, women of color, and of lower socioeconomic class. For fear of victimization for specific crimes, the demographics with the highest levels of fear may be different.

Generally, research has demonstrated that women from urban areas have higher levels of fear of crime. Even within cities, fear levels may differ from neighborhood to neighborhood. Increased social disorganization in the neighborhood (as measured by homelessness, drug sales, vandalism, prostitution, etc.) and higher rates of neighborhood serious crime lead to higher levels of fear of crime for both men and women, but both factors have a stronger effect on women's fear of crime.

Urban and rural communities tend to have very different levels of fear of crime. Rural areas are almost always perceived by residents and outsiders as safer, so it is often assumed that fear of crime levels will be lower there. Still, 2005 research in New Zealand and the United Kingdom noted that fear of crime levels in rural areas is on the rise, and found that sources of fear of crime among rural women often include perceived encroachment of urban influence (through people or attitudes) into their communities.

Theorists have suggested that Black and Latina women, and women of color in general, in the United States may have higher rates of fear of crime due to increased social vulnerability; because of institutional racism and sexism against women of color, their identities may put them at greater risk of victimization, leading to higher levels of fear.

In general, proposed solutions to women's fear of crime either place the responsibility on individual women (through preventive strategies) or on official agencies (through infrastructure improvements, anti-rape education, more involved policing, etc.), and are often framed as a combination of both. Of those that expect women to protect themselves from crime, most focus on the dangers for women in public spaces; however, as women usually face their highest rates of victimization in the home or at the hands of known people, these campaigns have been suggested to be particularly ill-equipped to help solve the problem of women's high fear of crime, and to support an untrue picture of women's victimization.

One of the most common individual strategies for dealing with fear of crime and preventing victimization is simple avoidance, the attempt to stay away from areas (such as dark alleys or public transportation) where it is believed victimization is likely to occur; research has found that women employ avoidance strategies more often than men do. Avoided areas may include neighborhoods with high crime rates, but for many women also include any unfamiliar areas. Women may also employ other isolation strategies by avoiding social interaction with strangers, ignoring them or moving quickly and with purpose to discourage interaction

Another common method of allaying fear of crime among women is by "crime-proofing" homes or possessions. Popular examples include home security systems, locking away valuables, or participating in neighborhood watch programs. These strategies are used by people of all genders, but some are more often employed by women. For example, many women in an American study reported choosing purses with zippers or holding purses protectively to defend against theft and purse-snatching.

As interest in women's safety and women's fear of crime has increased, so has interest in precautionary strategies; for example, in the past few decades, women's self-defense classes, books, and other self-defense instruction have become increasingly popular. Some women also choose to carry weapons, such as knives or guns, or repellents like pepper spray and Mace to ward off potential attackers.

Feminist commentators usually take the view that the responsibility for reducing women's fear of crime lies with the society, and that fear must be combatted at its source by addressing men's violence against women.

Although most research on women's fear of crime has been done in English-speaking countries, with the most done in the United States, similar trends in women's fear of crime have been found around the world.

A 2014 study using data from 20 countries in Sub-Saharan Africa concluded that fear of crime has a stronger negative effect on women's subjective well-being compared to men's, with subjective wellbeing defined as self-reported satisfaction with life. In the study, fear of crime had a statistically significant correlation with subjective wellbeing for females, but no significant correlation for males, suggesting that for the men in the study, fear of crime was not an important factor in determining their happiness and life satisfaction.

A 2013 study of Hong Kong social work students found significant gender differences in fear of crime levels. Consistent with the shadow of sexual assault hypothesis, the study found that the women had the highest levels of fear for rape, and that fear of rape was a predictor for fear of other crimes. Hong Kong has one of the lowest rates of crime and victimization in the world, so this study may suggest that the presence and size of gender differences in fear of crime are not strongly correlated with total crime and victimization rates.

A 1998 study in Glasgow, Scotland, found a gender disparity in fear of crime levels smaller than what is generally accepted. The study also found that men and women with similar fear levels tended to use similar reasoning to explain their fear of crime or lack of fear, although men's and women's fear appeared in different situations (men tended to be more often fearful about property crime, whereas women were more fearful about violent crime).

A 2010 Turkish study using a large nationwide sample confirmed that women expressed significantly higher levels of fear of crime than men. The study also found that previous victimization, a consistent predictor for higher levels of fear in women, was present at close to equal rates in the male and female samples, suggesting that prior victimization has a stronger effect on women's fear of crime than on men's. Also, if the study's sample is representative of the Turkish population, women have slightly higher victimization rates than men, and so their fear does not reflect the "gender-fear paradox" of victimization found in many other developed countries.


</doc>
<doc id="50697489" url="https://en.wikipedia.org/wiki?curid=50697489" title="National Crime Scene Cleanup Association">
National Crime Scene Cleanup Association

The National Crime Scene Cleanup Association (also commonly referred to as NCSCA) is an American company, that is owned by Prestige Worldwide Group, that provides crime scene cleanup, hoarding cleanup, trauma cleanup, unattended death cleanup, as well as various types of remediation services, such as mold, tear gas, or methamphetamine laboratories. Their crime scene cleaners are licensed professionals. National Crime Scene Cleanup Association is headquartered out of Patchogue, NY, as well as holding various satellite offices throughout the continental United States.

During the Ebola crisis in New York City, the National Crime Scene Cleanup Association provided support to the Bio Recovery Corporation crew, in the decontamination of Craig Spencer's apartment. Bio Recovery Corporation was hired to disinfect and clean the apartment, as well as the bowling alley, The Gutter, that Dr Spencer visited while diagnosed with Ebola. James Michel, at the time President of NCSCA, appeared with Sal Pane on news networks as consultants.

In November 2015, it was announced that the National Crime Scene Cleanup Association, along with scientist J. Marvin Herndon and documentary filmmaker, Michael J. Murphy, were to set out in 2016 to obtain test samples from the phenomenon known as 'Chem Trails'. The testing requires a pair of pilots from the National Crime Scene Cleanup Association, to fly up in powered paragliders, and use testing equipment to determine the presence of any unnatural chemicals or pathogens. All tests were to be verified by Dr Herndon, as well as documented by Michael J. Murphy, to be released as a feature at a later date.

In March 2016, National Crime Scene Cleanup Association's parent company, Prestige Worldwide Group, announced that they would begin receiving an initial public offering on NCSCA. This was after Prestige Worldwide Group acquired three crime scene cleanup firms. These new additions increased National Crime Scene Cleanup Association's reach and resources.

In June 2016, National Crime Scene Cleanup Association publicly announced plans surrounding their new educational experience, SafeGuard. Safeguard is a virtual reality educational experience designed to teach the public about the hazards and outline the details, equipment, and tools used in a typical crime scene remediation. Users navigate around a virtual crime scene and can interact and learn about various info points that show up near objects of interest. National Crime Scene Cleanup Association launched a new site to provide screenshots and updates on when the software would release.

National Crime Scene Cleanup Association also followed up with a new initiative following a few months after the announcement of Safeguard. This new initiative, dubbed 'STVR', is planned on being a virtual reality safety training course. Using the same concepts of interactivity and learning, STVR is being developed to be a safer alternative to standard 'textbook' learning, and provide more hands on learning without the risks that are normally associated with handling or working near hazardous materials and situations. STVR will not only focus on crime scene hazards training, but will also cover a wide array of scenarios and situations ranging from standard OSHA hazards to dealing with toxic chemicals spills. STVR is being targeted for use by hospitals and companies to train future professionals, nurses, rescue and hazmat workers.

In February 2017, National Crime Scene Cleanup Association company appeared on an episode of ‘The Guardians’ on Animal Planet. In the episode, the National Crime Scene Cleanup Association assisted the cast and crew of the show in the remediation of a cat hoarding veteran who lived in the woods. Workers donated their time and equipment to convert the veterans living area into a hospitable one, and helped captured the feral cats so they could be spayed and neutered.


</doc>
<doc id="14863504" url="https://en.wikipedia.org/wiki?curid=14863504" title="CIA transnational anti-crime and anti-drug activities">
CIA transnational anti-crime and anti-drug activities

This article deals with activities of the U.S. Central Intelligence Agency related to transnational crime, including the illicit drug trade.

Two offices of the CIA Directorate of Intelligence have analytical responsibilities in this area. The Office of Transnational Issues applies unique functional expertise to assess existing and emerging threats to US national security and provides the most senior US policymakers, military planners, and law enforcement with analysis, warning, and crisis support.

The CIA Crime and Narcotics Center researches information on international narcotics trafficking and organized crime for policymakers and the law enforcement community. Since the CIA has no domestic police authority, it sends its analytic information to the Federal Bureau of Investigation (FBI) and other law enforcement organizations, such as the Drug Enforcement Administration (DEA) and the Office of Foreign Assets Control of the United States Department of the Treasury (OFAC).

Another part of the CIA, the National Clandestine Service, collects human intelligence (HUMINT) in these areas.

According to the United Nations Office on Drugs and Crime (UNODOC),

Drug cultivation thrives on instability, corruption and poor governance. The world's biggest drug producing centres are in regions beyond the control of the central government, like South Afghanistan, South-West Colombia and East Myanmar. Until government control, democracy and the rule of law are restored, these regions will remain nests of insurgency and drug production—and represent the biggest challenge to containment.

Especially in developing countries in conflict, there have been allegations that the CIA assisted the illicit drug activities of local leaders who saw that as a payment for their assistance.

CIA publishes reference materials in this area, such as "Heroin Movement Worldwide".

There have been allegations that CIA was involved in the Latin American drug trade, possibly to finance operations in Nicaragua and other areas around the world where Congress had denied funding, such as Afghanistan during the Soviet invasion, and in Southeast Asia during the Vietnam War. According to a personal account by Everett Ellis Briggs, former U.S. Ambassador to Panama and Honduras, CIA undermined efforts to put a stop to the drug smuggling activities of Panamanian dictator Manuel Noriega prior to the December, 1989 U.S. invasion of Panama.

Released on April 13, 1989, the Kerry Committee report found that the U.S. State Department had assisted drug traffickers:

who provided support for the Contras were involved in drug trafficking ... and elements of the Contras themselves knowingly received financial and material assistance from drug traffickers.

Some of these payments were after the traffickers had been indicted by federal law enforcement agencies on drug charges or while traffickers were under active investigation by these same agencies. The report declared, "It is clear that individuals who provided support for the Contras were involved in drug trafficking ... and elements of the Contras themselves knowingly received financial and material assistance from drug traffickers."

Representative Maxine Waters testified to Congress:

In 1996, investigative journalist Gary Webb wrote a series of articles for the "San Jose Mercury News" entitled, "Dark Alliance", in which he reported evidence that CIA aircraft, which had ferried arms to the Nicaraguan "Contras," had been used to ship cocaine to the United States on their return flights. In 1998 the new DCI, George Tenet, declared that he was releasing the report. The report of CIA Inspector General Frederick Hitz and Hitz's testimony showed that the "CIA did not 'expeditiously' cut off relations with alleged drug traffickers" and "the CIA was aware of allegations that 'dozens of people and a number of companies connected in some fashion to the contra program' were involved in drug trafficking" Hitz also said that under an agreement in 1982 between Ronald Reagan's Attorney General William French Smith and the CIA, agency officers were not required to report allegations of drug trafficking involving non-employees, which was defined as meaning paid and non-paid "assets [meaning agents], pilots who ferried supplies to the contras, as well as contra officials and others. This agreement was revealed, at a time when there were allegations that the CIA was using drug dealers in its covert operation to bring down the leftist Sandinista government in Nicaragua. Only after Congressional funds were restored in 1986 was the agreement modified to require the CIA to stop paying agents whom it believed were involved in the drug trade.

Webb also alleged that Central American narcotics traffickers could distribute cocaine in U.S. cities in the 1980s without the interference of normal law enforcement agencies, and that the CIA intervened to prevent the prosecution of drug dealers who were helping to fund the "Contras". The "Mercury News" ultimately retracted Webb's conclusions, and Webb was not authorized to conduct any further investigative reporting. Webb was transferred to cover non-controversial suburban stories and subsequently gave up journalism and committed suicide.

In 1984, U.S. officials began receiving reports of Contra cocaine trafficking. Three officials told journalists that they considered these reports "reliable." Former Panamanian deputy health minister Dr. Hugo Spadafora, who had fought with the Contra army, outlined charges of cocaine trafficking to a prominent Panamanian official and was later found murdered. The charges linked the Contra trafficking to Sebastian Gonzalez Mendiola, who was charged with cocaine trafficking on November 26, 1984, in Costa Rica.

On March 16, 1986, the "San Francisco Examiner" published a report on the "1983 seizure of 430 pounds of cocaine from a Colombian freighter" in San Francisco which indicated that a "cocaine ring in the San Francisco Bay area helped finance Nicaragua's Contra rebels." Carlos Cabezas, convicted of conspiracy to traffic cocaine, said that the profits from his crimes "belonged to ... the Contra revolution." He told the Examiner, "I just wanted to get the Communists out of my country." Julio Zavala, also convicted on trafficking charges, said "that he supplied $500,000 to two Costa Rican-based Contra groups and that the majority of it came from cocaine trafficking in the San Francisco Bay area, Miami and New Orleans."

Former CIA agent David MacMichael explained the inherent relationship between CIA activity in Latin America and drug trafficking:

Once you set up a covert operation to supply arms and money, it's very difficult to separate it from the kind of people who are involved in other forms of trade, and especially drugs. There is a limited number of planes, pilots and landing strips. By developing a system for supply of the Contras, the US built a road for drug supply into the US.

In November 1996, shortly after then-CIA Director John Deutsch went to Los Angeles to refute allegations raised by the Gary Webb investigative report on cocaine trafficking and the CIA, a Miami jury indicted Venezuelan CIA asset, General Ramon Guillen Davila, who "led a CIA counter-narcotics program that put a ton of cocaine on U.S. streets in 1990." "The New York Times" reported:

The CIA—over the objections of the Drug Enforcement Administration, a branch of the Justice Department—approved the shipment of at least one ton of nearly pure cocaine to Miami International Airport as a way of gathering information about the Colombian drug cartels. But the cocaine ended up on the street because of "poor judgment and management on the part of several CIA officers," the intelligence agency said.

Alfred McCoy, author of The Politics of Heroin in Southeast Asia, described CIA complicity in the Vietnam-era drug trade originating in Southeast Asia, and further described CIA attempts to interfere with publication of the book.

On June 1 of this year an official of the US Central Intelligence Agency paid a visit to the New York offices of my publisher, Harper and Row, Inc. This CIA official was Mr. Cord Meyer, Jr. (now the CIA's Assistant Deputy Director of Plans; formerly the CIA official in charge of providing covert financial subsidies for organizations such as the National Student Association, Encounter Magazine, and the Congress for Cultural Freedom). Mr. Meyer urged several of his old friends among Harper and Row's senior management to provide him with a copy of the galley proofs of my history of the international narcotics traffic, The Politics of Heroin in Southeast Asia. In this book I show the complicity of various US agencies—particularly the CIA and the State Department—in organizing the Southeast Asian drug traffic since the early 1950s.

According to Dr. McCoy, the agency intimidated his sources and tried to keep the book from being published. There is also an article in Peace Magazine containing similar allegations. The Mel Gibson film, "Air America". "Air America" was based on the Christopher Robbins book "Air America", which chronicled the history of CIA proprietary airlines in Southeast Asia.

In his book, McCoy wrote

It is transported in the planes, vehicles, and other conveyances supplied by the United States. The profit from the trade has been going into the pockets of some of our best friends in Southeast Asia. The charge concludes with the statement that the traffic is being carried on with the indifference if not the closed-eye compliance of some American officials and there is no likelihood of its being shut down in the foreseeable future."

This is not inconsistent with Leary's description (with respect to Laos and Southeast Asia), although there seem to be differences in the degree of knowledge and consent by CIA management.

McCoy asserts that the French administration of Indochina had financed its covert operations with the drug trade, and the CIA had simply replaced the French, to finance similar operations. He said he had gone to Paris and interviewed retired general Maurice Belleux, the former head of the French equivalent of the CIA, an organization called Service de Documentation Extérieure et de Contre-Espionnage (SDECE, predecessor of the current French service, the Direction générale de la sécurité extérieure).

In an amazing interview he told me that French military intelligence had financed all their covert operations from the control of the Indochina drug trade ... The French paratroopers fighting with hill tribes collected the opium and French aircraft would fly the opium down to Saigon and the Sino-Vietnamese mafia that was the instrument of French intelligence would then distribute the opium. The central bank accounts, the sharing of the profits, was all controlled by French military intelligence. He concluded the interview by telling me that it was his information that the CIA had taken over the French assets and were pursuing something of the same policy. So I went to Southeast Asia to follow up on that lead and that's what took me into doing this whole book. It was basically pulling a thread and keep tucking at it and a veil masking the reality began to unravel.

 During the 40 years of the cold war, from the late 1940s to this year, the CIA pursued a policy that I call "radical pragmatism". Their mission was to stop communism and in pursuit of that mission they would ally with anyone and do anything to fight communism.

McCoy does not so much accuse the CIA of direct participation in the drug trade, than protecting the drug trade of people the CIA believed essential allies in its primary mission.

Powerful, upland political figures control the societies and economies in these regions and part of that panoply of power is the opium trade. The CIA extended the mantle of their alliance to these drug lords and in every case the drug lords used it to expand a small local trade in opium into a major source of supply for the world markets and the United States.

While they were allied with the United States these drug lords were absolutely immune to any kind of investigation. If you're involved in any kind of illicit commodity trade, organized crime activity like drug trafficking, there is only one requisite for success, immunity, and the CIA gave them that. As long as they were allied with the CIA, the local police and then the DEA stayed away from the drug lords.

UNODOC observes

Southeast Asia is closing a tragic chapter that has blighted the Golden Triangle for decades—the region is now almost opium free. Yet it is not free of poverty and therefore farmers remain vulnerable to the temptations of illicit incomes. Much more assistance—for alternative crops and also for viable income substitution—is needed to ensure that drug-free development is sustained in the greater Mekong basin.

It may well be that US aid, perhaps not from the CIA but from the Agency for International Development, will be needed create these alternatives. This level of strategy is the responsibility of the United States Department of State.

According to William M. Leary, a University of Georgia historian who analyzed Laotian operations in a study backed by the CIA's Center for the Study of Intelligence, CIA-led covert action in Laos was the largest paramilitary operation in the history of the Agency. Although a large body of evidence exists claiming that the CIA was knowingly complicit in opium smuggling operations, Leary takes a position which claims that the CIA, which funded his work, was not complicit in the drug trade.

While the CIA reports on the flow of opium, and its derivative, heroin, in Southwest Asia, US government researchers also observe that the indirect effects of the United States Department of Defense and the Central Intelligence Agency, as well as the Afghan Northern Alliance, have increased the flow."Afghanistan and Pakistan produced an estimated 41 percent of the world's opium in 1998. Europe remains the primary market for Southwest Asian heroin, but the drug is also consumed in Africa, the United States, and Canada." 
According to the CIA flow study,

LTC John Glaze, USAF, Deputy Commander of the 353rd Special Operations Group at Kadena Air Base, Japan, writing for the Strategic Studies Institute of the U.S. Army War College,

Opium production in Afghanistan has skyrocketed since the U.S. military teamed with the Central Intelligence Agency (CIA) and Afghanistan's Northern Alliance in toppling the Taliban in 2001 ... This growing opium trade is threatening to destabilize the Afghan government and turn the conflict-ridden country back into a safe haven for drug traffickers and terrorists.

He quotes Afghan President Hamid Karzai as saying "Either Afghanistan destroys opium or opium will destroy Afghanistan." Glaze does not suggest that the CIA takes an active role in the ongoing drug trade, but sees the CIA as having influenced the current Afghan economic, governance, and security situations, which encourage the growth of opium and heroin production.

According to the United Nations Office on Drugs and Crime (UNODC)

The magnitude and importance of Afghanistan's opium economy are virtually unprecedented and unique in global experience—it has been roughly estimated as equivalent to 36% of licit (i.e. non-drug) GDP in 2004/05, or if drugs are also included in the denominator, 27% of total drug-inclusive GDP

Karzai, on the Ministry of Counternarcotics webpage in 2006, said "Our goal is to secure a sustainable decrease in poppy cultivation, drug production, consumption of illicit drugs, and trafficking with a view to complete and sustain elimination. As a result, it will pave the way for a pro-poor, private sector-led economic growth." However, as of July 2007, efforts at eradication alienate the population and are carried out only half-heartedly by local military in the face of U.S. pressure.
The exact same situation was dramatized in 1989 in the British TV drama Traffik. A 2006 NY Times article said that 2006 Afghan opium production was up 50% over 2005. A recent United Nations report analyzes the economics of the opium industry.

It was alleged by the Soviets on multiple occasions that American CIA agents were helping smuggle opium out of Afghanistan, either into the West, in order to raise money for the Afghan resistance or into the Soviet Union in order to weaken it through drug addiction. According to Alfred McCoy, the CIA supported various Afghan drug lords, for instance Gulbuddin Hekmatyar.

After the September 11, 2001 attacks, a combination of U.S. CIA and military forces (US and allied powers), in support of the Northern Alliance, quickly regained control of Afghanistan from the Taliban, leaving the country "in economic ruin and political chaos. In December 2001, a number of prominent Afghans met in Bonn, Germany, under United Nations (UN) auspices to develop a plan to reestablish the State of Afghanistan, including provisions for a new constitution and national elections. As part of that agreement, the United Kingdom (UK) was designated the lead country in addressing counter-narcotics issues in Afghanistan. Afghanistan subsequently implemented its new constitution and held national elections. On December 7, 2004, Hamid Karzai was formally sworn in as president of a democratic Afghanistan."

Approximately 40,000 foreign troops help manage security in Afghanistan, principally of 32,000 regular soldiers from 37 North Atlantic Treaty Organization (NATO) forces: the International Security Assistance Force. 8,000 US and other special operations forces make up the balance. To manage this turmoil, over 40,000 foreign troops still occupy Afghanistan. There is significant resistance, both from the ideological/theocratic Taliban, especially in southern Afghanistan, and also independent local warlords and drug organizations. Antonio Maria Costa, Executive Director of the United Nations Office on Drugs and Crime (UNODC), described the situation this way: "There is no rule of law in most of the southern parts of Afghanistan—the bullets rule."

It is helpful to be aware of certain areas of Afghanistan, which play a role in the drug traffic.

The 2004 United Nations Development Programme ranked Afghanistan number 173 of 177 countries, using a human development index, with Afghanistan near or at the bottom of virtually every development indicator including nutrition, infant mortality, life expectancy, and literacy. Several factors encourage opium production, the greatest being economic: the high rate of return on investment from opium poppy cultivation has driven an agricultural shift in Afghanistan from growing traditional crops to growing opium poppy. Much of the funds involved do not go through traditional banks, but rather the "hawala" system, which makes tracking by the CIA much more difficult, although not impossible. See the role of "hawala" and Afghan drugs, and also the FININT section of CIA transnational anti-terrorism activities.

It must be emphasized that opium cultivation, on this scale, is not traditional.

Despite the fact that only 12 percent of its land is arable, agriculture is a way of life for 70 percent of Afghans and is the country's primary source of income. During good years, Afghanistan produced enough food to feed its people as well as supply a surplus for export. Its traditional agricultural products include wheat, corn, barley, rice, cotton, fruit, nuts, and grapes. However, its agricultural economy has suffered considerably ... Afghanistan's largest and fastest cash crop is opium.

Afghanistan's rugged terrain encourages local autonomy, which, in some cases, means local leadership committed to an opium economy. The terrain makes surveillance and enforcement difficult.

According to the United Nations Office on Drugs and Crime (UNODC) "2007 Afghanistan Opium Survey", Afghanistan produced approximately 8,200 metric tonnes of opium — nearly double the estimate of global annual consumption. In an April 25, 2007 op-ed in "The Washington Post", Antonio Maria Costa, Executive Director of UNODC, asked "Does opium defy the laws of economics? Historically, no. In 2001, prices surged tenfold from 2000, to a record high, after the Taliban all but eliminated opium poppy cultivation across the Afghan territory under its control. So why, with last year's bumper crop, is the opposite not occurring? Early estimates suggest that opium cultivation is likely to increase again this year. That should be an added incentive to sell.

He speculated,

As of October, 2009, the Taliban are supporting the opium trade and deriving funding from it.

Again, that "hawala" handles and launders much of the funds involved make enforcement even more difficult.

Working with the UK and the Afghan government, the United States developed its own strategy to counter the opium problem in Afghanistan, which has the following five pillars: 

The Department of State (DoS), the U.S. Agency for International Development (USAID), the Department of Defense (DoD), and the Department of Justice (DoJ) are the primary organizations involved in carrying out this counternarcotics strategy for the US. The role of the CIA has not been mentioned, although the CIA is involved in preparing lists of terrorism suspects for the United States Department of the Treasury Office of Foreign Assets Control. UNODC's executive director believes these measures are insufficient: "What can be done? Since NATO forces are wary of making enemies out of opium farmers by being associated with eradication, and since the Afghan government is opposed to spraying poppy fields, rounding up the major traffickers may be the best available option for disrupting Afghanistan's lucrative opium market."

Both demand and supply reduction are important. "the consuming countries need to get serious about curbing drug addiction. If there was less demand for heroin, the bottom really would fall out of the opium market." Farmers economically dependent on opium must have viable alternatives that give sustainable income. On the supply side, identifying the most-wanted traffickers and subjecting them to international arrest warrants with extradition, asset seizure, and travel bans could help. While it is not easy to destroy opium storage and heroin production laboratories, it is far easier to destroy drugs at the source than in transit.

"Afghanistan's neighbors are either accomplices or victims in the opium trade, so they need to be part of the solution. They could, for example, improve intelligence-sharing and border security to ensure that more opium is seized. At the moment, less than a quarter of the world's opium is intercepted, compared with around half of global cocaine output." This complicates, of course, the complex US relations with Pakistan and Iran.

There is an important nexus between drugs and "hawala" (informal money transfer system) in Afghanistan. The UN analysis is based on interviews with a sample of 54 "hawala" brokers in the main centers of "hawala" activity of Afghanistan as well as during a visit to Peshawar, Pakistan. In addition, interviews were conducted with users of the hawala system (drug dealers, businessmen, traders, international aid workers), regulators (government officials, central bank personnel), and formal
service providers (bankers, accountants). In addition to "hawala", they found protection payments and connections, by which the drug industry has major linkages with local administration as well as high levels of the national government.

See informal money transfer systems to support clandestine activity, including terrorism, drug trade, and intelligence collection. See the section of the article, CIA transnational anti-terrorism activities on how the intelligence community and the United States Department of the Treasury attempt to control "hawala" used to finance terrorism.

Different localities studied by the UNODC give different views of the laundering of drug funds. It is difficult to get a solid sense of the overall economy. In Faizabad, for example, indicated that during certain times of the year close to 100% of the liquidity of the hawala system in the province is derived from drugs, whereas in Herat, the Northern Alliance stronghold, it was estimated that only 30% of the "hawala" market's overall transaction volume is directly linked to drugs. Analysis of data gathered in places like Herat was complicated by confirmed links between drug money and legitimate imports. The southern region (Helmand and Kandahar provinces) is also a key centre for money laundering in Afghanistan (about 60% of the funds are drug related and 80-90% of the hawala dealers in Kandahar [the former Taliban stronghold] and Helmand are involved in money transfers related to narcotics).

Helmand has emerged as a key facilitator of the opium trade, both between provinces and exports, while overall estimates of the local hawala markets' drug-related component are of a similar order of magnitude to those in Kandahar. This finding
adds weight to the notion that the major trading centers in these two neighboring provinces should be treated as essentially one market. Bearing this in mind, the study calculated that Helmand could account for roughly US$800 million of Afghanistan's drug-related hawala business and that Herat is the second largest contributor, with in the range of US$
300-500 million of drug money laundered annually.

Furthermore, Dubai appears to be a central clearing house for international hawala activities. In addition, various cities in Pakistan, notably Peshawar, Quetta, and Karachi, are major transaction centers. It appears that even in the case of drug shipments to Iran, payments for them come into Afghanistan from Pakistan ... the hawala system has been key to the deepening and widening of the "informal economy" in Afghanistan, where there is anonymity and the opportunity to launder money.

Hawala, however, also contributes positively to the regional economy. It has been central to the survival of Afghanistan's financial system through war. According to Maimbo (2003), "integral to processes of early developmentand vital for the continued delivery of funds to the provinces."
"The hawala system also plays an important role in currency exchange. It participates in the Central Bank's regular foreign currency auctions, and was instrumental in the successful introduction of a new currency for Afghanistan in 2002-2003."

There are claims and counterclaims that the US may have used groups involved in drug smuggling in an effort to destabilize Iran. Hard evidence is lacking. The group, "Jundullah", is made up of ethnic Baluchis, and is in the Baluchistan region of Pakistan, bordering Iran. It has taken responsibility for the deaths and kidnappings of more than a dozen Iranian soldiers and officials. Again, there is no hard evidence. The situation also may reflect a conflict between the U.S. military and the Vice-President Dick Cheney, in that the military believes the weapons may be purchased through the drug trade, but Cheney believes they are being supplied by the government of Iran.

The Inter Press Service report quoted United States Undersecretary of State Nicholas Burns as saying, on June 12, 2007, that Iran was "transferring arms to the Taliban in Afghanistan", putting it in the context of a larger alleged Iranian role of funding "extremists" in the Palestinian territories, Lebanon and Iraq. "The following day he asserted that there was "irrefutable evidence" of such Iranian arms supply to the Taliban." The reporter mentioned that Cheney had used the same phrase "irrefutable evidence" on Sep. 20, 2002, in referring to the administration's accusation that Saddam Hussein had a programme to enrich uranium as the basis for a nuclear weapon. It is the reporter's theory that the recurrence of the phrase meant the statement could have been crafted by Cheney, but it also could be a coincidental use of a phrase that has been used in other official announcements.

The Jundallah group is made up Baluchi tribesmen, often operating out of Pakistan, but the Baluchi have a complex relationship with Pakistan, Iran, and Afghanistan. While news sources agree that the US government has not made a Presidential Finding that covert action is needed, nor reported such action to the eight senior members of Congress who oversee the most sensitive operations, the argument is made that CIA subsidies go to Pakistan, which, in turn, funds the group. If Pakistan does all the funding, the letter of the law would be followed, in that the US is not subsidizing the group.

It is possible that, as in Southeast Asia, the activities of a group are not directly funded, but are funded by allowing them to operate in the drug trade. General Dan McNeill, the NATO commander in Afgahanistan, pointed to the "U.S. command's knowledge of the link between the heroin trade and trafficking in arms between southeastern Iran and southern Afghanistan. The main entry point for opium and heroin smuggling between Afghanistan and Iran runs through the Iranian province of Sistan-Baluchistan to the capital of Zahedan. The two convoys of arms which were intercepted by NATO forces last spring had evidently come through that Iranian province." 

According to a report by Robert Tait of The Guardian Feb. 17, Sistan-Baluchistan province has also been the setting for frequent violent incidents involving militant Sunni groups and drug traffickers. Tait reported that more than 3,000 Iranian security personnel had been killed in armed clashes with drug traffickers since the 1979 Islamic revolution.

CIA representatives denied involvement to ABC News, saying "the account of alleged CIA action is false" and reiterated that the U.S. provides no funding of the Jundullah group, and no hard evidence of US involvement. Pakistani government sources say the secret campaign against Iran by Jundullah was on the agenda when Vice President Dick Cheney met with Pakistani President Pervez Musharraf in February.
While Herat is not the highest-volume area of opium trade, Herat, and the other Iranian border areas of Farah, and Nimroz, have some of the highest prices, presumably due to demand from the Iranian market. "Opium prices are especially high in Iran, where law enforcement is strict and where a large share of the opiate consumption market is still for opium rather than heroin. Not surprisingly, it appears that very significant profits can be made by crossing the Iranian border or by entering Central Asian countries like Tajikistan."

"The UNODC estimates 60 percent of Afghanistan's opium is trafficked across Iran's border (much of it in transit to Europe). Seizures of the narcotic by Iranian authorities in the first half of this year are up 29 percent from the same period last year, according to the country's police chief, as reported by Radio Free Europe/Radio Liberty (RFE/RL) ... The Washington Post reports that Iran has the world's highest per capita number of opium addicts ... Experts say those affected most are the millions of unemployed Iranians and youth chafing under the restrictions placed on them from the Islamic government and basij, or civilian morals police. The Iranian government has gone through several phases in dealing with its drug problem.

First, during the 1980s, its approach was supply-sided: "Law-and-order policies with zero tolerance led to the arrest of tens of thousands of addicts and the execution of thousands of narcotics traffickers." "There are an estimated 68,000 Iranians imprisoned for drug trafficking and another 32,000 for drug addiction (out of a total prison population of 170,000, based on 2001 statistics)"

Beehner said "Tehran also has spent millions of dollars and deployed thousands of troops to secure its porous 1,000-mile border with Afghanistan and Pakistan ... a few hundred Iranian drug police die each year in battles with smugglers. Referring to the head of the UNODC office in Iran, Roberto Arbitrio, Beehner quoted Arbitrio in an interview with "The Times." "You have drug groups like guerrilla forces, [who] ... shoot with rocket launchers, heavy machine guns, and Kalashnikovs."

A second-phase strategy came under President Mohammad Khatami, focused more on prevention and treatment. Drug traffic is considered a security problem, and much of it is associated with Baluchi tribesmen, who recognize traditional tribal rather than national borders. Current (2007) reports cite , possibly supported by the CIA.

Iranian drug strategy changed again under President Mahmoud Ahmadinejad, who took office in 2005. Iran's drug policy has been reconsidered and shifted back toward supply interdiction and boosting border security. It is unclear if this is connected to more wide-ranging concerns with border security, perhaps in relation to 

Samii's 2003 paper described Iran's "primary approach to the narcotics threat [as] interdiction.Iran shares a 936 kilometer border with Afghanistan and a 909 kilometer border with Pakistan, and the terrain in the two eastern provinces—Sistan va Baluchistan and Khorasan—is very rough. The Iranian government has set up static defenses along this border. This includes concrete dams, berms, trenches, and minefields ...

Various forms of slavery are still present throughout the world. Some put individuals into local service for labor, sex, or the related issues of child soldiers. There is also a form that ships individuals from less developed to more developed countries. Others are based on debt bondage. The US has a Special Advisor to the Secretary of State, at an Ambassadorial level, to deal with the problem in the Office to Monitor and Combat Trafficking in Persons.

A CIA analyst in an independent research program characterized the agency's understanding of the problem.

CIA provided analytic support to the Department of State on human smuggling and trafficking, with an expert who oversaw the assessment, drafting, and coordination of the 2002 Trafficking in Persons report. As part of intergovernmental work, it collected and reported intelligence to US law enforcement agencies conducting operations against members of Latin American and Middle Eastern terrorist groups and against smugglers of aliens into the United States.

CIA works with the United States Department of the Treasury Financial Crimes Enforcement Network (FINCen). With respect to efforts to apply the Patriot Act to a foreign bank involved in money laundering. CIA analysts identified key players in the bank, their relationship to international organized crime, and the bank's efforts to hide its accounts from US law enforcement. See Financial intelligence (FININT).



</doc>
<doc id="51886984" url="https://en.wikipedia.org/wiki?curid=51886984" title="Grade (crime)">
Grade (crime)

The grade of a crime is its ranking or classification by its degree or seriousness or severity. A felony is more serious than a misdemeanor, which is more serious than an infraction. A first degree felony is more serious than a second degree felony. The severity of punishment is based on the grade of the crime.


</doc>
<doc id="3998822" url="https://en.wikipedia.org/wiki?curid=3998822" title="Strain theory (sociology)">
Strain theory (sociology)

In sociology and criminology, strain theory states that social structures within society may pressure citizens to commit crime. Following on the work of Émile Durkheim, strain theories have been advanced by Robert King Merton (1938), Albert K. Cohen (1955), Richard Cloward, Lloyd Ohlin (1960), Neil Smelser (1963), Robert Agnew (1992), Steven Messner and Richard Rosenfeld (1994).

Strain theory is a sociology and criminology theory developed in 1938 by Robert K. Merton. The theory states that society puts pressure on individuals to achieve socially accepted goals (such as the American dream), though they lack the means. This leads to strain which may lead the individuals to commit crimes, examples being selling drugs or becoming involved in prostitution, to gain financial security.

Strain may either be:

Robert King Merton was an American sociologist who argued that society can encourage deviance to a large degree. Merton believed that socially accepted goals put pressure on people to conform. His theory was largely developed due to the social and economic circumstances occurring in the United States's society during the early 1900s. Robert Merton's Strain Theory stems from a fundamental question that he posed on why the rates of deviance were so different among societies. He thought that there could be deviance where there is a difference between what defines success and what the proper means are to achieve these goals. He found the United States as a prime example of high levels of deviance because there is a high value in achieving success, primarily monetary success, but there are contradictions for the means of achieving success. The college educated worker is respected, but the robber barons who stole for their money were also admired, showing success is seen as more important than the means to achieve success. In addition, he also saw how minority groups were unable to get good educations, and if they could then they could not get a good paying job with it, but the same high standard for success is set for everyone even though not everyone could reach those standards through conventional means. These contradictions led him to develop strain theory because of how high the US held success. People are forced to work within the system or become members of a deviant subculture to achieve the desired goal. Merton's belief became the theory known as Strain Theory. Merton continued on to say when individuals are faced with a gap between their goals (usually finances/money related) and their current status, strain occurs. When faced with strain, people have five ways to adapt:

General strain theory (GST) is a sociology and criminology theory developed in 1992 by Robert Agnew. Agnew believed that Merton's theory was too vague in nature and did not account for criminal activity which did not involve financial gain. The core idea of general strain theory is that people who experience strain or stress become distressed or upset which may lead them to commit crime in order to cope. One of the key principle of this theory is emotion as the motivator for crime. The theory was developed to conceptualize the full range of sources in society where strain possibly comes from, which Merton's strain theory does not. The theory also focuses on the perspective of goals for status, expectations and class rather than focusing on money (as Merton's theory does). Examples of General Strain Theory are people who use illegal drugs to make themselves feel better, or a student assaulting his peers to end the harassment they caused.

GST introduces 3 main sources of strain such as:

Institutional anomie theory (IAT) is a criminology theory developed in 1994 in by Steven Messner and Richard Rosenfeld. The theory proposes that an institutional arrangement with a market, where the market/economy is allowed to operate/dominate without restraints from other social intuitions like family will likely cause criminal behavior. Derived from Merton's Strain Theory, IAT expands on the macro levels of the theory. IAT's focus centers on the criminal influences of varied social institutions, rather than just the economic structure.

Illegitimate opportunities is a sociology theory developed in 1960 by Richard Cloward and Lloyd Ohlin. The theory states that crimes result from a high number of illegitimate opportunities and not from a lack of legitimate ones. The theory was created from Merton's strain theory to help address juvenile delinquency.

The theory of "role strain", developed by sociologist William J. Goode in 1960, states that social institutions are supported and operated by role relationships. Due to these role relationships that individuals may feel "role strain", or difficulty fulfilling their sociological duties in the relationship. It is through this "role strain" that social action and social structure are maintained. With these relationships, come social obligations that members of that society are required to follow, which people are usually not forced to fulfill. In order for the society to continue existing, these obligations must be fulfilled at the volition of the individuals in it, which the theory states is what most people are inclined to do. Due to the fact that there is no force involved in maintaining these role relationships, there will be individuals who can not, or will not, conform to these societal expectations.

In addition, the individuals within the society are not bound to one role relationship. In fact, all individuals will be part of multiple role relationships. Possession of multiple relationships can account for the conflicts of interest often faced in social settings. According to Goode, however, due to these multiple relationships, an individual will almost always have a total amount of role obligations that demand more than what the individual can give, whether it is in terms of time, emotional favor, or material resources. This can give rise to "role strain", which can lead the individual to attempting to fulfill socially acceptable goals in means that may not be socially acceptable (as explained in General Strain Theory).

While the theory of role strain attempts to attribute the maintenance of society to role relationships, Goode also acknowledges that the theory does not account for the existence of more complex social settings, such as that of urban society. The theory of role strain does not account for several aspects of urban life, such as the fact that some individuals accept absolutely none of the society's central values, the fact that individuals vary in their emotional commitment to these societal values, how these role relationships change when individuals go through a change in social position, or how these relationships hold up during times of crisis.

In 1992, Robert Agnew asserted that strain theory could be central in explaining crime and deviance, but that it needed revision so that it was not tied to social class or cultural variables, but re-focused on norms. To this end, Agnew proposed a general strain theory that is neither structural nor interpersonal but rather individual and emotional, paying special attention to an individual's immediate social environment. He argued that an individual's actual or anticipated failure to achieve positively valued goals, actual or anticipated removal of positively valued stimuli, and actual or anticipated presentation of negative stimuli all result in strain.

Anger and frustration confirm negative relationships. The resulting behavior patterns will often be characterized by more than their share of unilateral action because an individual will have a natural desire to avoid unpleasant rejections, and these unilateral actions (especially when antisocial) will further contribute to an individual's alienation from society. If particular rejections are generalized into feelings that the environment is unsupportive,more strongly negative emotions may motivate the individual to engage in crime. This is most likely to be true for younger individuals, and Agnew suggested that research focus on the magnitude, recency, duration, and clustering of such strain-related events to determine whether a person copes with strain in a criminal or conforming manner. Temperament, intelligence, interpersonal skills, self-efficacy, the presence of conventional social support, and the absence of association with antisocial ("e.g.", criminally inclined) age and status peers are chief among the factors Agnew identified as beneficial.

The strain theory of suicide postulates that suicide is usually preceded by psychological strains. A psychological strain is formed by at least two stresses or pressures, pushing the individual to different directions. A strain can be a consequence of any of the four conflicts: differential values, discrepancy between aspiration and reality, relative deprivation, and lack of coping skills for a crisis. Psychological strains in the form of all the four sources have been tested and supported with a sample of suicide notes in the United States and in rural China through psychological autopsy studies. The strain theory of suicide forms a challenge to the psychiatric model popular among the suicidologists in the world.
The strain theory of suicide is based on the theoretical frameworks established by previous sociologists, e.g. Durkheim (1951), Merton (1957), and Agnew (2006), and preliminary tests have been accomplished with some American (Zhang and Lester 2008) and Chinese data (Zhang 2010; Zhang, Dong, Delprino, and Zhou 2009; Zhang, Wieczorek, Conwell, and Tu 2011).
There could be four types of strain that precede a suicide, and each can be derived from specific sources. A source of strain must consist of two, and at least two, conflicting social facts. If the two social facts are non-contradictory, there would be no strain.
When two conflicting social values or beliefs are competing in an individual’s daily life, the person experiences value strain. The two conflicting social facts are competing personal beliefs internalized in the person’s value system. A cult member may experience strain if the mainstream culture and the cult religion are both considered important in the cult member’s daily life. Other examples include the second generation of immigrants in the United States who have to abide by the ethnic culture rules enforced in the family while simultaneously adapting to the American culture with peers and school. In China, rural young women appreciate gender egalitarianism advocated by the communist government, but at the same time, they are trapped in cultural sexual discrimination as traditionally cultivated by Confucianism. Another example that might be found in developing countries is the differential values of traditional collectivism and modern individualism. When the two conflicting values are taken as equally important in a person’s daily life, the person experiences great strain. When one value is more important than the other, there is then little or no strain.

Strain theory has received several criticisms, such as:

Strain theory was tested following its development. Most of these test examined ideal goals such as occupational goals and individual expectations, which would most ideally lead to crimes if not achieved under rule of strain theory. However, most of the research found that this was not the case. An example of these studies was a study done by Travis Hirschi in the 1969. He analyzes a large body of data on delinquency collected in Western Contra Costa County, California that contrast with strain theory. These results and other criticisms lead to the abandonment of strain theory around the 1970s to the 80s.

In addition to the study done by Hirschi, strain theory was explored in a 2011 study conducted by Jason D. Boardman (and others). The study explored how societal strain and stress can lead to drug use by individuals, in particular how one's neighborhood environment can affect their susceptibility to drug abuse. This study specifically centered around troubled neighborhoods in Detroit, and the results were based on census data taken of these neighborhoods, mainly because this data contained information on each individual resident's use of drugs. From this data, the study found that the more disadvantaged a neighborhood is, the more its residents abuse drugs. The study credited this positive trend to higher levels of stress and fewer available resources. According to strain theory, this lack of resources may compel an individual to abuse drugs to attain the positively valued goal of happiness by using the means that are currently available, which in the case of rough neighborhoods, were drugs.

Some research indicates that changes in the weather can increase the likelihood of children exhibiting deviant behavior.


O'Grady W. (2011). "Crime in Canadian Context." Strain/anomie theory 92-94



</doc>
<doc id="28248422" url="https://en.wikipedia.org/wiki?curid=28248422" title="Theft of electricity">
Theft of electricity

Theft of electricity is the criminal practice of stealing electrical power. It is a crime and is punishable by fines and/or incarceration. It belongs to the non-technical losses.

According to the annual "Emerging Markets Smart Grid: Outlook 2015" study by the Northeast Group, LLC, the world loses US$89.3 billion annually to electricity theft. The highest losses were in India ($16.2 billion), followed by Brazil ($10.5 billion) and Russia ($5.1 billion). 

President of Northeast Group Ben Gardner stated : "India loses more money to theft than any other country in the world. The state of Maharashtra—which includes Mumbai—alone loses $2.8 billion per year, more than all but eight countries in the world. Nationally, total transmission and distribution losses approach 23% and some states' losses exceed 50%."

There are various types of electrical power theft, including Tapping a line or bypassing the energy meter. According to a study , 80% of worldwide theft occurs in private dwellings and 20% on commercial and industrial premises. The various types of electrical power theft include:

What's known as "Cable Hooking" is the most used method. 80% of global power theft is by direct tapping from the line. The consumer taps into a power line from a point ahead of the energy meter. This energy consumption is unmeasured and procured with or without switches. 

In this method, the input terminal and output terminal of the energy meter is short-circuited, preventing the energy from registration in the energy meter.

Meters are manipulated via a remote by installing a circuit inside the meter so that the meter can be slowed down at any time. This kind of modification can evade external inspection attempts because the meter is always correct unless the remote is turned on.

This type of tampering is done to electromechanical meters with a rotating element. Foreign material is placed inside the meter to obstruct the free movement of the disc. A slower rotating disk signals less energy consumption.

This type of tampering is done on electronic meter to make it either latent damage or permanent damage. Detection can be done correctly in high end meters only.

A number of approaches to detect electricity theft have been proposed. The predominant direction in research and development is employing artificial intelligence, and in particular machine learning methods, to detect customers that steal electricity.

"Katiyabaaz" (Powerless), a 2014 Indian documentary film, dealt with issue of power theft in the city of Kanpur, Uttar Pradesh.

On March 27, 1886 it was reported that electricity espionage was accomplished by unscrupulous persons tapping into Edison Electricity in New York. The Superintendent of the power station sent a power surge into the line to burn out or destroy foreign objects trespassing on the line. 



</doc>
<doc id="7862242" url="https://en.wikipedia.org/wiki?curid=7862242" title="Gun violence">
Gun violence

Gun-related violence is violence committed with the use of a gun (firearm or small arm). Gun-related violence may or may not be considered criminal. Criminal violence includes homicide (except when and where ruled justifiable), assault with a deadly weapon, and suicide, or attempted suicide, depending on jurisdiction. Non-criminal violence includes accidental or unintentional injury and death (except perhaps in cases of criminal negligence). Also generally included in gun violence statistics are military or para-military activities.

According to GunPolicy.org, 75 percent of the world's 875 million guns are civilian controlled. Roughly half of these guns (48 percent) are in the United States, which has the highest rate of gun ownership in the world. Globally, millions are wounded and killed by the use of guns. Assault by firearm resulted in 180,000 deaths in 2013 up from 128,000 deaths in 1990. There were additionally 47,000 unintentional firearm-related deaths in 2013.

Levels of gun-related violence vary greatly among geographical regions, countries, and even subnationally. Rates of violent deaths by firearm range from as low as 0.03 and 0.04 per 100,000 population in Singapore and Japan, to 59 and 67 per 100,000 in Honduras and Venezuela. The highest rates of violent deaths by firearm in the world occur in low-income South and Central American countries such as Honduras, Venezuela, Colombia, El Salvador, Guatemala and Jamaica. The United States has the 11th highest rate of gun violence in the world, and by far the largest of any large or highly developed nation, having a gun homicide rate which is 25 times higher, an unintentional gun death rate which is 6 times higher, a firearm suicide rate which is 8 times higher, and an overall firearm death rate which is 10 times higher than the average respective rates of other high income nations. Compared to similarly wealthy nations with strict gun control laws, such as Japan, the United Kingdom, or South Korea, the United States has an overall rate of firearms death per capita, which is 50–100 times greater than many of its peers. The high rates of gun violence in the United States, which has the highest rate of gun-related deaths per capita among developed countries, despite having the highest number of police officers, is sometimes thought to be attributable to its extreme rate of gun ownership, as it is the only nation in which guns exceed people. Nearly all studies have found a positive association between gun ownership and gun-related homicide and suicide rates.

According to the United Nations, deaths from small firearms exceed that of all other weapons combined, and more die each year from gun-related violence than did in the atomic bombings of Hiroshima and Nagasaki combined. The global death toll from use of guns may number as high as 1,000 dead each day.

A number of ideas have been proposed on how to lessen the incidence of gun-related violence.

Some propose keeping a gun at home to keep one safer. Studies show that guns in the home is associated with an increased risk of violent death in the home. According to the FBI, gun-related violence is linked to gun ownership and is not a function or byproduct of crime. Their study indicates that more than 90% of gun-related deaths were not part of a commission of a crime, rather they were directly related to gun ownership. "Mother Jones" reports that "[a] Philadelphia study found that the odds of an assault victim being shot were 4.5 times greater if he carried a gun" and that "[h]is odds of being killed were 4.2 times greater" when armed. Others propose arming civilians to counter mass shootings. FBI research shows that between 2000 and 2013, "In 5 incidents (3.1%), the shooting ended after armed individuals who were not law enforcement personnel exchanged gunfire with the shooters." Another proposal is to expand self defense laws for cases where a person is being aggressed upon, although "those policies have been linked to a 7 to 10% increase in homicides" (that is, shootings where self-defense cannot be claimed).

There is a strong relationship between guns in the home, as well as access to guns more generally, and suicide risk, the evidence for which is strongest in the United States. A 1992 case-control study conducted in Tennessee and Washington found that individuals in a firearm owning home are close to five times more likely to commit suicide than those individuals who do not own firearms. A 2002 study found that access to guns in the home was associated with an increased risk of suicide among middle-aged and older adults, even after controlling for psychiatric illness. As of 2008, there were 12 case-control studies that had been conducted in the U.S., all of which had found that guns in the home were associated with an increased risk of suicide. However, a 1996 New Zealand study found no significant relationship between household guns and suicide. Assessing data from 14 developed countries where gun ownership levels were known, the Harvard Injury Control Research Center found statistically significant correlations between those levels and suicide rates. However, the parallels were lost when data from additional nations was included. A 2006 study found a significant effect of changes in gun ownership rates on gun suicide rates in multiple Western countries. During the 1980s and 1990s, the rate of adolescent suicides with guns caught up with adult rates, and the 75-and-older rate rose above all others. The use of firearms in suicides ranges from less than 10 percent in Australia to 50 percent in the United States, where it is the most common method and where suicides outnumber homicides 2-to-1. Those who purchased a firearm where found to be high risk for suicide within a week of the purchase The United States has both the highest number of Suicides and Gun ownerships for a developed country and firearms are the most popular method to commit suicide. In the United States when Gun ownerships rise so too does suicide by firearm. Suicide can be an impulsive act, 40% of those who survived a suicide attempt said that they only considered suicide up to five minutes before attempting the act. This impulsivity can lead to the use of a firearm as it is seen as a quick and lethal method.

According to U.S. criminologist Gary Kleck, studies that try to link gun ownership to victimology often fail to account for the presence of guns owned by other people. Research by economists John Lott of the U.S. and John Whitley of Australia indicates that safe-storage laws do not appear to affect juvenile accidental gun-related deaths or suicides. In contrast, a 2004 study led by Daniel Webster found that such laws were associated with slight reductions in suicide rates among children. The same study criticized Lott and Whitley's study on the subject for inappropriately using a Tobit model. A committee of the U.S. National Research Council said ecological studies on violence and firearms ownership provide contradictory evidence. The committee wrote: "[Existing] research studies and data include a wealth of descriptive information on homicide, suicide, and firearms, but, because of the limitations of existing data and methods, do not credibly demonstrate a causal relationship between the ownership of firearms and the causes or prevention of criminal violence or suicide."

The United Nations Office on Drugs and Crime (UNODC) defines intentional homicide as "acts in which the perpetrator intended to cause death or serious injury by his or her actions." This excludes deaths: related to conflicts (war); caused by recklessness or negligence; or justifiable, such as in self-defense or by law enforcement in the line of duty. A 2009 report by the Geneva Declaration using UNODC data showed that worldwide firearms were used in an average of 60 percent of all homicides. In the U.S. in 2011, 67 percent of homicide victims were killed by a firearm: 66 percent of single-victim homicides and 79 percent of multiple-victim homicides. In 2009, the United States' homicide rate was reported to be 5.0 per 100,000. A 2016 Harvard study claims that in 2010 the homicide rate was about 7 times higher than that of other high-income countries, and that the US gun homicide rate was 25.2 times higher. Another Harvard study found that higher gun availability was strongly correlated with higher homicide rates across 26 high-income countries. Access to guns is associated with an increased risk of being the victim of homicide. Access to firearms is not the sole contributor to increased homicide rates, however, as one study by the Southern Criminal Justice Association in 2011 found. Equally important seems to be the particular societal conditions in a given area, socio-culturally. These conditions include, but are not limited to societal age structure, economic inequality, cultural symbolism associated with firearms and the cultural value of individual life.

Some gun control advocates say that the strongest evidence linking availability of guns to death and injury is found in domestic violence studies, often referring to those by public health policy analyst Arthur Kellermann. In response to suggestions by some that homeowners would be wise to acquire firearms for protection from home invasions, Kellermann investigated in-home homicides in three cities over five years. He found that the risk of a homicide was in fact slightly higher in homes where a handgun was present. The data showed that the risk of a crime of passion or other domestic dispute ending in a fatal injury was higher when a gun was readily available (essentially loaded and unlocked) compared to when no gun was readily available. Kellerman said this increase in mortality overshadowed any protection a gun might have deterring or defending against burglaries or invasions. He also concluded that further research of domestic violence causes and prevention are needed.

Critics of Kellermann's study say that it is more directly a study of domestic violence than of gun ownership. Gary Kleck and others dispute the work. Kleck says that few of the homicides that Kellermann studied were committed with guns belonging to the victim or members of his or her household, and that it was implausible that victim household gun ownership contributed to their homicide. Instead, according to Kleck, the association that Kellermann found between gun ownership and victimization reflected that people who live in more dangerous circumstances are more likely to be murdered, but also were more likely to have acquired guns for self-protection.

In studies of nonfatal gun use, it was found that guns can contribute to coercive control, which can then escalate into chronic and more severe violence. Guns can have a negative impact on victims even without being discharged. Threats of gun use or showing a weapon can create damaging and long-lasting fear and emotional stress in victims because they are aware of the danger of having an abuser who has access to a gun.

The United Nations Office on Drugs and Crime defines robbery as the theft of property by force or threat of force. Assault is defined as a physical attack against the body of another person resulting in serious bodily injury. In the case of gun-related violence, the definitions become more specific and include only robbery and assault committed with the use of a firearm. Firearms are used in this threatening capacity four to six times more than firearms used as a means of protection in fighting crime. Hemenway's figures are disputed by other academics, who assert there are many more defensive uses of firearms than criminal uses. See John Lott's "More Guns, Less Crime".

In terms of occurrence, developed countries have similar rates of assaults and robberies with firearms, whereas the rates of homicides by firearms vary greatly by country.

From 1979 to 1997, almost 30,000 people in the United States alone died from accidental firearm injuries. A disproportionately high number of these deaths occurred in parts of the United States where firearms are more prevalent.

Violence committed with guns leads to significant public health, psychological, and economic costs.

The economic cost of gun-related violence in the United States is $229 billion a year, meaning a single murder has average direct costs of almost $450,000, from the police and ambulance at the scene, to the hospital, courts, and prison for the murderer. A 2014 study found that from 2006 to 2010, gun-related injuries in the United States cost $88 billion.

Assault by firearm resulted in 180,000 deaths worldwide in 2013, up from 128,000 deaths worldwide in 1990. There were 47,000 unintentional firearm deaths worldwide in 2013.

Emergency medical care is a major contributor to the monetary costs of such violence. It was determined in a study that for every firearm death in the United States for the year beginning 1 June 1992, an average of three firearm-related injuries were treated in hospital emergency departments.

Children exposed to gun-related violence, whether they are victims, perpetrators, or witnesses, can experience negative psychological effects over the short and long terms. Psychological trauma also is common among children who are exposed to high levels of violence in their communities or through the media. Psychologist James Garbarino, who studies children in the U.S. and internationally, found that individuals who experience violence are prone to mental and other health problems, such as post-traumatic stress disorder and sleep deprivation. These problems increase for those who experience violence as children.

The Port Arthur massacre of 1996 horrified the Australian public. The gunman opened fire on shop owners and tourists, killing 35 people and wounding 23. This massacre, kick started Australia's laws against guns. The Prime Minister at that time, John Howard, proposed a gun law that prevented the public from having all semi-automatic rifles, all semi-automatic and pump-action shotguns, in addition to a tightly restrictive system of licensing and ownership controls.

The government also bought back guns from people. In 1996–2003 it was estimated they bought back and destroyed nearly 1 million firearms. By the end of 1996, whilst Australia was still reeling from the Port Arthur massacre, the gun law was fully in place. Since then, the number of deaths related to gun-related violence dwindled almost every year. In 1979 six hundred and eighty-five people died due to gun violence, and in 1996 it was five hundred and sixteen. The numbers continue to drop, however they were declining also before the gun law was in place.

On the Australia's most mediated gun violence-related incident since Port Arthur, was the 2014 Sydney Hostage Crisis. On 15–16 December 2014, a lone gunman, Man Haron Monis, held hostage 17 customers and employees of a Lindt chocolate café. The perpetrator was on bail at the time, and had previously been convicted of a range of offences.

The following year in August, the New South Wales Government tightened the laws of bail and illegal firearms, creating a new offence for the possession of a stolen firearm, with a maximum of 14 years imprisonment.

Sweden witnessed a steep increase in gun violence in males aged 15 to 29 in the two decades prior to 2018, in addition to a rising trend in gun violence there was also a high rate of gun violence in Sweden compared to other countries in Western Europe. According to a report published by academic researchers in 2017, shooting incidents with fatal outcomes are about 4 to 5 times as common in Sweden compared to neighbouring countries such as Germany and Norway when taking population size into account. The city with the highest prevalence of shootings was Malmö. The grave violence in the studied period also changed character, from criminal motorcycle gangs to city suburbs.

According to researcher Amir Rostami at Stockholm University, police statistics for January–November 2018 showed that the number of shootings was at a continued high rate at 274, where up until the end of November 42 people had been shot and killed and 129 wounded compared to 43 in 2017. Rostami also said there had been 100 hand grenade attacks and 1500 shootings in Sweden since 2011, about 40 people are killed annually and 500 had been wounded. Rostami also said that if this violence had been attributed to some form of extremists, this would have considered a form of civil war. Almost half (46%) of all shootings in 2018 happened in public spaces in vulnerable areas. Both victims and perpetrators are becoming younger.

According to police in 2018, at least nine people who were innocent bystanders had been killed in cross-fire incidents in the last few years and the risk to the law-abiding public was therefore rising.

Gun violence in the United States results in tens of thousands of deaths and injuries annually. In 2013, there were 73,505 nonfatal firearm injuries (23.2 injuries per 100,000 U.S. citizens), and 33,636 deaths due to "injury by firearms" (10.6 deaths per 100,000 U.S. citizens). These deaths consisted of 11,208 homicides, 21,175 suicides, 505 deaths due to accidental or negligent discharge of a firearm, and 281 deaths due to firearms use with "undetermined intent". Of the 2,596,993 total deaths in the US in 2013, 1.3% were related to firearms. The ownership and control of guns are among the most widely debated issues in the country.

In 2010, 67% of all homicides in the U.S. were committed using a firearm. In 2012, there were 8,855 total firearm-related homicides in the US, with 6,371 of those attributed to handguns. In 2012, 64% of all gun-related deaths in the U.S. were suicides. In 2010, there were 19,392 firearm-related suicides, and 11,078 firearm-related homicides in the U.S. In 2010, 358 murders were reported involving a rifle while 6,009 were reported involving a handgun; another 1,939 were reported with an unspecified type of firearm.

Firearms were used to kill 13,286 people in the U.S. in 2015, excluding suicide. Approximately 1.4 million people have been killed using firearms in the U.S. between 1968 and 2011, equivalent to a top 10th largest U.S. city in 2016, falling between the populations of San Antonio and Dallas, Texas.

Compared to 22 other high-income nations, the U.S. gun-related murder rate is 25 times higher. Although it has half the population of the other 22 nations combined, the U.S. had 82 percent of all gun deaths, 90 percent of all women killed with guns, 91 percent of children under 14 and 92 percent of young people between ages 15 and 24 killed with guns. In 2010, gun violence cost U.S. taxpayers approximately $516 million in direct hospital costs.

Gun violence is most common in poor urban areas and frequently associated with gang violence, often involving male juveniles or young adult males. Although mass shootings have been covered extensively in the media, mass shootings in the US account for a small fraction of gun-related deaths and the frequency of these events steadily declined between 1994 and 2007, rising between 2007 and 2013.

Legislation at the federal, state, and local levels has attempted to address gun violence through a variety of methods, including restricting firearms purchases by youths and other "at-risk" populations, setting waiting periods for firearm purchases, establishing gun buyback programs, law enforcement and policing strategies, stiff sentencing of gun law violators, education programs for parents and children, and community-outreach programs. Despite widespread concern about the impacts of gun violence on public health, Congress has prohibited the Centers for Disease Control (CDC) from conducting research that advocates in favor of gun control. The CDC has interpreted this ban to extend to all research on gun violence prevention, and so has not funded any research on this subject since 1996.





</doc>
<doc id="3840014" url="https://en.wikipedia.org/wiki?curid=3840014" title="Illegal sports">
Illegal sports

An illegal sport is any sport that is illegal in one or more jurisdictions due to the violent or dangerous nature of the sport. Well-known illegal sports, such as cockfighting and dogfighting, are barred on the basis of animal abuse.

Illegal sports are controversial due to the dangerous aspects attributed to them and the pain they can inflict on humans or animals. They also are controversial due to the perceived nature of some of them — notably dogfighting — as being savage sports.

Cockfighting is a gambling and spectator sport where roosters fight, frequently to the death, in rings, while players place bets on which rooster will win. Often, sharp implements are attached to the legs of the birds, inflicting massive injuries and pain. The birds used for cockfighting sometimes are given stimulant drugs to enhance their fighting ability and make them more aggressive.

According to the Humane Society of the United States, cockfighting is illegal (at least a misdemeanor) in all fifty US states. It is classified as a felony in 39 states. Notable states that have less severe laws are Alabama, Hawaii, Idaho, and Mississippi (misdemeanor punishment for cockfighting; no punishment for possessing cock or being a spectator); South Carolina, South Dakota, Utah, and Kentucky (misdemeanor punishment for cockfighting, no punishment for possessing cocks, misdemeanor punishment for being a spectator).

Governor Frank Keating of Oklahoma said when outlawing cockfighting in his state that "Cockfighting is cruel, it promotes illegal gambling and it is simply embarrassing to Oklahoma to be seen as one of only a tiny handful of locations outside of the third world where this activity is legal." Since there is no reliable data on the status of cockfighting in the third world, it is assumed that cockfighting is largely legal, unpopular, or laws against it are unenforced amongst these nations.

Dog fighting is a practice, illegal in many jurisdictions, where two dogs, often a molosser breed, are put into an area to fight and sometimes kill each other. Dog fighting has been reported as far back as AD 43 when the Romans invaded Britain. Both sides employed fighting dogs, and out of their wartime use grew a sport, which achieved great popularity, particular in Britain and later the United States.

Dogfighting can involve high stakes, and carries with it the same sociological dangers of other gambling, and particularly illegal gambling, activities.

The American Society for the Prevention of Cruelty to Animals focuses heavily on the issue on dog fighting. There are various levels of dog fighting. There is “street” level, which means that the dogfights are informal because strict rules and regulations are absent from the matches. Another level is “hobbyists”, which are fights that are formally organized. They are mainly scheduled for income and speculators. The final level of dog fighting is “professional.” At the professional level, owners usually have more that fifty fighting dogs and carefully examine the specific breed, lineage, and winning history of each dog.

Dog fighting is illegal in every U.S. state and in many countries around the world (Britain, where it was quite popular, banned it as far back as the 1830s), although enforcement in other countries is frequently lax or nonexistent. Dog fighting is a felony in all states except Idaho and Wyoming, where it's a misdemeanor. It is a felony to possess dogs for fighting except in the states of New York, Texas, West Virginia, and Wyoming.

Street racing is the frequently illegal racing of motor vehicles on public roads and highways. These high-speed races, usually with untrained drivers, can result in fatal crashes that have the capacity to inflict damage on innocent people not participating in the race. In 2006, California state highway patrol issued 697 citations for "speed contests". There is no official statistic kept on street racing deaths. Street racing can become an addicting habit for many drivers.

BASE jumping is a form of skydiving from buildings. The sport is illegal in almost all cities, because the jumper risks seriously injuring himself and pedestrians or motorists when he lands. In many cases, BASE jumpers illegally access the high points from which they're jumping by breaking and entering or trespassing. Two BASE jumpers were arrested in St. Petersburg, Russia after jumping off of the Cathedral of the Apostles St. Peter and St. Paul in November 2011.


</doc>
<doc id="5785" url="https://en.wikipedia.org/wiki?curid=5785" title="Crime">
Crime

In ordinary language, a crime is an unlawful act punishable by a state or other authority. The term "crime" does not, in modern criminal law, have any simple and universally accepted definition, though statutory definitions have been provided for certain purposes. The most popular view is that crime is a category created by law; in other words, something is a crime if declared as such by the relevant and applicable law. One proposed definition is that a crime or offence (or criminal offence) is an act harmful not only to some individual but also to a community, society or the state ("a public wrong"). Such acts are forbidden and punishable by law.

The notion that acts such as murder, rape and theft are to be prohibited exists worldwide. What precisely is a criminal offence is defined by criminal law of each country. While many have a catalogue of crimes called the criminal code, in some common law countries no such comprehensive statute exists.

The state (government) has the power to severely restrict one's liberty for committing a crime. In modern societies, there are procedures to which investigations and trials must adhere. If found guilty, an offender may be sentenced to a form of reparation such as a community sentence, or, depending on the nature of their offence, to undergo imprisonment, life imprisonment or, in some jurisdictions, execution.

Usually, to be classified as a crime, the "act of doing something criminal" ("actus reus") mustwith certain exceptionsbe accompanied by the "intention to do something criminal" ("mens rea").

While every crime violates the law, not every violation of the law counts as a crime. Breaches of private law (torts and breaches of contract) are not automatically punished by the state, but can be enforced through civil procedure.

When informal relationships prove insufficient to establish and maintain a desired social order, a government or a state may impose more formalized or stricter systems of social control. With institutional and legal machinery at their disposal, agents of the State can compel populations to conform to codes and can opt to punish or attempt to reform those who do not conform.

Authorities employ various mechanisms to regulate (encouraging or discouraging) certain behaviors in general. Governing or administering agencies may for example codify rules into laws, police citizens and visitors to ensure that they comply with those laws, and implement other policies and practices that legislators or administrators have prescribed with the aim of discouraging or preventing crime. In addition, authorities provide remedies and sanctions, and collectively these constitute a criminal justice system. Legal sanctions vary widely in their severity; they may include (for example) incarceration of temporary character aimed at reforming the convict. Some jurisdictions have penal codes written to inflict permanent harsh punishments: legal mutilation, capital punishment or life without parole.

Usually, a natural person perpetrates a crime, but legal persons may also commit crimes. Conversely, at least under U.S. law, nonpersons such as animals cannot commit crimes.

The sociologist Richard Quinney has written about the relationship between society and crime. When Quinney states "crime is a social phenomenon" he envisages both how individuals conceive crime and how populations perceive it, based on societal norms.

The word "crime" is derived from the Latin root "cernō", meaning "I decide, I give judgment". Originally the Latin word "crīmen" meant "charge" or "cry of distress." The Ancient Greek word "krima" (κρίμα), from which the Latin cognate derives, typically referred to an intellectual mistake or an offense against the community, rather than a private or moral wrong.

In 13th century English "crime" meant "sinfulness", according to etymonline.com. It was probably brought to England as Old French "crimne" (12th century form of Modern French "crime"), from Latin "crimen" (in the genitive case: "criminis"). In Latin, "crimen" could have signified any one of the following: "charge, indictment, accusation; crime, fault, offense".

The word may derive from the Latin "cernere" – "to decide, to sift" (see crisis, mapped on Kairos and Chronos). But Ernest Klein (citing Karl Brugmann) rejects this and suggests *cri-men, which originally would have meant "cry of distress". Thomas G. Tucker suggests a root in "cry" words and refers to English plaint, plaintiff, and so on. The meaning "offense punishable by law" dates from the late 14th century. The Latin word is glossed in Old English by "facen", also "deceit, fraud, treachery", [cf. fake]. "Crime wave" is first attested in 1893 in American English.

Whether a given act or omission constitutes a crime does not depend on the nature of that act or omission. It depends on the nature of the legal consequences that may follow it. An act or omission is a crime if it is capable of being followed by what are called criminal proceedings.

History

The following definition of "crime" was provided by the Prevention of Crimes Act 1871, and applied for the purposes of section 10 of the Prevention of Crime Act 1908:

For the purpose of section 243 of the Trade Union and Labour Relations (Consolidation) Act 1992, a crime means an offence punishable on indictment, or an offence punishable on summary conviction, and for the commission of which the offender is liable under the statute making the offence punishable to be imprisoned either absolutely or at the discretion of the court as an alternative for some other punishment.

A normative definition views crime as deviant behavior that violates prevailing normscultural standards prescribing how humans ought to behave normally. This approach considers the complex realities surrounding the concept of crime and seeks to understand how changing social, political, psychological, and economic conditions may affect changing definitions of crime and the form of the legal, law-enforcement, and penal responses made by society.

These structural realities remain fluid and often contentious. For example: as cultures change and the political environment shifts, societies may criminalise or decriminalise certain behaviours, which directly affects the statistical crime rates, influence the allocation of resources for the enforcement of laws, and (re-)influence the general public opinion.

Similarly, changes in the collection and/or calculation of data on crime may affect the public perceptions of the extent of any given "crime problem". All such adjustments to crime statistics, allied with the experience of people in their everyday lives, shape attitudes on the extent to which the State should use law or social engineering to enforce or encourage any particular social norm. Behaviour can be controlled and influenced by a society in many ways without having to resort to the criminal justice system.

Indeed, in those cases where no clear consensus exists on a given norm, the drafting of criminal law by the group in power to prohibit the behaviour of another group may seem to some observers an improper limitation of the second group's freedom, and the ordinary members of society have less respect for the law or laws in generalwhether the authorities actually enforce the disputed law or not.

Legislatures can pass laws (called "mala prohibita") that define crimes against social norms. These laws vary from time to time and from place to place: note variations in gambling laws, for example, and the prohibition or encouragement of duelling in history. Other crimes, called "mala in se", count as outlawed in almost all societies, (murder, theft and rape, for example).

English criminal law and the related criminal law of Commonwealth countries can define offences that the courts alone have developed over the years, without any actual legislation: common law offences. The courts used the concept of "malum in se" to develop various common law offences.

One can view criminalization as a procedure deployed by society as a preemptive harm-reduction device, using the threat of punishment as a deterrent to anyone proposing to engage in the behavior causing harm. The State becomes involved because governing entities can become convinced that the costs of not criminalizing (through allowing the harms to continue unabated) outweigh the costs of criminalizing it (restricting individual liberty, for example, to minimize harm to others).

States control the process of criminalization because:

The label of "crime" and the accompanying social stigma normally confine their scope to those activities seen as injurious to the general population or to the State, including some that cause serious loss or damage to individuals. Those who apply the labels of "crime" or "criminal" intend to assert the hegemony of a dominant population, or to reflect a consensus of condemnation for the identified behavior and to justify any punishments prescribed by the State (in the event that standard processing tries and convicts an accused person of a crime).

Justifying the State's use of force to coerce compliance with its laws has proven a consistent theoretical problem. One of the earliest justifications involved the theory of natural law. This posits that the nature of the world or of human beings underlies the standards of morality or constructs them. Thomas Aquinas wrote in the 13th century: "the rule and measure of human acts is the reason, which is the first principle of human acts" (Aquinas, ST I-II, Q.90, A.I). He regarded people as by nature rational beings, concluding that it becomes morally appropriate that they should behave in a way that conforms to their rational nature. Thus, to be valid, any law must conform to natural law and coercing people to conform to that law is morally acceptable. In the 1760s William Blackstone (1979: 41) described the thesis:

But John Austin (1790–1859), an early positivist, applied utilitarianism in accepting the calculating nature of human beings and the existence of an objective morality. He denied that the legal validity of a norm depends on whether its content conforms to morality. Thus in Austinian terms, a moral code can objectively determine what people ought to do, the law can embody whatever norms the legislature decrees to achieve social utility, but every individual remains free to choose what to do. Similarly, Hart (1961) saw the law as an aspect of sovereignty, with lawmakers able to adopt any law as a means to a moral end.

Thus the necessary and sufficient conditions for the truth of a proposition of law simply involved internal logic and consistency, and that the state's agents used state power with responsibility. Ronald Dworkin (2005) rejects Hart's theory and proposes that all individuals should expect the equal respect and concern of those who govern them as a fundamental political right. He offers a theory of compliance overlaid by a theory of deference (the citizen's duty to obey the law) and a theory of enforcement, which identifies the legitimate goals of enforcement and punishment. Legislation must conform to a theory of legitimacy, which describes the circumstances under which a particular person or group is entitled to make law, and a theory of legislative justice, which describes the law they are entitled or obliged to make.

Indeed, despite everything, the majority of natural-law theorists have accepted the idea of enforcing the prevailing morality as a primary function of the law. This view entails the problem that it makes any moral criticism of the law impossible: if conformity with natural law forms a necessary condition for legal validity, all valid law must, by definition, count as morally just. Thus, on this line of reasoning, the legal validity of a norm necessarily entails its moral justice.

One can solve this problem by granting some degree of moral relativism and accepting that norms may evolve over time and, therefore, one can criticize the continued enforcement of old laws in the light of the current norms. People may find such law acceptable, but the use of State power to coerce citizens to comply with that law lacks moral justification. More recent conceptions of the theory characterise crime as the violation of individual rights.

Since society considers so many rights as natural (hence the term "right") rather than man-made, what constitutes a crime also counts as natural, in contrast to laws (seen as man-made). Adam Smith illustrates this view, saying that a smuggler would be an excellent citizen, "...had not the laws of his country made that a crime which nature never meant to be so."

Natural-law theory therefore distinguishes between "criminality" (which derives from human nature) and "illegality" (which originates with the interests of those in power). Lawyers sometimes express the two concepts with the phrases "malum in se" and "malum prohibitum" respectively. They regard a "crime "malum in se"" as inherently criminal; whereas a "crime "malum prohibitum"" (the argument goes) counts as criminal only because the law has decreed it so.

It follows from this view that one can perform an illegal act without committing a crime, while a criminal act could be perfectly legal. Many Enlightenment thinkers (such as Adam Smith and the American Founding Fathers) subscribed to this view to some extent, and it remains influential among so-called classical liberals and libertarians.

Some religious communities regard sin as a crime; some may even highlight the crime of sin very early in legendary or mythological accounts of originsnote the tale of Adam and Eve and the theory of original sin. What one group considers a crime may cause or ignite war or conflict. However, the earliest known civilizations had codes of law, containing both civil and penal rules mixed together, though not always in recorded form.

The Sumerians produced the earliest surviving written codes. Urukagina (reigned , short chronology) had an early code that has not survived; a later king, Ur-Nammu, left the earliest extant written law system, the Code of Ur-Nammu (), which prescribed a formal system of penalties for specific cases in 57 articles. The Sumerians later issued other codes, including the "code of Lipit-Ishtar". This code, from the 20th century BCE, contains some fifty articles, and scholars have reconstructed it by comparing several sources. 

Successive legal codes in Babylon, including the code of Hammurabi (), reflected Mesopotamian society's belief that law derived from the will of the gods (see Babylonian law).
Many states at this time functioned as theocracies, with codes of conduct largely religious in origin or reference. In the Sanskrit texts of Dharmaśāstra (), issues such as legal and religious duties, code of conduct, penalties and remedies, etc. have been discussed and forms one of the elaborate and earliest source of legal code.

Sir Henry Maine (1861) studied the ancient codes available in his day, and failed to find any criminal law in the "modern" sense of the word. While modern systems distinguish between offences against the "State" or "community", and offences against the "individual", the so-called penal law of ancient communities did not deal with "crimes" (Latin: "crimina"), but with "wrongs" (Latin: "delicta"). Thus the Hellenic laws treated all forms of theft, assault, rape, and murder as private wrongs, and left action for enforcement up to the victims or their survivors. The earliest systems seem to have lacked formal courts.

The Romans systematized law and applied their system across the Roman Empire. Again, the initial rules of Roman law regarded assaults as a matter of private compensation. The most significant Roman law concept involved "dominion". The "pater familias" owned all the family and its property (including slaves); the "pater" enforced matters involving interference with any property. The "Commentaries" of Gaius (written between 130 and 180 AD) on the Twelve Tables treated "furtum" (in modern parlance: "theft") as a tort.

Similarly, assault and violent robbery involved trespass as to the "pater's" property (so, for example, the rape of a slave could become the subject of compensation to the "pater" as having trespassed on his "property"), and breach of such laws created a "vinculum juris" (an obligation of law) that only the payment of monetary compensation (modern "damages") could discharge. Similarly, the consolidated Teutonic laws of the Germanic tribes, included a complex system of monetary compensations for what courts would consider the complete range of criminal offences against the person, from murder down.

Even though Rome abandoned its Britannic provinces around 400 AD, the Germanic mercenarieswho had largely become instrumental in enforcing Roman rule in Britanniaacquired ownership of land there and continued to use a mixture of Roman and Teutonic Law, with much written down under the early Anglo-Saxon kings. But only when a more centralized English monarchy emerged following the Norman invasion, and when the kings of England attempted to assert power over the land and its peoples, did the modern concept emerge, namely of a crime not only as an offence against the "individual", but also as a wrong against the "State".

This idea came from common law, and the earliest conception of a criminal act involved events of such major significance that the "State" had to usurp the usual functions of the civil tribunals, and direct a special law or "privilegium" against the perpetrator. All the earliest English criminal trials involved wholly extraordinary and arbitrary courts without any settled law to apply, whereas the civil (delictual) law operated in a highly developed and consistent manner (except where a king wanted to raise money by selling a new form of writ). The development of the idea that the "State" dispenses justice in a court only emerges in parallel with or after the emergence of the concept of sovereignty.

In continental Europe, Roman law persisted, but with a stronger influence from the Christian Church.
Coupled with the more diffuse political structure based on smaller feudal units, various legal traditions emerged, remaining more strongly rooted in Roman jurisprudence, but modified to meet the prevailing political climate.

In Scandinavia the effect of Roman law did not become apparent until the 17th century, and the courts grew out of the "things"the assemblies of the people. The people decided the cases (usually with largest freeholders dominating). This system later gradually developed into a system with a royal judge nominating a number of the most esteemed men of the parish as his board, fulfilling the function of "the people" of yore.

From the Hellenic system onwards, the policy rationale for requiring the payment of monetary compensation for wrongs committed has involved the avoidance of feuding between clans and families.
If compensation could mollify families' feelings, this would help to keep the peace. On the other hand, the institution of oaths also played down the threat of feudal warfare. Both in archaic Greece and in medieval Scandinavia, an accused person walked free if he could get a sufficient number of male relatives to swear him not guilty. (Compare the United Nations Security Council, in which the veto power of the permanent members ensures that the organization does not become involved in crises where it could not enforce its decisions.)

These means of restraining private feuds did not always work, and sometimes prevented the fulfillment of justice. But in the earliest times the "state" did not always provide an independent policing force. Thus criminal law grew out of what 21st-century lawyers would call torts; and, in real terms, many acts and omissions classified as crimes actually overlap with civil-law concepts.

The development of sociological thought from the 19th century onwards prompted some fresh views on crime and criminality, and fostered the beginnings of criminology as a study of crime in society. Nietzsche noted a link between crime and creativityin "The Birth of Tragedy" he asserted: "The best and brightest that man can acquire he must obtain by crime". In the 20th century Michel Foucault in "Discipline and Punish" made a study of criminalization as a coercive method of state control.

The following classes of offences are used, or have been used, as legal terms:

Researchers and commentators have classified crimes into the following categories, in addition to those above:

One can categorise crimes depending on the related punishment, with sentencing tariffs prescribed in line with the perceived seriousness of the offence. Thus fines and noncustodial sentences may address the crimes seen as least serious, with lengthy imprisonment or (in some jurisdictions) capital punishment reserved for the most serious.

Under the common law of England, crimes were classified as either treason, felony or misdemeanour, with treason sometimes being included with the felonies. This system was based on the perceived seriousness of the offence. It is still used in the United States but the distinction between felony and misdemeanour is abolished in England and Wales and Northern Ireland.

The following classes of offence are based on mode of trial:

In common law countries, crimes may be categorised into common law offences and statutory offences. In the US, Australia and Canada (in particular), they are divided into federal crimes and under state crimes.


In the United States since 1930, the FBI has tabulated Uniform Crime Reports (UCR) annually from crime data submitted by law enforcement agencies across the United States.
Officials compile this data at the city, county, and state levels into the UCR. They classify violations of laws based on common law as Part I (index) crimes in UCR data. These are further categorized as violent or property crimes. Part I violent crimes include murder and criminal homicide (voluntary manslaughter), forcible rape, aggravated assault, and robbery; while Part I property crimes include burglary, arson, larceny/theft, and motor-vehicle theft. All other crimes count come under Part II.

For convenience, such lists usually include infractions although, in the U.S., they may come into the sphere not of the criminal law, but rather of the civil law. Compare tortfeasance.

Booking arrests require detention for a time-frame ranging 1 to 24 hours.

There are several national and International organizations offering studies and statistics about global and local crime activity, such as United Nations Office on Drugs and Crime, the United States of America Overseas Security Advisory Council (OSAC) safety report or national reports generated by the law-enforcement authorities of EU state member reported to the Europol.

In England and Wales, as well as in Hong Kong, the term "offence" means the same thing as, and is interchangeable with, the term "crime", They are further split into:

Many different causes and correlates of crime have been proposed with varying degree of empirical support. They include socioeconomic, psychological, biological, and behavioral factors. Controversial topics include media violence research and effects of gun politics.

Emotional state (both chronic and current) have a tremendous impact on individual thought processes and, as a result, can be linked to criminal activities. The positive psychology concept of Broaden and Build posits that cognitive functioning expands when an individual is in a good-feeling emotional state and contracts as emotional state declines. In positive emotional states an individual is able to consider more possible solutions to problems, but in lower emotional states fewer solutions can be ascertained. The narrowed thought-action repertoires can result in the only paths perceptible to an individual being ones they would never use if they saw an alternative, but if they can't conceive of the alternatives that carry less risk they will choose one that they can see. Criminals who commit even the most horrendous of crimes, such as mass murders, did not see another solution.

Crimes defined by treaty as crimes against international law include:

From the point of view of state-centric law, extraordinary procedures (usually international courts) may prosecute such crimes. Note the role of the International Criminal Court at The Hague in the Netherlands.

Different religious traditions may promote distinct norms of behaviour, and these in turn may clash or harmonise with the perceived interests of a state. Socially accepted or imposed religious morality has influenced secular jurisdictions on issues that may otherwise concern only an individual's conscience. Activities sometimes criminalized on religious grounds include (for example) alcohol consumption (prohibition), abortion and stem-cell research. In various historical and present-day societies, institutionalized religions have established systems of earthly justice that punish crimes against the divine will and against specific devotional, organizational and other rules under specific codes, such as Roman Catholic canon law.

In the military sphere, authorities can prosecute both regular crimes and specific acts (such as mutiny or desertion) under martial-law codes that either supplant or extend civil codes in times of (for example) war.

Many constitutions contain provisions to curtail freedoms and criminalize otherwise tolerated behaviors under a state of emergency in the event of war, natural disaster or civil unrest. Undesired activities at such times may include assembly in the streets, violation of curfew, or possession of firearms.

Two common types of employee crime exist: embezzlement and wage theft.

The complexity and anonymity of computer systems may help criminal employees camouflage their operations. The victims of the most costly scams include banks, brokerage houses, insurance companies, and other large financial institutions.

In the United States, it is estimated that workers are not paid at least $19 billion every year in overtime and that in total $40 billion to $60 billion are lost annually due to all forms of wage theft. This compares to national annual losses of $340 million due to robbery, $4.1 billion due to burglary, $5.3 billion due to larceny, and $3.8 billion due to auto theft in 2012. In Singapore, as in the United States, wage theft was found to be widespread and severe. In a 2014 survey it was found that as many as one-third of low wage male foreign workers in Singapore, or about 130,000, were affected by wage theft from partial to full denial of pay.




</doc>
<doc id="5183398" url="https://en.wikipedia.org/wiki?curid=5183398" title="Midnight basketball">
Midnight basketball

Midnight basketball was a 1990s initiative to curb inner-city crime in the United States by keeping urban youth off the streets and engaging them with alternatives to drugs and crime. It was founded by G. Van Standifer in the late 1980s. Young people aged from 14 to 25, mostly men of various minority groups, could go and play basketball during the prime crime hours of 10 pm to 2 am, and then attended informative programs that gave them helpful skills for everyday life. It was a way for young men to form a sense of community, get out of a dangerous environment, and give them a sense of hope for the future. Midnight basketball helped decrease crime in the neighbourhoods where it was run, and it was a positive outlet for many young men. It helped many stay out of trouble and off the streets.

Midnight basketball began in Glenarden, Maryland, in 1986, when crack cocaine first came to Washington. The program was started when Van Standifer noticed that the crime rates were incredibly high especially during the hours of 10 pm and 2 am. He observed that young men had nothing to do, as many did not have jobs, were living in poverty and could not always afford to do something. He opened Glenarden Recreation Center, funded by both private donations and public funds. They ran during those specific hours, where young men could come and play basketball. It was run by volunteers and supervised by officers to make sure everything was alright. Even the officers complimented how well the programs were working and what a benefit it was to the community. Afterwards, participants would have to attend workshops that informed them about different necessities for living. It lowered crime rates in the area, and the programs were found to be incredibly helpful to the young men. Soon other communities saw the merit in the program and started to adopt Midnight Basketball themselves. It was later added to the Violent Crime Control and Law Enforcement Act of 1994 and was signed by President Bill Clinton.

In 1994, Bill Clinton pushed for an anti-crime bill that would lead to 100,000 more police officers as well as a number of programs intended to "deter crime where it starts" by providing "community activities like midnight basketball." At the time of its inception, despite being racially coded, it was a relatively unknown and uncontroversial piece of policy innovation. However, once President Clinton's anti-crime bill was being debated about five years after the creation of Midnight Basketball, it became a highly contentious part of the bill. This was striking because the initiative only made up $50 million of the original $33 billion bill. Midnight Basketball's initiative was already racially coded, so when lawmakers were discussing whether it was a positive or negative part of this massive bill, it was part of a covert racial dialogue. It was argued that race was the key to midnight basketball's importance. The influence of the media associating crimes with African Americans actually made crime seem more dangerous, and there was more want for anti-crime programs.

The plan was widely criticized by conservatives such as House Minority Whip Newt Gingrich, who cited midnight basketball as an ineffective and wasteful use of federal funds. Some, such as Rush Limbaugh, even called the proposal racist, given the largely African American populations targeted by the program. Midnight basketball was not a proposal unique to the Democrats as it was one of George H. W. Bush's "thousand points of light". It was also argued that violence portrayed in the media could influence young African American men and actually raise the crime rate, so there was some action taken to try to reduce the crime and violence shown to the younger generation. When Midnight Basketball was discussed in the media in relation to the anti-crime bill, 98.2 percent of the time it was being shown negatively was when it was coming from an identifiable conservative-Republican. On the other hand, when a liberal-Democratic source discussed it, it was shown in a positive light 97.9 percent of the time. It was even referred to as social engineering by some Republican opponents. Midnight Basketball became the symbol of the overall anti-crime bill struggle. Specifically, it allowed racial issues to be explicitly talked about, and because Midnight Basketball was almost completely for crime prevention in minorities, it helped make young African-American men the face of crime.

Either before or after participants would play in their basketball games, they would have to attend informal workshops or programs on different life skills. Programs would be aimed to provide assistance and advice to different groups of young people, mostly male minorities, including the unemployed, impoverished, ex-convicts, and young males. The programs goals were to help young people get to a place where they would be self-sufficient and well-versed in how to act and live successfully, while staying away from violent or harmful situations. It helped many young men who went back to school, and got jobs, all while staying off the streets.

The main focus of the programs include:
A list of some content of different sessions include:
The volunteers work hard to make sure they do everything they can to provide for the young men, and the programs have helped to give hope to its participants. It has also helped save many lives, and help them into a more successful environment.

Empirically, a 2006 study of the 1990-1994 period during which rates of most crimes in the United States peaked, and when urban midnight basketball programs were initiated as a crime-prevention strategy, found that—while confounding factors were likely involved—property crime rates fell more rapidly in cities that were early adopters of the original midnight basketball model than in other American cities in the same period. It shows that there was a drop in crime rates in places where these programs were taking place. There was a 30% drop in crime in Glenarden, where the program began, and Phoenix had 10.4% less juvenile arrests and 50% less juvenile related incidents. In one "Los Angeles Times" article it is stated that "There was a 60% reduction in drug-related crime." Although there was uncertainty about this statistic, as the Chicago leagues had only 160 participants and there were still around 85,000 young adults across the city that were at risk, which made the statistics seem unrealistic. Participants were not at risk of committing a crime when they attended basketball, and there were police officers stationed in the building to make sure of this. An article from Texas stated that it "has cut crime in one Fort Worth neighborhood 89 percent on nights when games are held." As well, "Murders, rapes, robberies and burglaries dropped to zero during the late-night games." The program helps show the young men a sense of community, friendship, and sportsmanship that they wouldn't have gotten to experience on the streets. There are some people who believed that it would actually increase crime because it would bring at-risk people into a group together, and it might encourage gangs. However, this is not the case, and the program has been very successful, and a program has even started in Australia. It has helped give young men an alternative to crime, and many have found jobs or are seeking further education.




</doc>
<doc id="23128919" url="https://en.wikipedia.org/wiki?curid=23128919" title="Smuggling tunnel">
Smuggling tunnel

Smuggling tunnels are secret passages used for the smuggling of goods and people. The term is also used where the tunnels are built in response to a siege.

The Sarajevo Tunnel operated during the Siege of Sarajevo as a passage underneath the no-man's land of the city's (closed) airport, providing a vital smuggling link for the beleaguered city residents. Guns were smuggled into the city and people were smuggled out. After the war, the Sarajevo Tunnel Museum was built onto the historic private house whose cellar served as the entrance to Sarajevo Tunnel.


A 700-meter smuggling tunnel with a narrow gauge railway was revealed in July 2012 between Uzhgorod, Ukraine, and Vyšné Nemecké, Slovakia, at the border of Schengen Area. The tunnel used professional mining and security technologies. It was used primarily for smuggling of cigarettes.

Many villages on the southern coast of England have a local legend of a smugglers' tunnel, although the entrances to most of the actual smugglers' tunnels have been lost or bricked up.

Some tunnel stories turn out to be plausible, such as the tunnel at Hayle in Cornwall, which seems to have been built specifically for smuggling. However, tunnels often double as a storm drain or some other functional channel, or else is an extension of a natural fissure in the rock as at Methleigh and Porthcothan, but tunnels and caches (both wholly excavated and formed by extending natural formations) are more commonplace where covert landings in areas with few sheltered beaches exposed smugglers to the attentions of the Revenue Men.While many sites are rudimentary, extensive workings have been found which show evidence of skillful excavation, strongly implying the assistance of tin miners, doubtless the case in the recent example of extensive excavations discovered in 2008 when builders renovating a waterfront warehouse in Penzance took up hatch covers and found several tunnels, one extending some 300 yards and emerging into the cellar of an 18th-century public house after passing beneath several roads.
Beith in North Ayrshire was a notorious haunt of smugglers at one time, and legend has it that a tunnel ran from the town centre down to Kilbirnie Loch.

The Gaza Strip smuggling tunnels connect Egypt and the Gaza Strip, bypassing the Egypt–Gaza barrier built by Israel along the international border established by the Egypt–Israel Peace Treaty. The tunnels pass under the Philadelphi corridor, an area specified in the Oslo accords as being under Israeli military control, in order to secure the border with Egypt.

In early 2005, a group of Canadian drug smugglers took up the idea, and constructed a tunnel between a greenhouse in Langley, British Columbia and the basement of a house in Lynden, Washington, which lay across the ditch marking the Canada–US border (the house on the Langley side was on 0 Avenue ("Zero Avenue"), which runs parallel to the border and is the baseline of Langley's avenue-numbering system). They bought the two properties and began construction work. Authorities were alerted when a neighbor noticed the large-scale construction work being undertaken in the greenhouse. Inspection revealed that tons of construction material were entering, and piles of earth were coming out.

It became known within a short time, by both American and Canadian border authorities, that a tunnel was being built. Video and audio devices were installed secretly by United States customs officials both at the termini and in the tunnel itself. On July 14, the tunnel having been completed, the first packs of marijuana began going through. Officials raided the home soon afterward and arrested the three men, who then appeared before court in Seattle. The tunnel was sealed and the roads above it were rebuilt, but the US house where the tunnel exited still exists.

As of September 30, 2015, 183 illicit cross-border tunnels have been discovered in the United States since Fiscal Year 1990.

On January 25, 2006, a tunnel was found on the US-Mexico border by a joint US Drug Enforcement Administration, US Immigration and Customs Enforcement, and US Border Patrol task force. The long tunnel runs from a warehouse near the Tijuana airport to a warehouse in San Diego. When discovered, it was devoid of people, but it did contain of marijuana. It was high and up to deep. The floor was made of cement, and the walls were exposed clay, with lights lining one side, a ventilation system to keep fresh air circulating, and a water drainage system to remove infiltrating ground water. Authorities said it was unclear how long the tunnel had been in operation.

On January 30, US Immigrations and Customs Enforcement agents arrested a Mexican citizen who was linked to the tunnel via the US warehouse, operated by V&F Distributors LLC. On the Friday before, January 27, immigration authorities reportedly received information that the Mexican cartel behind the operation was threatening the lives of any agents involved with the construction or occupation of the tunnel. US Customs and Immigration, however, pledged to protect them as best they could. Authorities believe Tijuana's Arellano-Felix drug syndicate, or some other well-known drug cartel, was behind the building and operation of the tunnel.

On November 26, 2010, a tunnel was discovered linking Tijuana to Otay Mesa, San Diego, California. In the same month another tunnel was discovered between these two cities. Both tunnels were discovered by a San Diego task force and are believed to be the work of Mexico's Sinaloa cartel. Over of cannabis was found and confiscated between the two.

An analysis of US-Mexico smuggling tunnels, the US-Canada smuggling tunnel, and the smuggling tunnels in Rafah, Gaza Strip, was completed by Lichtenwald and Perri as part of a transnational analysis of smuggling tunnels. Lichtenwald and Perri outlined sources and methods for evaluating which tunnels are used by different populations in various parts of the world to smuggle contraband that does not threaten a nation’s security, which tunnels that smuggle contraband that does threaten a nation’s security, and hybrid tunnels that smuggle contraband that threaten a nation’s security as well as that which does not.

In December 2012, a tunnel 3 feet in diameter and 100 yards long, with electricity and ventilation, was found near the Nogales, Arizona, port of entry. Since 1990, there have been almost 170 tunnels found leading into Mexico, mostly in Arizona and California. On February 14, 2014 another underground drug tunnel was discovered in Nogales.

The tunnel spanned , or longer than 1.5 American football fields. The tunnel was being used to smuggle marijuana and other drugs into the US. Another of marijuana was seized after federal agents stopped a vehicle they saw driving away from the residence. Some of marijuana and of heroin were found inside the tunnel. Three people have been arrested in connection with the bust.



</doc>
<doc id="54697184" url="https://en.wikipedia.org/wiki?curid=54697184" title="Crime drop">
Crime drop

The crime drop or crime decline is a pattern observed in many countries whereby rates of many types of crime declined by 50% or more beginning in the early 1990s. 

In the United States, for example, violent crime rates have fallen by over 50% in many major U.S. cities since these rates peaked in the early 1990s; in New York City, these rates had dropped by 75% from the early 1990s to 2010. In the United States, a second decline in the crime rate was also observed, with homicide rates declining first from 1994 to 2002, and then again from 2007 to 2011. The crime rate in Los Angeles decreased from 1993 onward, including e.g. a decrease in the crime rate of 10% during the first six months of 1998. 

On average, international crime declines from 1995 to 2004 were as follows: 77.1 percent in theft from cars, 60.3 percent in theft from person, 26.0 percent in burglary, 20.6 percent in assault and 16.8 percent in car theft. The crime drop since the early 1990s has occurred in many countries, including the United States, the United Kingdom, and New Zealand. However, no overall crime decline occurred in Western Europe during this period.

Many hypotheses have been proposed as to why crime has fallen, especially in the United States. Blumstein & Wallman (2006) conclude that a complex interaction between "prisons, drugs, guns, policing, economics," and "demography, including abortion" is the best explanation for the crime drop in the United States.

The lead-crime hypothesis proposed a link between elevated blood lead levels in children and later increases in crime. Children exposed to forms of lead at young ages are hypothesized to be more likely to develop learning disabilities, attention deficit hyperactivity disorder, and problems with impulse control. These problems are suggested to lead to the commission of more crimes as these children reach adulthood, especially violent crimes. 

Alfred Blumstein argues that part of the drop in the United States' violent crime rate is due to declining demand for crack cocaine. A 2014 report by the Home Office stated that changes in demand for illegal drugs (specifically, heroin) were a major contributor to the crime drop in the United Kingdom.

The mainstream view among criminologists is that unemployment and poverty are strongly related to crime, because a decrease in opportunities for legal employment, in theory, should increase the frequency of illegal employment. Multiple studies of the United States, for example, have found that the improvement of the American economy coincided with a drop in crime throughout the 1990s. A 2015 Brennan Center for Justice report, however, estimated that no more than 5 percent of the 1990s crime drop in the United States was attributable to changes in unemployment. The view that higher unemployment rates cause higher crime rates has also been challenged by the fact that the United States crime rate reached a 40-year low in 2010, despite America's lagging economy.

Studies of the United States have shown that increases in the concentration of immigrants are associated with decreases in violent crime rates, especially homicide and robbery. This relationship suggests that increasing immigration to the United States may be responsible for part of the recent drop in violent crime rates in the United States.

A 2015 Brennan Center for Justice report found that increased incarceration was responsible for about 5% of the crime drop in the United States during the 1990s, and for essentially none of the crime drop there since 2000. Commentators and academics who question the role of incarceration in the crime drop have noted that Canada's crime rates followed similar trends as those in the United States during the 1990s; in contrast, Canada's incarceration rate did not change significantly during this time, while that of the United States increased significantly. In 2009, Steven Messner and Richard Rosenfeld found that incarceration was negatively related to burglary rates "...only after unusual policy interventions, such as Italy's 2006 clemency measure that dramatically reduced the size of its prison population."

Some have proposed that changes in policing practices (e.g. the adoption of broken windows policing) were responsible for the crime drop in the United States, especially in New York City. However, Canada did not change its policing practices significantly prior to their crime drop, which casts doubt on the extent to which policing was responsible for this phenomenon. Some of the most popular claims about policing reducing violent crime are not supported by the evidence.

Levitt (2004) estimates that increases in the number of police accounted for between 5 and 6% of the crime drop in the United States during the 1990s. A 2007 study found that misdemeanor arrests were negatively associated with changes in total homicide rates in New York City.

A 2014 article in "Crime and Justice" reported that the "security hypothesis" was the best explanation for the drop out of the 17 hypotheses tested. This hypothesis proposes that improved and more widespread security devices, like electronic immobilizers and central locking, were responsible for a large part of the crime drop by preventing numerous crimes. Consistent with this hypothesis, attempted crime has also been declining, suggesting that would-be criminals are becoming discouraged by improved security.






</doc>
<doc id="5392947" url="https://en.wikipedia.org/wiki?curid=5392947" title="Fear of crime">
Fear of crime

The fear of crime refers to the fear of being a victim of crime as opposed to the actual probability of being a victim of crime. 
The fear of crime, along with fear of the streets and the fear of youth, is said to have been in Western culture for "time immemorial". While fear of crime can be differentiated into public feelings, thoughts and behaviors about the personal risk of criminal victimization, distinctions can also be made between the tendency to see situations as fearful, the actual experience while in those situations, and broader expressions about the cultural and social significance of crime and symbols of crime in people's neighborhoods and in their daily, symbolic lives.

Importantly, feelings, thoughts and behaviors can have a number of functional and dysfunctional effects on individual and group life, depending on actual risk and people's subjective approaches to danger. On a negative side, they can erode public health and psychological well-being; they can alter routine activities and habits; they can contribute to some places turning into 'no-go' areas via a withdrawal from community; and they can drain community cohesion, trust and neighborhood stability. Some degree of emotional response can be healthy: psychologists have long highlighted the fact that some degree of worry can be a problem-solving activity, motivating care and precaution, underlining the distinction between low-level anxieties that motivate caution and counter-productive worries that damage well-being.

Factors influencing the fear of crime include the psychology of risk perception, circulating representations of the risk of victimization (chiefly via interpersonal communication and the mass media), public perceptions of neighborhood stability and breakdown, the influence of neighbourhood context, and broader factors where anxieties about crime express anxieties about the pace and direction of social change. There are also some wider cultural influences. For example, some have argued that modern times have left people especially sensitive to issues of safety and insecurity.

Fear of crime has had a profound impact on the U.S. incarceration rate, having inspired the "tough on crime" policies of the 1980s that led to Draconian sentences being widespread. Crime rates started decreasing before the new sentencing policies were implemented. Also significant is how despite the decrease in crime, media coverage of crime increased by 600% between 1998 and 2008. The media's "culture of fear" has largely been dominated by frequent stories of crime and punishment.

The core aspect of fear of crime is the range of emotions that is provoked in citizens by the possibility of victimization. While people may feel angry and outraged about the extent and prospect of crime, surveys typically ask people "who they are afraid of" and "how worried they are". Underlying the answers that people give are (more often than not) two dimensions of 'fear': (a) those everyday moments of worry that transpire when one feels personally threatened; and (b) some more diffuse or 'ambient' anxiety about risk. While standard measures of worry about crime regularly show between 30% and 50% of the population of England and Wales express some kind of worry about falling victim, probing reveals that few individuals actually worry for their own safety on an everyday basis. One thus can distinguish between fear (an emotion, a feeling of alarm or dread caused by an awareness or expectation of danger) and some broader anxiety. Some people may be more willing to admit their worries and vulnerabilities than others.

Concern about crime can be differentiated from perceptions of the risk of personal victimization (i.e. cognitive aspects of fear of crime). Concern about crime includes public assessments of the size of the crime problem. An example of a question that could be asked is whether crime has increased, decreased or stayed the same in a certain period (and/or in a certain area, for instance the respondents own neighborhood). Between 1972 and 2001, the Gallup Poll shows that American respondents think crime has decreased. By contrast, the cognitive side of fear of crime includes public perceptions of the likelihood of falling victim, public senses of control over the possibility, and public estimations of the seriousness of the consequences of crime. People who feel especially vulnerable to victimization are likely to feel that they are especially likely to be targeted by criminals (i.e. victimization is likely), that they are unable to control the possibility (i.e. they have low self-efficacy), and that the consequences would be especially severe. Additionally, these three different components of risk perception may interact: the impact of perceived likelihood on subsequent emotional response (worry, fear, anxiety, etc.) is likely to be especially strong among those who feel that consequences are high and self-efficacy is low.

A third way to measure fear of crime is to ask people whether they ever avoid certain areas, protect certain objects or take preventive measures. This way, measuring fear of crime can become a relatively straightforward thing, because the questions asked tap into actual behavior and 'objective' facts, such as the amount of money spent on a burglar-alarm or extra locks. Although, some researchers such as Jesse Omoregie argue that measuring fear of crime can be problematic as there are various factors like social desirability effects, respondents downplaying or over-exaggerating their fear which can affect the reliability of data. Some degree of 'fear' might be healthy for some people, creating a 'natural defence' against crime. In short, when the risk of crime is real, a specific level of 'fear' might actually be 'functional': worry about crime might stimulate precaution which then makes people feel safer and lowers their risk of crime. The fear of crime is a very important feature in criminology.

Perhaps the biggest influence on fear of crime is public concern about neighbourhood disorder, social cohesion and collective efficacy. The incidence and risk of crime has become linked with perceived problems of social stability, moral consensus, and the collective informal control processes that underpin the social order of a neighborhood. Such 'day-to-day' issues ('young people hanging around', 'poor community spirit', 'low levels of trust and cohesion') produce information about risk and generate a sense of unease, insecurity and distrust in the environment (incivilities signal a lack of conventional courtesies and low-level social order in public places). Moreover, many people express through their fear of crime some broader concerns about neighbourhood breakdown, the loss of moral authority, and the crumbling of civility and social capital.

People can come to different conclusions about the same social and physical environment: two individuals who live next door to each other and share the same neighbourhood can view local disorder quite differently. Why might people have different levels of tolerance or sensitivity to these potentially ambiguous cues? UK research has suggested that broader social anxieties about the pace and direction of social change may shift levels of tolerance to ambiguous stimuli in the environment. Individuals who hold more authoritarian views about law and order, and who are especially concerned about a long-term deterioration of community, may be more likely to perceive disorder in their environment (net of the actual conditions of that environment). They may also be more likely to link these physical cues to problems of social cohesion and consensus, of declining quality of social bonds and informal social control.

Hearing about events; knowing others who have been victimised– these are thought to raise perceptions of the risk of victimisation. This has been described as a 'crime multiplier', or processes operating in the residential environment that would 'spread' the impacts of criminal events. Such evidence exists that hearing of friends' or neighbours' victimisation increases anxiety that indirect experiences of crime may play a stronger role in anxieties about victimisation than direct experience. However, there is a cautionary note: '… many residents of a neighbourhood only know of [crime] indirectly via channels that may inflate, deflate, or garble the picture.' A subject's criminal risk perception is exaggerated by peer-communication on crime and only moderated by the own experience.

Public perceptions of the risk of crime are no doubt also strongly shaped by mass media coverage. Individuals pick up from media and interpersonal communication circulating images of the criminal event - the perpetrators, victims, motive, and representations of consequential, uncontrollable, and sensational crimes. The notion of 'stimulus similarity' may be key: if the reader of a newspaper identifies with the described victim, or feels that their own neighbourhood bears resemblance to the one described, then the image of risk may be taken up, personalised and translated into personal safety concerns.

Yet the relationship between fear of crime and mass media is unclear, at least in its causal ordering. To put the dilemma in simple terms: do people fear crime because a lot of crime is being shown on television, or does television just provide footage about crimes because people fear crime and want to see what's going on? The complex nature of crime could allow the media to exploit social naivety, covering crime not only selective, but also distorting the everyday world of crime. Some say the media contribute to the climate of fear that is created, because the actual frequency of victimisation is a tiny fraction of potential crime.

With crime accounting for up to 25 per cent of news coverage, the quality and angle of the coverage becomes an issue. The media displays violent crime disproportionately, whilst neglecting minor crimes. The reality is violent crime has been declining in the past 10 years The profile of offenders in the media is distorted, causing misunderstanding of criminal offending.

Unfortunately, however, despite an abundant literature on media effects – particularly the 'mean world' hypothesis – little work has been done into how representations, imagery and symbols of crime circulate in society, transmitted and transformed by multiple actors with a wide array of effects, only to translate into personal fears about crime. Perhaps future work will take account of the transmission mechanisms through which representations, beliefs and attitudes about societal risks are propagated in different social and cultural contexts.

Fear of crime can also be understood from a social constructionist perspective. The term and concept of fear of crime did not, for example, enter the public or political lexicon until the mid-1960s. That is not to say individuals did not fear crime victimization prior to this period, clearly they did at various points in history to varying degrees. However it demonstrates that fear of crime only became part of a political economy when researchers began to measure and analyse it under the auspice of The US President's Commission on Law Enforcement and the Administration of Justice which reported in 1967 Once fear of crime had a name it could be deployed as a political tactic in a law and order politics. It also became something that citizens could experience as an emotional response to the threat of victimisation. The formation of a 'fear of crime feedback loop' then allowed more citizens to be surveyed as fearful, more politicians to be able to use crime fear as a political issue, security products to be sold on the back of crime fear and so on in an ever-increasing spiral that popularised crime fear. Moreover, once citizens were seen as being motivated by concerns about crime fear of crime could be used as a responsibilising technique to activate citizens to conduct themeselves or consume products in ways that reduce their vulnerability to crime victimisation. This approach to understanding fear of crime does not deny the experiences of individuals who fear crime victimisation but suggests that such experiences have to be understood as being intimately connected to broader socio-political contexts.




</doc>
<doc id="55870946" url="https://en.wikipedia.org/wiki?curid=55870946" title="Counterfeit illegal drug selling">
Counterfeit illegal drug selling

Selling counterfeit illegal drugs is a crime in many U.S. states' legal codes and in the federal law of the United States. It is also illegal to sell counterfeit drugs in the United Kingdom. The fake drugs are sometimes termed as imitation controlled substances.

Some fake drugs consist of substances from relatively harmless sources, such as grocery store goods like flour, oregano or allergy pills. Even despite the substances' harmlessness, legal penalties for the crime of selling them can include time in jail.

Certain fake drugs include other controlled drugs, or they may include synthetic drugs with similar properties. Uncertainty of an identity of the substance may increase the risk of an overdose.

A related, yet distinct, problem is the trade of counterfeit medications with pills including substances such as fentanyl which can be used recreationally.

There is a low chance of law punishing fraud among illicit drug traders, however it is likely that informal social control among drug traders reduces the likelihood of fraud between illegal trade partners. For instance, getting robbed or losing a business contact may not justify dealer's increased profits for a short-term from fraudulent behavior.

Selling counterfeit illicit drugs is illegal even if the substances used to make the imitation drug are not illegal on themselves. It is illegal to distribute or sell counterfeit fake drugs in many U.S. states including Nevada, Ohio, Illinois, Florida, Michigan and Massachusetts. Selling counterfeit illicit drugs is also illegal in the United Kingdom.

Selling counterfeit illicit drugs is illegal under the U.S. federal law. Relevant parts of the U.S. federal law include 21 U.S.C. Section 331 and 18 U.S. Code § 1001.

21 U.S.C. Section 331 makes it illegal to sell an adulterated or misbranded drug in interstate commerce.

18 U.S. Code § 1001 bans




</doc>
<doc id="18618063" url="https://en.wikipedia.org/wiki?curid=18618063" title="Black market">
Black market

A black market, underground economy, or shadow economy is a clandestine market or series of transactions that has some aspect of illegality or is characterized by some form of noncompliant behavior with an institutional set of rules. If the rule defines the set of goods and services whose production and distribution is prohibited by law, non-compliance with the rule constitutes a black market trade since the transaction itself is illegal. Parties engaging in the production or distribution of prohibited goods and services are members of the illegal economy. Examples include the drug trade, prostitution (where prohibited), illegal currency transactions and human trafficking. Violations of the tax code involving income tax evasion constitute membership in the unreported economy.

Because tax evasion or participation in a black market activity is illegal, participants will attempt to hide their behavior from the government or regulatory authority. Cash usage is the preferred medium of exchange in illegal transactions since cash usage does not leave a footprint. Common motives for operating in black markets are to trade contraband, avoid taxes and regulations, or skirt price controls or rationing. Typically the totality of such activity is referred to with the definite article as a complement to the official economies, by market for such goods and services, e.g. "the black market in bush meat".

The black market is distinct from the grey market, in which commodities are distributed through channels that, while legal, are unofficial, unauthorized, or unintended by the original manufacturer, and the white market, in which trade is legal and official.

Black money is the proceeds of an illegal transaction, on which income and other taxes have not been paid, and which can only be legitimised by some form of money laundering. Because of the clandestine nature of the black economy it is not possible to determine its size and scope.

The literature on the black market has not established a common terminology and has instead offered many synonyms including: subterranean; hidden; grey; shadow; informal; clandestine; illegal; unobserved; unreported; unrecorded; second; parallel and black.

There is no single underground economy; there are many. These underground economies are omnipresent, existing in market oriented as well as in centrally planned nations, be they developed or developing. Those engaged in underground activities circumvent, escape or are excluded from the institutional system of rules, rights, regulations and enforcement penalties that govern formal agents engaged in production and exchange. Different types of underground activities are distinguished according to the particular institutional rules that they violate. Four major underground economies can be identified:


The "illegal economy" consists of the income produced by those economic activities pursued in violation of legal statutes defining the scope of legitimate forms of commerce. Illegal economy participants engage in the production and distribution of prohibited goods and services, such as drug trafficking, arms trafficking, and prostitution.

The "unreported economy" consists of those economic activities that circumvent or evade the institutionally established fiscal rules as codified in the tax code. A summary measure of the unreported economy is the amount of income that should be reported to the tax authority but is not so reported. A complementary measure of the unreported economy is the "tax gap", namely the difference between the amount of tax revenues due the fiscal authority and the amount of tax revenue actually collected. In the U.S. unreported income is estimated to be $2 trillion resulting in a "tax gap" of $450–$600 billion.

The "unrecorded economy" consists of those economic activities that circumvent the institutional rules that define the reporting requirements of government statistical agencies. A summary measure of the unrecorded economy is the amount of unrecorded income, namely the amount of income that should (under existing rules and conventions) be recorded in national accounting systems (e.g. National Income and Product Accounts) but is not. Unrecorded income is a particular problem in transition countries that switched from a socialist accounting system to UN standard national accounting. New methods have been proposed for estimating the size of the unrecorded (non-observed) economy. But there is still little consensus concerning the size of the unreported economies of transition countries.

The "informal economy" comprises those economic activities that circumvent the costs and are excluded from the benefits and rights incorporated in the laws and administrative rules covering property relationships, commercial licensing, labor contracts, torts, financial credit and social security systems. A summary measure of the informal economy is the income generated by economic agents that operate informally. The informal sector is defined as the part of an economy that is not taxed, monitored by any form of government, or included in any gross national product (GNP), unlike the formal economy. In developed countries the informal sector is characterized by unreported employment. This is hidden from the state for tax, social security or labour law purposes but is legal in all other aspects. On the other hand, the term "black market" can be used in reference to a specific part of the economy in which contraband is traded.

Goods and services acquired illegally and/or transacted for in an illegal manner may exchange above or below the price of legal market transactions:

Even when the underground market offers lower prices, consumers still have an incentive to buy on the legal market when possible, because:

However, in some limited situations, consumers conclude that they are actually better off using black market services, particularly when government regulations hinder what would otherwise be a legitimate competitive service. For example:

Some examples of underground economic activities include:

Prostitution is illegal or highly regulated in many countries across the world. These places form a classic study of the underground economy, because of consistent high demand from customers, relatively high pay, but labor-intensive and low skilled work, which attracts a continual supply of workers. While prostitution exists in every country, studies show that it tends to flourish more in poorer countries, and in areas with large numbers of unattached men, such as around military bases. For instance, an empirical study showed that the supply of prostitutes rose abruptly in Denver and Minneapolis in 2008 when the Democratic and Republican National Conventions took place there.

Prostitutes in the black market generally operate with some degree of secrecy, sometimes negotiating prices and activities through codewords and subtle gestures. In countries such as Germany or the Netherlands, where prostitution is legal but regulated, illegal prostitutes exist whose services are offered cheaper without regard for the legal requirements or procedures—health checks, standards of accommodation, and so on.

In other countries, such as Nicaragua, where legal prostitution is regulated, hotels may require both parties to identify themselves, to prevent the rise of child prostitution.

Personally identifying information, financial information like credit card and bank account information, and medical data is bought and sold, mostly in darknet markets. People increase the value of the stolen data by aggregating it with publicly available data, and sell it again for a profit, increasing the damage that can be done to the people whose data was stolen.

From the late 19th and early 20th centuries, many countries began to ban the keeping or using of some recreational drugs, such as the United States' war on drugs. Many people nonetheless continue to use illegal drugs, and a black market exists to supply them. Despite law enforcement efforts to intercept them, demand remains high, providing a large profit motive for organized criminal groups to keep drugs supplied. The United Nations has reported that the retail market value of illegal drugs is $321.6 billion USD.

Although law enforcement agencies intercept a fraction of the illegal drugs, and incarcerate hundreds of thousands of wholesale and retail sellers, the very stable demand for such drugs and the high profit margins encourages new distributors to enter the market without a decrease in the retail price. Many drug legalization activists draw parallels between the illegal drug trade and the Prohibition of alcohol in the United States in the 1920s.

The legislatures of many countries forbid or restrict the personal ownership of weapons. These restrictions can range from small knives to firearms, either altogether or by classification (e.g. caliber, handguns, automatic weapons, and explosives). The black market supplies the demands for weaponry that can not be obtained legally, or may only be obtained legally after obtaining permits and paying fees. This may be by smuggling the arms from countries where they were bought legally or stolen, or by stealing from arms manufacturers within the country itself, using insiders. In cases where the underground economy is unable to smuggle firearms, they can also satisfy requests by gunsmithing their own firearms. Those who may buy this way include criminals to use for illegal activities, gun collectors, and otherwise law-abiding citizens interested in protecting their dwellings, families or businesses.

In England and Wales, certain categories of weapons used for hunting may be owned by qualified residents but must be registered with the local police force and kept within a locked cabinet. Another segment of the population who may purchase weapons on the black market are individuals who are unable to pass the legal requirements for registration—convicted felons or those suffering from mental illness for example. In a few jurisdictions, collectors may legally keep antique weapons made incapable of being readily restored to a firing condition.

The illegal logging of timber has posed as an issue. According to Interpol, the illegal logging industry is worth almost as much as drug production industry, in some countries.

In many developing countries, living animals are captured in the wild and sold as pets. Wild animals are also hunted and killed for their meat, hide, and organs, the latter of which and other animal parts are sold for use in traditional medicine.

In several of the states within the United States, laws requiring the pasteurization of milk has created black market situations involving the transport and sale of raw milk, and sometimes raw milk cheese which is legal in a number of EU countries but banned in the US if aged less than 60 days

Rum-running, or bootlegging, is the illegal business of transporting (smuggling) alcoholic beverages where such transportation is forbidden by law. Smuggling is usually done to circumvent taxation or prohibition laws within a particular jurisdiction. The term "rum-running" is more commonly applied to smuggling over water; "bootlegging" is applied to smuggling over land. According to the PBS documentary "Prohibition", the term "bootlegging" was popularized when thousands of city dwellers would sell liquor from flasks they kept in their boot leg all across major cities and rural areas. The term "rum-running" most likely originated at the start of Prohibition in the United States (1920–1933), when ships from Bimini in the western Bahamas transported cheap Caribbean rum to Florida speakeasies. But rum's cheapness made it a low-profit item for the rum-runners, and they soon moved on to smuggling Canadian whisky, French champagne, and English gin to major cities like New York City and Boston, where prices ran high. It was said that some ships carried $200,000 in contraband in a single run.

It has been reported that smuggling one truckload of cigarettes from a low-tax US state to a high-tax state can lead to a profit of up to $2 million. The low-tax states are generally the major tobacco producers, and have come under enormous criticism for their reluctance to increase taxes. North Carolina eventually agreed to raise its taxes from 5 cents to 35 cents per pack of 20 cigarettes, although this remains far below the national average. But South Carolina has so far refused to follow suit and raise taxes from seven cents per pack (the lowest in the USA).

In the UK, it has been reported that "27% of cigarettes and 68% of roll your own tobacco is purchased on the black market".

According to the World Health Organization (WHO), illegal organ trade occurs when organs are removed from the body for the purpose of commercial transactions. The WHO justifies its stance on the issue by stating, "Payment for ... organs is likely to take unfair advantage of the poorest and most vulnerable groups, undermines altruistic donation and leads to profiteering and human trafficking." Despite these ordinances, it was estimated that 5% of all organ recipients engaged in commercial organ transplant in 2005. Research indicates that illegal organ trade is on the rise, with a recent report by Global Financial Integrity estimating that the illegal organ trade generates profits between $600 million and $1.2 billion per year with a span over many countries.

A racket is a service that is fraudulently offered to solve a problem, such as for a problem that does not actually exist, that will not be put into effect, or that would not otherwise exist if the racket did not exist. Conducting a racket is racketeering. Particularly, the potential problem may be caused by the same party that offers to solve it, although that fact may be concealed, with the specific intent to engender continual patronage for this party. An archetype is the protection racket, wherein a person or group (e.g., a criminal gang) indicates to a store owner that they could protect her/his store from potential damage, damage that the same person or group would otherwise inflict, while the correlation of threat and protection may be more or less deniably veiled, distinguishing it from the more direct act of extortion.
Racketeering is often associated with organized crime, and the term was coined by the Employers' Association of Chicago in June 1927 in a statement about the influence of organized crime in the Teamsters union.

Where taxicabs, buses, and other transportation providers are strictly regulated or monopolized by government, a black market typically flourishes to provide transportation to poorly served or overpriced communities. In the United States, some cities restrict entry to the taxicab market with a medallion system, i.e., taxicabs must get a special license and display it on a medallion in the vehicle. In most such jurisdictions it is legal to sell the medallions, but the limited supply and resulting high prices of medallions have led to a market in unlicensed carpooling/illegal taxicab operation. In Baltimore, Maryland, for example, it is not uncommon for private individuals to provide illegal taxicab service for city residents.

In places where there is rent control there may be a black market for housing. For instance, in the UK there is illegal subletting of social housing homes where the tenant illegally rents out the home at a higher rent. In Sweden, rental contracts with regulated rent can be bought on the black market, either from the current tenant or sometimes directly from the property owner. Specialised black-market dealers assist the property owners with such transactions. In India, places like Chennai, Bangalore, Hyderabad, Mumbai, Kolkotta, and New Delhi where students are coming from all over India, getting high rented PG (paying guests) or other forms of rented apartments without any taxation or regulations.

Medicines and essential aircraft and automobile parts (e.g. brakes, motor parts, etc.) are counterfeited on a large scale.

Street vendors in countries where there is little enforcement of copyright law, particularly in Asia and Latin America, often sell deeply discounted copies of films, music CDs, and computer software such as video games, sometimes even before the official release of the title. A determined counterfeiter with a few hundred dollars can make copies that are digitally identical to an original and face no loss in quality; innovations in consumer DVD and CD writers and the widespread availability of cracks on the Internet for most forms of copy protection technology make this cheap and easy to do.

Copyright-holders and other proponents of copyright laws have found this phenomenon hard to stop through the courts, as the operations are distributed and widespread, transversing national borders and thus legal systems. Since digital information can be duplicated repeatedly with no loss of quality, and passed on electronically at little to no cost, the effective underground market value of media is zero, differentiating it from nearly all other forms of underground economic activity. The issue is compounded by widespread indifference to enforcing copyright law, both with governments and the public at large. To steal a car is seen as a crime in most people's eyes, but to obtain unauthorized copies of music or a game is not. Additionally, not all people agree with 'copyright laws', as it unfairly criminalises competition, allowing the copyright-holder to effectively monopolise related industries. It also authorises copyright-holders to use region-coding to discriminate against selected populations price-wise and availability-wise.

The comparison to car-theft, although common, is not truly analogous. Automobile theft results in an item being removed from the owner with the ownership transferred to a second party. Media piracy is a crime of duplication, with no physical property being stolen. Copyright infringement law goes as far as to deem illegal "mixtapes" and other such material copied to tape or disk. Copyright holders typically attest the act of theft to be in the profits forgone to the pirates. However, this makes the unsubstantiated assumption that the pirates would have bought the copyrighted material if it had not been available through file sharing or other means. Copyright holders also say that they did some work for creating their copyrighted material and they wish to get compensated for their work. No other system than copyright has been found to compensate the artists and other creators for their work, and many artists do not have any alternative source of income or another job. Many artists and film producers have accepted the role of piracy in media distribution. The spread of material through file sharing is a major source of publicity for artists and has been shown to build fan bases that may be more inclined to see the performer live (live performances make up the bulk of successful artists' revenues, however not all artists can make live performances, for example photographers typically only have a single source of income that is the licensing of their photos).

Money itself is traded on the black market. This may happen for one or more of several reasons:

A government may officially set the rate of exchange of its currency with that of other currencies, typically the US dollar. When it does, the peg often overvalues the local currency relative to what its market value would be if it were a floating currency. Those in possession of the "harder" currency, for example expatriate workers, may be able to use the black market to buy the local currency at better exchange rates than they can get officially.

In situations of financial instability and inflation, citizens may substitute a foreign currency for the local currency. The U.S. dollar is viewed as a relatively stable and safe currency and is often used abroad as a second currency. In 2012, $340 billion, roughly 37 percent of all U.S. currency, was believed to be circulating abroad. The most recent study of the amount of currency held overseas suggests that only 25 percent of U.S. currency is presently held abroad. The widespread substitution of U.S. currency for local currency is known as "de facto dollarisation", and has been observed in transition countries such as Cambodia and in some Latin American countries. Some countries, such as Ecuador, abandoned their local currency and now use US dollars, essentially for this reason, a process known as de jure dollarization. See also the example of the Ghanaian cedi from the 1970s and 1980s.

If foreign currency is difficult or illegal for local citizens to acquire, they will pay a premium to acquire it. U.S. currency is viewed as a relatively stable store of value and since it does not leave a paper trail, it is also a convenient medium of exchange for both illegal transactions and for unreported income both in the U.S and abroad.

More recently cryptocurrencies such as bitcoin have been used as medium of exchange in black market transactions. Cryptocurrencies are sometimes favored over centralized currency due to their anonymous nature and their ability to be traded over the internet.

In the EU, it is not illegal for a person or business to buy fuel in one EU state for their own use in another, but as with other goods the tax will generally be payable by the final customer at the physical place of making the purchase.

Between the Republic of Ireland and Northern Ireland, there has often been a black market in petrol and diesel.
The direction of smuggling can change depending on the variation of the taxes and the exchange rate between the Euro and Pound Sterling; indeed sometimes diesel will be smuggled in one direction and petrol the other.

In some countries, diesel fuel for agricultural vehicles or domestic use is taxed at a much lower rate than that for other vehicles. This is known as dyed fuel, because a coloured dye is added so it can be detected if used in other vehicles (e.g. a red dye in the UK, a green dye in Ireland). Nevertheless, the saving is attractive enough to make a black market in agricultural diesel. In 2007 it was estimated that £350 million was not gained in profit as a result of this phenomenon, in the UK.

In countries like India and Nepal, the price of fuel is set by the government, and it is illegal to sell the fuel over the set price. Due to the petrol crisis in Nepal, black marketing in fuel has been a common trend, especially during mass petrol shortage. At times, people need to queue for hours or even sometimes overnight to get the fuel. On the other hand, the petrol pump operators are alleged to hoarding the fuel, and selling it to black marketers. Black marketing in vehicle/cooking fuel became widespread during the 2015 economic blockade imposed on Nepal. Even after the economic blockade was eased, and petrol imports resumed, people are not getting the fuel as they were supposed to and are resort to buying from the black market.

People engaged in the black market usually run their business hidden under a front business that is legal.

Often, certain types of illegal products are traded against one another, depending on the geographical location.

Black markets flourish in most countries during wartime. States that are engaged in total war or other large-scale, extended wars often impose restrictions on home use of critical resources that are needed for the war effort, such as food, gasoline, rubber, metal, etc., typically through rationing. In most cases, a black market develops to supply rationed goods at exorbitant prices. The rationing and price controls enforced in many countries during World War II encouraged widespread black market activity. One source of black-market meat under wartime rationing was by farmers declaring fewer domestic animal births to the Ministry of Food than actually happened. Another in Britain was supplies from the US, intended only for use in US army bases on British land, but leaked into the local native British black market.

For example, in the Parliament of the United Kingdom on February 17, 1945, members said that "the whole turkey production of East Anglia had gone to the black market" and "prosecutions [for black-marketing] were like trying to stop a leak in a battleship", and it was said that official prices of such foods were set so low that their producers often sold their produce on the black market for higher prices; one such route (seen to operate at the market at Diss in Norfolk) was to sell live poultry to members of the public, and each purchaser would sign a form promising that he was buying the birds to breed from, and then take them home for eating.

During the Vietnam war, soldiers would spend Military Payment Certificates on maid service and sexual entertainment, thus supporting their partners and their families. If the Vietnamese civilian wanted something that was hard to get, he would buy it at double the price from one of the soldiers, who had a monthly ration card and thus had access to the military stores. The transactions ran through the on-base maids to the local populace. Although these activities were illegal, only flagrant or large-scale black-marketeers were prosecuted by the military.

A classic example of new regulation creating a black market is the prohibition of alcohol. Similarly, when the law disappears, so does the black market, which is why of the arguments for marijuana legalization is the elimination of the black market and thus taxes from that economy being used by the government.

In India, "black money" refers to funds earned on the black market, on which income and other taxes have not been paid. The black money market situation in India is epidemic. India currently tops the list for illegal monies in the entire world, estimated to be almost US$1,456 billion stored in Swiss banks in the form of unaccounted money. According to the data provided by the Swiss Banking Association, India has more black money than the rest of the world combined. Indian Swiss bank account assets are worth 13 times (1300%) the country’s national debt, and, if this black money is seized and brought back to the country, India has the potential to become one of the richest countries in the world. Allegations of Indians holding trillions in black money in Switzerland are, however, in dispute. Later reports, including those by Swiss Bankers Association and the Government of Switzerland, claim that these allegations are false and fabricated, and the total amount held in all Swiss banks by citizens of India is about 2 billion.




</doc>
<doc id="96637" url="https://en.wikipedia.org/wiki?curid=96637" title="Confidence trick">
Confidence trick

A confidence trick (synonyms include con, confidence game, confidence scheme, ripoff, scam, and stratagem) is an attempt to defraud a person or group after first gaining their confidence, used in the classical sense of trust. Confidence tricks exploit characteristics of the human psyche, such as credulity, naïveté, compassion, vanity, irresponsibility, and greed. Researchers Lindsey Huang and Barak Orbach defined the scheme as "a distinctive species of fraudulent conduct ... intending to further voluntary exchanges that are not mutually beneficial", as they "benefit con operators ('con men') at the expense of their victims (the 'marks')".

The perpetrator of a confidence trick (or "con trick") is often referred to as a confidence (or "con") man, con-artist, or a "grifter". Samuel Thompson (1821–1856) was the original "confidence man". Thompson was a clumsy swindler who asked his victims to express confidence in him by giving him money or their watch rather than gaining their confidence in a more nuanced way. A few people trusted Thompson with their money and watches. Thompson was arrested in July 1849. Reporting about this arrest, Dr. James Houston, a reporter of the "New York Herald", publicized Thompson by naming him the "Confidence Man". Although Thompson was an unsuccessful scammer, he gained reputation as a genius operator mostly because Houston's satirical writing wasn't understood as such. The National Police Gazette coined the term "confidence game" a few weeks after Houston first used the name "confidence man".
A confidence trick is also known as a con game, a con, a scam, a grift, a hustle, a bunko (or bunco), a swindle, a flimflam, a gaffle, or a bamboozle. The intended victims are known as marks, suckers, stooges, mugus, rubes, or gulls (from the word "gullible"). When accomplices are employed, they are known as shills.

A short con or small con is a fast swindle which takes just minutes. It typically aims to rob the victim of everything in his wallet.

A long con or big con (also, chiefly ) is a scam that unfolds over several days or weeks and involves a team of swindlers, as well as props, sets, extras, costumes, and scripted lines. It aims to rob the victim of huge sums of money or valuable things, often by getting him or her to empty out banking accounts and borrow from family members.

In "Confessions of a Confidence Man", Edward H. Smith lists the "six definite steps or stages of growth" of a confidence game. He notes that some steps may be omitted.


In addition, some games require a "corroboration" step, particularly those involving a "rare item". This usually includes the use of an accomplice who plays the part of an uninvolved (initially skeptical) third party, who later confirms the claims made by the con man.

Confidence tricks exploit typical human characteristics such as greed, dishonesty, vanity, opportunism, lust, compassion, credulity, irresponsibility, desperation, and naïvety. As such, there is no consistent profile of a confidence trick victim; the common factor is simply that the victim relies on the good faith of the con artist. Victims of investment scams tend to show an incautious level of greed and gullibility, and many con artists target the elderly, but even alert and educated people may be taken in by other forms of a confidence trick. Researchers Huang and Orbach argue:
Accomplices, also known as shills, help manipulate the mark into accepting the perpetrator's plan. In a traditional confidence trick, the mark is led to believe that he will be able to win money or some other prize by doing some task. The accomplices may pretend to be strangers who have benefited from performing the task in the past.




</doc>
<doc id="7753430" url="https://en.wikipedia.org/wiki?curid=7753430" title="Psychopathy">
Psychopathy

Psychopathy is traditionally a personality disorder characterized by persistent antisocial behavior, impaired empathy and remorse, and bold, disinhibited, and egotistical traits. It is sometimes considered synonymous with sociopathy. Different conceptions of psychopathy have been used throughout history that are only partly overlapping and may sometimes be contradictory.

Hervey M. Cleckley, an American psychiatrist, influenced the initial diagnostic criteria for antisocial personality reaction/disturbance in the "Diagnostic and Statistical Manual of Mental Disorders" (DSM), as did American psychologist George E. Partridge. The DSM and "International Classification of Diseases" (ICD) subsequently introduced the diagnoses of antisocial personality disorder (ASPD) and dissocial personality disorder (DPD) respectively, stating that these diagnoses have been referred to (or include what is referred to) as psychopathy or sociopathy. The creation of ASPD and DPD was driven by the fact that many of the classic traits of psychopathy were impossible to measure objectively. Canadian psychologist Robert D. Hare later repopularized the construct of psychopathy in criminology with his Psychopathy Checklist.

Although no psychiatric or psychological organization has sanctioned a diagnosis titled "psychopathy", assessments of psychopathic characteristics are widely used in criminal justice settings in some nations and may have important consequences for individuals. The study of psychopathy is an active field of research, and the term is also used by the general public, popular press, and in fictional portrayals. While the term is often employed in common usage along with "crazy", "insane", and "mentally ill", there is a distinction between psychosis and psychopathy.

A person suffering from a chronic mental disorder with abnormal or violent social behavior.

There are multiple conceptualizations of psychopathy, including "Cleckleyan psychopathy" (Hervey Cleckley's conception entailing bold, disinhibited behavior, and "feckless disregard") and "criminal psychopathy" (a meaner, more aggressive and disinhibited conception explicitly entailing persistent and sometimes serious criminal behavior). The latter conceptualization is typically used as the modern clinical concept and assessed by the Psychopathy Checklist. The label "psychopath" may have implications and stigma related to decisions about punishment severity for criminal acts, medical treatment, civil commitments, etc. Efforts have therefore been made to clarify the meaning of the term.

The triarchic model suggests that different conceptions of psychopathy emphasize three observable characteristics to various degrees. Analyses have been made with respect to the applicability of measurement tools such as the Psychopathy Checklist (PCL, PCL-R) and Psychopathic Personality Inventory (PPI) to this model.

An early and influential analysis from Harris and colleagues indicated that a discrete category, or taxon, may underlie PCL-R psychopathy, allowing it to be measured and analyzed. However, this was only found for the behavioral Factor 2 items they identified, child problem behaviors; adult criminal behavior did not support the existence of a taxon. Marcus, John, and Edens more recently performed a series of statistical analyses on PPI scores and concluded that psychopathy may best be conceptualized as having a "dimensional latent structure" like depression.

Marcus et al. repeated the study on a larger sample of prisoners, using the PCL-R and seeking to rule out other experimental or statistical issues that may have produced the previously different findings. They again found that the psychopathy measurements do not appear to be identifying a discrete type (a taxon). They suggest that while for legal or other practical purposes an arbitrary cut-off point on trait scores might be used, there is actually no clear scientific evidence for an objective point of difference by which to label some people "psychopaths"; in other words, a "psychopath" may be more accurately described as someone who is "relatively psychopathic".

The PCL-R was developed for research, not clinical forensic diagnosis, and even for research purposes to improve understanding of the underlying issues, it is necessary to examine dimensions of personality in general rather than only a constellation of traits.

There are different views as to which personality dimensions are more central in regard to psychopathy. Besides dimensions described elsewhere in this article, studies have linked psychopathy to alternative dimensions such as antagonism (high), conscientiousness (low) and anxiousness (low). Psychopathy has also been linked to high psychoticism—a theorized dimension referring to tough, aggressive or hostile tendencies. Aspects of this that appear associated with psychopathy are lack of socialization and responsibility, impulsivity, sensation-seeking (in some cases), and aggression.

Otto Kernberg, from a particular psychoanalytic perspective, believed psychopathy should be considered as part of a spectrum of pathological narcissism, that would range from narcissistic personality on the low end, malignant narcissism in the middle, and psychopathy at the high end. However, narcissism is generally seen as only one possible aspect of psychopathy as broadly defined.

Psychopathy, narcissism and Machiavellianism, three personality traits that are together referred to as the dark triad, share certain characteristics, such as a callous-manipulative interpersonal style. The dark tetrad refers to these traits with the addition of sadism.

The current conceptions of psychopathy have been criticized for being poorly conceptualized, highly subjective, and encompassing a wide variety of underlying disorders. Dorothy Otnow Lewis has written

Half of the Hare Psychopathy Checklist consists of symptoms of mania, hypomania, and frontal-lobe dysfunction, which frequently results in underlying disorders being dismissed. Hare's conception of psychopathy has also been criticized for being reductionist, dismissive, tautological, and ignorant of context as well as the dynamic nature of human behavior. Some have called for rejection of the concept altogether, due to its vague, subjective and judgmental nature that makes it prone to misuse.

Psychopathy refers to a personality trait that has been observed in a wide variety of settings. Socially, it expresses extensive callous and manipulative self-serving behaviors with no regard for others, and often is associated with repeated delinquency, crime and violence, but may also present itself in other, maybe even successful social settings. Mentally, impairments in processes related to affect (emotion) and cognition, particularly socially related mental processes, have been found in those with the disorder which suggest that their destructive social behavior is borne from these aberrant mental processes. Developmentally, symptoms of psychopathy have been identified in young children with conduct disorder, and is suggestive of at least a partial constitutional factor that influences its development.

In terms of simple correlations, the PCL-R manual states an average score of 22.1 has been found in North American prisoner samples, and that 20.5% scored 30 or higher. An analysis of prisoner samples from outside North America found a somewhat lower average value of 17.5. Studies have found that psychopathy scores correlated with repeated imprisonment, detention in higher security, disciplinary infractions, and substance misuse.

Psychopathy, as measured with the PCL-R in institutional settings, shows in meta-analyses small to moderate effect sizes with institutional misbehavior, postrelease crime, or postrelease violent crime with similar effects for the three outcomes. Individual studies give similar results for adult offenders, forensic psychiatric samples, community samples, and youth. The PCL-R is poorer at predicting sexual re-offending. This small to moderate effect appears to be due largely to the scale items that assess impulsive behaviors and past criminal history, which are well-established but very general risk factors. The aspects of core personality often held to be distinctively psychopathic generally show little or no predictive link to crime by themselves. For example, Factor 1 of the PCL-R and Fearless dominance of the PPI-R have smaller or no relationship to crime, including violent crime. In contrast, Factor 2 and Impulsive antisociality of the PPI-R are associated more strongly with criminality. Factor 2 has a relationship of similar strength to that of the PCL-R as a whole. The antisocial facet of the PCL-R is still predictive of future violence after controlling for past criminal behavior which, together with results regarding the PPI-R which by design does not include past criminal behavior, suggests that impulsive behaviors is an independent risk factor. Thus, the concept of psychopathy may perform poorly when attempted to be used as a general theory of crime.

Studies have suggested a strong correlation between psychopathy scores and violence, and the PCL-R emphasizes features that are somewhat predictive of violent behavior. Researchers, however, have noted that psychopathy is dissociable from and not synonymous with violence.

It has been suggested that psychopathy is associated with "instrumental", also known as predatory, proactive, or "cold blooded" aggression, a form of aggression characterized by reduced emotion and conducted with a goal differing from but facilitated by the commission of harm. One conclusion in this regard was made by a 2002 study of homicide offenders, which reported that the homicides committed by homicidal offenders with psychopathy were almost always (93.3%) primarily instrumental, significantly more than the proportion (48.4%) of those committed by non-psychopathic homicidal offenders, with the instrumentality of the homicide also correlated with the total PCL-R score of the offender as well as their scores on the Factor 1 "interpersonal-affective" dimension. However, contrary to the equating of this to mean exclusively "in cold blood", more than a third of the homicides committed by psychopathic offenders involved some component of emotional reactivity as well. In any case, FBI profilers indicate that serious victim injury is generally an emotional offense, and some research supports this, at least with regard to sexual offending. One study has found more serious offending by non-psychopathic offenders on average than by offenders with psychopathy (e.g. more homicides versus more armed robbery and property offenses) and another that the Affective facet of the PCL-R predicted reduced offense seriousness.

Studies on perpetrators of domestic violence find that abusers have high rates of psychopathy, with the prevalence estimated to be at around 15-30%. Furthermore, the commission of domestic violence is correlated with Factor 1 of the PCL-R, which describes the emotional deficits and the callous and exploitative interpersonal style found in psychopathy. The prevalence of psychopathy among domestic abusers indicate that the core characteristics of psychopathy, such as callousness, remorselessness, and a lack of close interpersonal bonds, predispose those with psychopathy to committing domestic abuse, and suggest that the domestic abuses committed by these individuals are callously perpetrated (i.e. instrumentally aggressive) rather than a case of emotional aggression and therefore may not be amenable to the types of psychosocial interventions commonly given to domestic abuse perpetrators.

Some clinicians suggest that assessment of the construct of psychopathy does not necessarily add value to violence risk assessment. A large systematic review and meta-regression found that the PCL performed the poorest out of nine tools for predicting violence. In addition, studies conducted by the authors or translators of violence prediction measures, including the PCL, show on average more positive results than those conducted by more independent investigators. There are several other risk assessment instruments which can predict further crime with an accuracy similar to the PCL-R and some of these are considerably easier, quicker, and less expensive to administer. This may even be done automatically by a computer simply based on data such as age, gender, number of previous convictions and age of first conviction. Some of these assessments may also identify treatment change and goals, identify quick changes that may help short-term management, identify more specific kinds of violence that may be at risk, and may have established specific probabilities of offending for specific scores. Nonetheless, the PCL-R may continue to be popular for risk assessment because of its pioneering role and the large amount of research done using it.

The Federal Bureau of Investigation reports that psychopathic behavior is consistent with traits common to some serial killers, including sensation seeking, a lack of remorse or guilt, impulsivity, the need for control, and predatory behavior. It has also been found that the homicide victims of psychopathic offenders were disproportionately female in comparison to the more equitable gender distribution of victims of non-psychopathic offenders.

Psychopathy has been associated with commission of sexual crime, with some researchers arguing that it is correlated with a preference for violent sexual behavior. A 2011 study of conditional releases for Canadian male federal offenders found that psychopathy was related to more violent and non-violent offences but not more sexual offences. For child molesters, psychopathy was associated with more offences. A study on the relationship between psychopathy scores and types of aggression in a sample of sexual murderers, in which 84.2% of the sample had PCL-R scores above 20 and 47.4% above 30, found that 82.4% of those with scores above 30 had engaged in sadistic violence (defined as enjoyment indicated by self-report or evidence) compared to 52.6% of those with scores below 30, and total PCL-R and Factor 1 scores correlated significantly with sadistic violence. Despite this, it is reported that offenders with psychopathy (both sexual and non-sexual offenders) are about 2.5 times more likely to be granted conditional release compared to non-psychopathic offenders.

In considering the issue of possible reunification of some sex offenders into homes with a non-offending parent and children, it has been advised that any sex offender with a significant criminal history should be assessed on the PCL-R, and if they score 18 or higher, then they should be excluded from any consideration of being placed in a home with children under any circumstances. There is, however, increasing concern that PCL scores are too inconsistent between different examiners, including in its use to evaluate sex offenders.

The possibility of psychopathy has been associated with organized crime, economic crime and war crimes. Terrorists are sometimes considered psychopathic, and comparisons may be drawn with traits such as antisocial violence, a selfish world view that precludes the welfare of others, a lack of remorse or guilt, and blame externalization. However, John Horgan, author of "The Psychology of Terrorism", argues that such comparisons could also then be drawn more widely: for example, to soldiers in wars. Coordinated terrorist activity requires organization, loyalty and ideological fanaticism often to the extreme of sacrificing oneself for an ideological cause. Traits such as a self-centered disposition, unreliability, poor behavioral controls, and unusual behaviors may disadvantage or preclude psychopathic individuals in conducting organized terrorism.

It may be that a significant portion of people with the disorder are socially successful and tend to express their antisocial behavior through more covert avenues such as social manipulation or white collar crime. Such individuals are sometimes referred to as "successful psychopaths", and may not necessarily always have extensive histories of traditional antisocial behavior as characteristic of traditional psychopathy.

The PCL:YV is an adaptation of the PCL-R for individuals aged 13–18 years. It is, like the PCL-R, done by a trained rater based on an interview and an examination of criminal and other records. The "Antisocial Process Screening Device" (APSD) is also an adaptation of the PCL-R. It can be administered by parents or teachers for individuals aged 6–13 years. High psychopathy scores for both juveniles, as measured with these instruments, and adults, as measured with the PCL-R and other measurement tools, have similar associations with other variables, including similar ability in predicting violence and criminality. Juvenile psychopathy may also be associated with more negative emotionality such as anger, hostility, anxiety, and depression. Psychopathic traits in youth typically comprise three factors: callous/unemotional, narcissism, and impulsivity/irresponsibility.

There is positive correlation between early negative life events of the ages 0–4 and the emotion-based aspects of psychopathy. There are moderate to high correlations between psychopathy rankings from late childhood to early adolescence. The correlations are considerably lower from early- or mid-adolescence to adulthood. In one study most of the similarities were on the Impulsive- and Antisocial-Behavior scales. Of those adolescents who scored in the top 5% highest psychopathy scores at age 13, less than one third (29%) were classified as psychopathic at age 24. Some recent studies have also found poorer ability at predicting long-term, adult offending.

Conduct disorder is diagnosed based on a prolonged pattern of antisocial behavior in childhood and/or adolescence, and may be seen as a precursor to ASPD. Some researchers have speculated that there are two subtypes of conduct disorder which mark dual developmental pathways to adult psychopathy. The DSM allows differentiating between childhood onset before age 10 and adolescent onset at age 10 and later. Childhood onset is argued to be more due to a personality disorder caused by neurological deficits interacting with an adverse environment. For many, but not all, childhood onset is associated with what is in Terrie Moffitt's developmental theory of crime referred to as "life-course- persistent" antisocial behavior as well as poorer health and economic status. Adolescent onset is argued to more typically be associated with short-term antisocial behavior.

It has been suggested that the combination of early-onset conduct disorder and ADHD may be associated with life-course-persistent antisocial behaviors as well as psychopathy. There is evidence that this combination is more aggressive and antisocial than those with conduct disorder alone. However, it is not a particularly distinct group since the vast majority of young children with conduct disorder also have ADHD. Some evidence indicates that this group has deficits in behavioral inhibition, similar to that of adults with psychopathy. They may not be more likely than those with conduct disorder alone to have the interpersonal/affective features and the deficits in emotional processing characteristic of adults with psychopathy. Proponents of different types/dimensions of psychopathy have seen this type as possibly corresponding to adult secondary psychopathy and increased disinhibition in the triarchic model.

The DSM-5 includes a specifier for those with conduct disorder who also display a callous, unemotional interpersonal style across multiple settings and relationships. The specifier is based on research which suggests that those with conduct disorder who also meet criteria for the specifier tend to have a more severe form of the disorder with an earlier onset as well as a different response to treatment. Proponents of different types/dimensions of psychopathy have seen this as possibly corresponding to adult primary psychopathy and increased boldness and/or meanness in the triarchic model.

Dysfunctions in the prefrontal cortex and amygdala regions of the brain have been associated with specific learning impairments in psychopathy. Since the 1980s, scientists have linked traumatic brain injury, including damage to these regions, with violent and psychopathic behavior. Patients with damage in such areas resembled "psychopathic individuals" whose brains were incapable of acquiring social and moral knowledge; those who acquired damage as children may have trouble conceptualizing social or moral reasoning, while those with adult-acquired damage may be aware of proper social and moral conduct but be unable to behave appropriately. Dysfunctions in the amygdala and ventromedial prefrontal cortex may also impair stimulus-reinforced learning in psychopaths, whether punishment-based or reward-based. People scoring 25 or higher in the PCL-R, with an associated history of violent behavior, appear to have significantly reduced mean microstructural integrity in their uncinate fasciculus—white matter connecting the amygdala and orbitofrontal cortex. There is evidence from DT-MRI, of breakdowns in the white matter connections between these two important areas.

Although some studies have suggested inverse relationships between psychopathy and intelligence, including with regards to verbal IQ, Hare and Neumann state that a large literature demonstrates at most only a weak association between psychopathy and IQ, noting that the early pioneer Cleckley included good intelligence in his checklist due to selection bias (since many of his patients were "well educated and from middle-class or upper-class backgrounds") and that "there is no obvious theoretical reason why the disorder described by Cleckley or other clinicians should be related to intelligence; some psychopaths are bright, others less so". Studies also indicate that different aspects of the definition of psychopathy (e.g. interpersonal, affective (emotion), behavioral and lifestyle components) can show different links to intelligence, and the result can depend on the type of intelligence assessment (e.g. verbal, creative, practical, analytical).

A large body of research suggests that psychopathy is associated with atypical responses to distress cues (e.g. facial and vocal expressions of fear and sadness), including decreased activation of the fusiform and extrastriate cortical regions, which may partly account for impaired recognition of and reduced autonomic responsiveness to expressions of fear, and impairments of empathy. The underlying biological surfaces for processing expressions of happiness are functionally intact in psychopaths, although less responsive than those of controls. The neuroimaging literature is unclear as to whether deficits are specific to particular emotions such as fear. The overall pattern of results across studies indicates that people diagnosed with psychopathy demonstrate reduced MRI, fMRI, aMRI, PET, and SPECT activity in areas of the brain. Research has also shown that an approximate 18% smaller amygdala size contributes to a significantly lower emotional sensation in regards to fear, sadness, amongst other negative emotions, which may likely be the reason as to why psychopathic individuals have lower empathy. Some recent fMRI studies have reported that emotion perception deficits in psychopathy are pervasive across emotions (positives and negatives). Studies on children with psychopathic tendencies have also shown such associations. Meta-analyses have also found evidence of impairments in both vocal and facial emotional recognition for several emotions (i.e., not only fear and sadness) in both adults and children/adolescents.

Psychopathy has been associated with amorality—an absence of, indifference towards, or disregard for moral beliefs. There are few firm data on patterns of moral judgment. Studies of developmental level (sophistication) of moral reasoning found all possible results—lower, higher or the same as non-psychopaths. Studies that compared judgments of personal moral transgressions versus judgments of breaking conventional rules or laws found that psychopaths rated them as equally severe, whereas non-psychopaths rated the rule-breaking as less severe.

A study comparing judgments of whether personal or impersonal harm would be endorsed in order to achieve the rationally maximum (utilitarian) amount of welfare found no significant differences between subjects high and low in psychopathy. However, a further study using the same tests found that prisoners scoring high on the PCL were more likely to endorse impersonal harm or rule violations than non-psychopathic controls were. The psychopathic offenders who scored low in anxiety were also more willing to endorse personal harm on average.

Assessing accidents, where one person harmed another unintentionally, psychopaths judged such actions to be more morally permissible. This result has been considered a reflection of psychopaths' failure to appreciate the emotional aspect of the victim's harmful experience.

Behavioral genetic studies have identified potential genetic and non-genetic contributors to psychopathy, including influences on brain function. Proponents of the triarchic model believe that psychopathy results from the interaction of genetic predispositions and an adverse environment. What is adverse may differ depending on the underlying predisposition: for example, it is hypothesized that persons having high boldness may respond poorly to punishment but may respond better to rewards and secure attachments.

Genetically informed studies of the personality characteristics typical of individuals with psychopathy have found moderate genetic (as well as non-genetic) influences. On the PPI, fearless dominance and impulsive antisociality were similarly influenced by genetic factors and uncorrelated with each other. Genetic factors may generally influence the development of psychopathy while environmental factors affect the specific expression of the traits that predominate. A study on a large group of children found more than 60% heritability for "callous-unemotional traits" and that conduct problems among children with these traits had a higher heritability than among children without these traits.

A study by Farrington of a sample of London males followed between age 8 and 48 included studying which factors scored 10 or more on the PCL:SV at age 48. The strongest factors included having a convicted parent, being physically neglected, low involvement of the father with the boy, low family income, and coming from a disrupted family. Other significant factors included poor supervision, harsh discipline, large family size, delinquent sibling, young mother, depressed mother, low social class, and poor housing. There has also been association between psychopathy and detrimental treatment by peers. However, it is difficult to determine the extent of an environmental influence on the development of psychopathy because of evidence of its strong heritability.

Researchers have linked head injuries with psychopathy and violence. Since the 1980s, scientists have associated traumatic brain injury, such as damage to the prefrontal cortex, including the orbitofrontal cortex, with psychopathic behavior and a deficient ability to make morally and socially acceptable decisions, a condition that has been termed "acquired sociopathy", or "pseudopsychopathy". Individuals with damage to the area of the prefrontal cortex known as the ventromedial prefrontal cortex show remarkable similarities to diagnosed psychopathic individuals, displaying reduced autonomic response to emotional stimuli, deficits in aversive conditioning, similar preferences in moral and economic decision making, and diminished empathy and social emotions like guilt or shame. These emotional and moral impairments may be especially severe when the brain injury occurs at a young age. Children with early damage in the prefrontal cortex may never fully develop social or moral reasoning and become "psychopathic individuals ... characterized by high levels of aggression and antisocial behavior performed without guilt or empathy for their victims". Additionally, damage to the amygdala may impair the ability of the prefrontal cortex to interpret feedback from the limbic system, which could result in uninhibited signals that manifest in violent and aggressive behavior.

Psychopathy is associated with several adverse life outcomes as well as increased risk of disability and death due to factors such as violence, accidents, homicides, and suicides. This, in combination with the evidence for genetic influences, is evolutionarily puzzling and may suggest that there are compensating evolutionary advantages, and researchers within evolutionary psychology have proposed several evolutionary explanations. According to one hypothesis, some traits associated with psychopathy may be socially adaptive, and psychopathy may be a frequency-dependent, socially parasitic strategy, which may work as long as there is a large population of altruistic and trusting individuals, relative to the population of psychopathic individuals, to be exploited. It is also suggested that some traits associated with psychopathy such as early, promiscuous, adulterous, and coercive sexuality may increase reproductive success. Robert Hare has stated that many psychopathic males have a pattern of mating with and quickly abandoning women, and thereby have a high fertility rate, resulting in children that may inherit a predisposition to psychopathy.

Criticism includes that it may be better to look at the contributing personality factors rather than treat psychopathy as a unitary concept due to poor testability. Furthermore, if psychopathy is caused by the combined effects of a very large number of adverse mutations then each mutation may have such a small effect that it escapes natural selection. The personality is thought to be influenced by a very large number of genes and may be disrupted by random mutations, and psychopathy may instead be a product of a high mutation load. Psychopathy has alternatively been suggested to be a spandrel, a byproduct, or side-effect, of the evolution of adaptive traits rather than an adaptation in itself.

Some laboratory research demonstrate correlations between psychopathy and atypical responses to aversive stimuli, including weak conditioning to painful stimuli and poor learning of avoiding responses that cause punishment, as well as low reactivity in the autonomic nervous system as measured with skin conductance while waiting for a painful stimulus but not when the stimulus occurs. While it has been argued that the reward system functions normally, some studies have also found reduced reactivity to pleasurable stimuli. According to the response modulation hypothesis, psychopathic individuals have also had difficulty switching from an ongoing action despite environmental cues signaling a need to do so. This may explain the difficulty responding to punishment, although it is unclear if it can explain findings such as deficient conditioning. There may be methodological issues regarding the research. While establishing a range of idiosyncrasies on average in linguistic and affective processing under certain conditions, this research program has not confirmed a common pathology of psychopathy.

Thanks to advancing MRI studies, experts are able to visualize specific brain differences and abnormalities of individuals with psychopathy in areas that control emotions, social interactions, ethics, morality, regret, impulsivity and conscience within the brain. Blair, a researcher who pioneered research into psychopathic tendencies stated, “With regard to psychopathy, we have clear indications regarding why the pathology gives rise to the emotional and behavioral disturbance and important insights into the neural systems implicated in this pathology”. Dadds et al., remarks that despite a rapidly advancing neuroscience of empathy, little is known about the developmental underpinnings of the psychopathic disconnect between affective and cognitive empathy.

A 2008 review by Weber et al. suggested that psychopathy is sometimes associated with brain abnormalities in prefrontal-temporo-limbic regions that are involved in emotional and learning processes, among others. Neuroimaging studies have found structural and functional differences between those scoring high and low on the PCL-R in a 2011 review by Skeem et al. stating that they are "most notably in the amygdala, hippocampus and parahippocampal gyri, anterior and posterior cingulate cortex, striatum, insula, and frontal and temporal cortex". A 2010 meta-analysis found that antisocial, violent and psychopathic individuals had reduced structure function in the right orbitofrontal cortex, right anterior cingulate cortex and left dorsolateral prefrontal cortex.

The amygdala and frontal areas have been suggested as particularly important. People scoring 25 or higher in the PCL-R, with an associated history of violent behavior, appear on average to have significantly reduced microstructural integrity between the white matter connecting the amygdala and orbitofrontal cortex (such as the uncinate fasciculus). The evidence suggested that the degree of abnormality was significantly related to the degree of psychopathy and may explain the offending behaviors. Furthermore, changes in the amygdala have been associated with "callous-unemotional" traits in children. However, the amygdala has also been associated with positive emotions, and there have been inconsistent results in the studies in particular areas, which may be due to methodological issues.

Some of these findings are consistent with other research and theories. For example, in a neuroimaging study of how individuals with psychopathy respond to emotional words, widespread differences in activation patterns have been shown across the temporal lobe when psychopathic criminals were compared to "normal" volunteers, which is consistent with views in clinical psychology. Additionally, the notion of psychopathy being characterized by low fear is consistent with findings of abnormalities in the amygdala, since deficits in aversive conditioning and instrumental learning are thought to result from amygdala dysfunction, potentially compounded by orbitofrontal cortex dysfunction, although the specific reasons are unknown.

Proponents of the primary-secondary psychopathy distinction and triarchic model argue that there are neurological differences between these subgroups of psychopathy which support their views. For instance, the boldness factor in the triarchic model is argued to be associated with reduced activity in the amygdala during fearful or aversive stimuli and reduced startle response, while the disinhibition factor is argued to be associated with impairment of frontal lobe tasks. There is evidence that boldness and disinhibition are genetically distinguishable.

High levels of testosterone combined with low levels of cortisol and/or serotonin have been theorized as contributing factors. Testosterone is "associated with approach-related behavior, reward sensitivity, and fear reduction", and injecting testosterone "shift[s] the balance from punishment to reward sensitivity", decreases fearfulness, and increases "responding to angry faces". Some studies have found that high testosterone levels are associated with antisocial and aggressive behaviors, yet other research suggests that testosterone alone does not cause aggression but increases dominance-seeking. It is unclear from studies if psychopathy correlates with high testosterone levels, but a few studies have found psychopathy to be linked to low cortisol levels and reactivity. Cortisol increases withdrawal behavior and sensitivity to punishment and aversive conditioning, which are abnormally low in individuals with psychopathy and may underlie their impaired aversion learning and disinhibited behavior. High testosterone levels combined with low serotonin levels are associated with "impulsive and highly negative reactions", and may increase violent aggression when an individual is provoked or becomes frustrated. Several animal studies note the role of serotonergic functioning in impulsive aggression and antisocial behavior.

However, some studies on animal and human subjects have suggested that the emotional-interpersonal traits and predatory aggression of psychopathy, in contrast to impulsive and reactive aggression, is related to "increased" serotoninergic functioning. A study by Dolan and Anderson on the relationship between setotonin and psychopathic traits in a sample of personality disordered offenders, found that serotonin functioning as measured by prolactin response, while inversely associated with impulsive and antisocial traits, were positively correlated with arrogant and deceitful traits, and, to a lesser extent, callous and remorseless traits. Bariş Yildirim theorizes that the 5-HTTLPR "long" allele, which is generally regarded as protective against internalizing disorders, may interact with other serotoninergic genes to create a hyper-regulation and dampening of affective processes that results in psychopathy's emotional impairments. Furthermore, the combination of the 5-HTTLPR long allele and high testosterone levels has been found to result in a reduced response to threat as measured by cortisol reactivity, which mirrors the fear deficits found in those afflicted with psychopathy.

Studies have suggested other correlations. Psychopathy was associated in two studies with an increased ratio of HVA (a dopamine metabolite) to 5-HIAA (a serotonin metabolite). Studies have found that individuals with the traits meeting criteria for psychopathy show a greater dopamine response to potential "rewards" such as monetary promises or taking drugs such as amphetamines. This has been theoretically linked to increased impulsivity. A 2010 British study found that a large 2D:4D digit ratio, an indication of high prenatal estrogen exposure, was a "positive correlate of psychopathy in females, and a positive correlate of callous affect (psychopathy sub-scale) in males".

Findings have also shown monoamine oxidase A to affect the predictive ability of the PCL-R. Monoamine oxidases (MAOs) are enzymes that are involved in the breakdown of neurotransmitters such as serotonin and dopamine and are, therefore, capable of influencing feelings, mood, and behavior in individuals. Findings suggest that further research is needed in this area.

Psychopathy is most commonly assessed with the "Psychopathy Checklist, Revised (PCL-R)", created by Robert D. Hare based on Cleckley's criteria from the 1940s, criminological concepts such as those of William and Joan McCord, and his own research on criminals and incarcerated offenders in Canada. The PCL-R is widely used and is referred to by some as the "gold standard" for assessing psychopathy. There are nonetheless numerous criticisms of the PCL-R as a theoretical tool and in real-world usage.

Unlike the PCL, the Psychopathic Personality Inventory (PPI) was developed to comprehensively index personality traits without explicitly referring to antisocial or criminal behaviors themselves. It is a self-report scale that was developed originally for non-clinical samples (e.g. university students) rather than prisoners, though may be used with the latter. It was revised in 2005 to become the PPI-R and now comprises 154 items organized into eight subscales. The item scores have been found to group into two overarching and largely separate factors (unlike the PCL-R factors), Fearless-Dominance and Impulsive Antisociality, plus a third factor, Coldheartedness, which is largely dependent on scores on the other two. Factor 1 is associated with social efficacy while Factor 2 is associated with maladaptive tendencies. A person may score at different levels on the different factors, but the overall score indicates the extent of psychopathic personality.

There are currently two widely established systems for classifying mental disorders—the "International Classification of Diseases" (ICD) produced by the World Health Organization (WHO) and the "Diagnostic and Statistical Manual of Mental Disorders" (DSM) produced by the American Psychiatric Association (APA). Both list categories of disorders thought to be distinct types, and have deliberately converged their codes in recent revisions so that the manuals are often broadly comparable, although significant differences remain.

The first edition of the DSM in 1952 had a section on sociopathic personality disturbances, then a general term that included such things as homosexuality and alcoholism as well as an "antisocial reaction" and "dyssocial reaction". The latter two eventually became antisocial personality disorder (ASPD) in the DSM and dissocial personality disorder in the ICD. Both manuals have stated that their diagnoses have been referred to, or include what is referred to, as psychopathy or sociopathy, although neither diagnostic manual has ever included a disorder officially titled as such.

There are some traditional personality tests that contain subscales relating to psychopathy, though they assess relatively non-specific tendencies towards antisocial or criminal behavior. These include the Minnesota Multiphasic Personality Inventory (Psychopathic Deviate scale), California Psychological Inventory (Socialization scale), and Millon Clinical Multiaxial Inventory Antisocial Personality Disorder scale. There is also the Levenson Self-Report Psychopathy Scale (LSRP) and the Hare Self-Report Psychopathy Scale (HSRP), but in terms of self-report tests, the PPI/PPI-R has become more used than either of these in modern psychopathy research on adults.

As with other mental disorders, psychopathy as a personality disorder may be present with a variety of other diagnosable conditions. Studies especially suggest strong comorbidity with antisocial personality disorder. Among numerous studies, positive correlations have also been reported between psychopathy and histrionic, narcissistic, borderline, paranoid, and schizoid personality disorders, panic and obsessive–compulsive disorders, but not neurotic disorders in general, schizophrenia, or depression.

Attention deficit hyperactivity disorder (ADHD) is known to be highly comorbid with conduct disorder (a theorized precursor to ASPD), and may also co-occur with psychopathic tendencies. This may be explained in part by deficits in executive function. Anxiety disorders often co-occur with ASPD, and contrary to assumptions, psychopathy can sometimes be marked by anxiety; this appears to be related to items from Factor 2 but not Factor 1 of the PCL-R. Psychopathy is also associated with substance use disorders.

It has been suggested that psychopathy may be comorbid with several other conditions than these, but limited work on comorbidity has been carried out. This may be partly due to difficulties in using inpatient groups from certain institutions to assess comorbidity, owing to the likelihood of some bias in sample selection.

Research on psychopathy has largely been done on men and the PCL-R was developed using mainly male criminal samples, raising the question of how well the results apply to women. Men score higher than women on both the PCL-R and the PPI and on both of their main scales. The differences tend to be somewhat larger on the interpersonal-affective scale than on the antisocial scale. Most but not all studies have found broadly similar factor structure for men and women.

Many associations with other personality traits are similar, although in one study the antisocial factor was more strongly related with impulsivity in men and more strongly related with openness to experience in women. It has been suggested that psychopathy in men manifest more as an antisocial pattern while in women it manifests more as a histrionic pattern. Studies on this have shown mixed results. PCL-R scores may be somewhat less predictive of violence and recidivism in women. On the other hand, psychopathy may have a stronger relationship with suicide and possibly internalizing symptoms in women. A suggestion is that psychopathy manifests more as externalizing behaviors in men and more as internalizing behaviors in women.

Studies have also found that women in prison score significantly lower on psychopathy than men, with one study reporting only 11 percent of violent females in prison met the psychopathy criteria in comparison to 31 percent of violent males. Other studies have also pointed out that high psychopathic females are rare in forensic settings.

Psychopathy has often been considered untreatable. Its unique characteristics makes it among the most refractory of personality disorders, a class of mental illnesses that are already traditionally considered difficult to treat. People afflicted with psychopathy are generally unmotivated to seek treatment for their condition, and can be uncooperative in therapy. Attempts to treat psychopathy with the current tools available to psychiatry have been disappointing. Harris and Rice's "Handbook of Psychopathy" says that there is currently little evidence for a cure or effective treatment for psychopathy; as of yet, no pharmacological therapies are known to or have been trialed for alleviating the emotional, interpersonal and moral deficits of psychopathy, and patients with psychopathy who undergo psychotherapy might gain the skills to become more adept at the manipulation and deception of others and be more likely to commit crime. Some studies suggest that punishment and behavior modification techniques are ineffective at modifying the behavior of psychopathic individuals as they are insensitive to punishment or threat. These failures have led to a widely pessimistic view on its treatment prospects, a view that is exacerbated by the little research being done into this disorder compared to the efforts committed to other mental illnesses, which makes it more difficult to gain the understanding of this condition that is necessary to develop effective therapies.

Although the core character deficits of highly psychopathic individuals are likely to be highly incorrigible to the currently available treatment methods, the antisocial and criminal behavior associated with it may be more amenable to management, the management of which being the main aim of therapy programs in correctional settings. It has been suggested that the treatments that may be most likely to be effective at reducing overt antisocial and criminal behavior are those that focus on self-interest, emphasizing the tangible, material value of prosocial behavior, with interventions that develop skills to obtain what the patient wants out of life in prosocial rather than antisocial ways. To this end, various therapies have been tried with the aim of reducing the criminal activity of incarcerated offenders with psychopathy, with mixed success. As psychopathic individuals are insensitive to sanction, reward-based management, in which small privileges are granted in exchange for good behavior, has been suggested and used to manage their behavior in institutional settings.

Psychiatric medications may also alleviate co-occurring conditions sometimes associated with the disorder or with symptoms such as aggression or impulsivity, including antipsychotic, antidepressant or mood-stabilizing medications, although none have yet been approved by the FDA for this purpose. For example, a study found that the antipsychotic clozapine may be effective in reducing various behavioral dysfunctions in a sample of high-security hospital inpatients with antisocial personality disorder and psychopathic traits. However, research into the pharmacological treatment of psychopathy and the related condition antisocial personality disorder is minimal, with much of the knowledge in this area being extrapolations based on what is known about pharmacology in other mental disorders.

The PCL-R, the PCL:SV, and the PCL:YV are highly regarded and widely used in criminal justice settings, particularly in North America. They may be used for risk assessment and for assessing treatment potential and be used as part of the decisions regarding bail, sentence, which prison to use, parole, and regarding whether a youth should be tried as a juvenile or as an adult. There have been several criticisms against its use in legal settings. They include the general criticisms against the PCL-R, the availability of other risk assessment tools which may have advantages, and the excessive pessimism surrounding the prognosis and treatment possibilities of those who are diagnosed with psychopathy.

The interrater reliability of the PCL-R can be high when used carefully in research but tend to be poor in applied settings. In particular Factor 1 items are somewhat subjective. In sexually violent predator cases the PCL-R scores given by prosecution experts were consistently higher than those given by defense experts in one study. The scoring may also be influenced by other differences between raters. In one study it was estimated that of the PCL-R variance, about 45% was due to true offender differences, 20% was due to which side the rater testified for, and 30% was due to other rater differences.

To aid a criminal investigation, certain interrogation approaches may be used to exploit and leverage the personality traits of suspects thought to have psychopathy and make them more likely to divulge information.

The PCL-R cut-off for a label of psychopathy is 25 in the United Kingdom, instead of 30 as it is in the United States.

In the United Kingdom, "psychopathic disorder" was legally defined in the Mental Health Act (UK), under MHA1983, as "a persistent disorder or disability of mind (whether or not including significant impairment of intelligence) which results in abnormally aggressive or seriously irresponsible conduct on the part of the person concerned". This term was intended to reflect the presence of a personality disorder in terms of conditions for detention under the Mental Health Act 1983. Amendments to MHA1983 within the Mental Health Act 2007 abolished the term "psychopathic disorder", with all conditions for detention (e.g. mental illness, personality disorder, etc.) encompassed by the generic term of "mental disorder".

In England and Wales, the diagnosis of dissocial personality disorder is grounds for detention in secure psychiatric hospitals under the Mental Health Act if they have committed serious crimes, but since such individuals are disruptive to other patients and not responsive to usual treatment methods this alternative to traditional incarceration is often not used.

Starting in the 1930s, before some modern concepts of psychopathy were developed, "sexual psychopath" laws, the term referring broadly to mental illness, were introduced by some states, and by the mid-1960s more than half of the states had such laws. Sexual offenses were considered to be caused by underlying mental illnesses, and it was thought that sex offenders should be treated, in agreement with the general rehabilitative trends at this time. Courts committed sex offenders to a mental health facility for community protection and treatment.

Starting in 1970, many of these laws were modified or abolished in favor of more traditional responses such as imprisonment due to criticism of the "sexual psychopath" concept as lacking scientific evidence, the treatment being ineffective, and predictions of future offending being dubious. There were also a series of cases where persons treated and released committed new sexual offenses. Starting in the 1990s, several states have passed sexually dangerous person laws, including registration, housing restrictions, public notification, mandatory reporting by health care professionals, and civil commitment, which permits indefinite confinement after a sentence has been completed. Psychopathy measurements may be used in the confinement decision process.

The prognosis for psychopathy in forensic and clinical settings is quite poor, with some studies reporting that treatment may worsen the antisocial aspects of psychopathy as measured by recidivism rates, though it is noted that one of the frequently cited studies finding increased criminal recidivism after treatment, a 2011 retrospective study of a treatment program in the 1960s, had several serious methodological problems and likely would not be approved of today. However, some relatively rigorous quasi-experimental studies using more modern treatment methods have found improvements regarding reducing future violent and other criminal behavior, regardless of PCL-R scores, although none were randomized controlled trials. Various other studies have found improvements in risk factors for crime such as substance abuse. No study has of yet in a 2013 review examined if the personality traits that form the core character disturbances of psychopathy could be changed by such treatments.

A 2008 study using the PCL:SV found that 1.2% of a US sample scored 13 or more out of 24, indicating "potential psychopathy". The scores correlated significantly with violence, alcohol use, and lower intelligence. A 2009 British study by Coid et al., also using the PCL:SV, reported a community prevalence of 0.6% scoring 13 or more. The scores correlated with younger age, male gender, suicide attempts, violence, imprisonment, homelessness, drug dependence, personality disorders (histrionic, borderline and antisocial), and panic and obsessive–compulsive disorders.

Psychopathy has a much higher prevalence in the convicted and incarcerated population, where it is thought that an estimated 15–25% of prisoners qualify for the diagnosis. A study on a sample of inmates in the UK found that 7.7% of the inmates interviewed met the PCL-R cut-off of 30 for a diagnosis of psychopathy. A study on a sample of inmates in Iran using the PCL:SV found a prevalence of 23% scoring 18 or more. A study by Nathan Brooks from Bond University found that around one in five corporate bosses display clinically significant psychopathic traits - a proportion similar to that among prisoners.

There is limited research on psychopathy in the general work populace, in part because the PCL-R includes antisocial behavior as a significant core factor (obtaining a PCL-R score above the threshold is unlikely without having significant scores on the antisocial-lifestyle factor) and does not include positive adjustment characteristics, and most researchers have studied psychopathy in incarcerated criminals, a relatively accessible population of research subjects.

However, psychologists Fritzon and Board, in their study comparing the incidence of personality disorders in business executives against criminals detained in a mental hospital, found that the profiles of some senior business managers contained significant elements of personality disorders, including those referred to as the "emotional components", or interpersonal-affective traits, of psychopathy. Factors such as boldness, disinhibition, and meanness as defined in the triarchic model, in combination with other advantages such as a favorable upbringing and high intelligence, are thought to correlate with stress immunity and stability, and may contribute to this particular expression. Such individuals are sometimes referred to as "successful psychopaths" or "corporate psychopaths" and they may not always have extensive histories of traditional criminal or antisocial behavior characteristic of the traditional conceptualization of psychopathy. Robert Hare claims that the prevalence of psychopathic traits is higher in the business world than in the general population, reporting that while about 1% of the general population meet the clinical criteria for psychopathy, figures of around 3–4% have been cited for more senior positions in business. Hare considers newspaper tycoon Robert Maxwell to have been a strong candidate as a "corporate psychopath".

Academics on this subject believe that although psychopathy is manifested in only a small percentage of workplace staff, it is more common at higher levels of corporate organizations, and its negative effects (for example, increased bullying, conflict, stress, staff turnover, absenteeism, reduction in productivity) often causes a ripple effect throughout an organization, setting the tone for an entire corporate culture. Employees with the disorder are self-serving opportunists, and may disadvantage their own organizations to further their own interests. They may be charming to staff above their level in the workplace hierarchy, aiding their ascent through the organization, but abusive to staff below their level, and can do enormous damage when they are positioned in senior management roles. Psychopathy as measured by the PCL-R is associated with lower performance appraisals among corporate professionals. The psychologist Oliver James identifies psychopathy as one of the dark triadic traits in the workplace, the others being narcissism and Machiavellianism, which, like psychopathy, can have negative consequences.

According to a study from the University of Notre Dame published in the "Journal of Business Ethics," psychopaths have a natural advantage in workplaces overrun by abusive supervision, and are more likely to thrive under abusive bosses, being more resistant to stress, including interpersonal abuse, and having less of a need for positive relationships than others.

Characters with psychopathy or sociopathy are some of the most notorious characters in film and literature, but their characterizations may only vaguely or partly relate to the concept of psychopathy as it is defined in psychiatry, criminology, and research. The character may be identified as having psychopathy within the fictional work itself, by its creators, or from the opinions of audiences and critics, and may be based on undefined popular stereotypes of psychopathy. Characters with psychopathic traits have appeared in Greek and Roman mythology, Bible stories, and some of Shakespeare's works.

Such characters are often portrayed in an exaggerated fashion and typically in the role of a villain or antihero, where the general characteristics and stereotypes associated with psychopathy are useful to facilitate conflict and danger. Because the definitions, criteria, and popular conceptions throughout its history have varied over the years and continue to change even now, many of the characters characterized as psychopathic in notable works at the time of publication may no longer fit the current definition and conception of psychopathy. There are several archetypal images of psychopathy in both lay and professional accounts which only partly overlap and can involve contradictory traits: the charming con artist, the deranged serial killer and mass murderer, the callous and scheming businessperson, and the chronic low-level offender and juvenile delinquent. The public concept reflects some combination of fear of a mythical bogeyman, the disgust and intrigue surrounding evil, and fascination and sometimes perhaps envy of people who might appear to go through life without attachments and unencumbered by guilt, anguish or insecurity.

The word "psychopathy" is a joining of the Greek words "psyche" (ψυχή) "soul" and "pathos" (πάθος) "suffering, feeling". The first documented use is from 1847 in Germany as "psychopatisch", and the noun "psychopath" has been traced to 1885. In medicine, "patho-" has a more specific meaning of disease (thus "pathology" has meant the study of disease since 1610, and "psychopathology" has meant the study of mental disorder in general since 1847. A sense of "a subject of pathology, morbid, excessive" is attested from 1845, including the phrase "pathological liar" from 1891 in the medical literature).

The term "psychopathy" initially had a very general meaning referring to all sorts of mental disorders and social aberrations, popularised from 1891 in Germany by Koch's concept of "psychopathic inferiority" (psychopathische Minderwertigkeiten). Some medical dictionaries still define psychopathy in both a narrow and broad sense, such as MedlinePlus from the U.S. National Library of Medicine. On the other hand, Stedman's Medical Dictionary defines psychopathy only as an outdated term for an antisocial type of personality disorder.

The term "psychosis" was also used in Germany from 1841, originally in a very general sense. The suffix -ωσις (-osis) meant in this case "abnormal condition". This term or its adjective "psychotic" would come to refer to the more severe mental disturbances and then specifically to mental states or disorders characterized by hallucinations, delusions or in some other sense markedly out of touch with reality.

The slang term "psycho" has been traced to a shortening of the adjective "psychopathic" from 1936, and from 1942 as a shortening of the noun "psychopath", but it is also used as shorthand for psychotic or crazed.

The media usually uses the term "psychopath" to designate any criminal whose offenses are particularly abhorrent and unnatural, but that is not its original or general psychiatric meaning.

The word element "socio"- has been commonly used in compound words since around 1880. The term "sociopathy" may have been first introduced in 1909 in Germany by biological psychiatrist Karl Birnbaum and in 1930 in the US by educational psychologist George E. Partridge, as an alternative to the concept of "psychopathy". It was used to indicate that the defining feature is violation of social norms, or antisocial behavior, and has often also been associated with postulating social as well as biological causation.

The term is used in various different ways in contemporary usage. Robert Hare stated in the popular science book entitled "Snakes in Suits" that "sociopathy" and "psychopathy" are often used interchangeably, but in some cases the term "sociopathy" is preferred because it is less likely than is "psychopathy" to be confused with psychosis, whereas in other cases the two terms may be used with different meanings that reflect the user's views on the origins and determinants of the disorder. Hare contended that the term "sociopathy" is preferred by those that see the causes as due to social factors and early environment, and the term "psychopathy" preferred by those who believe that there are psychological, biological, and genetic factors involved in addition to environmental factors. Hare also provides his own definitions: he describes psychopathy as not having a sense of empathy or morality, but sociopathy as only differing from the average person in the sense of right and wrong.

Ancient writings that have been connected to psychopathy include Deuteronomy 21:18–21, which was written around 700 BCE, and a description of an unscrupulous man by the Greek philosopher Theophrastus around 300 BCE.

The concept of psychopathy has been indirectly connected to the early 19th century with the work of Pinel (1801; "mania without delirium") and Pritchard (1835; "moral insanity"), although historians have largely discredited the idea of a direct equivalence. "Psychopathy" originally described any illness of the mind, but found its application to a narrow subset of mental conditions when was used toward the end of the 19th century by the German psychiatrist Julius Koch (1891) to describe various behavioral and moral dysfunction in the absence of an obvious mental illness or intellectual disability. He applied the term "psychopathic inferiority" (psychopathischen Minderwertigkeiten) to various chronic conditions and character disorders, and his work would influence the later conception of the personality disorder.

The term "psychopathic" came to be used to describe a diverse range of dysfunctional or antisocial behavior and mental and sexual deviances, including at the time homosexuality. It was often used to imply an underlying "constitutional" or genetic origin. Disparate early descriptions likely set the stage for modern controversies about the definition of psychopathy.

An influential figure in shaping modern American conceptualizations of psychopathy was American psychiatrist Hervey Cleckley. In his classic monograph, "The Mask of Sanity" (1941), Cleckley drew on a small series of vivid case studies of psychiatric patients at a Veterans Administration hospital in Georgia to describe the disorder. Cleckley used the metaphor of the "mask" to refer to the tendency of psychopaths to appear confident, personable, and well-adjusted compared to most psychiatric patients, while revealing underlying pathology through their actions over time. Cleckley formulated sixteen criteria to describe the disorder. The Scottish psychiatrist David Henderson had also been influential in Europe from 1939 in narrowing the diagnosis.

The diagnostic category of "sociopathic personality" in early editions of the "Diagnostic and Statistical Manual" (DSM) had some key similarities to Cleckley's ideas, though in 1980 when renamed Antisocial Personality Disorder some of the underlying personality assumptions were removed. In 1980, Canadian psychologist Robert D. Hare introduced an alternative measure, the "Psychopathy Checklist" (PCL) based largely on Cleckley's criteria, which was revised in 1991 (PCL-R), and is the most widely used measure of psychopathy. There are also several self-report tests, with the Psychopathic Personality Inventory (PPI) used more often among these in contemporary adult research.

Famous individuals have sometimes been diagnosed, albeit at a distance, as psychopaths. As one example out of many possible from history, in a 1972 version of a secret report originally prepared for the Office of Strategic Services in 1943, and which may have been intended to be used as propaganda, non-medical psychoanalyst Walter C. Langer suggested Adolf Hitler was probably a psychopath. However, others have not drawn this conclusion; clinical forensic psychologist Glenn Walters argues that Hitler's actions do not warrant a diagnosis of psychopathy as, although he showed several characteristics of criminality, he was not always egocentric, callously disregarding of feelings or lacking impulse control, and there is no proof he could not learn from mistakes.





</doc>
