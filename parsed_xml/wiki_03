<doc id="46287275" url="https://en.wikipedia.org/wiki?curid=46287275" title="Knowledge enterprise">
Knowledge enterprise

Knowledge enterprise, also named as knowledge company or knowledge-intensive company, or enterprise. According to D. Jemielniak, origin, and scope of this term is unclear. How this can be understood depends on how much company depends on knowledge, that in such a configuration, should be a critical asset of organization. There is no agreement on how knowledge-intensive (to what extent) companies should be to be named like so. However, there are some hints to distinguish knowledge companies, since in economies, there are two groups of companies, of which one is labor-intensive, and another knowledge intensive.

According to Jemielniak, knowledge enterprises have emerged due to changes in the global economy, which throughout decades has been giving greater priorities to services. The emergence of knowledge companies is also called as a symptom of the third industrial revolution where boundaries between owners of production resources, and workers. On the example of IBM it can be seen that such a change have influenced the structure of income of companies. In 1924, IBM’s profits were generated by leasing of manufacturing equipment in 96%, while punched cards were responsible for 4% of the profit. In 1970’s, 80% of profit came from equipment divisions, 15% from software division and 5% from services. In 1990’s services contributed to 30% of IBM’s profits, later in 2007 it was already 45% that the company had earned from rendering services, and 20% from software. This example only reflects the overall change, that is manifested by the reversed proportion between tangible and intangible assets of companies. This evolution has forced a shift in the access to these resources from manual to non-manual (knowledge) workers. Also decision making power is handed in top-down, from owners, and top managers to mid-managers and specialists. These developments accompany the emergence and growing importance of knowledge enterprises.

Knowledge enterprises, according to Lowendahl, can be divided into:
and example companies are: management consultancy companies.
In another approach knowledge companies are divided into professional service companies, and research and development companies.

Knowledge enterprises, due to their high-tech profile, chiefly have to base on IT technologies, including hardware and software to conduct managerial processes, and to organize working environments for all the staff, from executive to top management. This is why software development is crucial for existence and evolution of such companies. Software applications are developed for many areas within such organizations, since without them it is difficult to control, and coordinate work that is dedicated to innovation, and problem solving.

The main reason of ‘drain brain’ phenomenon and involvement of knowledge companies into it, is a great gap between educational infrastructure in the origin countries that IT professionals can get (but it is not limited to this profession), and low wages that they can be proposed in the origin country. The problem is that educational infrastructure in the transition countries (Central and Eastern Europe) does not actually have to catch-up with the counterparts in knowledge-based economies, like the United States. However salaries of the knowledge workers in both groups of countries differ very much. Knowledge-intensive companies from knowledge-based economies may propose much better incentives to have them move and work for them. This is the reason why human resources from transition countries are drained to those countries, that are characterized by the salary competitive advantage.


</doc>
<doc id="5702463" url="https://en.wikipedia.org/wiki?curid=5702463" title="Knowledge environment">
Knowledge environment

Knowledge environments are social practices, technological and physical arrangements intended to facilitate collaborative knowledge building, decision making, inference or discovery, depending on the epistemological premises and goals.

Knowledge environments departing from constructivist epistemology assume that domain knowledge is built in and results from cognitive and/or social practices. From this perspective the primary purpose of knowledge environments is to host and support activities of knowledge building, the means including cognitive ergonomics, social software, immediate information access exploiting means of multimedia and hypertext, content contribution functionalities and structured ontologies. Wikipedia itself is a prototypical example of a knowledge environment in this sense.

From another perspective, the purpose of a knowledge environment can be defined as a method to facilitate consistent knowledge outcomes. Knowledge outcomes reveal themselves as learning, communication, goals, decisions, etc. Consistent knowledge outcomes imply predictable learning results or replicable communication results and predictable quality of decisions. The design of knowledge environments is both commonplace activity and specialised expert work. At a simplistic level every teacher, every author, every librarian and every database manager is a creator of a knowledge environment. At a specialized level, knowledge environments need sophisticated architecture and modeling capabilities. This approach is necessary when the creator of the knowledge environment wants to deliver replicable results in hundreds of specific instances of the same knowledge environment. On the other hand, the strengthening trend of public authorship leads to open-ended ontologies by means of, say, tagging or folksonomies. In a significant sense, knowledge environments are in such cases created not only by their authors or owners but also by the contributors of their ontologies.

There are various kinds of knowledge environments:

Knowledge environments are all pervasive but difficult to build on a scalable and a replicable basis. This is because of two groups of interacting variables:

Some of the issues in development are:

Knowledge environments are useful for designing:



</doc>
<doc id="31002435" url="https://en.wikipedia.org/wiki?curid=31002435" title="Knowledge extraction">
Knowledge extraction

Knowledge extraction is the creation of knowledge from structured (relational databases, XML) and unstructured (text, documents, images) sources. The resulting knowledge needs to be in a machine-readable and machine-interpretable format and must represent knowledge in a manner that facilitates inferencing. Although it is methodically similar to information extraction (NLP) and ETL (data warehouse), the main criteria is that the extraction result goes beyond the creation of structured information or the transformation into a relational schema. It requires either the reuse of existing formal knowledge (reusing identifiers or ontologies) or the generation of a schema based on the source data.

The RDB2RDF W3C group is currently standardizing a language for extraction of resource description frameworks (RDF) from relational databases. Another popular example for knowledge extraction is the transformation of Wikipedia into structured data and also the mapping to existing knowledge (see DBpedia and Freebase).

After the standardization of knowledge representation languages such as RDF and OWL, much research has been conducted in the area, especially regarding transforming relational databases into RDF, identity resolution, knowledge discovery and ontology learning. The general process uses traditional methods from information extraction and extract, transform, and load (ETL), which transform the data from the sources into structured formats.

The following criteria can be used to categorize approaches in this topic (some of them only account for extraction from relational databases):


President Obama called Wednesday on Congress to extend a tax break for students included in last year's economic stimulus package, arguing that the policy provides more generous assistance. 


When building a RDB representation of a problem domain, the starting point is frequently an entity-relationship diagram (ERD). Typically, each entity is represented as a database table, each attribute of the entity becomes a column in that table, and relationships between entities are indicated by foreign keys. Each table typically defines a particular class of entity, each column one of its attributes. Each row in the table describes an entity
instance, uniquely identified by a primary key. The table rows collectively describe an entity set. In an equivalent RDF representation of the same entity set:

So, to render an equivalent view based on RDF semantics, the basic mapping algorithm would be as follows:

Early mentioning of this basic or direct mapping can be found in Tim Berners-Lee's comparison of the ER model to the RDF model.

The 1:1 mapping mentioned above exposes the legacy data as RDF in a straightforward way, additional refinements can be employed to improve the usefulness of RDF output respective the given Use Cases. Normally, information is lost during the transformation of an entity-relationship diagram (ERD) to relational tables (Details can be found in object-relational impedance mismatch) and has to be reverse engineered. From a conceptual view, approaches for extraction can come from two directions. The first direction tries to extract or learn an OWL schema from the given database schema. Early approaches used a fixed amount of manually created mapping rules to refine the 1:1 mapping. More elaborate methods are employing heuristics or learning algorithms to induce schematic information (methods overlap with ontology learning). While some approaches try to extract the information from the structure inherent in the SQL schema (analysing e.g. foreign keys), others analyse the content and the values in the tables to create conceptual hierarchies (e.g. a columns with few values are candidates for becoming categories). The second direction tries to map the schema and its contents to a pre-existing domain ontology (see also: ontology alignment). Often, however, a suitable domain ontology does not exist and has to be created first.

As XML is structured as a tree, any data can be easily represented in RDF, which is structured as a graph. XML2RDF is one example of an approach that uses RDF blank nodes and transforms XML elements and attributes to RDF properties. The topic however is more complex as in the case of relational databases. In a relational table the primary key is an ideal candidate for becoming the subject of the extracted triples. An XML element, however, can be transformed - depending on the context- as a subject, a predicate or object of a triple. XSLT can be used a standard transformation language to manually convert XML to RDF.

The largest portion of information contained in business documents (about 80%) is encoded in natural language and therefore unstructured. Because unstructured data is rather a challenge for knowledge extraction, more sophisticated methods are required, which generally tend to supply worse results compared to structured data. The potential for a massive acquisition of extracted knowledge, however, should compensate the increased complexity and decreased quality of extraction. In the following, natural language sources are understood as sources of information, where the data is given in an unstructured fashion as plain text. If the given text is additionally embedded in a markup document (e. g. HTML document), the mentioned systems normally remove the markup elements automatically.

Traditional information extraction is a technology of natural language processing, which extracts information from typically natural language texts and structures these in a suitable manner. The kinds of information to be identified must be specified in a model before beginning the process, which is why the whole process of traditional Information Extraction is domain dependent. The IE is split in the following five subtasks.


The task of named entity recognition is to recognize and to categorize all named entities contained in a text (assignment of a named entity to a predefined category). This works by application of grammar based methods or statistical models.

Coreference resolution identifies equivalent entities, which were recognized by NER, within a text. There are two relevant kinds of equivalence relationship. The first one relates to the relationship between two different represented entities (e.g. IBM Europe and IBM) and the second one to the relationship between an entity and their anaphoric references (e.g. it and IBM). Both kinds can be recognized by coreference resolution.

During template element construction the IE system identifies descriptive properties of entities, recognized by NER and CO. These properties correspond to ordinary qualities like red or big.

Template relation construction identifies relations, which exist between the template elements. These relations can be of several kinds, such as works-for or located-in, with the restriction, that both domain and range correspond to entities.

In the template scenario production events, which are described in the text, will be identified and structured with respect to the entities, recognized by NER and CO and relations, identified by TR.

Ontology-based information extraction is a subfield of information extraction, with which at least one ontology is used to guide the process of information extraction from natural language text. The OBIE system uses methods of traditional information extraction to identify concepts, instances and relations of the used ontologies in the text, which will be structured to an ontology after the process. Thus, the input ontologies constitute the model of information to be extracted.

Ontology learning is the automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms from natural language text. As building ontologies manually is extremely labor-intensive and time consuming, there is great motivation to automate the process.

During semantic annotation, natural language text is augmented with metadata (often represented in RDFa), which should make the semantics of contained terms machine-understandable. At this process, which is generally semi-automatic, knowledge is extracted in the sense, that a link between lexical terms and for example concepts from ontologies is established. Thus, knowledge is gained, which meaning of a term in the processed context was intended and therefore the meaning of the text is grounded in machine-readable data with the ability to draw inferences. Semantic annotation is typically split into the following two subtasks.


At the terminology extraction level, lexical terms from the text are extracted. For this purpose a tokenizer determines at first the word boundaries and solves abbreviations. Afterwards terms from the text, which correspond to a concept, are extracted with the help of a domain-specific lexicon to link these at entity linking.

In entity linking a link between the extracted lexical terms from the source text and the concepts from an ontology or knowledge base such as DBpedia is established. For this, candidate-concepts are detected appropriately to the several meanings of a term with the help of a lexicon. Finally, the context of the terms is analyzed to determine the most appropriate disambiguation and to assign the term to the correct concept.

The following criteria can be used to categorize tools, which extract knowledge from natural language text.

The following table characterizes some tools for Knowledge Extraction from natural language sources.

Knowledge discovery describes the process of automatically searching large volumes of data for patterns that can be considered knowledge "about" the data. It is often described as "deriving" knowledge from the input data. Knowledge discovery developed out of the data mining domain, and is closely related to it both in terms of methodology and terminology.

The most well-known branch of data mining is knowledge discovery, also known as knowledge discovery in databases (KDD). Just as many other forms of knowledge discovery it creates abstractions of the input data. The "knowledge" obtained through the process may become additional "data" that can be used for further usage and discovery. Often the outcomes from knowledge discovery are not actionable, actionable knowledge discovery, also known as domain driven data mining, aims to discover and deliver actionable knowledge and insights.

Another promising application of knowledge discovery is in the area of software modernization, weakness discovery and compliance which involves understanding existing software artifacts. This process is related to a concept of reverse engineering. Usually the knowledge obtained from existing software is presented in the form of models to which specific queries can be made when necessary. An entity relationship is a frequent format of representing knowledge obtained from existing software. Object Management Group (OMG) developed the specification Knowledge Discovery Metamodel (KDM) which defines an ontology for the software assets and their relationships for the purpose of performing knowledge discovery in existing code. Knowledge discovery from existing software systems, also known as software mining is closely related to data mining, since existing software artifacts contain enormous value for risk management and business value, key for the evaluation and evolution of software systems. Instead of mining individual data sets, software mining focuses on metadata, such as process flows (e.g. data flows, control flows, & call maps), architecture, database schemas, and business rules/terms/process.





</doc>
<doc id="12362106" url="https://en.wikipedia.org/wiki?curid=12362106" title="Knowledge mobilization">
Knowledge mobilization

The term knowledge mobilization (KMb) refers to moving available knowledge (often from formal research) into active use. More than just "bridging the gap", KMb seeks to make connections between research/expertise and policy/practice in order to improve outcomes in various organizations or sectors. KMb involves knowledge sharing between research producers (e.g. university researchers) and research users (including professionals or others whose work can benefit from research findings), often with the help of third parties or intermediaries. The concept has grown out of increasing recognition that verified empirical knowledge should be the basis for many policies and practices.
Social science research deals with the people side of quality of life issues and nation-building that are so crucial to the future of humanity. Human, technological and cultural developments are needed for economic prosperity, environmental sustainability, social harmony and cultural vitality. Yet using research in the social sciences presents particular challenges because the issues are often complex and long-term, and deeply affected by local contexts.

The term KMb gained wider use following the publication of the evaluation report of the Community-University Research Alliance (CURA) program of the Social Sciences and Humanities Research Council of Canada (SSHRC) in 2004. This led SSHRC to create a division of Knowledge Products and Mobilization to enhance and accelerate the movement of research findings into policy and program development. Although many other terms are used to describe this same work, KMb, or knowledge mobilization, is the term most often used by the social science and humanities fields in Canada.

As in many other areas of social science, many different terms and approaches are used to define the knowledge mobilization process in different sectors and disciplines. The health sector often uses the term knowledge translation, whereas the business sector uses knowledge management, and so on. The Research Supporting Practice in Education (RSPE) Team at the University of Toronto – Ontario Institute for Studies in Education has created a synthesized list of the various terms and definitions currently being used.

There is considerable overlap between different terms but the subtle differences can affect our understanding of the topic. For example, the term Knowledge Transfer, implies that knowledge is like an object that can be given from one person to another, whereas terms such as Knowledge Exchange or Knowledge Mobilization imply that knowledge is altered as it passes from person to person. However, regardless of the term, the underlying intent in all cases is to make research matter more in policy and practice for organizational and system improvement.
The term 'knowledge' also carries multiple meanings. Some literature describes two types of knowledge; explicit and tacit. Tacit knowledge is gained through personal experience, and is difficult to codify and transfer; where explicit knowledge is often instrumental and can be more easily transported through various mediums. KMb tends to focus on explicit knowledge derived from formal research, while recognizing that tacit knowledge is also very important in practice.

Even within formal research settings, there is often disagreement about how much and what kinds of evidence provide sufficient warrant to claim that something is 'knowledge'.
A similar debate exists over what can be regarded as 'use' of research, with considerable evidence showing that research has an impact in diffuse ways and sometimes over long periods of time A detailed definition of knowledge mobilization, in relation to other practices such as community engagement, can be found on the website of the Institute for Community Engaged Scholarship.

Knowledge mobilization is a proactive process that involves specific efforts to build relationships between research producers and users, such as formal and informal events, networks, and collaboration on resources for research use. The broad concept of knowledge mobilization encompasses a variety of strategies, including producer push (where researchers do the work of trying to share knowledge), user pull (where research users seek information), knowledge exchange and the co-production of knowledge. These strategies may be informal or formal and can take place in many different places and ways.

The internet has become the prime vehicle through which research knowledge is shared, although direct personal connections among people remain a powerful means of sharing knowledge. In some fields or organizations there are specific roles for knowledge mobilization specialists (whose roles may have various names) to find, evaluate, synthesize and summarize findings to tailor and maximize the use of relevant and appropriate research. The goal is to replace practices based on belief with evidence-based practices in order to produce more effective outcomes. Researchers and research users can both benefit from the interaction required by KMb. Collaboration among various parties can improve the research enterprise as well by facilitating more relevant and effective scholarship as well as increased take-up of research findings.

Knowledge brokers or intermediaries act as bridges between the users and producers of the knowledge. They have to ensure that relevant information is made available in the right format. These ideas of quality research informed by the needs of research users, accurate interpretation, open access and just-in-time service are the bases for good researcher-user interface, often provided by knowledge brokers who can synthesize a large body of research and look for policy and practice implications that facilitate use of research results. Many different individuals and organizations play a brokering or intermediary role, from think tanks to lobby groups to political parties to professional or trade associations, to promoters of particular products or strategies. These various bodies may have very different motivations and degrees of objectivity in their approach. Much brokering occurs as part of political debate, in which the contention among ideas is part of broader political processes.

Research into the role of knowledge brokering in the UK health sector found that key individuals often play a major role in knowledge mobilization. A large study of knowledge mobilization by University of Oxford researchers found effective 'knowledge leadership' is crucial to moving evidence-based research into organizational practice, and creating 'epistemic fit'.

The Canadian Health Services Research Foundation (CHSRF), which has made extensive use of knowledge brokering and promoted evidence-informed decision making in the health services field, has developed extensive tools and resources that are finding use outside the health field. Similarly, the Canadian Institutes of Health Research (CIHR) have developed the idea of knowledge translation as a means to make better use of research in the health field. The RSPE provides many examples of and resources for knowledge brokering.

Networks are an important mechanism to support KMb. A number of KMb networks support professional knowledge brokers and the practice of KMb. ResearchImpact-RéseauImpact Recherche (RIR) is Canada's KMb network. Led by York University in Toronto, and pioneered by the work of David Phipps, it includes knowledge brokers from York University, Memorial University of Newfoundland and Labrador, Université du Québec à Montréal, Université de Montréal, Carleton University, University of Guelph, University of Saskatchewan, Kwantlen Polytechnic University, University of Victoria, McMaster University, and University of New Brunswick. (DRUSSA) is a network of 24 universities developing professional supports for research uptake (=KMb). The Canadian (KTECoP) has over 800 members and has chapters in Toronto, Ottawa and Vancouver. Ed Comms (www.educationcommunities.org) is the open to all knowledge mobilization network supported by a world wide network universities and educational organisations that form the Education Futures Collaboration (www.edfuturescollaboration.org). A core goal of Ed Comms is to link researchers and research users and to support educators to find others interested in collaborative working particularly to scale up small scale research so that educational research can be more impactful.

Movements such as open access and open data can play a positive role in KMb. Access to scholarly research and data sets has increased partly as a result of these movements, as well as greater digitization and dissemination of resources by government and NGOs. However, many institutions do not yet make their research publicly available, lack an open access repository or directory, or have well organized websites for posting research-based resources. However access to research is not nearly sufficient for Knowledge Mobilization, as the main barriers to research use are less a matter of knowing than they are of the capacity and motivation to use that knowledge in practice.

The field of KMb has been developing for about 50 years now. A good review of this work is in Estabrooks et al. (2008) There are many excellent research articles examining research utilization. In 2007, Sandra Nutley and colleagues from the Research Unit for Research Utilization (RURU) at the University of Edinburgh published one of the most comprehensive guides to KMb, "Using Evidence: How Research Can Inform Public Services", which identifies three interacting domains: research production, research use, and the intermediary process that links these two domains. This book provides an extensive review of the literature on research utilization from traditional constructs to contemporary design, from the practice and policy perspectives, and examines strategies to enhance research utilization and measure the impact of research use.

Many resources regarding this field, including definitions, conceptual models and links to other organizations, can be found on the website of the RSPE team at the University of Toronto's Ontario Institute for Studies in Education (OISE) and at KMbeing.com. A recent review of current research in knowledge mobilization can be found in the London Review of Education.




</doc>
<doc id="50239310" url="https://en.wikipedia.org/wiki?curid=50239310" title="Knowledge neglect">
Knowledge neglect

Knowledge neglect refers to cases when people fail to retrieve and apply previously stored knowledge appropriately into a current situation (Marsh, Umanath, 2014).
Perhaps the most famous example of knowledge neglect is the Moses Illusion, discovered in 1981 by Erickson and Mattson. For the illusion, participants are asked to answer the question, “How many pairs of each animal did Moses bring on his ark?” If a participant answers the question by simply saying, “2,” then this is an example of knowledge neglect because the person has failed to apply their previously learned knowledge that Noah was the individual who constructed the ark and herded the animals, not Moses. Another example would be a teacher asking the class, "Who was the main villain in Stephen King's "Harry Potter" series?" Any fan of the "Harry Potter" series knows that J. K. Rowling authored the books, however someone might still answer this question without applying their previous knowledge about the correct author, demonstrating knowledge neglect.

A more general example of knowledge neglect can also occur, for instance, when someone is rehearsing lines for a play and then forgets some of the lines while they are performing. The lines were available to the person in their memory but that person failed to access or retrieve them from their memory and use them for the situation, also demonstrating knowledge neglect.

One possible reason that people fall victim to knowledge neglect is because people tend to have a truth bias, meaning that people tend to believe that the information they hear is true. With the truth bias, people are inclined to believe that plausible information is true, regardless of the source of such information or their own prior knowledge. For this reason, individuals may fall victim to knowledge neglect simply because they aren't expecting that what they are being told or reading about will be incorrect.

Knowledge neglect could also be explained by the idea that people's attention is often fragmented, and that their cognitive ability is being used to examine the meaning of what they are reading or hearing about, rather than detecting errors in validity. For example, while reading stories or detecting/answering distorted questions, the participant is doing a lot and may not have the processing resources available to assess whether or not the information is true (Marsh, Umanath 2014). The reader of a story is processing a plot line, keeping track of characters, and more generally, building a mental model of the text (e.g., Bower & Morrow, 1990; Johnson‐ Laird, 1983); catching contradictions with stored knowledge is thus, not the main focus of the reader (Marsh, Umanath 2014).

The simple fact of believing something when it is presented to you is common. This can be a significant cause for knowledge neglect. When something is believed, the meaning is represented, coded, or presented in a mental system and usually is treated as if it is true (Gilbert 1991). If you have no prior knowledge about a subject when you encode it and you believe such information to be true, you are more likely to retrieve this information at a later time believing it is true, putting you at risk for knowledge neglect.

Rapp, D., & Braasch, J. L. (n.d.). Processing inaccurate information: Theoretical and applied perspectives from cognitive science and the educational sciences.

Bottoms, H. C., Eslick, A. N., & Marsh, E. J. (2010). Memory and the Moses illusion: Failures to detect contradictions with stored knowledge yield negative memorial consequences. Memory, 18(6), 670-678

Park, H., & Reder, L. M. (2004). Moses illusion: Implications for human cognition. In R. F. Pohl (Ed.), Cognitive illusions: A handbook on fallacies and biases in thinking, judgment, and memory (pp. 275"292). Hove, UK: Psychology Press.

Knowledge does not protect against illusory truth.
Fazio, Lisa K.; Brashier, Nadia M.; Payne, B. Keith; Marsh, Elizabeth J.
Journal of Experimental Psychology: General, Vol 144(5), Oct 2015, 993-1002.

Allison D. Cantor & Elizabeth J. Marsh (2016): Expertise effects in the Moses illusion: detecting contradictions with stored knowledge, Memory, DOI: 10.1080/09658211.2016.1152377

Gilbert, D. T. (1991). How mental systems believe. American psychologist, 46(2), 107.

Marsh, E. J., & Umanath, S. (2014). Knowledge Neglect: Failures to Notice Contradictions with Stored Knowledge. Chapter in D. N. Rapp and J. Braasch (Eds.) Processing Inaccurate Information: Theoretical and Applied Perspectives from Cognitive Science and the Educational Sciences. MIT Press.


</doc>
<doc id="52906318" url="https://en.wikipedia.org/wiki?curid=52906318" title="Knowledge regime">
Knowledge regime

A knowledge regime is a type of system involving a specific set of actors, organizations, and institutions that create policy ideas used to alter the organization and overall operation of the policy-making and production process. Knowledge regimes are beneficial for the implementation of public policy because they introduce new sets of data, research, theories, recommendations, and many other influential ideas directed towards an end goal of economic competition.

These regimes became increasingly important following WWII when many capitalist societies were facing long periods of high inflation and economic stagnation associated with high levels of unemployment. Following this era, knowledge regimes were used in the study of comparative political economies, which examined both policymaking regimes as well as production regimes. The information and policies that arises from knowledge regimes differs depending on the political economy that a state operates in.

In a liberal market economy (LME) with a decentralized, open market, the knowledge regimes tend to be more market-oriented, meaning there are less external constraints from the government. In open markets there is more competition between companies and actors, resulting in a more adversarial environment. In an LME with a more centralized and closed market, there is nonpartisan state-involvement, all the while in a hostile environment. In coordinated market economies (CME) with decentralized, open states, there are strong associational institutional arrangements, which results in more consensus-oriented knowledge regimes whereas in a CME with a centralized closed market, policy changes come from within the state.

Depending on the political economy of a state, there are four corresponding knowledge-producing organizations. The first organization is composed of scholars who have specific knowledge on a topic; these members tend to be university students and/or professors. Another organization is made up of advocacy research units with individuals who have dedicated their time to one given topic. A third organization includes the individuals closely associated with a political party who conduct research that will provide expert advice and analysis for party members. The last knowledge-producing organization includes state research units who are situated within the government and are readily available for members within the government at any given time.

Capitalist countries began acknowledging the importance of knowledge regimes following the end of the Golden Age; this period was characterized by economic stagflation, eventually leading to inflation throughout the 1970s and 1980s. Economic bubbles and crises occur as a result of the processes that countries previously adapted, typically over the past 30 years, which are ingrained into the economy and hard to alter. The high rates of stagflation that occurred in the mid 1960s after the end of the Golden Age created the questions of what the adequate policies would be in order to pursue macroeconomic goals of long-term economic growth. This era contradicted the traditional Keynesian policy ideas, which led many advanced countries to turn to the use of theories, data, and ideologies as tools in the fight over different economic policies. This placed heavy emphasis on the creation and use of knowledge regimes.

The end of the Golden Age introduced the era of neoliberalism, characterized by a decrease in public spending, lower taxes, and less state intervention. Through neoliberalism and neoliberal ways of operation, many capitalist countries began globalizing at increased rates, which brought about new forms of economic organizations, such as global outsourcing and international commodity chains. Given this level of globalization, knowledge regimes were developed to create new policies and advise firms on appropriate production measures.

Varieties of capitalism is used to describe is used to describe the way a firm operates in two differentiating political capitalist economies, placing the emphasis on the state-firm relationship rather than the state-citizen relationship. The two political economies that nations will operate in are either liberal market economies (LMEs) or coordinated market economies (CMEs). There are five sectors that firms address when developing relationships with the state, including industrial relations, vocational training and education, corporate governance, inter-firm relations, and employees. Firms use the five sectors to design different policies that are best suited for their political economy.

Liberal market economies operate in capitalist nations that use a system of hierarchy and competitive markets to determine relationships between firms and the state. LMEs operate in highly commodified economies whereby there individuals are particularly dependent on the sale of their own labour as a reliable source of income. The commodification of labour is strongly affected by the price signals that are indicated by the markets, and these fluctuating price levels lead to either an increase or decrease in a firm's willingness to supply and a customer's willingness to consume. In liberal market economies, firms will use market mechanisms to solve any issues incurred, specifically through the exchange of money by buyers and sellers, who have a well-rounded understanding of the value of trade-offs so as to ensure the most efficient distribution of goods and services within an economy.

In a liberal market economy, firms require vocational education and training that is either individually funded or provided through on-the-job training to provide firm-specific education. These firms tend to focus their decisions on publicly accessible data of performance, allowing for greater venture capital and easily switchable assets that result in higher returns for investors. Due to the hierarchical nature of management, there are very few unions created in the work environment as labour is highly commodified and it is easy for a firm to hire and fire employees. The relationships between firms and employees operate on a contract basis. As a result of the individually funded vocational training, there is greater incentive to pursue individual success through innovation, which is generally funded by the larger venture capital opportunities.

LMEs can also operate alternatively, contingent on the type of market a state follows. If an economy has a more decentralized and open market, knowledge regimes will tend to be me more market-oriented with less external constraints from the government, as is the case with United States; if an economy is more centralized with a closed market, there is more state-led involvement and guidance, much like Great Britain.

The United States of America is a country with a liberal market economy, accentuated by decentralized government with a relatively open market. Through the open market, firms and investors are able to import and export different goods and services with very little interference from the government, allowing for the price levels of those goods and services to be set solely by the supply and demand in the economy.

The political economy in the United States is run primarily by two political parties, the Republican Party and the Democratic Party. Since the United States is a highly decentralized state, the two main parties operate using privately funded resources, resulting in a distinct separation of power at the legislative and executive branches of government. The United States demonstrates how a decentralized open market economy tends to have more market-oriented knowledge regimes. Through privately funded channels, individuals have a higher incentive to create knowledge regimes in attempt to influence the public policy making process.

Great Britain represents a group of countries (Wales, Scotland, England) that operate in an LME with a centralized, closed market. These countries follow a unitary system of government, whereby there is a single power dictating the operations of the country as a whole. The market system in Great Britain operates with greater state involvement and control, and the price levels of goods and services are more commonly dictated by government-imposed market tools, such as tariffs, taxes, and subsidies.

The central authority holds power in both the legislative branch and executive branch of government, allowing the central authority to impose new policies and decisions without opposition from other political parties. As a result, knowledge regimes are publicly funded and not as common as they are in LMEs with an open market. State research units are more prevalent throughout Great Britain and are embedded throughout the civil society, creating more politically tempered knowledge regimes.

Coordinated market economies (CME) are characterized by very little state involvement with firms focused on building close relationships between individuals in managerial positions and employees. Through the strong relationships created within the firm, there is a highly decommodified environment with a strong sense of social entitlement and separation from market dependency and state participation. When firms incur a problem of any sort, they use strategic interactions to create a feasible solution. These strategic interactions incorporate employees at every level of the firm so as to ensure opinions and viewpoints from all sectors are being taken into account; this typically allows for a stronger built solution. In addition, firms use strategic interaction to determine at which point the equilibrium should be set between the firm and their consumers, which establishes the appropriate combination between how much of a product is supplied and subsequently purchased.

In a coordinated market economy, there is publicly subsidized training to support high-skilled education for greater industry-specific labour needs; this is a result of the multilateral decisions that are made through strategic interactions. Additionally, there is greater confidence instilled in potential investors through the promotion of dense networks. Through the structure of the market, there are several unions and long-term worker contracts, which ensures job security and decreases the likelihood of hostile takeovers. Due to the interaction and cooperation throughout multiple firms, there is greater society-wide success through innovative tendencies, such as the green energy industry in Germany.

CMEs operate differently depending on if a state has a closed market or an open market. In a CME with a decentralized and open market, such as Germany, there tends to be strong associational institutional arrangements, producing more consensus-oriented knowledge regimes; a CME with a centralized and closed market, such as France, many policy changes are encouraged and led by state involvement.

Germany is a country with a coordinated market economy, characterized by a decentralized government with an open market system. Firms in this economy operate through well-established networks, while developing and maintaining relationships to promote and coordinate economic activity. There is very little state-involvement throughout the market, with the emphasis and responsibility being placed on the firms and corporations to set and adjust prices accordingly. Germany follows a proportional representation electoral system, creating a stronger consensus-based environment whereby policies are formulated at the regional level of government rather than the federal level.

Through regional-based policy formulation tactics, there is a higher rate of scholarly research units affiliated with several different universities, churches, and other knowledge-producing institutions. There is also a stronger incentive for political parties to create their own party research units to be used for future elections and policy-making tactics. The knowledge regimes created throughout Germany represent the institutional tendencies that firms rely on, such as the negotiation among different political parties, problem-solving mediation, and general consensus building.

France is a country with a coordinated market economy, distinguished by a central government and a closed market. In France, the central government is the main actor when making economic decisions and solving financial problems; the government holds sole ownership of several of the main infrastructure sectors throughout the country, weakening state-firm relationships. With a central government, the same political party holds control of both the legislative and executive branches, resulting in much of policy making taking place at the national level.

As a result of the highly centralized state, many of the knowledge regimes throughout France emerge from state-led research units, as individuals are given very few incentives or means to create or pursue their own research units. Other knowledge regimes emerge from scholarly research units that are funded through the central government.

Knowledge regimes are organized in different ways depending on the type of political economy they are operating in. There are 4 common knowledge producing organizations, which correspond to either liberal market economies or coordinated market economies. These knowledge producing organizations also differentiate if a country has either a centralized or decentralized government, or if there is an open or closed market.

Academic research units are made up of academia from many institutions. The most commonly found participants in these units are students and professors, however many firms with a coordinated market economy send their employees to these research units. These units are often publicly funded through the government, although they may be privately funded as well, and tend to be both politically and ideologically impartial. Academic research units are most common in liberal market economies with a decentralized government and open market. Prior to WWII, many of these research units were privately funded through philanthropic organizations, but following WWII, many governments began providing funding for academic research units by contracting out for policy research.

Advocacy research units are created by individuals who are independently motivated through their own values and morals. These research units are privately funded through organizations that directly correlate to the topic or issue being addressed through the unit. These research units are both politically and ideologically partisan in nature, and are more focused on discrediting research that has already been done by using the media to persuade politicians to alter certain policies. Advocacy research units are most common in political economies with decentralized states and open markets, as politicians are less likely to conform to political party standards and will seek advice through external resources.

Party research units are independently funded research units on behalf of a specific political party. These units are both politically and ideologically biased towards the values of a political party, composed of individuals who conduct research on behalf of the leaders. Political leaders will use the research from these units to pursue designated policy goals that will generate as much public approval and support as possible. These research units are most common in economies that operate through highly decentralized governments with several different political parties running for office during an election.

State-led research units are the only form of research unit that does not directly involve the participation of the civil society when conducting research. These units are closely affiliated with specific government departments and ministries that conduct research on a very specific matter that is then reported back to the central authority. These research units operate in economies with centralized and closed markets and are publicly funded through the central government.


</doc>
<doc id="9960212" url="https://en.wikipedia.org/wiki?curid=9960212" title="Knowledge Revolution">
Knowledge Revolution

The knowledge revolution refers to a global-scale paradigm shift that many compare to the agricultural and industrial revolutions. The revolution is about a fundamental socioeconomic change from adding value by producing things which is, ultimately limited, to adding value by creating and using knowledge which can grow indefinitely.

Overviews of the knowledge revolution were provided by Marilyn Ferguson, who refers to the ascendance of an irreversible shift in the global state of mind; a fundamentally new world view that encompasses insights from ancient times through current breakthrough science. Sakaiya indicates that three major disrupters of the established order – population shifts, resource supply, and technological developments are producing phenomena never before encountered in the industrial society. Brown states that the revolution will not flow from the mobilization of new machines; rather, it will require a fundamental revamp of the human context in which machines are used. Finally, Johnson observes that when such paradigm shifts occur only once every few centuries, one has to be a visionary to see beyond the limits of current forms.

From a perspective of understanding this global societal sea change, Savage states that the shift is one of attitudes, values, and norms. It will only come through a struggle of thought because many of the changes are counterintuitive from a traditional point of view and they are difficult to conceptualize with industrial era vocabulary. He also notes that it will not be a simple or cumulative process, in that new principles will have to be learned and some old principles will have to be unlearned. Brown (1999) indicates that creating new frameworks for the evolving world will require challenging the assumptions that support our traditional intellectual constructs.

In terms of what will shift, Gilder states that the basic tenet of the knowledge revolution will be the “overthrow of matter.” Wealth, in the form of physical assets will diminish, while wealth, in the form of knowledge assets will increase. The power of mind will usurp the brute force of things. Similarly, Jeremy Rifkin indicates that whereas the industrial age emphasized the exchange of goods and services, the coming age will emphasize the exchange of concepts.

From an organizational perspective, Amidon indicates that the knowledge movement is reshaping how organizations are created, evolve, mature, and evolve or die. It is reshaping how business is done, how economies develop, and how societies prosper. Ruggles and Holtshouse note that the movement is characterized by a dispersion of power and by managers who lead by empowering knowledge workers to contribute and make decisions.

From a societal perspective, John Seely Brown asks a number of key questions, including who will control the keys to the digital domain? Who will be the trusted intermediary in the marketplace? How transparent will their mediation be? What standards will be used for accountability? Thomas A. Stewart points out that just as the industrial revolution did not end agriculture because people have to eat, this revolution will not end industry because we still need physical products.

The digital revolution is revolutionizing the future agriculture. Thus, future agriculture, more importantly, the agricultural systems modelling could benefit from the advancements in ICT with big data, crowdsourcing, remote sensing, and high computational abilities, catching up with the relative slow developments over the last two decades. Tools to enable visualization of agricultural source data, model outputs and synthesized data products are needed to enhance the discovery and understanding of information for the entire spectrum of future agriculture users, including data collectors, model developers, model users, integrative research, application developers and end users. To make sense of large amounts of unfamiliar or complex data, humans need overviews, summaries, and the capability to look for patterns and discover emergent phenomena, empirical models, and theories related to the data.



</doc>
<doc id="39845988" url="https://en.wikipedia.org/wiki?curid=39845988" title="Knowledge society">
Knowledge society

A knowledge society generates, shares and makes available to all members of the society knowledge that may be used to improve the human condition. A knowledge society differs from an information society in that the former serves to transform information into resources that allow society to take effective action while the latter only creates and disseminates the raw data. The capacity to gather and analyze information has existed throughout human history. However, the idea of the present-day knowledge society is based on the vast increase in data creation and information dissemination that results from the innovation of information technologies. The UNESCO World Report addresses the definition, content and future of knowledge societies.

The growth of Information and communication technology (ICT) has significantly increased the world’s capacity for creation of raw data and the speed at which it is produced. The advent of the Internet delivered unheard-of quantities of information to people. The evolution of the internet from Web 1.0 to Web 2.0 offered individuals tools to connect with each other worldwide as well as become content users and producers. Innovation in digital technologies and mobile devices offers individuals a means to connect anywhere anytime where digital technologies are accessible. Tools of ICT have the potential to transform education, training, employment and access to life-sustaining resources for all members of society.
However, this capacity for individuals to produce and use data on a global scale does not necessarily result in knowledge creation. Contemporary media delivers seemingly endless amounts of information and yet, the information alone does not create knowledge. For knowledge creation to take place, reflection is required to create awareness, meaning and understanding. The improvement of human circumstances requires critical analysis of information to develop the knowledge that assists humankind. Absent reflection and critical thinking, information can actually become "non-knowledge", that which is false or inaccurate. The anticipated Semantic Web 3.0 and Ubiquitous Web 4.0 will move both information and knowledge creation forward in their capacities to use intelligence to digitally create meaning independent of user-driven ICT.

The social theory of a knowledge society explains how knowledge is fundamental to the politics, economics, and culture of modern society. Associated ideas include the knowledge economy created by economists and the learning society created by educators. Knowledge is a commodity to be traded for economic prosperity. In a knowledge society, individuals, communities, and organizations produce knowledge-intensive work. Peter Drucker viewed knowledge as a key economic resource and coined the term knowledge worker in 1969. Fast forward to the present day, and in this knowledge-intensive environment, knowledge begets knowledge, new competencies develop, and the result is innovation. 
A knowledge society promotes human rights and offers equal, inclusive, and universal access to all knowledge creation. The UNESCO World Report establishes four principles that are essential for development of an equitable knowledge society:

However, they acknowledge that the digital divide is an obstacle to achievement of genuine knowledge societies. Access to the internet is available to 39 percent of the world’s population. This statistic represents growth as well as a continued gap. Among the many challenges that contribute to a global digital divide are issues regarding economic resources, geography, age, gender, language, education, social and cultural background, employment and disabilities.

To reduce the span of the digital divide, leaders and policymakers worldwide must first develop and understanding of knowledge societies and second, create and deploy initiatives that will universally benefit all populations. The public expects politicians and public institutions to act rationally and rely on relevant knowledge for decision-making. Yet, in many cases, there are no definitive answers for some of the issues that impact humankind. Science is no longer viewed as the provider of unquestionable knowledge and sometimes raises more uncertainty in its search for knowledge. The very advancement of knowledge creates the existence of increased ignorance or non-knowledge. This means that public policy must learn to manage doubt, probability, risk and uncertainty while making the best decisions possible.

To confront the uncertainty that comes from an increase in both knowledge and the resulting lack of knowledge, members of a society disagree and make decisions using justification and observation of consequences. Public policy may operate with the intent to prevent the worst possible outcome versus find the perfect solution. Democratization of expert knowledge occurs when a knowledge society produces and relies on more experts. Expert knowledge is no longer exclusive to certain individuals, professional or organizations. If in a knowledge society, knowledge is a public good to which all people have access, any individual may also serve as a creator of knowledge and receive credit as an expert. Since politicians rely on expert knowledge for decision making, the layperson who may lack specialized knowledge might hold a view that serves as expertise to the political process.

As technologies are deployed to improve global information access, the role of education will continue to grow and change. Education is viewed as a basic human right. For a society where reading and counting are a requisite for daily living, skills in reading, writing, and basic arithmetic are critical for future learning. However, in a knowledge society, education is not restricted to school. The advent of ICT allows learners to seek information and develop knowledge at any time and any place where access is available and unrestricted. In these circumstances, the skill of learning to learn is one of the most important tools to help people acquire formal and informal education. In a knowledge society supported by ICT, the ability to locate, classify and sort information is essential. Equipped with this skill, the use of ICT becomes an active versus a passive endeavor and integral to literacy and lifelong learning.

One marker of a knowledge society is continuous innovation that demands lifelong learning, knowledge development, and knowledge sharing. The institution of education will need to become responsive to changing demands. Education professionals will need to learn along with everyone else, and as leaders of changing designs in learning, they will serve as a bridge between technology and teaching. The ability to individually reflect on personal learning requirements and seek knowledge in whatever method is appropriate characterizes lifelong learning. One model that supports this type of learning is the W. Edwards Deming Plan-do-check-act cycle that promotes continuous improvement. Educational professionals will need to prepare learners to be accountable for their own lifelong learning.



</doc>
<doc id="31938666" url="https://en.wikipedia.org/wiki?curid=31938666" title="Knowledge space (philosophy)">
Knowledge space (philosophy)

In philosophy and media studies, a knowledge space is described as an emerging anthropological space in which the knowledge of individuals becomes the primary focus for social structure, values, and beliefs. The concept is put forward and explored by philosopher and media critic Pierre Lévy in his 1997 book "Collective Intelligence".

Levy's notion of the "knowledge space" relies on his conception of anthropological spaces, which he defines as "a system of proximity (space) unique to the world of humanity (anthropological), and thus dependent on human technologies, significations, language, culture, conventions, representations, and emotions" (5). Building on the language of the philosophers Gilles Deleuze and Félix Guattari, he states that "anthropological spaces in themselves are neither infrastructures nor superstructures but planes of existence, frequencies, velocities, determined within the social spectrum" (147). Each space contains "worlds of signification" (149) by which humans come to understand and make sense of the world. Furthermore, although one space may dominate, many spaces can and do exist simultaneously.

Levy describes three existing anthropological spaces. They are:

The knowledge space is an emerging anthropological space which, while it has always existed (139), is only now coming into fruition as a guiding space of humanity. In this space, singularities (individuals) are recognized as singularities and knowledge becomes the guiding value for humanity. Since all human experience represents unique knowledge, within the knowledge space all individuals are valued for their unique knowledge regardless of race (earth space), nationality (territorial space), or economic status (commodity space). Within this space static identity gives way to the "quantum identities" as individuals become participates and the distinction between of "us" and "them" disappears (159). Instead, humanity forms "collective intelligences" in which knowledge is valued and freely traded. What is "real" becomes "that which implies the practical activity, intellectual and imaginary, of living subjects" (168). Life, experiences, and knowledge become the underlying and ever changing guiding path for human societies.

Levy's theories rely heavily on the technological developments of the 1990s, particularly the rise of biotechnology, nanotechnology, the Internet, new media and information technologies. In chapter 3, he describes how technologies have made a shift from the molar to the molecular (a move which makes literal a distinction by Delueze and Guattari) in that technologies now handle units as individuals (his term is "singularities") rather than in mass. He suggests that this mirrors our rising recognition of the individuals as singularities rather than massive conglomerated groups.


</doc>
<doc id="37374009" url="https://en.wikipedia.org/wiki?curid=37374009" title="Knowledge translation">
Knowledge translation

Knowledge translation (KT) is the umbrella term for all of the activities involved in moving research from the laboratory, the research journal, and the academic conference into the hands of people and organizations who can put it to practical use. The term is most often used relative to the health professions, including medicine, nursing, pharmaceuticals, rehabilitation, physical therapy, and public health.

Depending on the type of research being translated, the "practical user" might be a medical doctor, a nurse, a teacher, a school administrator, an occupational or physical therapist, a legislator, an epidemiologist, a community health worker, or a parent.

KT is not an action, but a spectrum of activities which will change according to the type of research, the time frame, and the audience being targeted.

The most widely used definition of knowledge translation was published in 2000 by the Canadian Institutes of Health Research (CIHR): "Knowledge translation (KT) is defined as a dynamic and iterative process that includes synthesis, dissemination, exchange and ethically-sound application of knowledge to improve the health of Canadians, provide more effective health services and products and strengthen the health care system."

Using the CIHR definition as a basis, the National Center for the Dissemination of Disability Research (NCDDR) published this definition of KT in 2005: "The collaborative and systematic review, assessment, identification, aggregation, and practical application of high-quality disability and rehabilitation research by key stakeholders (i.e., consumers, researchers, practitioners, and policymakers) for the purpose of improving the lives of individuals with disabilities."

In 2006, Graham, et al., acknowledged the proliferation of related terms for the activity of knowledge translation, documenting 29 different terms used by 33 different health research funding agencies in their publications, including knowledge transfer, knowledge mobilization, knowledge exchange, implementation, and translational research.

In 2007, NCDDR re-published an overview written by Pimjai Sudsawad, then with the University of Wisconsin-Madison, now with the U.S. Department of Education, entitled: "Knowledge Translation: Introduction to Models, Strategies, and Measures". The overview correlates a variety of KT models which have been in development since at least 1976, including the Stetler Model of Research Utilization, the Coordinated Implementation Model, the Promoting Action on Research Implementation in Health Services (PARIHS) framework, the Ottawa Model of Research Utilization (OMRU), and the Knowledge to Action (KTA) process framework.

The activity of knowledge translation is observable as far back as agricultural extension services established by the Smith-Lever Act of 1914. The Smith-Lever Act formalized the relationship between United States land-grant universities and the United States Department of Agriculture (USDA) for the performance of agricultural extension. Agricultural extension agents based at the land-grant universities disseminated information to farmers and ranchers on seed development, land management and animal husbandry.

In their Technical Brief #10 2005, NCDDR points out: "KT is a relatively new term that is used to describe a relatively old problem - the underutilization of evidence-based research in systems of care. Underutilization of evidence-based research is often described as a gap between 'what is known' and 'what is currently done' in practice settings."

While evaluations of research utilization in the health fields have been going on since at least the mid-1960s, institutional interest in this long-standing issue has accelerated in the last 25 years. In 1989, the U.S. Department of Health and Human Services established the Agency for Healthcare Research and Quality. In 1997, the Canadian government endowed the Canadian Health Services Research Foundation (CHSRF) - now called the Canadian Foundation for Healthcare Improvement, or CFHI. In 2000, the Canadian government consolidated several existing agencies into the Canadian Institutes for Health Research. In 2006, the U.S. National Institutes of Health created the Clinical and Translational Science Awards, currently funding about 60 academic medical institutions across the country. The role of health research funders is increasingly playing a role in how evidence is being moved to practice, reducing the time between research and implementation.

More recently, the challenges of filtering information for knowledge translation is being increasingly addressed with Moloney, Taylor & Ralph proposing a "spillway model" to better control information flow and improve the implementation of research in healthcare. Other recent studies look at the role of design artefacts such as sketches, visual representations and prototypes to support knowledge translation in research and development projects.




</doc>
<doc id="5946039" url="https://en.wikipedia.org/wiki?curid=5946039" title="Knowledge triangle">
Knowledge triangle

The knowledge triangle refers to the interaction between research, education and innovation, which are key drivers of a knowledge-based society. In the European Union, it also refers to an attempt to better link together these key concepts, with research and innovation already highlighted by the development of the Lisbon Strategy and, more recently, lies behind the creation of the European Institute of Technology (EIT).



</doc>
<doc id="10307426" url="https://en.wikipedia.org/wiki?curid=10307426" title="Knowledge value">
Knowledge value

The idea that knowledge has value is ancient. In the 1st century AD, Juvenal (55-130) stated “All wish to know but none wish to pay the price". In 1775, Samuel Johnson wrote: “All knowledge is of itself of some value.”

In the 19th century, Coleridge (1825) stated that : “The worth and value of knowledge is in proportion to the worth and value of its object.” Auerbach (1865) asked: “What is all our knowledge worth?" although he proposed no answer. Largely the same ideas are already expressed in the term "intellectual capital" or the more ancient "knowledge is power" - given that power is a value in its own right.

Only towards of the end of the 20th century, however, was the value of knowledge in a business context generally recognized. The idea has since become something of a management fad, although many authors indicate that the underlying principles will become standard business practice. It is now understood that knowledge about how to produce products and provide services as well as their embedded knowledge is often more valuable than the products and services themselves or the materials they contain. Although measuring the value of knowledge remains elusive, describing its flow through value chains is a step in the right direction.

Firestone was the first to relate knowledge to business when he noted that “Thought, not money is the real business capital.” Alvin Toffler (1990) proposed that knowledge is a wealth and force multiplier, in that it augments what is available or reduces the amount needed to achieve a given purpose.

In comparing knowledge and product value, Amidon (1997) observes that knowledge about how to produce products may be more valuable than the products themselves. Leonard similarly points out that products are physical manifestations of knowledge and that their worth depends largely on the value of the embedded knowledge.

Davis (1999) further notes that the computer chips in a high-end automobile are worth more than the steel, plastics, glass, or rubber. However, Davis and Botin (1994) indicate that awareness of the value of knowledge exceeds the ability of many businesses to extract it from the goods and services in which it is embedded.

Measuring the value of knowledge has not progressed much beyond an awareness that traditional accounting practices are misleading and can lead to wrong business decisions (Martin, 1996). Amidon (1997) points out that the shift from tangible to intangible assets will revolutionize the way that enterprises are measured and that there is an entirely new way to value economic wealth.

Simard et al. (2007) developed a content value chain describing the flow of content through a sequence of stages in which its form is changed and its value or utility to users are notably increased at each stage: objects, data, information, knowledge, and wisdom. They also developed a knowledge services value chain, which describes the flow of knowledge services through a sequence of stages, in which value is embedded, advanced, or extracted.

The stages are: generate, transform, manage, use internally, transfer, add value, use professionally, use personally, and evaluate.




</doc>
<doc id="243391" url="https://en.wikipedia.org/wiki?curid=243391" title="Knowledge">
Knowledge

Knowledge is a familiarity, awareness, or understanding of someone or something, such as facts, information, descriptions, or skills, which is acquired through experience or education by perceiving, discovering, or learning.

Knowledge can refer to a theoretical or practical understanding of a subject. It can be implicit (as with practical skill or expertise) or explicit (as with the theoretical understanding of a subject); it can be more or less formal or systematic. In philosophy, the study of knowledge is called epistemology; the philosopher Plato famously defined knowledge as "justified true belief", though this definition is now thought by some analytic philosophers to be problematic because of the Gettier problems, while others defend the platonic definition. However, several definitions of knowledge and theories to explain it exist.

Knowledge acquisition involves complex cognitive processes: perception, communication, and reasoning; while knowledge is also said to be related to the capacity of "acknowledgement" in human beings.

The definition of knowledge is a matter of ongoing debate among philosophers in the field of epistemology. The classical definition, described but not ultimately endorsed by Plato, specifies that a statement must meet three criteria in order to be considered knowledge: it must be justified, true, and believed. Some claim that these conditions are not sufficient, as Gettier case examples allegedly demonstrate. There are a number of alternatives proposed, including Robert Nozick's arguments for a requirement that knowledge 'tracks the truth' and Simon Blackburn's additional requirement that we do not want to say that those who meet any of these conditions 'through a defect, flaw, or failure' have knowledge. Richard Kirkham suggests that our definition of knowledge requires that the evidence for the belief necessitates its truth.

In contrast to this approach, Ludwig Wittgenstein observed, following Moore's paradox, that one can say "He believes it, but it isn't so," but not "He knows it, but it isn't so." He goes on to argue that these do not correspond to distinct mental states, but rather to distinct ways of talking about conviction. What is different here is not the mental state of the speaker, but the activity in which they are engaged. For example, on this account, to "know" that the kettle is boiling is not to be in a particular state of mind, but to perform a particular task with the statement that the kettle is boiling. Wittgenstein sought to bypass the difficulty of definition by looking to the way "knowledge" is used in natural languages. He saw knowledge as a case of a family resemblance. Following this idea, "knowledge" has been reconstructed as a cluster concept that points out relevant features but that is not adequately captured by any definition.

Symbolic representations can be used to indicate meaning and can be thought of as a dynamic process. Hence the transfer of the symbolic representation can be viewed as one ascription process whereby knowledge can be transferred. Other forms of communication include observation and imitation, verbal exchange, and audio and video recordings. Philosophers of language and semioticians construct and analyze theories of knowledge transfer or communication.

While many would agree that one of the most universal and significant tools for the transfer of knowledge is writing and reading (of many kinds), argument over the usefulness of the written word exists nonetheless, with some scholars skeptical of its impact on societies. In his collection of essays "", Neil Postman demonstrates the argument against the use of writing through an excerpt from Plato's work "Phaedrus" (Postman, Neil (1992) "Technopoly", Vintage, New York, p. 73). In this excerpt, the scholar Socrates recounts the story of Thamus, the Egyptian king and Theuth the inventor of the written word. In this story, Theuth presents his new invention "writing" to King Thamus, telling Thamus that his new invention "will improve both the wisdom and memory of the Egyptians" (Postman, Neil (1992) Technopoly, Vintage, New York, p. 74). King Thamus is skeptical of this new invention and rejects it as a tool of recollection rather than retained knowledge. He argues that the written word will infect the Egyptian people with fake knowledge as they will be able to attain facts and stories from an external source and will no longer be forced to mentally retain large quantities of knowledge themselves (Postman, Neil (1992) "Technopoly", Vintage, New York, p. 74).

Classical early modern theories of knowledge, especially those advancing the influential empiricism of the philosopher John Locke, were based implicitly or explicitly on a model of the mind which likened ideas to words. This analogy between language and thought laid the foundation for a graphic conception of knowledge in which the mind was treated as a table, a container of content, that had to be stocked with facts reduced to letters, numbers or symbols. This created a situation in which the spatial alignment of words on the page carried great cognitive weight, so much so that educators paid very close attention to the visual structure of information on the page and in notebooks.

Major libraries today can have millions of books of knowledge (in addition to works of fiction). It is only recently that audio and video technology for recording knowledge have become available and the use of these still requires replay equipment and electricity. Verbal teaching and handing down of knowledge is limited to those who would have contact with the transmitter or someone who could interpret written work. Writing is still the most available and most universal of all forms of recording and transmitting knowledge. It stands unchallenged as mankind's primary technology of knowledge transfer down through the ages and to all cultures and languages of the world.

Situated knowledge is knowledge specific to a particular situation. It was used by Donna Haraway as an extension of the feminist approaches of "successor science" suggested by Sandra Harding, one which "offers a more adequate, richer, better account of a world, in order to live in it well and in critical, reflexive relation to our own as well as others' practices of domination and the unequal parts of privilege and oppression that makes up all positions." This situation partially transforms science into a narrative, which Arturo Escobar explains as, "neither fictions nor supposed facts." This narrative of situation is historical textures woven of fact and fiction, and as Escobar explains further, "even the most neutral scientific domains are narratives in this sense," insisting that rather than a purpose dismissing science as a trivial matter of contingency, "it is to treat (this narrative) in the most serious way, without succumbing to its mystification as 'the truth' or to the ironic skepticism common to many critiques."

Haraway's argument stems from the limitations of the human perception, as well as the overemphasis of the sense of vision in science. According to Haraway, vision in science has been, "used to signify a leap out of the marked body and into a conquering gaze from nowhere." This is the "gaze that mythically inscribes all the marked bodies, that makes the unmarked category claim the power to see and not be seen, to represent while escaping representation." This causes a limitation of views in the position of science itself as a potential player in the creation of knowledge, resulting in a position of "modest witness". This is what Haraway terms a "god trick", or the aforementioned representation while escaping representation. In order to avoid this, "Haraway perpetuates a tradition of thought which emphasizes the importance of the subject in terms of both ethical and political accountability".

Some methods of generating knowledge, such as trial and error, or learning from experience, tend to create highly situational knowledge.
Situational knowledge is often embedded in language, culture, or traditions. This integration of situational knowledge is an allusion to the community, and its attempts at collecting subjective perspectives into an embodiment "of views from somewhere." 

Even though Haraway's arguments are largely based on feminist studies, this idea of different worlds, as well as the skeptic stance of situated knowledge is present in the main arguments of post-structuralism. Fundamentally, both argue the contingency of knowledge on the presence of history; power, and geography, as well as the rejection of universal rules or laws or elementary structures; and the idea of power as an inherited trait of objectification.

One discipline of epistemology focuses on partial knowledge. In most cases, it is not possible to understand an information domain exhaustively; our knowledge is always "incomplete" or partial. Most real problems have to be solved by taking advantage of a partial understanding of the problem context and problem data, unlike the typical math problems one might solve at school, where all data is given and one is given a complete understanding of formulas necessary to solve them.

This idea is also present in the concept of bounded rationality which assumes that in real life situations people often have a limited amount of information and make decisions accordingly.

Intuition is the ability to acquire partial knowledge without inference or the use of reason. An individual may "know" about a situation and be unable to explain the process that led to their knowledge.

The development of the scientific method has made a significant contribution to how knowledge of the physical world and its phenomena is acquired. To be termed scientific, a method of inquiry must be based on gathering observable and measurable evidence subject to specific principles of reasoning and experimentation. The scientific method consists of the collection of data through observation and experimentation, and the formulation and testing of hypotheses. Science, and the nature of scientific knowledge have also become the subject of Philosophy. As science itself has developed, scientific knowledge now includes a broader usage in the soft sciences such as biology and the social sciences – discussed elsewhere as meta-epistemology, or genetic epistemology, and to some extent related to "theory of cognitive development". Note that "epistemology" is the study of knowledge and how it is acquired. Science is "the process used everyday to logically complete thoughts through inference of facts determined by calculated experiments." Sir Francis Bacon was critical in the historical development of the scientific method; his works established and popularized an inductive methodology for scientific inquiry. His famous aphorism, "knowledge is power", is found in the Meditations Sacrae (1597).

Until recent times, at least in the Western tradition, it was simply taken for granted that knowledge was something possessed only by humans – and probably "adult" humans at that. Sometimes the notion might stretch to "Society-as-such", as in (e. g.) "the knowledge possessed by the Coptic culture" (as opposed to its individual members), but that was not assured either. Nor was it usual to consider "unconscious" knowledge in any systematic way until this approach was popularized by Freud.

Other biological domains where "knowledge" might be said to reside, include: (iii) the "immune system", and (iv) in the "DNA of the genetic code". See the list of four "epistemological domains": Popper, (1975); and Traill (2008: Table S, p. 31) – also references by both to Niels Jerne.

Such considerations seem to call for a separate definition of "knowledge" to cover the biological systems. For biologists, knowledge must be usefully "available" to the system, though that system need not be conscious. Thus the criteria seem to be:

Scientific knowledge may not involve a claim to certainty, maintaining skepticism means that a scientist will never be absolutely certain when they are correct and when they are not. It is thus an irony of proper scientific method that one must doubt even when correct, in the hopes that this practice will lead to greater convergence on the truth in general.

In many expressions of Christianity, such as Catholicism and Anglicanism, knowledge is one of the seven gifts of the Holy Spirit.

The Old Testament's tree of the knowledge of good and evil contained the knowledge that separated Man from God: "And the LORD God said, Behold, the man is become as one of us, to know good and evil..." ()

In Gnosticism, divine knowledge or gnosis is hoped to be attained.

विद्या दान (Vidya Daan) i.e. knowledge sharing is a major part of Daan, a tenet of all Dharmic Religions.
Hindu Scriptures present two kinds of knowledge, "Paroksh Gyan" and "Prataksh Gyan". "Paroksh Gyan" (also spelled "Paroksha-Jnana") is secondhand knowledge: knowledge obtained from books, hearsay, etc. "Pratyaksh Gyan" (also spelled "Pratyaksha-Jnana") is the knowledge borne of direct experience, i.e., knowledge that one discovers for oneself. Jnana yoga ("path of knowledge") is one of three main types of yoga expounded by Krishna in the Bhagavad Gita. (It is compared and contrasted with Bhakti Yoga and Karma yoga.)

In Islam, knowledge (Arabic: علم, "ʿilm") is given great significance. "The Knowing" ("al-ʿAlīm") is one of the 99 names reflecting distinct attributes of God. The Qur'an asserts that knowledge comes from God () and various "hadith" encourage the acquisition of knowledge. Muhammad is reported to have said "Seek knowledge from the cradle to the grave" and "Verily the men of knowledge are the inheritors of the prophets". Islamic scholars, theologians and jurists are often given the title "alim", meaning "knowledgeble". 

In Jewish tradition, knowledge (Hebrew: דעת "da'ath") is considered one of the most valuable traits a person can acquire. Observant Jews recite three times a day in the Amidah "Favor us with knowledge, understanding and discretion that come from you. Exalted are you, Existent-One, the gracious giver of knowledge." The Tanakh states, "A wise man gains power, and a man of knowledge maintains power", and "knowledge is chosen above gold".

According to the sociologist Mervin F. Verbit, knowledge may be understood as one of the key components of religiosity. Religious knowledge itself may be broken down into four dimensions:
The content of one's religious knowledge may vary from person to person, as will the degree to which it may occupy the person's mind (frequency), the intensity of the knowledge, and the centrality of the information (in that religious tradition, or to that individual).




</doc>
<doc id="9005414" url="https://en.wikipedia.org/wiki?curid=9005414" title="Sensemaking">
Sensemaking

Sensemaking or sense-making is the process by which people give meaning to their collective experiences. It has been defined as "the ongoing retrospective development of plausible images that rationalize what people are doing" (Weick, Sutcliffe, & Obstfeld, 2005, p. 409). The concept was introduced to organizational studies by Karl E. Weick in the 1970s and has affected both theory and practice. Weick intended to encourage a shift away from the traditional focus of organization theorists on decision-making and towards the processes that constitute the meaning of the decisions that are enacted in behavior.

In 1966, Daniel Katz and Robert L. Kahn published "The Social Psychology of Organizations" (Katz & Kahn, 1966). In 1969, Karl Weick played on this title in his book "The Social Psychology of Organizing", shifting the focus from organizations as entities to organiz"ing" as an activity. It was especially the second edition, published ten years later (Weick, 1979) that established Weick's approach in organization studies.

Weick identified seven properties of sensemaking (Weick, 1995):


Each of these seven aspects interact and intertwine as individuals interpret events. Their interpretations become evident through narratives – written and spoken – which convey the sense they have made of events (Currie & Brown, 2003), as well as through diagrammatic reasoning and associated material practices (Huff, 1990; Stigliani & Ravasi, 2012).

The rise of the sensemaking perspective marks a shift of focus in organization studies from how decisions shape organizations to how meaning drives organizing (Weick, 1993). The aim was to focus attention on the largely cognitive activity of framing experienced situations as meaningful. It is a collaborative process of creating shared awareness and understanding out of different individuals' perspectives and varied interests.

Sensemaking scholars are less interested in the intricacies of planning than in the details of action (Weick, 1995, p. 55).

The sensemaking approach is often used to provide insight into factors that surface as organizations address either uncertain or ambiguous situations (Weick 1988, 1993; Weick et al., 2005). Beginning in the 1980s with an influential re-analysis of the Bhopal disaster, Weick's name has come to be associated with the study of the situated sensemaking that influences the outcomes of disasters (Weick 1993).

A 2014 review of the literature on sensemaking in organizations identified a dozen different categories of sensemaking and a half-dozen sensemaking related concepts (Maitlis & Christianson, 2014). The categories of sensemaking included: constituent-minded, cultural, ecological, environmental, future-oriented, intercultural, interpersonal, market, political, prosocial, prospective, and resourceful. The sensemaking-related concepts included: sensebreaking, sensedemanding, sense-exchanging, sensegiving, sensehiding, and sense specification.

Sensemaking is central to the conceptual framework for military network-centric operations (NCO) espoused by the United States Department of Defense (Garstka and Alberts, 2004). In a joint/coalition military environment, sensemaking is complicated by numerous technical, social, organizational, cultural, and operational factors. A central hypothesis of NCO is that the quality of shared sensemaking and collaboration will be better in a "robustly networked" force than in a platform-centric force, empowering people to make better decisions. According to NCO theory, there is a mutually-reinforcing relationship among and between individual sensemaking, shared sensemaking, and collaboration.

In defense applications, sensemaking theorists have primarily focused on how shared awareness and understanding are developed within command and control organizations at the operational level. At the tactical level, individuals monitor and assess their immediate physical environment in order to predict where different elements will be in the next moment. At the operational level, where the situation is far broader, more complex and more uncertain, and evolves over hours and days, the organization must collectively make sense of enemy dispositions, intentions and capabilities, as well as anticipate the (often unintended) effects of own-force actions on a complex system of systems.

Sensemaking has been studied in the patient safety literature (Battles, et al. 2006). It has been used as a conceptual framework for identifying and detecting high risk patient situations. For example, Rhodes, et al. (2015) examined sensemaking and the co-production of safety of primary medical care patients.



</doc>
<doc id="1958462" url="https://en.wikipedia.org/wiki?curid=1958462" title="Subject-matter expert">
Subject-matter expert

A subject-matter expert (SME) or domain expert is a person who is an authority in a particular area or topic. The term "domain expert" is frequently used in expert systems software development, and there the term always refers to the domain other than the software domain. A domain expert is a person with special knowledge or skills in a particular area of endeavour (e.g. an accountant is an expert in the domain of accountancy). The development of accounting software requires knowledge in two different domains: accounting and software. Some of the development workers may be experts in one domain and not the other.

In general, the term is used when developing materials (a book, an examination, a manual, etc.) about a topic, and expertise on the topic is needed by the personnel developing the material. For example, tests are often created by a team of psychometricians and a team of SMEs. The psychometricians understand how to engineer a test while the SMEs understand the actual content of the exam. Books, manuals, and technical documentation are developed by technical writers and instructional designers in conjunctions with SMEs. Technical communicators interview SMEs to extract information and convert it into a form suitable for the audience. SMEs are often required to sign off on the documents or training developed, checking it for technical accuracy. SMEs are also necessary for the development of training materials.

In software engineering environments, the term is used to describe professionals with expertise in the field of application. The term "SME" also has a broader definition in engineering and high tech as one who has the greatest expertise in a technical topic. SMEs are often asked to review, improve, and approve technical work; to guide others; and to teach. According to Six Sigma an SME "exhibits the highest level of expertise in performing a specialized job, task, or skill of broad definition."

In pharmaceuticals and biotechnology areas, ASTM standard E 2500 specifies SMEs for various functions in project and process management. SME is defined as an individual who is an expert on that subject. In one project, there will be many SMEs who are experts on air, water, utilities, process machines, process, packaging, storage, distribution and supply chain management, to name a few.

In software development, as in the development of "complex computer systems" (e.g., artificial intelligence, expert systems, control, simulation, or business software) an SME is a person who is knowledgeable about the domain being represented (but often not knowledgeable about the programming technology used to represent it in the system). The SME tells the software developers what needs to be done by the computer system, and how the SME intends to use it. The SME may interact directly with the system, possibly through a simplified interface, or may codify domain knowledge for use by knowledge engineers or ontologists. An SME is also involved in validating the resulting system. SME has formal meaning in certain contexts such as CMMs.

In electronic discovery environments, the term "SME" labels professionals with expertise using Computer Assisted Review technology (CAR)/Technology Assisted Review (TAR) to perform searches designed to produce precisely refined results that identify groups of data as potentially responsive or non-responsive to relevant issues. E-discovery SMEs also typically have experience in constructing the search strings used in the search process.

A lawyer in an administrative agency may be designated an SME if he or she specializes in a particular field of law, such as tort, intellectual property rights etc.

In engineering and technical field, an SME is the one who is an authority in the design concept, calculations and performance of a system or process.




</doc>
<doc id="57147939" url="https://en.wikipedia.org/wiki?curid=57147939" title="Non-science">
Non-science

A non-science is an area of study that is not scientific, especially one that is not a natural science or a social science that is an object of scientific inquiry. In this model, history, art, and religion are all examples of non-sciences.

Since the 17th century, some writers have used the word "science" to exclude some areas of studies, such as the arts and the liberal arts. The word "nonscience", to describe non-scientific academic disciplines, was first used in the middle of the 19th century.

In some cases, it can be difficult to identify exact boundaries between science and non-science. The demarcation problem is the study of the difficulties in determining whether certain fields of study, near the boundaries of science and non-science, should be considered as one or the other. No single test has yet been devised that can clearly separate science from non-science, but some factors, taken as a whole and evaluated over time, are commonly used. In the view of Thomas Kuhn, these factors include the desire of scientists to investigate a question as if it were a puzzle. Kuhn's view of science is also focused on the process of scientific inquiry, rather than the result.

Boundary-work is the process of advocating for a desired outcome in the process of classifying fields of study that are near the borders. The rewards associated with winning a particular classification suggest that the boundary between science and non-science is socially constructed and ideologically motivated rather than representing a stark natural difference between science and non-science. The belief that scientific knowledge (e.g., biology) is more valuable than other forms of knowledge (e.g., ethics) is called "scientism".

Non-science includes all areas of study that are not science. Non-science encompasses all of the humanities, including:


The philosopher Martin Mahner proposed calling these academic fields the "parasciences", to distinguish them from disreputable forms of non-science, such as pseudoscience.

Non-sciences offer information about the meaning of life, human values, the human condition, and ways of interacting with other people, including studies of cultures, morality and ethics.

Philosophers disagree about whether areas of study involving abstract concepts, such as pure mathematics, are scientific or non-scientific.

Interdisciplinary studies may cover knowledge-generating work that includes both scientific and non-scientific studies. Archaeology is an example of a field that borrows from both the natural sciences and history.

Fields of inquiry may change status over time. For many centuries, alchemy was accepted as scientific: it produced some useful information, and it supported experiments and open inquiry in the pursuit of understanding the physical world. Since the 20th century, it has been considered a pseudoscience. Modern chemistry, which developed out of alchemy, is considered a major natural science.

Some philosophers, such as Paul Feyerabend, object to the effort to classify knowledge into science and non-science. The distinction is artificial, as there is little or nothing that ties together all of the bodies of knowledge that are called "sciences".

Some systems of organizing knowledge separate systematic knowledge from non-systematic methods of knowing or learning something, such as personal experiences, intuition, and innate knowledge. Wissenschaft is a broad concept that encompasses reliable knowledge without making a distinction between subject area. The "Wissenschaft" concept is more useful than the distinction between science and non-science in distinguishing between knowledge and pseudo-knowledge, as the errors made in all forms of pseudo-scholarship, from pseudohistory to pseudoscience, are similar. This "Wissenschaft" concept is used in the 2006 list of Fields of Science and Technology published by the Organisation for Economic Co-operation and Development, which defines "science and technology" as encompassing all humanistic disciplines, including religion and fine art.




</doc>
<doc id="26700" url="https://en.wikipedia.org/wiki?curid=26700" title="Science">
Science

Science (from the Latin word "scientia", meaning "knowledge") is a systematic enterprise that builds and organizes knowledge in the form of testable explanations and predictions about the universe.

The earliest roots of science can be traced to Ancient Egypt and Mesopotamia in around 3500 to 3000 BCE. Their contributions to mathematics, astronomy, and medicine entered and shaped Greek natural philosophy of classical antiquity, whereby formal attempts were made to provide explanations of events in the physical world based on natural causes. After the fall of the Western Roman Empire, knowledge of Greek conceptions of the world deteriorated in Western Europe during the early centuries (400 to 1000 CE) of the Middle Ages but was preserved in the Muslim world during the Islamic Golden Age. The recovery and assimilation of Greek works and Islamic inquiries into Western Europe from the 10th to 13th century revived "natural philosophy", which was later transformed by the Scientific Revolution that began in the 16th century as new ideas and discoveries departed from previous Greek conceptions and traditions. The scientific method soon played a greater role in knowledge creation and it was not until the 19th century that many of the institutional and professional features of science began to take shape; along with the changing from "natural philosophy" to the "natural sciences".

Modern science is typically divided into three major branches that consist of the natural sciences (e.g., biology, chemistry, and physics), which study nature in the broadest sense; the social sciences (e.g., economics, psychology, and sociology), which study individuals and societies; and the formal sciences (e.g., logic, mathematics, and theoretical computer science), which study abstract concepts. There is disagreement, however, on whether the formal sciences actually constitute a science as they do not rely on empirical evidence. Disciplines that use existing scientific knowledge for practical purposes, such as engineering and medicine, are described as applied sciences.

Science is based on research, which is commonly conducted in academic and research institutions as well as in government agencies and companies. The practical impact of scientific research has led to the emergence of science policies that seek to influence the scientific enterprise by prioritizing the development of commercial products, armaments, health care, and environmental protection.

Science in a broad sense existed before the modern era and in many historical civilizations. Modern science is distinct in its approach and successful in its results, so it now defines what science is in the strictest sense of the term. Science in its original sense was a word for a type of knowledge, rather than a specialized word for the pursuit of such knowledge. In particular, it was the type of knowledge which people can communicate to each other and share. For example, knowledge about the working of natural things was gathered long before recorded history and led to the development of complex abstract thought. This is shown by the construction of complex calendars, techniques for making poisonous plants edible, public works at national scale, such as those which harnessed the floodplain of the Yangtse with reservoirs, dams, and dikes, and buildings such as the Pyramids. However, no consistent conscious distinction was made between knowledge of such things, which are true in every community, and other types of communal knowledge, such as mythologies and legal systems. Metallurgy was known in prehistory, and the Vinča culture was the earliest known producer of bronze-like alloys. It is thought that early experimentation with heating and mixing of substances over time developed into alchemy.

Neither the words nor the concepts "science" and "nature" were part of the conceptual landscape in the ancient near east. The ancient Mesopotamians used knowledge about the properties of various natural chemicals for manufacturing pottery, faience, glass, soap, metals, lime plaster, and waterproofing; they also studied animal physiology, anatomy, and behavior for divinatory purposes and made extensive records of the movements of astronomical objects for their study of astrology. The Mesopotamians had intense interest in medicine and the earliest medical prescriptions appear in Sumerian during the Third Dynasty of Ur ( 2112 BCE – 2004 BCE). Nonetheless, the Mesopotamians seem to have had little interest in gathering information about the natural world for the mere sake of gathering information and mainly only studied scientific subjects which had obvious practical applications or immediate relevance to their religious system.

In classical antiquity, there is no real ancient analog of a modern scientist. Instead, well-educated, usually upper-class, and almost universally male individuals performed various investigations into nature whenever they could afford the time. Before the invention or discovery of the concept of "nature" (ancient Greek "phusis") by the Pre-Socratic philosophers, the same words tend to be used to describe the "natural" "way" in which a plant grows, and the "way" in which, for example, one tribe worships a particular god. For this reason, it is claimed these men were the first philosophers in the strict sense, and also the first people to clearly distinguish "nature" and "convention." Natural philosophy, the precursor of natural science, was thereby distinguished as the knowledge of nature and things which are true for every community, and the name of the specialized pursuit of such knowledge was "philosophy" – the realm of the first philosopher-physicists. They were mainly speculators or theorists, particularly interested in astronomy. In contrast, trying to use knowledge of nature to imitate nature (artifice or technology, Greek "technē") was seen by classical scientists as a more appropriate interest for artisans of lower social class.

The early Greek philosophers of the Milesian school, which was founded by Thales of Miletus and later continued by his successors Anaximander and Anaximenes, were the first to attempt to explain natural phenomena without relying on the supernatural. The Pythagoreans developed a complex number philosophy and contributed significantly to the development of mathematical science. The theory of atoms was developed by the Greek philosopher Leucippus and his student Democritus. The Greek doctor Hippocrates established the tradition of systematic medical science and is known as "The Father of Medicine".

A turning point in the history of early philosophical science was Socrates' example of applying philosophy to the study of human matters, including human nature, the nature of political communities, and human knowledge itself. The Socratic method as documented by Plato's dialogues is a dialectic method of hypothesis elimination: better hypotheses are found by steadily identifying and eliminating those that lead to contradictions. This was a reaction to the Sophist emphasis on rhetoric. The Socratic method searches for general, commonly held truths that shape beliefs and scrutinizes them to determine their consistency with other beliefs. Socrates criticized the older type of study of physics as too purely speculative and lacking in self-criticism. Socrates was later, in the words of his "Apology", accused of corrupting the youth of Athens because he did "not believe in the gods the state believes in, but in other new spiritual beings". Socrates refuted these claims, but was sentenced to death.

Aristotle later created a systematic programme of teleological philosophy: Motion and change is described as the actualization of potentials already in things, according to what types of things they are. In his physics, the Sun goes around the Earth, and many things have it as part of their nature that they are for humans. Each thing has a formal cause, a final cause, and a role in a cosmic order with an unmoved mover. The Socratics also insisted that philosophy should be used to consider the practical question of the best way to live for a human being (a study Aristotle divided into ethics and political philosophy). Aristotle maintained that man knows a thing scientifically "when he possesses a conviction arrived at in a certain way, and when the first principles on which that conviction rests are known to him with certainty".

The Greek astronomer Aristarchus of Samos (310–230 BCE) was the first to propose a heliocentric model of the universe, with the Sun at the center and all the planets orbiting it. Aristarchus's model was widely rejected because it was believed to violate the laws of physics. The inventor and mathematician Archimedes of Syracuse made major contributions to the beginnings of calculus and has sometimes been credited as its inventor, although his proto-calculus lacked several defining features. Pliny the Elder was a Roman writer and polymath, who wrote the seminal encyclopedia "Natural History", dealing with history, geography, medicine, astronomy, earth science, botany, and zoology.
Other scientists or proto-scientists in Antiquity were Theophrastus, Euclid, Herophilos, Hipparchus, Ptolemy, and Galen.

Because of the collapse of the Western Roman Empire due to the Migration Period an intellectual decline took place in the western part of Europe in the 400s. In contrast, the Byzantine Empire resisted the attacks from invaders, and preserved and improved upon the learning. John Philoponus, a Byzantine scholar in the 500s, questioned Aristotle's teaching of physics and to note its flaws. John Philoponus' criticism of Aristotelian principles of physics served as an inspiration to medieval scholars as well as to Galileo Galilei who ten centuries later, during the Scientific Revolution, extensively cited Philoponus in his works while making the case as to why Aristotelian physics was flawed.

During late antiquity and the early Middle Ages, the Aristotelian approach to inquiries on natural phenomena was used. Aristotle's four causes prescribed that four "why" questions should be answered in order to explain things scientifically. Some ancient knowledge was lost, or in some cases kept in obscurity, during the fall of the Western Roman Empire and periodic political struggles. However, the general fields of science (or "natural philosophy" as it was called) and much of the general knowledge from the ancient world remained preserved through the works of the early Latin encyclopedists like Isidore of Seville. However, Aristotle's original texts were eventually lost in Western Europe, and only one text by Plato was widely known, the "Timaeus", which was the only Platonic dialogue, and one of the few original works of classical natural philosophy, available to Latin readers in the early Middle Ages. Another original work that gained influence in this period was Ptolemy's "Almagest", which contains a geocentric description of the solar system.

During late antiquity, in the Byzantine empire many Greek classical texts were preserved. Many Syriac translations were done by groups such as the Nestorians and Monophysites. They played a role when they translated Greek classical texts into Arabic under the Caliphate, during which many types of classical learning were preserved and in some cases improved upon. In addition, the neighboring Sassanid Empire established the medical Academy of Gondeshapur where Greek, Syriac and Persian physicians established the most important medical center of the ancient world during the 6th and 7th centuries.

The House of Wisdom was established in Abbasid-era Baghdad, Iraq,
where the Islamic study of Aristotelianism flourished. Al-Kindi (801–873) was the first of the Muslim Peripatetic philosophers, and is known for his efforts to introduce Greek and Hellenistic philosophy to the Arab world. The Islamic Golden Age flourished from this time until the Mongol invasions of the 13th century. Ibn al-Haytham (Alhazen), as well as his predecessor Ibn Sahl, was familiar with Ptolemy's "Optics", and used experiments as a means to gain knowledge. Alhazen disproved Ptolemy's theory of vision, but did not make any corresponding changes to Aristotle's metaphysics. Furthermore, doctors and alchemists such as the Persians Avicenna and Al-Razi also greatly developed the science of Medicine with the former writing the Canon of Medicine, a medical encyclopedia used until the 18th century and the latter discovering multiple compounds like alcohol. Avicenna's canon is considered to be one of the most important publications in medicine and they both contributed significantly to the practice of experimental medicine, using clinical trials and experiments to back their claims. 

In Classical antiquity, Greek and Roman taboos had meant that dissection was usually banned in ancient times, but in Middle Ages it changed: medical teachers and students at Bologna began to open human bodies, and Mondino de Luzzi (c. 1275–1326) produced the ﬁrst known anatomy textbook based on human dissection.

By the eleventh century most of Europe had become Christian; stronger monarchies emerged; borders were restored; technological developments and agricultural innovations were made which increased the food supply and population. In addition, classical Greek texts started to be translated from Arabic and Greek into Latin, giving a higher level of scientific discussion in Western Europe.

By 1088, the first university in Europe (the University of Bologna) had emerged from its clerical beginnings. Demand for Latin translations grew (for example, from the Toledo School of Translators); western Europeans began collecting texts written not only in Latin, but also Latin translations from Greek, Arabic, and Hebrew. Manuscript copies of Alhazen's "Book of Optics" also propagated across Europe before 1240, as evidenced by its incorporation into Vitello's "Perspectiva". Avicenna's Canon was translated into Latin. In particular, the texts of Aristotle, Ptolemy, and Euclid, preserved in the Houses of Wisdom and also in the Byzantine Empire, were sought amongst Catholic scholars. The influx of ancient texts caused the Renaissance of the 12th century and the flourishing of a synthesis of Catholicism and Aristotelianism known as Scholasticism in western Europe, which became a new geographic center of science. An "experiment" in this period would be understood as a careful process of observing, describing, and classifying. One prominent scientist in this era was Roger Bacon. Scholasticism had a strong focus on revelation and dialectic reasoning, and gradually fell out of favour over the next centuries, as alchemy's focus on experiments that include direct observation and meticulous documentation slowly increased in importance.

New developments in optics played a role in the inception of the Renaissance, both by challenging long-held metaphysical ideas on perception, as well as by contributing to the improvement and development of technology such as the camera obscura and the telescope. Before what we now know as the Renaissance started, Roger Bacon, Vitello, and John Peckham each built up a scholastic ontology upon a causal chain beginning with sensation, perception, and finally apperception of the individual and universal forms of Aristotle. A model of vision later known as perspectivism was exploited and studied by the artists of the Renaissance. This theory uses only three of Aristotle's four causes: formal, material, and final.

In the sixteenth century, Copernicus formulated a heliocentric model of the solar system unlike the geocentric model of Ptolemy's "Almagest". This was based on a theorem that the orbital periods of the planets are longer as their orbs are farther from the centre of motion, which he found not to agree with Ptolemy's model.

Kepler and others challenged the notion that the only function of the eye is perception, and shifted the main focus in optics from the eye to the propagation of light. Kepler modelled the eye as a water-filled glass sphere with an aperture in front of it to model the entrance pupil. He found that all the light from a single point of the scene was imaged at a single point at the back of the glass sphere. The optical chain ends on the retina at the back of the eye. Kepler is best known, however, for improving Copernicus' heliocentric model through the discovery of Kepler's laws of planetary motion. Kepler did not reject Aristotelian metaphysics, and described his work as a search for the Harmony of the Spheres.
Galileo made innovative use of experiment and mathematics. However, he became persecuted after Pope Urban VIII blessed Galileo to write about the Copernican system. Galileo had used arguments from the Pope and put them in the voice of the simpleton in the work "Dialogue Concerning the Two Chief World Systems", which greatly offended Urban VIII.

In Northern Europe, the new technology of the printing press was widely used to publish many arguments, including some that disagreed widely with contemporary ideas of nature. René Descartes and Francis Bacon published philosophical arguments in favor of a new type of non-Aristotelian science. Descartes emphasized individual thought and argued that mathematics rather than geometry should be used in order to study nature. Bacon emphasized the importance of experiment over contemplation. Bacon further questioned the Aristotelian concepts of formal cause and final cause, and promoted the idea that science should study the laws of "simple" natures, such as heat, rather than assuming that there is any specific nature, or "formal cause", of each complex type of thing. This new science began to see itself as describing "laws of nature". This updated approach to studies in nature was seen as mechanistic. Bacon also argued that science should aim for the first time at practical inventions for the improvement of all human life.

As a precursor to the Age of Enlightenment, Isaac Newton and Gottfried Wilhelm Leibniz succeeded in developing a new physics, now referred to as classical mechanics, which could be confirmed by experiment and explained using mathematics (Newton (1687), "Philosophiæ Naturalis Principia Mathematica"). Leibniz also incorporated terms from Aristotelian physics, but now being used in a new non-teleological way, for example, "energy" and "potential" (modern versions of Aristotelian ""energeia" and "potentia""). This implied a shift in the view of objects: Where Aristotle had noted that objects have certain innate goals that can be actualized, objects were now regarded as devoid of innate goals. In the style of Francis Bacon, Leibniz assumed that different types of things all work according to the same general laws of nature, with no special formal or final causes for each type of thing. It is during this period that the word "science" gradually became more commonly used to refer to a "type of pursuit" of a type of knowledge, especially knowledge of nature – coming close in meaning to the old term "natural philosophy."

During this time, the declared purpose and value of science became producing wealth and inventions that would improve human lives, in the materialistic sense of having more food, clothing, and other things. In Bacon's words, "the real and legitimate goal of sciences is the endowment of human life with new inventions and riches", and he discouraged scientists from pursuing intangible philosophical or spiritual ideas, which he believed contributed little to human happiness beyond "the fume of subtle, sublime, or pleasing speculation".

Science during the Enlightenment was dominated by scientific societies and academies, which had largely replaced universities as centres of scientific research and development. Societies and academies were also the backbone of the maturation of the scientific profession. Another important development was the popularization of science among an increasingly literate population. Philosophes introduced the public to many scientific theories, most notably through the "Encyclopédie" and the popularization of Newtonianism by Voltaire as well as by Émilie du Châtelet, the French translator of Newton's "Principia".

Some historians have marked the 18th century as a drab period in the history of science; however, the century saw significant advancements in the practice of medicine, mathematics, and physics; the development of biological taxonomy; a new understanding of magnetism and electricity; and the maturation of chemistry as a discipline, which established the foundations of modern chemistry.

Enlightenment philosophers chose a short history of scientific predecessors – Galileo, Boyle, and Newton principally – as the guides and guarantors of their applications of the singular concept of nature and natural law to every physical and social field of the day. In this respect, the lessons of history and the social structures built upon it could be discarded.

The nineteenth century is a particularly important period in the history of science since during this era many distinguishing characteristics of contemporary modern science began to take shape such as: transformation of the life and physical sciences, frequent use of precision instruments, emergence of terms like "biologist", "physicist", "scientist"; slowly moving away from antiquated labels like "natural philosophy" and "natural history", increased professionalization of those studying nature lead to reduction in amateur naturalists, scientists gained cultural authority over many dimensions of society, economic expansion and industrialization of numerous countries, thriving of popular science writings and emergence of science journals.

Early in the 19th century, John Dalton suggested the modern atomic theory, based on Democritus's original idea of individible particles called "atoms".

Both John Herschel and William Whewell systematized methodology: the latter coined the term scientist. When Charles Darwin published "On the Origin of Species" he established evolution as the prevailing explanation of biological complexity. His theory of natural selection provided a natural explanation of how species originated, but this only gained wide acceptance a century later.

The laws of conservation of energy, conservation of momentum and conservation of mass suggested a highly stable universe where there could be little loss of resources. With the advent of the steam engine and the industrial revolution, there was, however, an increased understanding that all forms of energy as defined in physics were not equally useful： they did not have the same energy quality. This realization led to the development of the laws of thermodynamics, in which the cumulative energy quality of the universe is seen as constantly declining: the entropy of the universe increases over time.

The electromagnetic theory was also established in the 19th century, and raised new questions which could not easily be answered using Newton's framework. The phenomena that would allow the deconstruction of the atom were discovered in the last decade of the 19th century: the discovery of X-rays inspired the discovery of radioactivity. In the next year came the discovery of the first subatomic particle, the electron.

Einstein's theory of relativity and the development of quantum mechanics led to the replacement of classical mechanics with a new physics which contains two parts that describe different types of events in nature.

In the first half of the century, the development of antibiotics and artificial fertilizer made global human population growth possible. At the same time, the structure of the atom and its nucleus was discovered, leading to the release of "atomic energy" (nuclear power). In addition, the extensive use of technological innovation stimulated by the wars of this century led to revolutions in transportation (automobiles and aircraft), the development of ICBMs, a space race, and a nuclear arms race.

The molecular structure of DNA was discovered in 1953. The discovery of the cosmic microwave background radiation in 1964 led to a rejection of the Steady State theory of the universe in favour of the Big Bang theory of Georges Lemaître.

The development of spaceflight in the second half of the century allowed the first astronomical measurements done on or near other objects in space, including manned landings on the Moon. Space telescopes lead to numerous discoveries in astronomy and cosmology.

Widespread use of integrated circuits in the last quarter of the 20th century combined with communications satellites led to a revolution in information technology and the rise of the global internet and mobile computing, including smartphones. The need for mass systematization of long, intertwined causal chains and large amounts of data led to the rise of the fields of systems theory and computer-assisted scientific modelling, which are partly based on the Aristotelian paradigm.

Harmful environmental issues such as ozone depletion, acidification, eutrophication and climate change came to the public's attention in the same period, and caused the onset of environmental science and environmental technology.

The Human Genome Project was completed in 2003, determining the sequence of nucleotide base pairs that make up human DNA, and identifying and mapping all of the genes of the human genome. Induced pluripotent stem cells were developed in 2006, a technology allowing adult cells to be transformed into stem cells capable of giving rise to any cell type found in the body, potentially of huge importance to the field of regenerative medicine.

With the discovery of the Higgs boson in 2012, the last particle predicted by the Standard Model of particle physics was found. In 2015, gravitational waves, predicted by general relativity a century before, were first observed.

Modern science is commonly divided into three major branches that consist of the natural sciences, social sciences, and formal sciences. Each of these branches comprise various specialized yet overlapping scientific disciplines that often possess their own nomenclature and expertise. Both natural and social sciences are empirical sciences as their knowledge are based on empirical observations and are capable of being tested for its validity by other researchers working under the same conditions.

There are also closely related disciplines that use science, such as engineering and medicine, which are sometimes described as applied sciences. The relationships between the branches of science are summarized by the following table.

Natural science is concerned with the description, prediction, and understanding of natural phenomena based on empirical evidence from observation and experimentation. It can be divided into two main branches: life science (or biological science) and physical science. Physical science is subdivided into branches, including physics, chemistry, astronomy and earth science. These two branches may be further divided into more specialized disciplines. Modern natural science is the successor to the natural philosophy that began in Ancient Greece. Galileo, Descartes, Bacon, and Newton debated the benefits of using approaches which were more mathematical and more experimental in a methodical way. Still, philosophical perspectives, conjectures, and presuppositions, often overlooked, remain necessary in natural science. Systematic data collection, including discovery science, succeeded natural history, which emerged in the 16th century by describing and classifying plants, animals, minerals, and so on. Today, "natural history" suggests observational descriptions aimed at popular audiences.

Social science is concerned with society and the relationships among individuals within a society. It has many branches that include, but are not limited to, anthropology, archaeology, communication studies, economics, history, human geography, jurisprudence, linguistics, political science, psychology, public health, and sociology. Social scientists may adopt various philosophical theories to study individuals and society. For example, positivist social scientists use methods resembling those of the natural sciences as tools for understanding society, and so define science in its stricter modern sense. Interpretivist social scientists, by contrast, may use social critique or symbolic interpretation rather than constructing empirically falsifiable theories, and thus treat science in its broader sense. In modern academic practice, researchers are often eclectic, using multiple methodologies (for instance, by combining both quantitative and qualitative research). The term "social research" has also acquired a degree of autonomy as practitioners from various disciplines share in its aims and methods.

Formal science is involved in the study of formal systems. It includes mathematics, systems theory, and theoretical computer science. The formal sciences share similarities with the other two branches by relying on objective, careful, and systematic study of an area of knowledge. They are, however, different from the empirical sciences as they rely exclusively on deductive reasoning, without the need for empirical evidence, to verify their abstract concepts. The formal sciences are therefore "a priori" disciplines and because of this, there is disagreement on whether they actually constitute a science. Nevertheless, the formal sciences play an important role in the empirical sciences. Calculus, for example, was initially invented to understand motion in physics. Natural and social sciences that rely heavily on mathematical applications include mathematical physics, mathematical chemistry, mathematical biology, mathematical finance, and mathematical economics.

Scientific research can be labeled as either basic or applied research. Basic research is the search for knowledge and applied research is the search for solutions to practical problems using this knowledge. Although some scientific research is applied research into specific problems, a great deal of our understanding comes from the curiosity-driven undertaking of basic research. This leads to options for technological advance that were not planned or sometimes even imaginable. This point was made by Michael Faraday when allegedly in response to the question "what is the "use" of basic research?" he responded: "Sir, what is the use of a new-born child?". For example, research into the effects of red light on the human eye's rod cells did not seem to have any practical purpose; eventually, the discovery that our night vision is not troubled by red light would lead search and rescue teams (among others) to adopt red light in the cockpits of jets and helicopters. Finally, even basic research can take unexpected turns, and there is some sense in which the scientific method is built to harness luck.

Scientific research involves using the scientific method, which seeks to objectively explain the events of nature in a reproducible way. An explanatory thought experiment or hypothesis is put forward as explanation using principles such as parsimony (also known as "Occam's Razor") and are generally expected to seek consilience – fitting well with other accepted facts related to the phenomena. This new explanation is used to make falsifiable predictions that are testable by experiment or observation. The predictions are to be posted before a confirming experiment or observation is sought, as proof that no tampering has occurred. Disproof of a prediction is evidence of progress. This is done partly through observation of natural phenomena, but also through experimentation that tries to simulate natural events under controlled conditions as appropriate to the discipline (in the observational sciences, such as astronomy or geology, a predicted observation might take the place of a controlled experiment). Experimentation is especially important in science to help establish causal relationships (to avoid the correlation fallacy).

When a hypothesis proves unsatisfactory, it is either modified or discarded. If the hypothesis survived testing, it may become adopted into the framework of a scientific theory, a logically reasoned, self-consistent model or framework for describing the behavior of certain natural phenomena. A theory typically describes the behavior of much broader sets of phenomena than a hypothesis; commonly, a large number of hypotheses can be logically bound together by a single theory. Thus a theory is a hypothesis explaining various other hypotheses. In that vein, theories are formulated according to most of the same scientific principles as hypotheses. In addition to testing hypotheses, scientists may also generate a model, an attempt to describe or depict the phenomenon in terms of a logical, physical or mathematical representation and to generate new hypotheses that can be tested, based on observable phenomena.

While performing experiments to test hypotheses, scientists may have a preference for one outcome over another, and so it is important to ensure that science as a whole can eliminate this bias. This can be achieved by careful experimental design, transparency, and a thorough peer review process of the experimental results as well as any conclusions. After the results of an experiment are announced or published, it is normal practice for independent researchers to double-check how the research was performed, and to follow up by performing similar experiments to determine how dependable the results might be. Taken in its entirety, the scientific method allows for highly creative problem solving while minimizing any effects of subjective bias on the part of its users (especially the confirmation bias).

John Ziman points out that intersubjective verifiability is fundamental to the creation of all scientific knowledge. Ziman shows how scientists can identify patterns to each other across centuries; he refers to this ability as "perceptual consensibility." He then makes consensibility, leading to consensus, the touchstone of reliable knowledge.

Mathematics is essential in the formation of hypotheses, theories, and laws in the natural and social sciences. For example, it is used in quantitative scientific modeling, which can generate new hypotheses and predictions to be tested. It is also used extensively in observing and collecting measurements. Statistics, a branch of mathematics, is used to summarize and analyze data, which allow scientists to assess the reliability and variability of their experimental results.

Computational science applies computing power to simulate real-world situations, enabling a better understanding of scientific problems than formal mathematics alone can achieve. According to the Society for Industrial and Applied Mathematics, computation is now as important as theory and experiment in advancing scientific knowledge.

Scientists usually take for granted a set of basic assumptions that are needed to justify the scientific method: (1) that there is an objective reality shared by all rational observers; (2) that this objective reality is governed by natural laws; (3) that these laws can be discovered by means of systematic observation and experimentation. Philosophy of science seeks a deep understanding of what these underlying assumptions mean and whether they are valid.

The belief that scientific theories should and do represent metaphysical reality is known as realism. It can be contrasted with anti-realism, the view that the success of science does not depend on it being accurate about unobservable entities such as electrons. One form of anti-realism is idealism, the belief that the mind or consciousness is the most basic essence, and that each mind generates its own reality. In an idealistic world view, what is true for one mind need not be true for other minds.

There are different schools of thought in philosophy of science. The most popular position is empiricism, which holds that knowledge is created by a process involving observation and that scientific theories are the result of generalizations from such observations. Empiricism generally encompasses inductivism, a position that tries to explain the way general theories can be justified by the finite number of observations humans can make and hence the finite amount of empirical evidence available to confirm scientific theories. This is necessary because the number of predictions those theories make is infinite, which means that they cannot be known from the finite amount of evidence using deductive logic only. Many versions of empiricism exist, with the predominant ones being Bayesianism and the hypothetico-deductive method.
Empiricism has stood in contrast to rationalism, the position originally associated with Descartes, which holds that knowledge is created by the human intellect, not by observation. Critical rationalism is a contrasting 20th-century approach to science, first defined by Austrian-British philosopher Karl Popper. Popper rejected the way that empiricism describes the connection between theory and observation. He claimed that theories are not generated by observation, but that observation is made in the light of theories and that the only way a theory can be affected by observation is when it comes in conflict with it. Popper proposed replacing verifiability with falsifiability as the landmark of scientific theories and replacing induction with falsification as the empirical method. Popper further claimed that there is actually only one universal method, not specific to science: the negative method of criticism, trial and error. It covers all products of the human mind, including science, mathematics, philosophy, and art.

Another approach, instrumentalism, colloquially termed "shut up and multiply," emphasizes the utility of theories as instruments for explaining and predicting phenomena. It views scientific theories as black boxes with only their input (initial conditions) and output (predictions) being relevant. Consequences, theoretical entities, and logical structure are claimed to be something that should simply be ignored and that scientists shouldn't make a fuss about (see interpretations of quantum mechanics). Close to instrumentalism is constructive empiricism, according to which the main criterion for the success of a scientific theory is whether what it says about observable entities is true.

Thomas Kuhn argued that the process of observation and evaluation takes place within a paradigm, a logically consistent "portrait" of the world that is consistent with observations made from its framing. He characterized "normal science" as the process of observation and "puzzle solving" which takes place within a paradigm, whereas "revolutionary science" occurs when one paradigm overtakes another in a paradigm shift. Each paradigm has its own distinct questions, aims, and interpretations. The choice between paradigms involves setting two or more "portraits" against the world and deciding which likeness is most promising. A paradigm shift occurs when a significant number of observational anomalies arise in the old paradigm and a new paradigm makes sense of them. That is, the choice of a new paradigm is based on observations, even though those observations are made against the background of the old paradigm. For Kuhn, acceptance or rejection of a paradigm is a social process as much as a logical process. Kuhn's position, however, is not one of relativism.

Finally, another approach often cited in debates of scientific skepticism against controversial movements like "creation science" is methodological naturalism. Its main point is that a difference between natural and supernatural explanations should be made and that science should be restricted methodologically to natural explanations. That the restriction is merely methodological (rather than ontological) means that science should not consider supernatural explanations itself, but should not claim them to be wrong either. Instead, supernatural explanations should be left a matter of personal belief outside the scope of science. Methodological naturalism maintains that proper science requires strict adherence to empirical study and independent verification as a process for properly developing and evaluating explanations for observable phenomena. The absence of these standards, arguments from authority, biased observational studies and other common fallacies are frequently cited by supporters of methodological naturalism as characteristic of the non-science they criticize.

A scientific theory is empirical and is always open to falsification if new evidence is presented. That is, no theory is ever considered strictly certain as science accepts the concept of fallibilism. The philosopher of science Karl Popper sharply distinguished truth from certainty. He wrote that scientific knowledge "consists in the search for truth," but it "is not the search for certainty ... All human knowledge is fallible and therefore uncertain.

New scientific knowledge rarely results in vast changes in our understanding. According to psychologist Keith Stanovich, it may be the media's overuse of words like "breakthrough" that leads the public to imagine that science is constantly proving everything it thought was true to be false. While there are such famous cases as the theory of relativity that required a complete reconceptualization, these are extreme exceptions. Knowledge in science is gained by a gradual synthesis of information from different experiments by various researchers across different branches of science; it is more like a climb than a leap. Theories vary in the extent to which they have been tested and verified, as well as their acceptance in the scientific community. For example, heliocentric theory, the theory of evolution, relativity theory, and germ theory still bear the name "theory" even though, in practice, they are considered factual.
Philosopher Barry Stroud adds that, although the best definition for "knowledge" is contested, being skeptical and entertaining the "possibility" that one is incorrect is compatible with being correct. Therefore, scientists adhering to proper scientific approaches will doubt themselves even once they possess the truth. The fallibilist C. S. Peirce argued that inquiry is the struggle to resolve actual doubt and that merely quarrelsome, verbal, or hyperbolic doubt is fruitless – but also that the inquirer should try to attain genuine doubt rather than resting uncritically on common sense. He held that the successful sciences trust not to any single chain of inference (no stronger than its weakest link) but to the cable of multiple and various arguments intimately connected.

Stanovich also asserts that science avoids searching for a "magic bullet"; it avoids the single-cause fallacy. This means a scientist would not ask merely "What is "the" cause of ...", but rather "What "are" the most significant "causes" of ...". This is especially the case in the more macroscopic fields of science (e.g. psychology, physical cosmology). Research often analyzes few factors at once, but these are always added to the long list of factors that are most important to consider. For example, knowing the details of only a person's genetics, or their history and upbringing, or the current situation may not explain a behavior, but a deep understanding of all these variables combined can be very predictive.

Scientific research is published in an enormous range of scientific literature. Scientific journals communicate and document the results of research carried out in universities and various other research institutions, serving as an archival record of science. The first scientific journals, "Journal des Sçavans" followed by the "Philosophical Transactions", began publication in 1665. Since that time the total number of active periodicals has steadily increased. In 1981, one estimate for the number of scientific and technical journals in publication was 11,500. The United States National Library of Medicine currently indexes 5,516 journals that contain articles on topics related to the life sciences. Although the journals are in 39 languages, 91 percent of the indexed articles are published in English.

Most scientific journals cover a single scientific field and publish the research within that field; the research is normally expressed in the form of a scientific paper. Science has become so pervasive in modern societies that it is generally considered necessary to communicate the achievements, news, and ambitions of scientists to a wider populace.

Science magazines such as "New Scientist", "Science & Vie", and "Scientific American" cater to the needs of a much wider readership and provide a non-technical summary of popular areas of research, including notable discoveries and advances in certain fields of research. Science books engage the interest of many more people. Tangentially, the science fiction genre, primarily fantastic in nature, engages the public imagination and transmits the ideas, if not the methods, of science.

Recent efforts to intensify or develop links between science and non-scientific disciplines such as literature or more specifically, poetry, include the "Creative Writing Science" resource developed through the Royal Literary Fund.

Discoveries in fundamental science can be world-changing. For example:

The replication crisis is an ongoing methodological crisis primarily affecting parts of the social and life sciences in which scholars have found that the results of many scientific studies are difficult or impossible to replicate or reproduce on subsequent investigation, either by independent researchers or by the original researchers themselves. The crisis has long-standing roots; the phrase was coined in the early 2010s as part of a growing awareness of the problem. The replication crisis represents an important body of research in metascience, which aims to improve the quality of all scientific research while reducing waste.

An area of study or speculation that masquerades as science in an attempt to claim a legitimacy that it would not otherwise be able to achieve is sometimes referred to as pseudoscience, fringe science, or junk science. Physicist Richard Feynman coined the term "cargo cult science" for cases in which researchers believe they are doing science because their activities have the outward appearance of science but actually lack the "kind of utter honesty" that allows their results to be rigorously evaluated. Various types of commercial advertising, ranging from hype to fraud, may fall into these categories. Science has been described as "the most important tool" for separating valid claims from invalid ones.

There can also be an element of political or ideological bias on all sides of scientific debates. Sometimes, research may be characterized as "bad science," research that may be well-intended but is actually incorrect, obsolete, incomplete, or over-simplified expositions of scientific ideas. The term "scientific misconduct" refers to situations such as where researchers have intentionally misrepresented their published data or have purposely given credit for a discovery to the wrong person.

The scientific community is a group of all interacting scientists, along with their respective societies and institutions.

Scientists are individuals who conduct scientific research to advance knowledge in an area of interest. The term "scientist" was coined by William Whewell in 1833. In modern times, many professional scientists are trained in an academic setting and upon completion, attain an academic degree, with the highest degree being a doctorate such as a Doctor of Philosophy (PhD), Doctor of Medicine (MD), or Doctor of Engineering (DEng). Many scientists pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit organizations.

Scientists exhibit a strong curiosity about reality, with some scientists having a desire to apply scientific knowledge for the benefit of health, nations, environment, or industries. Other motivations include recognition by their peers and prestige. The Nobel Prize, a widely regarded prestigious award, is awarded annually to those who have achieved scientific advances in the fields of medicine, physics, chemistry, and economics.

Science has historically been a male-dominated field, with some notable exceptions. Women faced considerable discrimination in science, much as they did in other areas of male-dominated societies, such as frequently being passed over for job opportunities and denied credit for their work. For example, Christine Ladd (1847–1930) was able to enter a PhD program as "C. Ladd"; Christine "Kitty" Ladd completed the requirements in 1882, but was awarded her degree only in 1926, after a career which spanned the algebra of logic (see truth table), color vision, and psychology. Her work preceded notable researchers like Ludwig Wittgenstein and Charles Sanders Peirce. The achievements of women in science have been attributed to their defiance of their traditional role as laborers within the domestic sphere.

In the late 20th century, active recruitment of women and elimination of institutional discrimination on the basis of sex greatly increased the number of women scientists, but large gender disparities remain in some fields; in the early 21st century over half of new biologists were female, while 80% of PhDs in physics are given to men. In the early part of the 21st century, women in the United States earned 50.3% of bachelor's degrees, 45.6% of master's degrees, and 40.7% of PhDs in science and engineering fields. They earned more than half of the degrees in psychology (about 70%), social sciences (about 50%), and biology (about 50-60%) but earned less than half the degrees in the physical sciences, earth sciences, mathematics, engineering, and computer science. Lifestyle choice also plays a major role in female engagement in science; women with young children are 28% less likely to take tenure-track positions due to work-life balance issues, and female graduate students' interest in careers in research declines dramatically over the course of graduate school, whereas that of their male colleagues remains unchanged.

Learned societies for the communication and promotion of scientific thought and experimentation have existed since the Renaissance. Many scientists belong to a learned society that promotes their respective scientific discipline, profession, or group of related disciplines. Membership may be open to all, may require possession of some scientific credentials, or may be an honor conferred by election. Most scientific societies are non-profit organizations, and many are professional associations. Their activities typically include holding regular conferences for the presentation and discussion of new research results and publishing or sponsoring academic journals in their discipline. Some also act as professional bodies, regulating the activities of their members in the public interest or the collective interest of the membership. Scholars in the sociology of science argue that learned societies are of key importance and their formation assists in the emergence and development of new disciplines or professions.

The professionalization of science, begun in the 19th century, was partly enabled by the creation of distinguished academy of sciences in a number of countries such as the Italian in 1603, the British Royal Society in 1660, the French in 1666, the American National Academy of Sciences in 1863, the German Kaiser Wilhelm Institute in 1911, and the Chinese Academy of Sciences in 1928. International scientific organizations, such as the International Council for Science, have since been formed to promote cooperation between the scientific communities of different nations.

Science policy is an area of public policy concerned with the policies that affect the conduct of the scientific enterprise, including research funding, often in pursuance of other national policy goals such as technological innovation to promote commercial product development, weapons development, health care and environmental monitoring. Science policy also refers to the act of applying scientific knowledge and consensus to the development of public policies. Science policy thus deals with the entire domain of issues that involve the natural sciences. In accordance with public policy being concerned about the well-being of its citizens, science policy's goal is to consider how science and technology can best serve the public.

State policy has influenced the funding of public works and science for thousands of years, particularly within civilizations with highly organized governments such as imperial China and the Roman Empire. Prominent historical examples include the Great Wall of China, completed over the course of two millennia through the state support of several dynasties, and the Grand Canal of the Yangtze River, an immense feat of hydraulic engineering begun by Sunshu Ao (孫叔敖 7th c. BCE), Ximen Bao (西門豹 5th c.BCE), and Shi Chi (4th c. BCE). This construction dates from the 6th century BCE under the Sui Dynasty and is still in use today. In China, such state-supported infrastructure and scientific research projects date at least from the time of the Mohists, who inspired the study of logic during the period of the Hundred Schools of Thought and the study of defensive fortifications like the Great Wall of China during the Warring States period.

Public policy can directly affect the funding of capital equipment and intellectual infrastructure for industrial research by providing tax incentives to those organizations that fund research. Vannevar Bush, director of the Office of Scientific Research and Development for the United States government, the forerunner of the National Science Foundation, wrote in July 1945 that "Science is a proper concern of government."

Scientific research is often funded through a competitive process in which potential research projects are evaluated and only the most promising receive funding. Such processes, which are run by government, corporations, or foundations, allocate scarce funds. Total research funding in most developed countries is between 1.5% and 3% of GDP. In the OECD, around two-thirds of research and development in scientific and technical fields is carried out by industry, and 20% and 10% respectively by universities and government. The government funding proportion in certain industries is higher, and it dominates research in social science and humanities. Similarly, with some exceptions (e.g. biotechnology) government provides the bulk of the funds for basic scientific research. Many governments have dedicated agencies to support scientific research. Prominent scientific organizations include the National Science Foundation in the United States, the National Scientific and Technical Research Council in Argentina, Commonwealth Scientific and Industrial Research Organisation (CSIRO) in Australia, in France, the Max Planck Society and in Germany, and CSIC in Spain. In commercial research and development, all but the most research-oriented corporations focus more heavily on near-term commercialisation possibilities rather than "blue-sky" ideas or technologies (such as nuclear fusion).

The public awareness of science relates to the attitudes, behaviors, opinions, and activities that make up the relations between science and the general public. it integrates various themes and activities such as science communication, science museums, science festivals, science fairs, citizen science, and science in popular culture. Social scientists have devised various metrics to measure the public understanding of science such as factual knowledge, self-reported knowledge, and structural knowledge.

The mass media face a number of pressures that can prevent them from accurately depicting competing scientific claims in terms of their credibility within the scientific community as a whole. Determining how much weight to give different sides in a scientific debate may require considerable expertise regarding the matter. Few journalists have real scientific knowledge, and even beat reporters who know a great deal about certain scientific issues may be ignorant about other scientific issues that they are suddenly asked to cover.

Politicization of science occurs when government, business, or advocacy groups use legal or economic pressure to influence the findings of scientific research or the way it is disseminated, reported, or interpreted. Many factors can act as facets of the politicization of science such as populist anti-intellectualism, perceived threats to religious beliefs, postmodernist subjectivism, and fear for business interests. Politicization of science is usually accomplished when scientific information is presented in a way that emphasizes the uncertainty associated with the scientific evidence. Tactics such as shifting conversation, failing to acknowledge facts, and capitalizing on doubt of scientific consensus have been used to gain more attention for views that have been undermined by scientific evidence. Examples of issues that have involved the politicization of science include the global warming controversy, health effects of pesticides, and health effects of tobacco.



Publications

Resources


</doc>
<doc id="22500921" url="https://en.wikipedia.org/wiki?curid=22500921" title="Outline of knowledge">
Outline of knowledge

The following outline is provided as an overview of and topical guide to knowledge:

Knowledge – familiarity with someone or something, which can include facts, information, descriptions, and/or skills acquired through experience or education. It can refer to the theoretical or practical understanding of a subject. It can be implicit (as with practical skill or expertise) or explicit (as with the theoretical understanding of a subject); and it can be more or less formal or systematic.



Taxonomies –



Epistemology – philosophy of knowledge. It is the study of knowledge and justified belief. It questions what knowledge is and how it can be acquired, and the extent to which knowledge pertinent to any given subject or entity can be acquired. Much of the debate in this field has focused on the philosophical analysis of the nature of knowledge and how it relates to connected notions such as truth, belief, and justification.

Knowledge management – 

Methods of obtaining knowledge –

Knowledge can be stored in:


Knowledge retrieval – Stored knowledge can be retrieved by:

Imparting knowledge means spreading or disseminating knowledge to others.




Sociology of knowledge –


The world's knowledge (knowledge possessed by human civilization)







</doc>
<doc id="57429694" url="https://en.wikipedia.org/wiki?curid=57429694" title="Surprisingly popular">
Surprisingly popular

The surprisingly popular answer is a wisdom of the crowd technique that taps into the expert minority opinion within a crowd. For a given question, a group is asked both "What do you think the right answer is?" and "What do you think the popular answer will be?" The answer that maximizes the average difference between the "right" answer and the "popular" answer is the "surprisingly popular" answer.

Question to be determined:<br>
Is Philadelphia the capital of Pennsylvania?
<br><br>Questions asked to the group and the response rates:<br>
Is Philadelphia the capital of Pennsylvania?
What do you think most people will respond to that question?

The difference between the answers to the "right" question and the "popular" question:

Thus, the "No" answer is surprisingly popular (10% > -10%). Because of the relatively high margin of 10%, there can be high confidence that the correct answer is "No".


</doc>
<doc id="18311131" url="https://en.wikipedia.org/wiki?curid=18311131" title="Privileged access">
Privileged access

In the fields of epistemology and philosophy of mind, a person (the subject, the self) has privileged access to their own thoughts. This implies the subject has access to, and knows, their own thoughts (has self-knowledge) in such a way that others do not. Privileged access can be characterized in two ways:


The still prevailing traditional position argues each of us do in fact have privileged access to our own thoughts. Descartes is the paradigmatic proponent of such kind of view (even though "privileged access" is an anachronic label for his thesis):

For Descartes, we still have privileged access even in the doubt scenario. That is, for him we would retain self-knowledge even in those extreme situations in which we can't have knowledge about anything else.

Gilbert Ryle, on the other hand, maintains a diametrically opposed view. According to the behaviorism of Ryle, each of us knows our own thoughts in the same way we know other's thoughts. We only come to know the thoughts of others through their linguistic and bodily behaviors, and must do exactly the same in order to know our own thoughts. There is no privileged access. We only have access to what we think upon evidences supplied through our own actions.



</doc>
<doc id="23369987" url="https://en.wikipedia.org/wiki?curid=23369987" title="Descriptive knowledge">
Descriptive knowledge

Descriptive knowledge, also declarative knowledge, propositional knowledge, or constative knowledge, is the type of knowledge that is, by its very nature, expressed in declarative sentences or indicative propositions. This distinguishes descriptive knowledge from what is commonly known as "knowing-how", or procedural knowledge (the knowledge of how, and especially how best, to perform some task), and "knowing of", or knowledge by acquaintance (the non-propositional knowledge of something through direct awareness of it). Descriptive knowledge is also identified as "knowing-that" or knowledge of fact, embodying concepts, principles, ideas, schemas, and theories. The entire descriptive knowledge of an individual constitute his understanding of the world and more specifically how it or a part of it works.

The distinction between knowing-how and knowing-that was introduced in epistemology by Gilbert Ryle. For Ryle, the former differs in its emphasis and purpose since it is primarily practical knowledge whereas the latter focuses on indicative or explanatory knowledge.



</doc>
<doc id="1120085" url="https://en.wikipedia.org/wiki?curid=1120085" title="Distributed knowledge">
Distributed knowledge

In multi-agent system research, distributed knowledge is all the knowledge that a community of agents possesses and might apply in solving a problem. Distributed knowledge is approximately what "a wise man knows" or what someone who has complete knowledge of what each member of the community knows knows. Distributed knowledge might also be called the aggregate knowledge of a community, as it represents all the knowledge that a community might bring to bear to solve a problem. Other related phrasings include cumulative knowledge, collective knowledge, pooled knowledge, or the wisdom of the crowd. Distributed knowledge is the union of all the knowledge of individuals in a community.

The logicians Aaleyah and Isko are sitting in their dark office wondering whether or not it is raining outside. Now, none of them actually knows, but Aaleyah knows something about her friend Yu Yan, namely that Yu Yan wears her red coat only if it is raining. Bob does not know this, but he just saw Yu Yan, and noticed that she was wearing her red coat. Even though none of them knows whether or not it is raining, it is "distributed knowledge" amongst them that it is raining. If either one of them tells the other what they know, it will be clear to the other that it is raining.

If we denote by formula_1 that Yu Yan wears a red coat and with formula_2 that if Yu Yan wears a red coat, it is raining, we have

Directly translated: Bob knows that Carol wears a red coat and Aaleyah knows that if Carol wears a red coat it is raining so together they know that it is raining.

Distributed knowledge is related to the concept Wisdom of the crowd. Distributed knowledge reflects the fact that "no one of us is smarter than all of us."




</doc>
<doc id="25524" url="https://en.wikipedia.org/wiki?curid=25524" title="Research">
Research

Research is "creative and systematic work undertaken to increase the stock of knowledge, including knowledge of humans, culture and society, and the use of this stock of knowledge to devise new applications." It is used to establish or confirm facts, reaffirm the results of previous work, solve new or existing problems, support theorems, or develop new theories. A research project may also be an expansion on past work in the field. Research projects can be used to develop further knowledge on a topic, or in the example of a school research project, they can be used to further a student's research prowess to prepare them for future jobs or reports. To test the validity of instruments, procedures, or experiments, research may replicate elements of prior projects or the project as a whole. The primary purposes of basic research (as opposed to applied research) are documentation, discovery, interpretation, or the research and development (R&D) of methods and systems for the advancement of human knowledge. Approaches to research depend on epistemologies, which vary considerably both within and between humanities and sciences. There are several forms of research: scientific, humanities, artistic, economic, social, business, marketing, practitioner research, life, technological, etc. The scientific study of research practices is known as meta-research.

The word "research" is derived from the Middle French "recherche", which means "to go about seeking", the term itself being derived from the Old French term "recerchier" a compound word from "re-" + "cerchier", or "sercher", meaning 'search'. The earliest recorded use of the term was in 1577.

Research has been defined in a number of different ways, and while there are similarities, there does not appear to be a single, all-encompassing definition that is embraced by all who engage in it.

One definition of research is used by the OECD, "Any creative systematic activity undertaken in order to increase the stock of knowledge, including knowledge of man, culture and society, and the use of this knowledge to devise new applications."

Another definition of research is given by John W. Creswell, who states that "research is a process of steps used to collect and analyze information to increase our understanding of a topic or issue". It consists of three steps: pose a question, collect data to answer the question, and present an answer to the question.

The Merriam-Webster Online Dictionary defines research in more detail as "studious inquiry or examination; "especially" : investigation or experimentation aimed at the discovery and interpretation of facts, revision of accepted theories or laws in the light of new facts, or practical application of such new or revised theories or laws"

Original research is research that is not exclusively based on a summary, review or synthesis of earlier publications on the subject of research. This material is of a primary source character. The purpose of the original research is to produce new knowledge, rather than to present the existing knowledge in a new form ("e.g.", summarized or classified).

Original research can take a number of forms, depending on the discipline it pertains to. In experimental work, it typically involves direct or indirect observation of the researched subject(s), e.g., in the laboratory or in the field, documents the methodology, results, and conclusions of an experiment or set of experiments, or offers a novel interpretation of previous results. In analytical work, there are typically some new (for example) mathematical results produced, or a new way of approaching an existing problem. In some subjects which do not typically carry out experimentation or analysis of this kind, the originality is in the particular way existing understanding is changed or re-interpreted based on the outcome of the work of the researcher.

The degree of originality of the research is among major criteria for articles to be published in academic journals and usually established by means of peer review. Graduate students are commonly required to perform original research as part of a dissertation.

Scientific research is a systematic way of gathering data and harnessing curiosity. This research provides scientific information and theories for the explanation of the nature and the properties of the world. It makes practical applications possible. Scientific research is funded by public authorities, by charitable organizations and by private groups, including many companies. Scientific research can be subdivided into different classifications according to their academic and application disciplines. Scientific research is a widely used criterion for judging the standing of an academic institution, but some argue that such is an inaccurate assessment of the institution, because the quality of research does not tell about the quality of teaching (these do not necessarily correlate).

Research in the humanities involves different methods such as for example hermeneutics and semiotics. Humanities scholars usually do not search for the ultimate correct answer to a question, but instead, explore the issues and details that surround it. Context is always important, and context can be social, historical, political, cultural, or ethnic. An example of research in the humanities is historical research, which is embodied in historical method. Historians use primary sources and other evidence to systematically investigate a topic, and then to write histories in the form of accounts of the past. Other studies aim to merely examine the occurrence of behaviours in societies and communities, without particularly looking for reasons or motivations to explain these. These studies may be qualitative or quantitative, and can use a variety of approaches, such as queer theory or feminist theory.

Artistic research, also seen as 'practice-based research', can take form when creative works are considered both the research and the object of research itself. It is the debatable body of thought which offers an alternative to purely scientific methods in research in its search for knowledge and truth.

Generally, research is understood to follow a certain structural process. Though step order may vary depending on the subject matter and researcher, the following steps are usually part of most formal research, both basic and applied:

A common misconception is that a hypothesis will be proven (see, rather, null hypothesis). Generally, a hypothesis is used to make predictions that can be tested by observing the outcome of an experiment. If the outcome is inconsistent with the hypothesis, then the hypothesis is rejected (see falsifiability). However, if the outcome is consistent with the hypothesis, the experiment is said to support the hypothesis. This careful language is used because researchers recognize that alternative hypotheses may also be consistent with the observations. In this sense, a hypothesis can never be proven, but rather only supported by surviving rounds of scientific testing and, eventually, becoming widely thought of as true.

A useful hypothesis allows prediction and within the accuracy of observation of the time, the prediction will be verified. As the accuracy of observation improves with time, the hypothesis may no longer provide an accurate prediction. In this case, a new hypothesis will arise to challenge the old, and to the extent that the new hypothesis makes more accurate predictions than the old, the new will supplant it. Researchers can also use a null hypothesis, which states no relationship or difference between the independent or dependent variables.

The historical method comprises the techniques and guidelines by which historians use historical sources and other evidence to research and then to write history. There are various history guidelines that are commonly used by historians in their work, under the headings of external criticism, internal criticism, and synthesis. This includes lower criticism and sensual criticism. Though items may vary depending on the subject matter and researcher, the following concepts are part of most formal historical research:

The controversial trend of artistic teaching becoming more academics-oriented is leading to artistic research being accepted as the primary mode of enquiry in art as in the case of other disciplines. One of the characteristics of artistic research is that it must accept subjectivity as opposed to the classical scientific methods. As such, it is similar to the social sciences in using qualitative research and intersubjectivity as tools to apply measurement and critical analysis.

Artistic research has been defined by the University of Dance and Circus (Dans och Cirkushögskolan, DOCH), Stockholm in the following manner - "Artistic research is to investigate and test with the purpose of gaining knowledge within and for our artistic disciplines. It is based on artistic practices, methods, and criticality. Through presented documentation, the insights gained shall be placed in a context." Artistic research aims to enhance knowledge and understanding with presentation of the arts. A more simple understanding by Julian Klein defines Artistic Research as any kind of research employing the artistic mode of perception. For a survey of the central problematics of today's Artistic Research, see Giaco Schiesser.

According to artist Hakan Topal, in artistic research, "perhaps more so than other disciplines, intuition is utilized as a method to identify a wide range of new and unexpected productive modalities". Most writers, whether of fiction or non-fiction books, also have to do research to support their creative work. This may be factual, historical, or background research. Background research could include, for example, geographical or procedural research.

The Society for Artistic Research (SAR) publishes the triannual "Journal for Artistic Research" (JAR), an international, online, open access, and peer-reviewed journal for the identification, publication, and dissemination of artistic research and its methodologies, from all arts disciplines and it runs the "Research Catalogue" (RC), a searchable, documentary database of artistic research, to which anyone can contribute.

Patricia Leavy addresses eight arts-based research (ABR) genres: narrative inquiry, fiction-based research, poetry, music, dance, theatre, film, and visual art.

In 2016 ELIA (European League of the Institutes of the Arts) launched "The Florence Principles' on the Doctorate in the Arts". The Florence Principles relating to the Salzburg Principles and the Salzburg Recommendations of EUA (European University Association) name seven points of attention to specify the Doctorate / PhD in the Arts compared to a scientific doctorate / PhD The Florence Principles have been endorsed and are supported also by AEC, CILECT, CUMULUS and SAR.

Research is often conducted using the hourglass model structure of research. The hourglass model starts with a broad spectrum for research, focusing in on the required information through the method of the project (like the neck of the hourglass), then expands the research in the form of discussion and results. The major steps in conducting research are:

The steps generally represent the overall process; however, they should be viewed as an ever-changing iterative process rather than a fixed set of steps. Most research begins with a general statement of the problem, or rather, the purpose for engaging in the study. The literature review identifies flaws or holes in previous research which provides justification for the study. Often, a literature review is conducted in a given subject area before a research question is identified. A gap in the current literature, as identified by a researcher, then engenders a research question. The research question may be parallel to the hypothesis. The hypothesis is the supposition to be tested. The researcher(s) collects data to test the hypothesis. The researcher(s) then analyzes and interprets the data via a variety of statistical methods, engaging in what is known as empirical research. The results of the data analysis in rejecting or failing to reject the null hypothesis are then reported and evaluated. At the end, the researcher may discuss avenues for further research. However, some researchers advocate for the reverse approach: starting with articulating findings and discussion of them, moving "up" to identification of a research problem that emerges in the findings and literature review. The reverse approach is justified by the transactional nature of the research endeavor where research inquiry, research questions, research method, relevant research literature, and so on are not fully known until the findings have fully emerged and been interpreted.

Rudolph Rummel says, "... no researcher should accept any one or two tests as definitive. It is only when a range of tests are consistent over many kinds of data, researchers, and methods can one have confidence in the results."

Plato in Meno talks about an inherent difficulty, if not a paradox, of doing research that can be paraphrased in the following way, "If you know what you're searching for, why do you search for it?! [i.e., you have already found it] If you don't know what you're searching for, what are you searching for?!"

The goal of the research process is to produce new knowledge or deepen understanding of a topic or issue. This process takes three main forms (although, as previously discussed, the boundaries between them may be obscure):
There are two major types of empirical research design: qualitative research and quantitative research. Researchers choose qualitative or quantitative methods according to the nature of the research topic they want to investigate and the research questions they aim to answer:


Social media posts are used for qualitative research.


The quantitative data collection methods rely on random sampling and structured data collection instruments that fit diverse experiences into predetermined response categories. These methods produce results that are easy to summarize, compare, and generalize. Quantitative research is concerned with testing hypotheses derived from theory or being able to estimate the size of a phenomenon of interest.

If the research question is about people, participants may be randomly assigned to different treatments (this is the only way that a quantitative study can be considered a true experiment). If this is not feasible, the researcher may collect data on participant and situational characteristics to statistically control for their influence on the dependent, or outcome, variable. If the intent is to generalize from the research participants to a larger population, the researcher will employ probability sampling to select participants.

In either qualitative or quantitative research, the researcher(s) may collect primary or secondary data. Primary data is data collected specifically for the research, such as through interviews or questionnaires. Secondary data is data that already exists, such as census data, which can be re-used for the research. It is good ethical research practice to use secondary data wherever possible.

Mixed-method research, i.e. research that includes qualitative and quantitative elements, using both primary and secondary data, is becoming more common. This method has benefits that using one method alone cannot offer. For example, a researcher may choose to conduct a qualitative study and follow it up with a quantitative study to gain additional insights.

Big data has brought big impacts on research methods so that now many researchers do not put much effort into data collection; furthermore, methods to analyze easily available huge amounts of data have also been developed.

Non-empirical (theoretical) research is an approach that involves the development of theory as opposed to using observation and experimentation. As such, non-empirical research seeks solutions to problems using existing knowledge as its source. This, however, does not mean that new ideas and innovations cannot be found within the pool of existing and established knowledge. Non-empirical research is not an absolute alternative to empirical research because they may be used together to strengthen a research approach. Neither one is less effective than the other since they have their particular purpose in science. Typically empirical research produces observations that need to be explained; then theoretical research tries to explain them, and in so doing generates empirically testable hypotheses; these hypotheses are then tested empirically, giving more observations that may need further explanation; and so on. See Scientific method.

A simple example of a non-empirical task is the prototyping of a new drug using a differentiated application of existing knowledge; another is the development of a business process in the form of a flow chart and texts where all the ingredients are from established knowledge. Much of cosmological research is theoretical in nature. Mathematics research does not rely on externally available data; rather, it seeks to prove theorems about mathematical objects.

Research ethics is concerned with the moral issues that arise during or as a result of research activities, as well as the ethical conduct of researchers. Historically, the revelation of scandals such as Nazi human experimentation and the Tuskegee syphilis experiment led to the realisation that clear measures are needed for the ethical governance of research to ensure that people, animals and environments are not unduly harmed in research. 

When making ethical decisions, we may be guided by different things and philosophers commonly distinguish between approaches like deontology, consequentialism, virtue ethics and value (ethics). Regardless of approach, the application of ethical theory to specific controversial topics is known as applied ethics and research ethics can be viewed as a form of applied ethics because ethical theory is applied in real-world research scenarios. 

Ethical issues may arise in the design and implementation of research involving human experimentation or animal experimentation. There may also be consequences for the environment, for society or for future generations that need to be considered. Research ethics is most developed as a concept in medical research, the most notable Code being the 1964 Declaration of Helsinki. Research in other fields such as social sciences, information technology, biotechnology, or engineering may generate different types of ethical concerns to those in medical research. 

Nowadays, research ethics is commonly distinguished from matters of research integrity that includes issues such as: scientific misconduct (such as fraud, fabrication of data and plagiarism), etc.

Meta-research is the study of research through the use of research methods. Also known as "research on research", it aims to reduce waste and increase the quality of research in all fields. Meta-research concerns itself with the detection of bias, methodological flaws, and other errors and inefficiencies. Among the finding of meta-research is a low rates of reproducibility across a large number of fields. This widespread difficulty in reproducing research has been termed the "replication crisis."

In many disciplines, Western methods of conducting research are predominant. Researchers are overwhelmingly taught Western methods of data collection and study. The increasing participation of indigenous peoples as researchers has brought increased attention to the lacuna in culturally-sensitive methods of data collection. Western methods of data collection may not be the most accurate or relevant for research on non-Western societies. For example, "Hua Oranga" was created as a criterion for psychological evaluation in Māori populations, and is based on dimensions of mental health important to the Māori people – "taha wairua (the spiritual dimension), taha hinengaro (the mental dimension), taha tinana (the physical dimension), and taha whanau (the family dimension)".

Periphery scholars face the challenges of exclusion and linguicism in research and academic publication. As the great majority of mainstream academic journals are written in English, multilingual periphery scholars often must translate their work to be accepted to elite Western-dominated journals. Multilingual scholars' influences from their native communicative styles can be assumed to be incompetence instead of difference.

Peer review is a form of self-regulation by qualified members of a profession within the relevant field. Peer review methods are employed to maintain standards of quality, improve performance, and provide credibility. In academia, scholarly peer review is often used to determine an academic paper's suitability for publication. Usually, the peer review process involves experts in the same field who are consulted by editors to give a review of the scholarly works produced by a colleague of theirs from an unbiased and impartial point of view, and this is usually done free of charge. The tradition of peer reviews being done for free has however brought many pitfalls which are also indicative of why most peer reviewers decline many invitations to review. It was observed that publications from periphery countries rarely rise to the same elite status as those of North America and Europe, because limitations on the availability of resources including high-quality paper and sophisticated image-rendering software and printing tools render these publications less able to satisfy standards currently carrying formal or informal authority in the publishing industry. These limitations in turn result in the under-representation of scholars from periphery nations among the set of publications holding prestige status relative to the quantity and quality of those scholars' research efforts, and this under-representation in turn results in disproportionately reduced acceptance of the results of their efforts as contributions to the body of knowledge available worldwide.

The open access movement assumes that all information generally deemed useful should be free and belongs to a "public domain", that of "humanity". This idea gained prevalence as a result of Western colonial history and ignores alternative conceptions of knowledge circulation. For instance, most indigenous communities consider that access to certain information proper to the group should be determined by relationships.

There is alleged to be a double standard in the Western knowledge system. On the one hand, "digital right management" used to restrict access to personal information on social networking platforms is celebrated as a protection of privacy, while simultaneously when similar functions are used by cultural groups (i.e. indigenous communities) this is denounced as "access control" and reprehended as censorship.

Even though Western dominance seems to be prominent in research, some scholars, such as Simon Marginson, argue for "the need [for] a plural university world". Marginson argues that the East Asian Confucian model could take over the Western model.

This could be due to changes in funding for research both in the East and the West. Focussed on emphasizing educational achievement, East Asian cultures, mainly in China and South Korea, have encouraged the increase of funding for research expansion. In contrast, in the Western academic world, notably in the United Kingdom as well as in some state governments in the United States, funding cuts for university research have occurred, which some say may lead to the future decline of Western dominance in research.

In several national and private academic systems, the professionalisation of research has resulted in formal job titles.

In present-day Russia, the former Soviet Union and in some post-Soviet states the term "researcher" (, "nauchny sotrudnik") is both a generic term for a person who carried out scientific research, as well as a job position within the frameworks of the USSR Academy of Sciences, Soviet universities, and in other research-oriented establishments.

The following ranks are known:

Academic publishing is a system that is necessary for academic scholars to peer review the work and make it available for a wider audience. The system varies widely by field and is also always changing, if often slowly. Most academic work is published in journal article or book form. There is also a large body of research that exists in either a thesis or dissertation form. These forms of research can be found in databases explicitly for theses and dissertations. In publishing, STM publishing is an abbreviation for academic publications in science, technology, and medicine.
Most established academic fields have their own scientific journals and other outlets for publication, though many academic journals are somewhat interdisciplinary, and publish work from several distinct fields or subfields. The kinds of publications that are accepted as contributions of knowledge or research vary greatly between fields, from the print to the electronic format. A study suggests that researchers should not give great consideration to findings that are not replicated frequently. It has also been suggested that all published studies should be subjected to some measure for assessing the validity or reliability of its procedures to prevent the publication of unproven findings. Business models are different in the electronic environment. Since about the early 1990s, licensing of electronic resources, particularly journals, has been very common. Presently, a major trend, particularly with respect to scholarly journals, is open access. There are two main forms of open access: open access publishing, in which the articles or the whole journal is freely available from the time of publication, and self-archiving, where the author makes a copy of their own work freely available on the web.

Most funding for scientific research comes from three major sources: corporate research and development departments; private foundations, for example, the Bill and Melinda Gates Foundation; and government research councils such as the National Institutes of Health in the USA and the Medical Research Council in the UK. These are managed primarily through universities and in some cases through military contractors. Many senior researchers (such as group leaders) spend a significant amount of their time applying for grants for research funds. These grants are necessary not only for researchers to carry out their research but also as a source of merit. The Social Psychology Network provides a comprehensive list of U.S. Government and private foundation funding sources.




</doc>
<doc id="154170" url="https://en.wikipedia.org/wiki?curid=154170" title="Intuition">
Intuition

Intuition is the ability to acquire knowledge without proof, evidence, or conscious reasoning, or without understanding how the knowledge was acquired. Different writers give the word "intuition" a great variety of different meanings, ranging from direct access to unconscious knowledge, unconscious cognition, inner sensing, inner insight to unconscious pattern-recognition and the ability to understand something instinctively, without the need for conscious reasoning.

The word "intuition" comes from the Latin verb "intueri" translated as "consider" or from the late middle English word "intuit", "to contemplate".

Both Eastern and Western philosophers have studied the concept in great detail. Philosophy of mind deals with the concept of intuition.

In the East intuition is mostly intertwined with religion and spirituality, and various meanings exist from different religious texts.

In Hinduism various attempts have been made to interpret the Vedic and other esoteric texts.

For Sri Aurobindo intuition comes under the realms of knowledge by identity; he describes the psychological plane in humans (often referred to as mana in sanskrit) having two arbitrary natures, the first being imprinting of psychological experiences which is constructed through sensory information (mind seeking to become aware of external world). The second nature being the action when it seeks to be aware of itself, resulting in humans being aware of their existence or aware of being angry & aware of other emotions. He terms this second nature as knowledge by identity.
He finds that at present as the result of evolution the mind has accustomed itself to depend upon certain physiological functioning and their reactions as its normal means of entering into relations with the outer material world. As a result, when we seek to know about the external world the dominant habit is through arriving at truths about things via what our senses convey to us. However, knowledge by identity, which we currently only give the awareness of human beings' existence, can be extended further to outside of ourselves resulting in intuitive knowledge.

He finds this intuitive knowledge was common to older humans (Vedic) and later was taken over by reason which currently organises our perception, thoughts and actions resulting from Vedic to metaphysical philosophy and later to experimental science. He finds that this process, which seems to be decent, is actually a circle of progress, as a lower faculty is being pushed to take up as much from a higher way of working. He finds when self-awareness in the mind is applied to one's self and the outer (other) -self, results in luminous self-manifesting identity; the reason also converts itself into the form of the self-luminous intuitional knowledge.

Osho believed consciousness of human beings to be in increasing order from basic animal instincts to intelligence and intuition, and humans being constantly living in that conscious state often moving between these states depending on their affinity. He also suggests living in the state of intuition is one of the ultimate aims of humanity.

Advaita vedanta (a school of thought) takes intuition to be an experience through which one can come in contact with an experience Brahman.

Buddhism finds intuition to be a faculty in the mind of immediate knowledge and puts the term intuition beyond the mental process of conscious thinking, as the conscious thought cannot necessarily access subconscious information, or render such information into a communicable form. In Zen Buddhism various techniques have been developed to help develop one's intuitive capability, such as koans – the resolving of which leads to states of minor enlightenment (satori). In parts of Zen Buddhism intuition is deemed a mental state between the Universal mind and one's individual, discriminating mind.

In Islam there are various scholars with varied interpretations of intuition (often termed as hadas (Arabic: حدس), hitting correctly on a mark), sometimes relating the ability of having intuitive knowledge to prophethood. 
Siháb al Din-al Suhrawadi, in his book "Philosophy Of Illumination" (ishraq), finds that intuition is a knowledge acquired through illumination and is mystical in nature and also suggests mystical contemplation (mushahada) on this to bring about correct judgments. while Ibn Sīnā finds the ability of having intuition as a "prophetic capacity" and terms it as a knowledge obtained without intentionally acquiring it. He finds that regular knowledge is based on imitation while intuitive knowledge is based on intellectual certitude.

In the West, intuition does not appear as a separate field of study, and early mentions and definitions can be traced back to Plato. In his book "Republic" he tries to define intuition as a fundamental capacity of human reason to comprehend the true nature of reality. In his works "Meno" and "Phaedo", he describes intuition as a pre-existing knowledge residing in the "soul of eternity", and a phenomenon by which one becomes conscious of pre-existing knowledge. He provides an example of mathematical truths, and posits that they are not arrived at by reason. He argues that these truths are accessed using a knowledge already present in a dormant form and accessible to our intuitive capacity. This concept by Plato is also sometimes referred to as anamnesis. The study was later continued by his followers.

In his book "Meditations on First Philosophy", Descartes refers to an intuition as a pre-existing knowledge gained through rational reasoning or discovering truth through contemplation. This definition is commonly referred to as rational intuition. Later philosophers, such as Hume, have more ambiguous interpretations of intuition. Hume claims intuition is a recognition of relationships (relation of time, place, and causation) while he states that "the resemblance" (recognition of relations) "will strike the eye" (which would not require further examination) but goes on to state, "or rather in mind"—attributing intuition to power of mind, contradicting the theory of empiricism.

Immanuel Kant finds intuition is thought of as basic sensory information provided by the cognitive faculty of sensibility (equivalent to what might loosely be called perception). Kant held that our mind casts all of our external intuitions in the form of space, and all of our internal intuitions (memory, thought) in the form of time. Intuitionism is a position advanced by Luitzen Egbertus Jan Brouwer in philosophy of mathematics derived from Kant's claim that all mathematical knowledge is knowledge of the pure forms of the intuition—that is, intuition that is not empirical. Intuitionistic logic was devised by Arend Heyting to accommodate this position (and has been adopted by other forms of constructivism in general). It is characterized by rejecting the law of excluded middle: as a consequence it does not in general accept rules such as double negation elimination and the use of reductio ad absurdum to prove the existence of something.

Intuitions are customarily appealed to independently of any particular theory of how intuitions provide evidence for claims, and there are divergent accounts of what sort of mental state intuitions are, ranging from mere spontaneous judgment to a special presentation of a necessary truth. In recent years a number of philosophers, especially George Bealer have tried to defend appeals to intuition against Quinean doubts about conceptual analysis. A different challenge to appeals to intuition has recently come from experimental philosophers, who argue that appeals to intuition must be informed by the methods of social science.

The metaphilosophical assumption that philosophy depends on intuitions has recently been challenged by some philosophers. Timothy Williamson has argued that intuition plays no special role in philosophy practice, and that skepticism about intuition cannot be meaningfully separated from a general skepticism about judgment. On this view, there are no qualitative differences between the methods of philosophy and common sense, the sciences or mathematics.

According to Sigmund Freud, knowledge could only be attained through the intellectual manipulation of carefully made observations and rejected any other means of acquiring knowledge such as intuition, and his findings could have been an analytic turn of his mind towards the subject.

In Carl Jung's theory of the ego, described in 1916 in "Psychological Types", intuition is an "irrational function", opposed most directly by sensation, and opposed less strongly by the "rational functions" of thinking and feeling. Jung defined intuition as "perception via the unconscious": using sense-perception only as a starting point, to bring forth ideas, images, possibilities, ways out of a blocked situation, by a process that is mostly unconscious.

Jung said that a person in whom intuition is dominant, an "intuitive type", acts not on the basis of rational judgment but on sheer intensity of perception. An extraverted intuitive type, "the natural champion of all minorities with a future", orients to new and promising but unproven possibilities, often leaving to chase after a new possibility before old ventures have borne fruit, oblivious to his or her own welfare in the constant pursuit of change. An introverted intuitive type orients by images from the unconscious, ever exploring the psychic world of the archetypes, seeking to perceive the meaning of events, but often having no interest in playing a role in those events and not seeing any connection between the contents of the psychic world and him- or herself. Jung thought that extraverted intuitive types were likely entrepreneurs, speculators, cultural revolutionaries, often undone by a desire to escape every situation before it becomes settled and constraining—even repeatedly leaving lovers for the sake of new romantic possibilities. His introverted intuitive types were likely mystics, prophets, or cranks, struggling with a tension between protecting their visions from influence by others and making their ideas comprehensible and reasonably persuasive to others—a necessity for those visions to bear real fruit.

In more-recent psychology, intuition can encompass the ability to know valid solutions to problems and decision making. For example, the recognition primed decision (RPD) model explains how people can make relatively fast decisions without having to compare options. Gary Klein found that under time pressure, high stakes, and changing parameters, experts used their base of experience to identify similar situations and intuitively choose feasible solutions. Thus, the RPD model is a blend of intuition and analysis. The intuition is the pattern-matching process that quickly suggests feasible courses of action. The analysis is the mental simulation, a conscious and deliberate review of the courses of action.

Instinct is often misinterpreted as intuition and its reliability considered to be dependent on past knowledge and occurrences in a specific area. For example, someone who has had more experiences with children will tend to have a better instinct about what they should do in certain situations with them. This is not to say that one with a great amount of experience is always going to have an accurate intuition.

Intuitive abilities were quantitatively tested at Yale University in the 1970s. While studying nonverbal communication, researchers noted that some subjects were able to read nonverbal facial cues before reinforcement occurred. In employing a similar design, they noted that highly intuitive subjects made decisions quickly but could not identify their rationale. Their level of accuracy, however, did not differ from that of non-intuitive subjects.

According to the works of Daniel Kahneman, intuition is the ability to automatically generate solutions without long logical arguments or evidence.

Intuition, as a gut feeling based on experience, has been found to be useful for business leaders for making judgement about people, culture and strategy. Law enforcement officers often claim to observe suspects and immediately "know" that they possess a weapon or illicit narcotic substances, which could also be action of instincts. Often unable to articulate why they reacted or what prompted them at the time of the event, they sometimes retrospectively can plot their actions based upon what had been clear and present danger signals. Such examples liken intuition to "gut feelings" and when viable illustrate preconscious activity.

Intuition Peak in Antarctica is so named "in appreciation of the role of scientific intuition for the advancement of human knowledge."



</doc>
<doc id="59301865" url="https://en.wikipedia.org/wiki?curid=59301865" title="Scholar">
Scholar

A scholar is a person who devotes themselves to scholarly pursuits, particularly to the study of an area in which they have developed expertise. A scholar may also be an academic, a person who works as a teacher or researcher at a university or other higher education institution. An academic usually holds an advanced degree.

The term scholar is sometimes used with equivalent meaning to that of "academic" and describes in general those who attain mastery in a research discipline. However, it has wider application, with it also being used to describe those whose occupation was researched prior to organized higher education. In 1847, minister Emanuel Vogel Gerhart delivered an extensive address on the role of the scholar in society, writing:

Gerhart argued that a scholar can not be focused on a single discipline, contending that knowledge of multiple disciplines is necessary to put each into context and to inform the development of each:

A more recent examination outlined the following attributes commonly accorded to scholars as "described by many writers, with some slight variations in the definition":

Scholars may rely on the scholarly method or scholarship, a body of principles and practices used by scholars to make their claims about the world as valid and trustworthy as possible, and to make them known to the scholarly public. It is the methods that systemically advance the teaching, research, and practice of a given scholarly or academic field of study through rigorous inquiry. Scholarship is creative, can be documented, can be replicated or elaborated, and can be and is peer-reviewed through various methods.

Scholars have generally been upheld as creditable figures engaged in work important to the advance of society. In Imperial China, in the period from 206 BC until AD 1912, the intellectuals were the "Scholar-officials" ("Scholar-gentlemen"), who were civil servants appointed by the Emperor of China to perform the tasks of daily governance. Such civil servants earned academic degrees by means of imperial examination, and also were skilled calligraphers, and knew Confucian philosophy. Historian Wing-Tsit Chan concludes that:

In Joseon Korea (1392–1910), the intellectuals were the "literati", who knew how to read and write, and had been designated, as the chungin (the "middle people"), in accordance with the Confucian system. Socially, they constituted the petite bourgeoisie, composed of scholar-bureaucrats (scholars, professionals, and technicians) who administered the dynastic rule of the Joseon dynasty.

In his 1847 address, Gerhart asserted that scholars have an obligation to constantly continue their studies so as to remain aware of new knowledge being generated, and to contribute their own insights to the body of knowledge available to all:

Many scholars are also professors engaged in the teaching of others. In a number of countries, the title "research professor" refers to a professor who is exclusively or mainly engaged in research, and who has few or no teaching obligations. For example, the title is used in this sense in the United Kingdom (where it is known as research professor at some universities and professorial research fellow at some other institutions) and in northern Europe. Research professor is usually the most senior rank of a research-focused career pathway in those countries, and regarded as equal to the ordinary full professor rank. Most often they are permanent employees, and the position is often held by particularly distinguished scholars; thus the position is often seen as more prestigious than an ordinary full professorship. The title is used in a somewhat similar sense in the United States, with the exception that research professors in the United States are often not permanent employees and often must fund their salary from external sources, which is usually not the case elsewhere.

An independent scholar is anyone who conducts scholarly research outside universities and traditional academia. In the United States, a professional association exists for independent scholars: this association is the National Coalition of Independent Scholars. In Canada, the equivalent professional association is the Canadian Academy of Independent Scholars (in association with Simon Fraser University). Similar organizations exist around the world. Membership in a professional association generally entails a degree of post-secondary education and established research.




</doc>
<doc id="61032" url="https://en.wikipedia.org/wiki?curid=61032" title="Rationality">
Rationality

Rationality is the quality or state of being rational – that is, being based on or agreeable to reason. Rationality implies the conformity of one's beliefs with one's reasons to believe, and of one's actions with one's reasons for action. "Rationality" has different specialized meanings in philosophy, economics, sociology, psychology, evolutionary biology, game theory and political science.

To determine what behavior is the most rational, one needs to make several key assumptions, and also needs a logical formulation of the problem. When the goal or problem involves making a decision, rationality factors in all information that is available (e.g. complete or incomplete knowledge). Collectively, the formulation and background assumptions are the model within which rationality applies. Rationality is relative: if one accepts a model in which benefitting oneself is optimal, then rationality is equated with behavior that is self-interested to the point of being selfish; whereas if one accepts a model in which benefiting the group is optimal, then purely selfish behavior is deemed irrational. It is thus meaningless to assert rationality without also specifying the background model assumptions describing how the problem is framed and formulated.

The German sociologist Max Weber proposed an interpretation of social action that distinguished between four different idealized types of rationality. The first, which he called "Zweckrational" or purposive/instrumental rationality, is related to the expectations about the behavior of other human beings or objects in the environment. These expectations serve as means for a particular actor to attain ends, ends which Weber noted were "rationally pursued and calculated." The second type, Weber called "Wertrational" or value/belief-oriented. Here the action is undertaken for what one might call reasons intrinsic to the actor: some ethical, aesthetic, religious or other motive, independent of whether it will lead to success. The third type was affectual, determined by an actor's specific affect, feeling, or emotion—to which Weber himself said that this was a kind of rationality that was on the borderline of what he considered "meaningfully oriented." The fourth was traditional or conventional, determined by ingrained habituation. Weber emphasized that it was very unusual to find only one of these orientations: combinations were the norm. His usage also makes clear that he considered the first two as more significant than the others, and it is arguable that the third and fourth are subtypes of the first two.

The advantage in Weber's interpretation of rationality is that it avoids a value-laden assessment, say, that certain kinds of beliefs are irrational. Instead, Weber suggests that a ground or motive can be given—for religious or affect reasons, for example—that may meet the criterion of explanation or justification even if it is not an explanation that fits the "Zweckrational" orientation of means and ends. The opposite is therefore also true: some means-ends explanations will not satisfy those whose grounds for action are "Wertrational".

Weber's constructions of rationality have been critiqued both from a Habermasian (1984) perspective (as devoid of social context and under-theorised in terms of social power) and also from a feminist perspective (Eagleton, 2003) whereby Weber's rationality constructs are viewed as imbued with masculine values and oriented toward the maintenance of male power. An alternative position on rationality (which includes both bounded rationality, as well as the affective and value-based arguments of Weber) can be found in the critique of Etzioni (1988), who reframes thought on decision-making to argue for a reversal of the position put forward by Weber. Etzioni illustrates how purposive/instrumental reasoning is subordinated by normative considerations (ideas on how people 'ought' to behave) and affective considerations (as a support system for the development of human relationships).

In the psychology of reasoning, psychologists and cognitive scientists have defended different positions on human rationality. One prominent view, due to Philip Johnson-Laird and Ruth M. J. Byrne among others is that humans are rational in principle but they err in practice, that is, humans have the competence to be rational but their performance is limited by various factors. However, it has been argued that many standard tests of reasoning, such as those on the conjunction fallacy, on the Wason selection task, or the base rate fallacy suffer from methodological and conceptual problems. This has led to disputes in psychology over whether researchers should (only) use standard rules of logic, probability theory and statistics, or rational choice theory as norms of good reasoning. Opponents of this view, such as Gerd Gigerenzer, favor a conception of bounded rationality, especially for tasks under high uncertainty.

Richard Brandt proposed a "reforming definition" of rationality, arguing someone is rational if their notions survive a form of cognitive-psychotherapy.

Abulof argues that rationality has become an "essentially contested concept," as its "proper use… inevitably involves endless disputes." He identifies "four fronts" for the disputes about the meaning of rationality: 

It is believed by some philosophers (notably A. C. Grayling) that a good rationale must be independent of emotions, personal feelings or any kind of instincts. Any process of evaluation or analysis, that may be called rational, is expected to be highly objective, logical and "mechanical". If these minimum requirements are not satisfied i.e. if a person has been, even slightly, influenced by personal emotions, feelings, instincts, or culturally specific moral codes and norms, then the analysis may be termed irrational, due to the injection of subjective bias.

Modern cognitive science and neuroscience show that studying the role of emotion in mental function (including topics ranging from flashes of scientific insight to making future plans), that no human has ever satisfied this criterion, except perhaps a person with no affective feelings, for example an individual with a massively damaged amygdala or severe psychopathy. Thus, such an idealized form of rationality is best exemplified by computers, and not people. However, scholars may productively appeal to the idealization as a point of reference. 

Kant had distinguished theoretical from practical reason. Rationality theorist Jesús Mosterín makes a parallel distinction between theoretical and practical rationality, although, according to him, reason and rationality are not the same: reason would be a psychological faculty, whereas rationality is an optimizing strategy. Humans are not rational by definition, but they can think and behave rationally or not, depending on whether they apply, explicitly or implicitly, the strategy of theoretical and practical rationality to the thoughts they accept and to the actions they perform.

The distinction is also described as that between epistemic rationality, the attempt to form beliefs in an unbiased manner, and instrumental rationality.

Theoretical rationality has a formal component that reduces to logical consistency and a material component that reduces to empirical support, relying on our inborn mechanisms of signal detection and interpretation. Mosterín distinguishes between involuntary and implicit belief, on the one hand, and voluntary and explicit acceptance, on the other. Theoretical rationality can more properly be said to regulate our acceptances than our beliefs. Practical rationality is the strategy for living one’s best possible life, achieving your most important goals and your own preferences in as far as possible.

As the study of arguments that are correct in virtue of their form, logic is of fundamental importance in the study of rationality. The study of rationality in logic is more concerned with epistemic rationality, that is, attaining beliefs in a rational manner, than instrumental rationality.

Rationality plays a key role and there are several strands to this. Firstly, there is the concept of instrumentality—basically the idea that people and organisations are instrumentally rational—that is, adopt the best actions to achieve their goals. Secondly, there is an axiomatic concept that rationality is a matter of being logically consistent within your preferences and beliefs. Thirdly, people have focused on accuracy of beliefs and full use of information—in this view a person who is not rational has beliefs that don't fully use the information they have.

Debates within economic sociology also arise as to whether or not people or organizations are "really" rational, as well as whether it makes sense to model them as such in formal models. Some have argued that a kind of bounded rationality makes more sense for such models.

Others think that any kind of rationality along the lines of rational choice theory is a useless concept for understanding human behavior; the term "homo economicus" (economic man: the imaginary man being assumed in economic models who is logically consistent but amoral) was coined largely in honor of this view. Behavioral economics aims to account for economic actors as they actually are, allowing for psychological biases, rather than assuming idealized instrumental rationality.

Recently, a new evolutionary approach to the relationship between emotional and cognitive phenomena has been published, redefining emotions as "the optimization system of brain functioning", and creating a new framework to try to explain numerous rational and irrational, or non-adaptive, psychological, behavioral and decision making phenomena,(Garcés & Finkel 2019) 

Within artificial intelligence, a "rational agent" is typically one that maximizes its expected utility, given its current knowledge. Utility is the usefulness of the consequences of its actions. The utility function is arbitrarily defined by the designer, but should be a function of "performance", which is the directly measurable consequences, such as winning or losing money. In order to make a safe agent that plays defensively, a nonlinear function of performance is often desired, so that the reward for winning is lower than the punishment for losing. An agent might be rational within its own problem area, but finding the rational decision for arbitrarily complex problems is not practically possible. The rationality of human thought is a key problem in the psychology of reasoning.

There is an ongoing debate over the merits of using “rationality” in the study of international relations (IR). Some scholars hold it indispensable. Others are more critical. Still, the pervasive and persistent usage of "rationality" in political science and IR is beyond dispute. "Rationality" remains ubiquitous in this field. Abulof finds that Some 40% of all scholarly references to "foreign policy" allude to "rationality"—and this ratio goes up to more than half of pertinent academic publications in the 2000s. He further argues that when it comes to concrete security and foreign policies, IR employment of rationality borders on "malpractice": rationality-based descriptions are largely either false or unfalsifiable; many observers fail to explicate the meaning of "rationality" they employ; and the concept is frequently used politically to distinguish between "us and them."



</doc>
<doc id="46426065" url="https://en.wikipedia.org/wiki?curid=46426065" title="Logic">
Logic

Logic (from the ) is the systematic study of the form of valid inference, and the most general laws of truth. A valid inference is one where there is a specific relation of logical support between the assumptions of the inference and its conclusion. In ordinary discourse, inferences may be signified by words such as "therefore", "thus", "hence", "ergo", and so on.

There is no universal agreement as to the exact scope and subject matter of logic (see , below), but it has traditionally included the classification of arguments, the systematic exposition of the 'logical form' common to all valid arguments, the study of proof and inference, including paradoxes and fallacies, and the study of syntax and semantics. Historically, logic has been studied in philosophy (since ancient times) and mathematics (since the mid-19th century), and recently logic has been studied in cognitive science (encompasses computer science, linguistics, philosophy and psychology).

The concept of logical form is central to logic. The validity of an argument is determined by its logical form, not by its content. Traditional Aristotelian syllogistic logic and modern symbolic logic are examples of formal logic.

However, agreement on what logic is has remained elusive although the field of universal logic has studied the common structure of logics.

Logic is generally considered formal when it analyzes and represents the "form" of any valid argument type. The form of an argument is displayed by representing its sentences in the formal grammar and symbolism of a logical language to make its content usable in formal inference. Simply put, to formalize simply means to translate English sentences into the language of logic.

This is called showing the "logical form" of the argument. It is necessary because indicative sentences of ordinary language show a considerable variety of form and complexity that makes their use in inference impractical. It requires, first, ignoring those grammatical features irrelevant to logic (such as gender and declension, if the argument is in Latin), replacing conjunctions irrelevant to logic (such as "but") with logical conjunctions like "and" and replacing ambiguous, or alternative logical expressions ("any", "every", etc.) with expressions of a standard type (such as "all", or the universal quantifier ∀).

Second, certain parts of the sentence must be replaced with schematic letters. Thus, for example, the expression "all Ps are Qs" shows the logical form common to the sentences "all men are mortals", "all cats are carnivores", "all Greeks are philosophers", and so on. The schema can further be condensed into the formula "A(P,Q)", where the letter "A" indicates the judgement 'all – are –'.

The importance of form was recognised from ancient times. Aristotle uses variable letters to represent valid inferences in "Prior Analytics", leading Jan Łukasiewicz to say that the introduction of variables was "one of Aristotle's greatest inventions". According to the followers of Aristotle (such as Ammonius), only the logical principles stated in schematic terms belong to logic, not those given in concrete terms. The concrete terms "man", "mortal", etc., are analogous to the substitution values of the schematic placeholders "P", "Q", "R", which were called the "matter" (Greek "hyle") of the inference.

There is a big difference between the kinds of formulas seen in traditional term logic and the predicate calculus that is the fundamental advance of modern logic. The formula "A(P,Q)" (all Ps are Qs) of traditional logic corresponds to the more complex formula formula_1 in predicate logic, involving the logical connectives for universal quantification and implication rather than just the predicate letter "A" and using variable arguments formula_2 where traditional logic uses just the term letter "P". With the complexity comes power, and the advent of the predicate calculus inaugurated revolutionary growth of the subject.

The validity of an argument depends upon the meaning or "semantics" of the sentences that make it up.

Aristotle's Organon, especially "On Interpretation", gives a cursory outline of semantics which the scholastic logicians, particularly in the thirteenth and fourteenth century, developed into a complex and sophisticated theory, called Supposition Theory. This showed how the truth of simple sentences, expressed schematically, depend on how the terms 'supposit' or "stand for" certain extra-linguistic items. For example, in part II of his Summa Logicae, William of Ockham presents a comprehensive account of the necessary and sufficient conditions for the truth of simple sentences, in order to show which arguments are valid and which are not. Thus "every A is B' is true if and only if there is something for which 'A' stands, and there is nothing for which 'A' stands, for which 'B' does not also stand."

Early modern logic defined semantics purely as a relation between ideas. Antoine Arnauld in the "Port Royal-Logic", says that 'after conceiving things by our ideas, we compare these ideas, and, finding that some belong together and some do not, we unite or separate them. This is called "affirming" or "denying", and in general "judging". Thus truth and falsity are no more than the agreement or disagreement of ideas. This suggests obvious difficulties, leading Locke to distinguish between 'real' truth, when our ideas have 'real existence' and 'imaginary' or 'verbal' truth, where ideas like harpies or centaurs exist only in the mind. This view (psychologism) was taken to the extreme in the nineteenth century, and is generally held by modern logicians to signify a low point in the decline of logic before the twentieth century.

Modern semantics is in some ways closer to the medieval view, in rejecting such psychological truth-conditions. However, the introduction of quantification, needed to solve the problem of multiple generality, rendered impossible the kind of subject-predicate analysis that underlies medieval semantics. The main modern approach is "model-theoretic semantics", based on Alfred Tarski's semantic theory of truth. The approach assumes that the meaning of the various parts of the propositions are given by the possible ways we can give a recursively specified group of interpretation functions from them to some predefined domain of discourse: an interpretation of first-order predicate logic is given by a mapping from terms to a universe of individuals, and a mapping from propositions to the truth values "true" and "false". Model-theoretic semantics is one of the fundamental concepts of model theory. Modern semantics also admits rival approaches, such as the proof-theoretic semantics that associates the meaning of propositions with the roles that they can play in inferences, an approach that ultimately derives from the work of Gerhard Gentzen on structural proof theory and is heavily influenced by Ludwig Wittgenstein's later philosophy, especially his aphorism "meaning is use".

"Inference" is not to be confused with "implication". An implication is a sentence of the form 'If p then q', and can be true or false. The Stoic logician Philo of Megara was the first to define the truth conditions of such an implication: false only when the antecedent p is true and the consequent q is false, in all other cases true. An inference, on the other hand, consists of two separately asserted propositions of the form 'p therefore q'. An inference is not true or false, but valid or invalid. However, there is a connection between implication and inference, as follows: if the implication 'if p then q' is "true", the inference 'p therefore q' is "valid". This was given an apparently paradoxical formulation by Philo, who said that the implication 'if it is day, it is night' is true only at night, so the inference 'it is day, therefore it is night' is valid in the night, but not in the day.

The theory of inference (or 'consequences') was systematically developed in medieval times by logicians such as William of Ockham and Walter Burley. It is uniquely medieval, though it has its origins in Aristotle's Topics and Boethius' "De Syllogismis hypotheticis". This is why many terms in logic are Latin. For example, the rule that licenses the move from the implication 'if p then q' plus the assertion of its antecedent p, to the assertion of the consequent q is known as modus ponens (or 'mode of positing'). Its Latin formulation is 'Posito antecedente ponitur consequens'. The Latin formulations of many other rules such as 'ex falso quodlibet' (anything follows from a falsehood), 'reductio ad absurdum' (disproof by showing the consequence is absurd) also date from this period.

However, the theory of consequences, or of the so-called 'hypothetical syllogism' was never fully integrated into the theory of the 'categorical syllogism'. This was partly because of the resistance to reducing the categorical judgment 'Every S is P' to the so-called hypothetical judgment 'if anything is S, it is P'. The first was thought to imply 'some S is P', the second was not, and as late as 1911 in the Encyclopædia Britannica article on Logic, we find the Oxford logician T.H. Case arguing against Sigwart's and Brentano's modern analysis of the universal proposition.

A formal system is an organization of terms used for the analysis of deduction. It consists of an alphabet, a language over the alphabet to construct sentences, and a rule for deriving sentences. Among the important properties that logical systems can have are:

Some logical systems do not have all four properties. As an example, Kurt Gödel's incompleteness theorems show that sufficiently complex formal systems of arithmetic cannot be consistent and complete; however, first-order predicate logics not extended by specific axioms to be arithmetic formal systems with equality can be complete and consistent.

As the study of argument is of clear importance to the reasons that we hold things to be true, logic is of essential importance to rationality. Here we have defined logic to be "the systematic study of the form of arguments"; the reasoning behind argument is of several sorts, but only some of these arguments fall under the aegis of logic proper.

Deductive reasoning concerns the logical consequence of given premises and is the form of reasoning most closely connected to logic. On a narrow conception of logic (see below) logic concerns just deductive reasoning, although such a narrow conception controversially excludes most of what is called informal logic from the discipline.

There are other forms of reasoning that are rational but that are generally not taken to be part of logic. These include inductive reasoning, which covers forms of inference that move from collections of particular judgements to universal judgements, and abductive reasoning, which is a form of inference that goes from observation to a hypothesis that accounts for the reliable data (observation) and seeks to explain relevant evidence. The American philosopher Charles Sanders Peirce (1839–1914) first introduced the term as "guessing". Peirce said that to "abduce" a hypothetical explanation formula_3 from an observed surprising circumstance formula_4 is to surmise that formula_3 may be true because then formula_4 would be a matter of course. Thus, to abduce formula_3 from formula_4 involves determining that formula_3 is sufficient (or nearly sufficient), but not necessary, for formula_4.

While inductive and abductive inference are not part of logic proper, the methodology of logic has been applied to them with some degree of success. For example, the notion of deductive validity (where an inference is deductively valid if and only if there is no possible situation in which all the premises are true but the conclusion false) exists in an analogy to the notion of inductive validity, or "strength", where an inference is inductively strong if and only if its premises give some degree of probability to its conclusion. Whereas the notion of deductive validity can be rigorously stated for systems of formal logic in terms of the well-understood notions of semantics, inductive validity requires us to define a reliable generalization of some set of observations. The task of providing this definition may be approached in various ways, some less formal than others; some of these definitions may use logical association rule induction, while others may use mathematical models of probability such as decision trees.

Logic arose (see below) from a concern with correctness of argumentation. Modern logicians usually wish to ensure that logic studies just those arguments that arise from appropriately general forms of inference. For example, Thomas Hofweber writes in the "Stanford Encyclopedia of Philosophy" that logic "does not, however, cover good reasoning as a whole. That is the job of the theory of rationality. Rather it deals with inferences whose validity can be traced back to the formal features of the representations that are involved in that inference, be they linguistic, mental, or other representations."

Logic has been defined as "the study of arguments correct in virtue of their form". This has not been the definition taken in this article, but the idea that logic treats special forms of argument, deductive argument, rather than argument in general, has a history in logic that dates back at least to logicism in mathematics (19th and 20th centuries) and the advent of the influence of mathematical logic on philosophy. A consequence of taking logic to treat special kinds of argument is that it leads to identification of special kinds of truth, the logical truths (with logic equivalently being the study of logical truth), and excludes many of the original objects of study of logic that are treated as informal logic. Robert Brandom has argued against the idea that logic is the study of a special kind of logical truth, arguing that instead one can talk of the logic of material inference (in the terminology of Wilfred Sellars), with logic making explicit the commitments that were originally implicit in informal inference.

Logic comes from the Greek word "logos", originally meaning "the word" or "what is spoken", but coming to mean "thought" or "reason". In the Western World, logic was first developed by Aristotle, who called the subject 'analytics'. Aristotelian logic became widely accepted in science and mathematics and remained in wide use in the West until the early 19th century. Aristotle's system of logic was responsible for the introduction of hypothetical syllogism, temporal modal logic, and inductive logic, as well as influential vocabulary such as terms, predicables, syllogisms and propositions. There was also the rival Stoic logic.

In Europe during the later medieval period, major efforts were made to show that Aristotle's ideas were compatible with Christian faith. During the High Middle Ages, logic became a main focus of philosophers, who would engage in critical logical analyses of philosophical arguments, often using variations of the methodology of scholasticism. In 1323, William of Ockham's influential "Summa Logicae" was released. By the 18th century, the structured approach to arguments had degenerated and fallen out of favour, as depicted in Holberg's satirical play "Erasmus Montanus".
The Chinese logical philosopher Gongsun Long () proposed the paradox "One and one cannot become two, since neither becomes two." In China, the tradition of scholarly investigation into logic, however, was repressed by the Qin dynasty following the legalist philosophy of Han Feizi.

In India, the Anviksiki school of logic was founded by Medhatithi Gautama (c. 6th century BCE). Innovations in the scholastic school, called Nyaya, continued from ancient times into the early 18th century with the Navya-Nyaya school. By the 16th century, it developed theories resembling modern logic, such as Gottlob Frege's "distinction between sense and reference of proper names" and his "definition of number", as well as the theory of "restrictive conditions for universals" anticipating some of the developments in modern set theory. Since 1824, Indian logic attracted the attention of many Western scholars, and has had an influence on important 19th-century logicians such as Charles Babbage, Augustus De Morgan, and George Boole. In the 20th century, Western philosophers like Stanislaw Schayer and Klaus Glashoff have explored Indian logic more extensively.

The syllogistic logic developed by Aristotle predominated in the West until the mid-19th century, when interest in the foundations of mathematics stimulated the development of symbolic logic (now called mathematical logic). In 1854, George Boole published "An Investigation of the Laws of Thought on Which are Founded the Mathematical Theories of Logic and Probabilities", introducing symbolic logic and the principles of what is now known as Boolean logic. In 1879, Gottlob Frege published "Begriffsschrift", which inaugurated modern logic with the invention of quantifier notation, reconciling the Aristotelian and Stoic logics in a broader system, and solving such problems for which Aristotelian logic was impotent, such as the problem of multiple generality. From 1910 to 1913, Alfred North Whitehead and Bertrand Russell published "Principia Mathematica" on the foundations of mathematics, attempting to derive mathematical truths from axioms and inference rules in symbolic logic. In 1931, Gödel raised serious problems with the foundationalist program and logic ceased to focus on such issues.

The development of logic since Frege, Russell, and Wittgenstein had a profound influence on the practice of philosophy and the perceived nature of philosophical problems (see analytic philosophy) and philosophy of mathematics. Logic, especially sentential logic, is implemented in computer logic circuits and is fundamental to computer science. Logic is commonly taught by university philosophy departments, often as a compulsory discipline.

The "Organon" was Aristotle's body of work on logic, with the "Prior Analytics" constituting the first explicit work in formal logic, introducing the syllogistic. The parts of syllogistic logic, also known by the name term logic, are the analysis of the judgements into propositions consisting of two terms that are related by one of a fixed number of relations, and the expression of inferences by means of syllogisms that consist of two propositions sharing a common term as premise, and a conclusion that is a proposition involving the two unrelated terms from the premises.

Aristotle's work was regarded in classical times and from medieval times in Europe and the Middle East as the very picture of a fully worked out system. However, it was not alone: the Stoics proposed a system of propositional logic that was studied by medieval logicians. Also, the problem of multiple generality was recognized in medieval times. Nonetheless, problems with syllogistic logic were not seen as being in need of revolutionary solutions.

Today, some academics claim that Aristotle's system is generally seen as having little more than historical value (though there is some current interest in extending term logics), regarded as made obsolete by the advent of propositional logic and the predicate calculus. Others use Aristotle in argumentation theory to help develop and critically question argumentation schemes that are used in artificial intelligence and legal arguments.

A propositional calculus or logic (also a sentential calculus) is a formal system in which formulae representing propositions can be formed by combining atomic propositions using logical connectives, and in which a system of formal proof rules establishes certain formulae as "theorems". An example of a theorem of propositional logic is formula_11, which says that if A holds, then B implies A.

Predicate logic is the generic term for symbolic formal systems such as first-order logic, second-order logic, many-sorted logic, and infinitary logic. It provides an account of quantifiers general enough to express a wide set of arguments occurring in natural language. For example, Bertrand Russell's famous barber paradox, "there is a man who shaves all and only men who do not shave themselves" can be formalised by the sentence formula_12, using the non-logical predicate formula_13 to indicate that "x" is a man, and the non-logical relation formula_14 to indicate that "x" shaves "y"; all other symbols of the formulae are logical, expressing the universal and existential quantifiers, conjunction, implication, negation and biconditional.

Whilst Aristotelian syllogistic logic specifies a small number of forms that the relevant part of the involved judgements may take, predicate logic allows sentences to be analysed into subject and argument in several additional ways—allowing predicate logic to solve the problem of multiple generality that had perplexed medieval logicians.

The development of predicate logic is usually attributed to Gottlob Frege, who is also credited as one of the founders of analytical philosophy, but the formulation of predicate logic most often used today is the first-order logic presented in Principles of Mathematical Logic by David Hilbert and Wilhelm Ackermann in 1928. The analytical generality of predicate logic allowed the formalization of mathematics, drove the investigation of set theory, and allowed the development of Alfred Tarski's approach to model theory. It provides the foundation of modern mathematical logic.

Frege's original system of predicate logic was second-order, rather than first-order. Second-order logic is most prominently defended (against the criticism of Willard Van Orman Quine and others) by George Boolos and Stewart Shapiro.

In languages, modality deals with the phenomenon that sub-parts of a sentence may have their semantics modified by special verbs or modal particles. For example, ""We go to the games" can be modified to give "We should go to the games", and "We can go to the games" and perhaps "We will go to the games"". More abstractly, we might say that modality affects the circumstances in which we take an assertion to be satisfied. Confusing modality is known as the modal fallacy.

Aristotle's logic is in large parts concerned with the theory of non-modalized logic. Although, there are passages in his work, such as the famous sea-battle argument in "De Interpretatione" § 9, that are now seen as anticipations of modal logic and its connection with potentiality and time, the earliest formal system of modal logic was developed by Avicenna, who ultimately developed a theory of "temporally modalized" syllogistic.

While the study of necessity and possibility remained important to philosophers, little logical innovation happened until the landmark investigations of Clarence Irving Lewis in 1918, who formulated a family of rival axiomatizations of the alethic modalities. His work unleashed a torrent of new work on the topic, expanding the kinds of modality treated to include deontic logic and epistemic logic. The seminal work of Arthur Prior applied the same formal language to treat temporal logic and paved the way for the marriage of the two subjects. Saul Kripke discovered (contemporaneously with rivals) his theory of frame semantics, which revolutionized the formal technology available to modal logicians and gave a new graph-theoretic way of looking at modality that has driven many applications in computational linguistics and computer science, such as dynamic logic.

The motivation for the study of logic in ancient times was clear: it is so that one may learn to distinguish good arguments from bad arguments, and so become more effective in argument and oratory, and perhaps also to become a better person. Half of the works of Aristotle's Organon treat inference as it occurs in an informal setting, side by side with the development of the syllogistic, and in the Aristotelian school, these informal works on logic were seen as complementary to Aristotle's treatment of rhetoric.

This ancient motivation is still alive, although it no longer takes centre stage in the picture of logic; typically dialectical logic forms the heart of a course in critical thinking, a compulsory course at many universities. Dialectic has been linked to logic since ancient times, but it has not been until recent decades that European and American logicians have attempted to provide mathematical foundations for logic and dialectic by formalising dialectical logic. Dialectical logic is also the name given to the special treatment of dialectic in Hegelian and Marxist thought. There have been pre-formal treatises on argument and dialectic, from authors such as Stephen Toulmin ("The Uses of Argument"), Nicholas Rescher ("Dialectics"), and van Eemeren and Grootendorst (Pragma-dialectics). Theories of defeasible reasoning can provide a foundation for the formalisation of dialectical logic and dialectic itself can be formalised as moves in a game, where an advocate for the truth of a proposition and an opponent argue. Such games can provide a formal game semantics for many logics.

Argumentation theory is the study and research of informal logic, fallacies, and critical questions as they relate to every day and practical situations. Specific types of dialogue can be analyzed and questioned to reveal premises, conclusions, and fallacies. Argumentation theory is now applied in artificial intelligence and law.

Mathematical logic comprises two distinct areas of research: the first is the application of the techniques of formal logic to mathematics and mathematical reasoning, and the second, in the other direction, the application of mathematical techniques to the representation and analysis of formal logic.

The earliest use of mathematics and geometry in relation to logic and philosophy goes back to the ancient Greeks such as Euclid, Plato, and Aristotle. Many other ancient and medieval philosophers applied mathematical ideas and methods to their philosophical claims.

One of the boldest attempts to apply logic to mathematics was the logicism pioneered by philosopher-logicians such as Gottlob Frege and Bertrand Russell. Mathematical theories were supposed to be logical tautologies, and the programme was to show this by means of a reduction of mathematics to logic. The various attempts to carry this out met with failure, from the crippling of Frege's project in his "Grundgesetze" by Russell's paradox, to the defeat of Hilbert's program by Gödel's incompleteness theorems.

Both the statement of Hilbert's program and its refutation by Gödel depended upon their work establishing the second area of mathematical logic, the application of mathematics to logic in the form of proof theory. Despite the negative nature of the incompleteness theorems, Gödel's completeness theorem, a result in model theory and another application of mathematics to logic, can be understood as showing how close logicism came to being true: every rigorously defined mathematical theory can be exactly captured by a first-order logical theory; Frege's proof calculus is enough to "describe" the whole of mathematics, though not "equivalent" to it.

If proof theory and model theory have been the foundation of mathematical logic, they have been but two of the four pillars of the subject. Set theory originated in the study of the infinite by Georg Cantor, and it has been the source of many of the most challenging and important issues in mathematical logic, from Cantor's theorem, through the status of the Axiom of Choice and the question of the independence of the continuum hypothesis, to the modern debate on large cardinal axioms.

Recursion theory captures the idea of computation in logical and arithmetic terms; its most classical achievements are the undecidability of the Entscheidungsproblem by Alan Turing, and his presentation of the Church–Turing thesis. Today recursion theory is mostly concerned with the more refined problem of complexity classes—when is a problem efficiently solvable?—and the classification of degrees of unsolvability.

Philosophical logic deals with formal descriptions of ordinary, non-specialist ("natural") language, that is strictly only about the arguments within philosophy's other branches. Most philosophers assume that the bulk of everyday reasoning can be captured in logic if a method or methods to translate ordinary language into that logic can be found. Philosophical logic is essentially a continuation of the traditional discipline called "logic" before the invention of mathematical logic. Philosophical logic has a much greater concern with the connection between natural language and logic. As a result, philosophical logicians have contributed a great deal to the development of non-standard logics (e.g. free logics, tense logics) as well as various extensions of classical logic (e.g. modal logics) and non-standard semantics for such logics (e.g. Kripke's supervaluationism in the semantics of logic).

Logic and the philosophy of language are closely related. Philosophy of language has to do with the study of how our language engages and interacts with our thinking. Logic has an immediate impact on other areas of study. Studying logic and the relationship between logic and ordinary speech can help a person better structure his own arguments and critique the arguments of others. Many popular arguments are filled with errors because so many people are untrained in logic and unaware of how to formulate an argument correctly.

Logic cut to the heart of computer science as it emerged as a discipline: Alan Turing's work on the "Entscheidungsproblem" followed from Kurt Gödel's work on the incompleteness theorems. The notion of the general purpose computer that came from this work was of fundamental importance to the designers of the computer machinery in the 1940s.

In the 1950s and 1960s, researchers predicted that when human knowledge could be expressed using logic with mathematical notation, it would be possible to create a machine that mimics the problem-solving skills of a human being. This was more difficult than expected because of the complexity of human reasoning. In the summer of 1956, John McCarthy, Marvin Minsky, Claude Shannon and Nathan Rochester organized a conference on the subject of what they called "artificial intelligence" (a term coined by McCarthy for the occasion). Newell and Simon proudly presented the group with the Logic Theorist and were somewhat surprised when the program received a lukewarm reception.

In logic programming, a program consists of a set of axioms and rules. Logic programming systems such as Prolog compute the consequences of the axioms and rules in order to answer a query.

Today, logic is extensively applied in the field of artificial intelligence, and this field provide a rich source of problems in formal and informal logic. Argumentation theory is one good example of how logic is being applied to artificial intelligence. The ACM Computing Classification System in particular regards:

Furthermore, computers can be used as tools for logicians. For example, in symbolic logic and mathematical logic, proofs by humans can be computer-assisted. Using automated theorem proving, the machines can find and check proofs, as well as work with proofs too lengthy to write out by hand.

The logics discussed above are all "bivalent" or "two-valued"; that is, they are most naturally understood as dividing propositions into true and false propositions. Non-classical logics are those systems that reject various rules of Classical logic.

Hegel developed his own dialectic logic that extended Kant's transcendental logic but also brought it back to ground by assuring us that "neither in heaven nor in earth, neither in the world of mind nor of nature, is there anywhere such an abstract 'either–or' as the understanding maintains. Whatever exists is concrete, with difference and opposition in itself".

In 1910, Nicolai A. Vasiliev extended the law of excluded middle and the law of contradiction and proposed the law of excluded fourth and logic tolerant to contradiction. In the early 20th century Jan Łukasiewicz investigated the extension of the traditional true/false values to include a third value, "possible", so inventing ternary logic, the first multi-valued logic in the Western tradition.

Logics such as fuzzy logic have since been devised with an infinite number of "degrees of truth", represented by a real number between 0 and 1.

Intuitionistic logic was proposed by L.E.J. Brouwer as the correct logic for reasoning about mathematics, based upon his rejection of the law of the excluded middle as part of his intuitionism. Brouwer rejected formalization in mathematics, but his student Arend Heyting studied intuitionistic logic formally, as did Gerhard Gentzen. Intuitionistic logic is of great interest to computer scientists, as it is a constructive logic and sees many applications, such as extracting verified programs from proofs and influencing the design of programming languages through the formulae-as-types correspondence.

Modal logic is not truth conditional, and so it has often been proposed as a non-classical logic. However, modal logic is normally formalized with the principle of the excluded middle, and its relational semantics is bivalent, so this inclusion is disputable.

What is the epistemological status of the laws of logic? What sort of argument is appropriate for criticizing purported principles of logic? In an influential paper entitled "Is Logic Empirical?" Hilary Putnam, building on a suggestion of W. V. Quine, argued that in general the facts of propositional logic have a similar epistemological status as facts about the physical universe, for example as the laws of mechanics or of general relativity, and in particular that what physicists have learned about quantum mechanics provides a compelling case for abandoning certain familiar principles of classical logic: if we want to be realists about the physical phenomena described by quantum theory, then we should abandon the principle of distributivity, substituting for classical logic the quantum logic proposed by Garrett Birkhoff and John von Neumann.

Another paper of the same name by Michael Dummett argues that Putnam's desire for realism mandates the law of distributivity. Distributivity of logic is essential for the realist's understanding of how propositions are true of the world in just the same way as he has argued the principle of bivalence is. In this way, the question, "Is Logic Empirical?" can be seen to lead naturally into the fundamental controversy in metaphysics on realism versus anti-realism.

The notion of implication formalized in classical logic does not comfortably translate into natural language by means of "if ... then ...", due to a number of problems called the paradoxes of material implication.

The first class of paradoxes involves counterfactuals, such as "If the moon is made of green cheese, then 2+2=5", which are puzzling because natural language does not support the principle of explosion. Eliminating this class of paradoxes was the reason for C.I. Lewis's formulation of strict implication, which eventually led to more radically revisionist logics such as relevance logic.

The second class of paradoxes involves redundant premises, falsely suggesting that we know the succedent because of the antecedent: thus "if that man gets elected, granny will die" is materially true since granny is mortal, regardless of the man's election prospects. Such sentences violate the Gricean maxim of relevance, and can be modelled by logics that reject the principle of monotonicity of entailment, such as relevance logic.

Hegel was deeply critical of any simplified notion of the law of non-contradiction. It was based on Gottfried Wilhelm Leibniz's idea that this law of logic also requires a sufficient ground to specify from what point of view (or time) one says that something cannot contradict itself. A building, for example, both moves and does not move; the ground for the first is our solar system and for the second the earth. In Hegelian dialectic, the law of non-contradiction, of identity, itself relies upon difference and so is not independently assertable.

Closely related to questions arising from the paradoxes of implication comes the suggestion that logic ought to tolerate inconsistency. Relevance logic and paraconsistent logic are the most important approaches here, though the concerns are different: a key consequence of classical logic and some of its rivals, such as intuitionistic logic, is that they respect the principle of explosion, which means that the logic collapses if it is capable of deriving a contradiction. Graham Priest, the main proponent of dialetheism, has argued for paraconsistency on the grounds that there are in fact, true contradictions.

The philosophical vein of various kinds of skepticism contains many kinds of doubt and rejection of the various bases on which logic rests, such as the idea of logical form, correct inference, or meaning, typically leading to the conclusion that there are no logical truths. This is in contrast with the usual views in philosophical skepticism, where logic directs skeptical enquiry to doubt received wisdoms, as in the work of Sextus Empiricus.

Friedrich Nietzsche provides a strong example of the rejection of the usual basis of logic: his radical rejection of idealization led him to reject truth as a "... mobile army of metaphors, metonyms, and anthropomorphisms—in short ... metaphors which are worn out and without sensuous power; coins which have lost their pictures and now matter only as metal, no longer as coins." His rejection of truth did not lead him to reject the idea of either inference or logic completely, but rather suggested that "logic [came] into existence in man's head [out] of illogic, whose realm originally must have been immense. Innumerable beings who made inferences in a way different from ours perished". Thus there is the idea that logical inference has a use as a tool for human survival, but that its existence does not support the existence of truth, nor does it have a reality beyond the instrumental: "Logic, too, also rests on assumptions that do not correspond to anything in the real world".

This position held by Nietzsche however, has come under extreme scrutiny for several reasons. Some philosophers, such as Jürgen Habermas, claim his position is self-refuting—and accuse Nietzsche of not even having a coherent perspective, let alone a theory of knowledge. Georg Lukács, in his book "The Destruction of Reason", asserts that, "Were we to study Nietzsche's statements in this area from a logico-philosophical angle, we would be confronted by a dizzy chaos of the most lurid assertions, arbitrary and violently incompatible." Bertrand Russell described Nietzsche's irrational claims with "He is fond of expressing himself paradoxically and with a view to shocking conventional readers" in his book "A History of Western Philosophy".



</doc>
<doc id="1005874" url="https://en.wikipedia.org/wiki?curid=1005874" title="Principle">
Principle

A principle is a proposition or value that is a guide for behavior or evaluation. In law, it is a rule that has to be or usually is to be followed, or can be desirably followed, or is an inevitable consequence of something, such as the laws observed in nature or the way that a system is constructed. The principles of such a system are understood by its users as the essential characteristics of the system, or reflecting system's designed purpose, and the effective operation or use of which would be impossible if any one of the principles was to be ignored. A system may be explicitly based on and implemented from a document of principles as was done in IBM's 360/370 "Principles of Operation".

Examples of principles are, entropy in a number of fields, least action in physics, those in descriptive comprehensive and fundamental law: doctrines or assumptions forming normative rules of conduct, separation of church and state in statecraft, the central dogma of molecular biology, fairness in ethics, etc.

In common English, it is a substantive and collective term referring to rule governance, the absence of which, being "unprincipled", is considered a character defect. It may also be used to declare that a reality has diverged from some ideal or norm as when something is said to be true only "in principle" but not in fact.

A principle represents values that orient and rule the conduct of persons in a particular society. To "act on principle" is to act in accordance with one's moral ideals. Principles are absorbed in childhood through a process of socialization. There is a presumption of liberty of individuals that is restrained. Exemplary principles include First, do no harm, the golden rule and the doctrine of the mean.

It represents a set of values that inspire the written norms that organize the life of a society submitting to the powers of an authority, generally the State. The law establishes a legal obligation, in a coercive way; it therefore acts as principle conditioning of the action that limits the liberty of the individuals. See, for examples, the territorial principle, homestead principle, and precautionary principle.

Archimedes principle, relating buoyancy to the weight of displaced water, is an early example of a law in science. Another early one developed by Malthus is the "population principle", now called the Malthusian principle. Freud also wrote on principles, especially the reality principle necessary to keep the id and pleasure principle in check. Biologists use the principle of priority and principle of Binominal nomenclature for precision in naming species. There are many principles observed in physics, notably in cosmology which observes the mediocrity principle, the anthropic principle, the principle of relativity and the cosmological principle. Other well-known principles include the uncertainty principle in quantum mechanics and the pigeonhole principle and superposition principle in mathematics.

The principle states that every event has a rational explanation. The principle has a variety of expressions, all of which are perhaps best summarized by the following:

However, one realizes that in every sentence there is a direct relation between the predicate and the subject. To say that "the Earth is round", corresponds to a direct relation between the subject and the predicate.

According to Aristotle, “It is impossible for the same thing to belong and not to belong at the same time to the same thing and in the same respect.” For example, it is not possible that in exactly the same moment and place, it rains and doesn't rain.

The principle of the excluding third or "principium tertium exclusum" is a principle of the traditional logic formulated canonically by Leibniz as: either "A" is "B" or "A" isn't "B". It is read the following way: either "P" is true, or its denial ¬"P" is.
It is also known as "tertium non datur" ('A third (thing) is not). Classically it is considered to be one of the most important fundamental principles or laws of thought (along with the principles of identity, no contradiction and sufficient reason).


</doc>
<doc id="319762" url="https://en.wikipedia.org/wiki?curid=319762" title="Logos">
Logos

Logos (, ; ; from , , ) is a term in Western philosophy, psychology, rhetoric, and religion derived from a Greek word variously meaning "ground", "plea", "opinion", "expectation", "word", "speech", "account", "reason", "proportion", and "discourse". It became a technical term in Western philosophy beginning with Heraclitus (), who used the term for a principle of order and knowledge.

Ancient Greek philosophers used the term in different ways. The sophists used the term to mean discourse. Aristotle applied the term to refer to "reasoned discourse" or "the argument" in the field of rhetoric, and considered it one of the three modes of persuasion alongside "ethos" and "pathos". Pyrrhonist philosophers used the term to refer to dogmatic accounts of non-evident matters. The Stoics spoke of the "logos spermatikos" (the generative principle of the Universe) which foreshadows related concepts in Neoplatonism.

Within Hellenistic Judaism, Philo () adopted the term into Jewish philosophy.
Philo distinguished between "logos prophorikos" ("the uttered word") and the "logos endiathetos" ("the word remaining within").

The Gospel of John identifies the Christian Logos, through which all things are made, as divine ("theos"), and further identifies Jesus Christ as the incarnate Logos. Early translators of the Greek New Testament such as Jerome (in the 4th century AD) were frustrated by the inadequacy of any single Latin word to convey the meaning of the word "logos" as used to describe Jesus Christ in the Gospel of John. The Vulgate Bible usage of was thus constrained to use the (perhaps inadequate) noun for "word", but later Romance language translations had the advantage of nouns such as in French. Reformation translators took another approach. Martin Luther rejected (verb) in favor of (word), for instance, although later commentators repeatedly turned to a more dynamic use involving "the living word" as felt by Jerome and Augustine. The term is also used in Sufism, and the analytical psychology of Carl Jung.

Despite the conventional translation as "word", it is not used for a word in the grammatical sense; instead, the term "lexis" (, ) was used. However, both "logos" and "lexis" derive from the same verb (), meaning "(I) count, tell, say, speak".

The writing of Heraclitus () was the first place where the word "logos" was given special attention in ancient Greek philosophy, although Heraclitus seems to use the word with a meaning not significantly different from the way in which it was used in ordinary Greek of his time. For Heraclitus, "logos" provided the link between rational discourse and the world's rational structure.

What "logos" means here is not certain; it may mean "reason" or "explanation" in the sense of an objective cosmic law, or it may signify nothing more than "saying" or "wisdom". Yet, an independent existence of a universal "logos" was clearly suggested by Heraclitus.

Aristotle identifies two specific types of persuasion methods: artistic and inartistic. He defines artistic proofs as arguments that the rhetor generates and creates on their own. Examples of these include relationships, testimonies, and conjugates. He defines inartistic proofs as arguments that the rhetor quotes using information from a non-self-generated source. Examples of these include laws, contracts, and oaths.

Following one of the other meanings of the word, Aristotle gave "logos" a different technical definition in the "Rhetoric", using it as meaning argument from reason, one of the three modes of persuasion. The other two modes are "pathos" (, ), which refers to persuasion by means of emotional appeal, "putting the hearer into a certain frame of mind"; and "ethos" (, ), persuasion through convincing listeners of one's "moral character". According to Aristotle, "logos" relates to "the speech itself, in so far as it proves or seems to prove". In the words of Paul Rahe:

"Logos", "pathos", and "ethos" can all be appropriate at different times. Arguments from reason (logical arguments) have some advantages, namely that data are (ostensibly) difficult to manipulate, so it is harder to argue against such an argument; and such arguments make the speaker look prepared and knowledgeable to the audience, enhancing "ethos". On the other hand, trust in the speaker—built through "ethos"—enhances the appeal of arguments from reason.

Robert Wardy suggests that what Aristotle rejects in supporting the use of "logos" "is not emotional appeal per se, but rather emotional appeals that have no 'bearing on the issue', in that the "pathē" [, ] they stimulate lack, or at any rate are not shown to possess, any intrinsic connection with the point at issue—as if an advocate were to try to whip an antisemitic audience into a fury because the accused is Jewish; or as if another in drumming up support for a politician were to exploit his listeners's reverential feelings for the politician's ancestors".

Aristotle comments on the three modes by stating: 
The Pyrrhonist philosopher Sextus Empiricus defined the Pyrrhonist usage of "logos" as "When we say 'To every logos an equal logos is opposed,' by 'every logos' we mean 'every logos that has been considered by us,' and we use 'logos' not in its ordinary sense but for that which establishes something dogmatically, that is to say, concerning the non-evident, and which establishes it in any way at all, not necessarily by means of premises and conclusion."

Stoic philosophy began with Zeno of Citium , in which the "logos" was the active reason pervading and animating the Universe. It was conceived as material and is usually identified with God or Nature. The Stoics also referred to the "seminal logos" (""logos spermatikos"), or the law of generation in the Universe, which was the principle of the active reason working in inanimate matter. Humans, too, each possess a portion of the divine "logos".

The Stoics took all activity to imply a "logos" or spiritual principle. As the operative principle of the world, the "logos" was "anima mundi" to them, a concept which later influenced Philo of Alexandria, although he derived the contents of the term from Plato. In his Introduction to the 1964 edition of Marcus Aurelius' "Meditations", the Anglican priest Maxwell Staniforth wrote that "Logos" ... had long been one of the leading terms of Stoicism, chosen originally for the purpose of explaining how deity came into relation with the universe".

Public discourse on ancient Greek rhetoric has historically emphasized Aristotle's appeals to "logos", "pathos", and "ethos", while less attention has been directed to Isocrates' teachings about philosophy and "logos", and their partnership in generating an ethical, mindful "polis". Isocrates does not provide a single definition of "logos" in his work, but Isocratean "logos" characteristically focuses on speech, reason, and civic discourse. He was concerned with establishing the "common good" of Athenian citizens, which he believed could be achieved through the pursuit of philosophy and the application of "logos".

In the Septuagint the term "logos" is used for the word of God in the creation of heaven in Psalm 33:6, and in some related contexts.

Philo (), a Hellenized Jew, used the term "logos" to mean an intermediary divine being or demiurge. Philo followed the Platonic distinction between imperfect matter and perfect Form, and therefore intermediary beings were necessary to bridge the enormous gap between God and the material world. The "logos" was the highest of these intermediary beings, and was called by Philo "the first-born of God".
Philo also wrote that "the Logos of the living God is the bond of everything, holding all things together and binding all the parts, and prevents them from being dissolved and separated".

Plato's Theory of Forms was located within the "logos", but the "logos]] also acted on behalf of God in the physical world. In particular, the Angel of the Lord in the Hebrew Bible (Old Testament) was identified with the "logos" by Philo, who also said that the "logos" was God's instrument in the creation of the Universe.

In Christology, the "Logos" () is a name or title of Jesus Christ, seen as the pre-existent second person of the Trinity. The concept derives from , which in the Douay–Rheims, King James, New International, and other versions of the Bible, reads:

Neoplatonist philosophers such as Plotinus (270 AD) used "logos" in ways that drew on Plato and the Stoics, but the term "logos" was interpreted in different ways throughout Neoplatonism, and similarities to Philo's concept of "logos" appear to be accidental. The "logos" was a key element in the meditations of Plotinus regarded as the first Neoplatonist. Plotinus referred back to Heraclitus and as far back as Thales in interpreting "logos" as the principle of meditation, existing as the interrelationship between the hypostases—the soul, the intellect ("nous"), and the One.

Plotinus used a trinity concept that consisted of "The One", the "Spirit", and "Soul". The comparison with the Christian Trinity is inescapable, but for Plotinus these were not equal and "The One" was at the highest level, with the "Soul" at the lowest. For Plotinus, the relationship between the three elements of his trinity is conducted by the outpouring of "logos" from the higher principle, and "eros" (loving) upward from the lower principle. Plotinus relied heavily on the concept of "logos", but no explicit references to Christian thought can be found in his works, although there are significant traces of them in his doctrine. Plotinus specifically avoided using the term "logos" to refer to the second person of his trinity. However, Plotinus influenced Gaius Marius Victorinus, who then influenced Augustine of Hippo. Centuries later, Carl Jung acknowledged the influence of Plotinus in his writings.

Victorinus differentiated between the "logos" interior to God and the "logos" related to the world by creation and salvation.

Augustine of Hippo, often seen as the father of medieval philosophy, was also greatly influenced by Plato and is famous for his re-interpretation of Aristotle and Plato in the light of early Christian thought. A young Augustine experimented with, but failed to achieve ecstasy using the meditations of Plotinus. In his "Confessions", Augustine described "logos" as the "Divine Eternal Word", by which he, in part, was able to motivate the early Christian thought throughout the Hellenized world (of which the Latin speaking West was a part) Augustine's "logos" "had taken body" in Christ, the man in whom the "logos" (i.e. or ) was present as in no other man.

The concept of the "logos" also exists in Islam, where it was definitively articulated primarily in the writings of the classical Sunni mystics and Islamic philosophers, as well as by certain Shi'a thinkers, during the Islamic Golden Age. In Sunni Islam, the concept of the "logos" has been given many different names by the denomination's metaphysicians, mystics, and philosophers, including "ʿaql" ("Intellect"), "al-insān al-kāmil" ("Universal Man"), "kalimat Allāh" ("Word of God"), "haqīqa muḥammadiyya" ("The Muhammadan Reality"), and "nūr muḥammadī" ("The Muhammadan Light").

One of the names given to a concept very much like the Christian Logos by the classical Muslim metaphysicians is "ʿaql", which is the "Arabic equivalent to the Greek (intellect)." In the writings of the Islamic Neoplatonist philosophers, such as al-Farabi () and Avicenna (d. 1037), the idea of the "ʿaql" was presented in a manner that both resembled "the late Greek doctrine" and, likewise, "corresponded in many respects to the Logos Christology."

The concept of "logos" in Sufism is used to relate the "Uncreated" (God) to the "Created" (humanity). In Sufism, for the Deist, no contact between man and God can be possible without the "logos". The "logos" is everywhere and always the same, but its personification is "unique" within each region. Jesus and Muhammad are seen as the personifications of the "logos", and this is what enables them to speak in such absolute terms.

One of the boldest and most radical attempts to reformulate the Neoplatonic concepts into Sufism arose with the philosopher Ibn Arabi, who traveled widely in Spain and North Africa. His concepts were expressed in two major works "The Ringstones of Wisdom" ("Fusus al-Hikam") and "The Meccan Illuminations" ("Al-Futūḥāt al-Makkiyya"). To Ibn Arabi, every prophet corresponds to a reality which he called a "logos" ("Kalimah"), as an aspect of the unique divine being. In his view the divine being would have for ever remained hidden, had it not been for the prophets, with "logos" providing the link between man and divinity.

Ibn Arabi seems to have adopted his version of the "logos" concept from Neoplatonic and Christian sources, although (writing in Arabic rather than Greek) he used more than twenty different terms when discussing it. For Ibn Arabi, the "logos" or "Universal Man" was a mediating link between individual human beings and the divine essence.

Other Sufi writers also show the influence of the Neoplatonic "logos". In the 15th century Abd al-Karīm al-Jīlī introduced the "Doctrine of Logos and the Perfect Man". For al-Jīlī, the "perfect man" (associated with the "logos" or the Prophet) has the power to assume different forms at different times and to appear in different guises.

In Ottoman Sufism, Şeyh Gâlib (d. 1799) articulates Sühan ("logos"-"Kalima") in his "Hüsn ü Aşk" ("Beauty and Love") in parallel to Ibn Arabi's Kalima. In the romance, "Sühan" appears as an embodiment of Kalima as a reference to the Word of God, the Perfect Man, and the Reality of Muhammad.

Carl Jung contrasted the critical and rational faculties of "logos" with the emotional, non-reason oriented and mythical elements of "eros". In Jung's approach, "logos" vs "eros" can be represented as "science vs mysticism", or "reason vs imagination" or "conscious activity vs the unconscious".

For Jung, "logos" represented the masculine principle of rationality, in contrast to its female counterpart, "eros":

Jung attempted to equate "logos" and "eros", his intuitive conceptions of masculine and feminine consciousness, with the alchemical Sol and Luna. Jung commented that in a man the lunar anima and in a woman the solar animus has the greatest influence on consciousness. Jung often proceeded to analyze situations in terms of "paired opposites", e.g. by using the analogy with the eastern yin and yang and was also influenced by the Neoplatonists.

In his book "Mysterium Coniunctionis" Jung made some important final remarks about anima and animus:
And in this book Jung again emphasized that the animus compensates "eros", while the anima'compensates "logos".

Author and professor Jeanne Fahnestock describes "logos" as a "premise". She states that, to find the reason behind a rhetor's backing of a certain position or stance, one must acknowledge the different "premises" that the rhetor applies via his or her chosen diction. The rhetor's success, she argues, will come down to "certain objects of agreement...between arguer and audience". "Logos is logical appeal, and the term logic is derived from it. It is normally used to describe facts and figures that support the speaker's topic." Furthermore, "logos" is credited with appealing to the audience's sense of logic, with the definition of "logic" being concerned with the thing as it is known.
Furthermore, one can appeal to this sense of logic in two ways. The first is through inductive reasoning, providing the audience with relevant examples and using them to point back to the overall statement. The second is through deductive enthymeme, providing the audience with general scenarios and then indicating commonalities among them.

The word "logos" has been used in different senses along with "rhema". Both Plato and Aristotle used the term "logos" along with "rhema" to refer to sentences and propositions.

The Septuagint translation of the Hebrew Bible into Greek uses the terms "rhema" and "logos" as equivalents and uses both for the Hebrew word "dabar", as the Word of God.

Some modern usage in Christian theology distinguishes "rhema" from "logos" (which here refers to the written scriptures) while "rhema" refers to the revelation received by the reader from the Holy Spirit when the Word ("logos") is read, although this distinction has been criticized.



</doc>
<doc id="44917295" url="https://en.wikipedia.org/wiki?curid=44917295" title="Informality">
Informality

Informality is an umbrella concept to refer to the social and cultural complexity associated with non-transparency of social phenomena for the outsiders: unwritten rules, open secrets, and hidden practices.

The term ‘informality’ is often used to describe unplanned settlements as well as shadow, second and covert economies. Ordinally, informality is linked to poverty, underdevelopment, oppressive regimes, socialism and communism, but in fact informal practices are central for the functioning of every society. Old boy network, caffè sospeso, cash for access, astroturfing and kompromat are just a few examples of the various techniques and the geography of informality. The Global Encyclopedia of Informality consists of more than 200 entries from five continents.


</doc>
<doc id="30758" url="https://en.wikipedia.org/wiki?curid=30758" title="Age of Enlightenment">
Age of Enlightenment

The Age of Enlightenment (also known as the Age of Reason or simply the Enlightenment) was an intellectual and philosophical movement that dominated the world of ideas in Europe during the 18th century, the "Century of Philosophy".

Some consider the publication of Isaac Newton's "Principia Mathematica" (1687) as the first major enlightenment work. French historians traditionally date the Enlightenment from 1715 to 1789, from the beginning of the reign of Louis XV until the French Revolution. Most end it with the turn of the 19th century. Philosophers and scientists of the period widely circulated their ideas through meetings at scientific academies, Masonic lodges, literary salons, coffeehouses and in printed books, journals, and pamphlets. The ideas of the Enlightenment undermined the authority of the monarchy and the Church and paved the way for the political revolutions of the 18th and 19th centuries. A variety of 19th-century movements, including liberalism and neo-classicism, trace their intellectual heritage to the Enlightenment.

The Enlightenment included a range of ideas centered on reason as the primary source of knowledge and advanced ideals such as liberty, progress, toleration, fraternity, constitutional government and separation of church and state. In France, the central doctrines of the Enlightenment philosophers were individual liberty and religious tolerance, in opposition to an absolute monarchy and the fixed dogmas of the Roman Catholic Church. The Enlightenment was marked by an emphasis on the scientific method and reductionism, along with increased questioning of religious orthodoxy—an attitude captured by the phrase "Sapere aude" (Dare to know).

The Age of Enlightenment was preceded by and closely associated with the scientific revolution. Earlier philosophers whose work influenced the Enlightenment included Bacon and Descartes. The major figures of the Enlightenment included Beccaria, Diderot, Hume, Kant, Montesquieu, Rousseau, Adam Smith, and Voltaire. Some European rulers, including Catherine II of Russia, Joseph II of Austria and Frederick II of Prussia, tried to apply Enlightenment thought on religious and political tolerance, which became known as enlightened absolutism. Benjamin Franklin visited Europe repeatedly and contributed actively to the scientific and political debates there and brought the newest ideas back to Philadelphia. Thomas Jefferson closely followed European ideas and later incorporated some of the ideals of the Enlightenment into the Declaration of Independence (1776). One of his peers, James Madison, incorporated these ideals into the United States Constitution during its framing in 1787.

The most influential publication of the Enlightenment was the "" ("Encyclopaedia"). Published between 1751 and 1772 in thirty-five volumes, it was compiled by Diderot, d'Alembert (until 1759) and a team of 150 scientists and philosophers. It helped spread the ideas of the Enlightenment across Europe and beyond. Other landmark publications were Voltaire's "Dictionnaire philosophique" ("Philosophical Dictionary"; 1764) and "Letters on the English" (1733); Rousseau's "Discourse on Inequality" (1754) and "The Social Contract" (1762); Adam Smith's "The Theory of Moral Sentiments" (1759) and "The Wealth of Nations" (1776); and Montesquieu's "The Spirit of the Laws" (1748). The ideas of the Enlightenment played a major role in inspiring the French Revolution, which began in 1789. After the Revolution, the Enlightenment was followed by the intellectual movement known as Romanticism.

René Descartes' rationalist philosophy laid the foundation for enlightenment thinking. His attempt to construct the sciences on a secure metaphysical foundation was not as successful as his method of doubt applied in philosophic areas leading to a dualistic doctrine of mind and matter. His skepticism was refined by John Locke's Essay Concerning Human Understanding (1690) and David Hume's writings in the 1740s. His dualism was challenged by Spinoza's uncompromising assertion of the unity of matter in his Tractatus (1670) and Ethics (1677).

These laid down two distinct lines of Enlightenment thought: first, the moderate variety, following Descartes, Locke and Christian Wolff, which sought accommodation between reform and the traditional systems of power and faith, and second, the radical enlightenment, inspired by the philosophy of Spinoza, advocating democracy, individual liberty, freedom of expression and eradication of religious authority. The moderate variety tended to be deistic, whereas the radical tendency separated the basis of morality entirely from theology. Both lines of thought were eventually opposed by a conservative Counter-Enlightenment, which sought a return to faith.

In the mid-18th century, Paris became the center of an explosion of philosophic and scientific activity challenging traditional doctrines and dogmas. The philosophic movement was led by Voltaire and Jean-Jacques Rousseau, who argued for a society based upon reason as in ancient Greece rather than faith and Catholic doctrine, for a new civil order based on natural law, and for science based on experiments and observation. The political philosopher Montesquieu introduced the idea of a separation of powers in a government, a concept which was enthusiastically adopted by the authors of the United States Constitution. While the "Philosophes" of the French Enlightenment were not revolutionaries and many were members of the nobility, their ideas played an important part in undermining the legitimacy of the Old Regime and shaping the French Revolution.

Francis Hutcheson, a moral philosopher, described the utilitarian and consequentialist principle that virtue is that which provides, in his words, "the greatest happiness for the greatest numbers". Much of what is incorporated in the scientific method (the nature of knowledge, evidence, experience and causation) and some modern attitudes towards the relationship between science and religion were developed by his protégés David Hume and Adam Smith. Hume became a major figure in the skeptical philosophical and empiricist traditions of philosophy.

Immanuel Kant (1724–1804) tried to reconcile rationalism and religious belief, individual freedom and political authority, as well as map out a view of the public sphere through private and public reason. Kant's work continued to shape German thought and indeed all of European philosophy, well into the 20th century. 

Mary Wollstonecraft was one of England's earliest feminist philosophers. She argued for a society based on reason and that women as well as men should be treated as rational beings. She is best known for her work "A Vindication of the Rights of Woman" (1791).

Science played an important role in Enlightenment discourse and thought. Many Enlightenment writers and thinkers had backgrounds in the sciences and associated scientific advancement with the overthrow of religion and traditional authority in favour of the development of free speech and thought. Scientific progress during the Enlightenment included the discovery of carbon dioxide (fixed air) by the chemist Joseph Black, the argument for deep time by the geologist James Hutton and the invention of the condensing steam engine by James Watt. The experiments of Lavoisier were used to create the first modern chemical plants in Paris and the experiments of the Montgolfier Brothers enabled them to launch the first manned flight in a hot-air balloon on 21 November 1783 from the Château de la Muette, near the Bois de Boulogne.

Broadly speaking, Enlightenment science greatly valued empiricism and rational thought and was embedded with the Enlightenment ideal of advancement and progress. The study of science, under the heading of natural philosophy, was divided into physics and a conglomerate grouping of chemistry and natural history, which included anatomy, biology, geology, mineralogy and zoology. As with most Enlightenment views, the benefits of science were not seen universally: Rousseau criticized the sciences for distancing man from nature and not operating to make people happier. Science during the Enlightenment was dominated by scientific societies and academies, which had largely replaced universities as centres of scientific research and development. Societies and academies were also the backbone of the maturation of the scientific profession. Another important development was the popularization of science among an increasingly literate population. Philosophes introduced the public to many scientific theories, most notably through the "Encyclopédie" and the popularization of Newtonianism by Voltaire and Émilie du Châtelet. Some historians have marked the 18th century as a drab period in the history of science. However, the century saw significant advancements in the practice of medicine, mathematics and physics; the development of biological taxonomy; a new understanding of magnetism and electricity; and the maturation of chemistry as a discipline, which established the foundations of modern chemistry.

Scientific academies and societies grew out of the Scientific Revolution as the creators of scientific knowledge in contrast to the scholasticism of the university. During the Enlightenment, some societies created or retained links to universities, but contemporary sources distinguished universities from scientific societies by claiming that the university's utility was in the transmission of knowledge while societies functioned to create knowledge. As the role of universities in institutionalized science began to diminish, learned societies became the cornerstone of organized science. Official scientific societies were chartered by the state in order to provide technical expertise. Most societies were granted permission to oversee their own publications, control the election of new members and the administration of the society. After 1700, a tremendous number of official academies and societies were founded in Europe and by 1789 there were over seventy official scientific societies. In reference to this growth, Bernard de Fontenelle coined the term "the Age of Academies" to describe the 18th century.

The influence of science also began appearing more commonly in poetry and literature during the Enlightenment. Some poetry became infused with scientific metaphor and imagery, while other poems were written directly about scientific topics. Sir Richard Blackmore committed the Newtonian system to verse in "Creation, a Philosophical Poem in Seven Books" (1712). After Newton's death in 1727, poems were composed in his honour for decades. James Thomson (1700–1748) penned his "Poem to the Memory of Newton", which mourned the loss of Newton, but also praised his science and legacy.

Hume and other Scottish Enlightenment thinkers developed a "science of man", which was expressed historically in works by authors including James Burnett, Adam Ferguson, John Millar and William Robertson, all of whom merged a scientific study of how humans behaved in ancient and primitive cultures with a strong awareness of the determining forces of modernity. Modern sociology largely originated from this movement and Hume's philosophical concepts that directly influenced James Madison (and thus the U.S. Constitution) and as popularised by Dugald Stewart, would be the basis of classical liberalism.

In 1776, Adam Smith published "The Wealth of Nations", often considered the first work on modern economics as it had an immediate impact on British economic policy that continues into the 21st century. It was immediately preceded and influenced by Anne-Robert-Jacques Turgot, Baron de Laune drafts of "Reflections on the Formation and Distribution of Wealth" (Paris, 1766). Smith acknowledged indebtedness and possibly was the original English translator.

Cesare Beccaria, a jurist, criminologist, philosopher and politician and one of the great Enlightenment writers, became famous for his masterpiece "Of Crimes and Punishments" (1764), later translated into 22 languages, which condemned torture and the death penalty and was a founding work in the field of penology and the Classical School of criminology by promoting criminal justice. Another prominent intellectual was Francesco Mario Pagano, who wrote important studies such as "Saggi Politici" (Political Essays, 1783), one of the major works of the Enlightenment in Naples; and "Considerazioni sul processo criminale" (Considerations on the criminal trial, 1787), which established him as an international authority on criminal law.

The Enlightenment has long been hailed as the foundation of modern Western political and intellectual culture. The Enlightenment brought political modernization to the West, in terms of introducing democratic values and institutions and the creation of modern, liberal democracies. This thesis has been widely accepted by Anglophone scholars and has been reinforced by the large-scale studies by Robert Darnton, Roy Porter and most recently by Jonathan Israel.

John Locke, one of the most influential Enlightenment thinkers, based his governance philosophy in social contract theory, a subject that permeated Enlightenment political thought. The English philosopher Thomas Hobbes ushered in this new debate with his work "Leviathan" in 1651. Hobbes also developed some of the fundamentals of European liberal thought: the right of the individual; the natural equality of all men; the artificial character of the political order (which led to the later distinction between civil society and the state); the view that all legitimate political power must be "representative" and based on the consent of the people; and a liberal interpretation of law which leaves people free to do whatever the law does not explicitly forbid.

Both Locke and Rousseau developed social contract theories in "Two Treatises of Government" and "Discourse on Inequality", respectively. While quite different works, Locke, Hobbes and Rousseau agreed that a social contract, in which the government's authority lies in the consent of the governed, is necessary for man to live in civil society. Locke defines the state of nature as a condition in which humans are rational and follow natural law, in which all men are born equal and with the right to life, liberty and property. However, when one citizen breaks the Law of Nature both the transgressor and the victim enter into a state of war, from which it is virtually impossible to break free. Therefore, Locke said that individuals enter into civil society to protect their natural rights via an "unbiased judge" or common authority, such as courts, to appeal to. Contrastingly, Rousseau's conception relies on the supposition that "civil man" is corrupted, while "natural man" has no want he cannot fulfill himself. Natural man is only taken out of the state of nature when the inequality associated with private property is established. Rousseau said that people join into civil society via the social contract to achieve unity while preserving individual freedom. This is embodied in the sovereignty of the general will, the moral and collective legislative body constituted by citizens.

Locke is known for his statement that individuals have a right to "Life, Liberty and Property" and his belief that the natural right to property is derived from labor. Tutored by Locke, Anthony Ashley-Cooper, 3rd Earl of Shaftesbury wrote in 1706: "There is a mighty Light which spreads its self over the world especially in those two free Nations of England and Holland; on whom the Affairs of Europe now turn". Locke's theory of natural rights has influenced many political documents, including the United States Declaration of Independence and the French National Constituent Assembly's Declaration of the Rights of Man and of the Citizen.

The "philosophes" argued that the establishment of a contractual basis of rights would lead to the market mechanism and capitalism, the scientific method, religious tolerance and the organization of states into self-governing republics through democratic means. In this view, the tendency of the "philosophes" in particular to apply rationality to every problem is considered the essential change.

Although much of Enlightenment political thought was dominated by social contract theorists, both David Hume and Adam Ferguson criticized this camp. Hume's essay "Of the Original Contract" argues that governments derived from consent are rarely seen and civil government is grounded in a ruler's habitual authority and force. It is precisely because of the ruler's authority over-and-against the subject, that the subject tacitly consents and Hume says that the subjects would "never imagine that their consent made him sovereign", rather the authority did so. Similarly, Ferguson did not believe citizens built the state, rather polities grew out of social development. In his 1767 "An Essay on the History of Civil Society", Ferguson uses the four stages of progress, a theory that was very popular in Scotland at the time, to explain how humans advance from a hunting and gathering society to a commercial and civil society without "signing" a social contract.

Both Rousseau and Locke's social contract theories rest on the presupposition of natural rights, which are not a result of law or custom, but are things that all men have in pre-political societies and are therefore universal and inalienable. The most famous natural right formulation comes from John Locke in his "Second Treatise", when he introduces the state of nature. For Locke, the law of nature is grounded on mutual security or the idea that one cannot infringe on another's natural rights, as every man is equal and has the same inalienable rights. These natural rights include perfect equality and freedom, as well as the right to preserve life and property. Locke also argued against slavery on the basis that enslaving yourself goes against the law of nature because you cannot surrender your own rights, your freedom is absolute and no one can take it from you. Additionally, Locke argues that one person cannot enslave another because it is morally reprehensible, although he introduces a caveat by saying that enslavement of a lawful captive in time of war would not go against one's natural rights.

As a spillover of the Enlightenment, nonsecular beliefs expressed first by Quakers and then by Protestant evangelicals in Britain and the United States emerged. To these groups, slavery became "repugnant to our religion" and a "crime in the sight of God." These ideas added to those expressed by Enlightenment thinkers, leading many in Britain to believe that slavery was "not only morally wrong and economically inefficient, but also politically unwise." As these notions gained more adherents, Britain was forced to end its participation in the slave trade.

The leaders of the Enlightenment were not especially democratic, as they more often look to absolute monarchs as the key to imposing reforms designed by the intellectuals. Voltaire despised democracy and said the absolute monarch must be enlightened and must act as dictated by reason and justice – in other words, be a "philosopher-king".

In several nations, rulers welcomed leaders of the Enlightenment at court and asked them to help design laws and programs to reform the system, typically to build stronger states. These rulers are called "enlightened despots" by historians. They included Frederick the Great of Prussia, Catherine the Great of Russia, Leopold II of Tuscany and Joseph II of Austria. Joseph was over-enthusiastic, announcing many reforms that had little support so that revolts broke out and his regime became a comedy of errors and nearly all his programs were reversed. Senior ministers Pombal in Portugal and Johann Friedrich Struensee in Denmark also governed according to Enlightenment ideals. In Poland, the model constitution of 1791 expressed Enlightenment ideals, but was in effect for only one year before the nation was partitioned among its neighbors. More enduring were the cultural achievements, which created a nationalist spirit in Poland.

Frederick the Great, the king of Prussia from 1740 to 1786, saw himself as a leader of the Enlightenment and patronized philosophers and scientists at his court in Berlin. Voltaire, who had been imprisoned and maltreated by the French government, was eager to accept Frederick's invitation to live at his palace. Frederick explained: "My principal occupation is to combat ignorance and prejudice ... to enlighten minds, cultivate morality, and to make people as happy as it suits human nature, and as the means at my disposal permit".

The Enlightenment has been frequently linked to the French Revolution of 1789. One view of the political changes that occurred during the Enlightenment is that the "consent of the governed" philosophy as delineated by Locke in "Two Treatises of Government" (1689) represented a paradigm shift from the old governance paradigm under feudalism known as the "divine right of kings". In this view, the revolutions of the late 1700s and early 1800s were caused by the fact that this governance paradigm shift often could not be resolved peacefully and therefore violent revolution was the result. Clearly a governance philosophy where the king was never wrong was in direct conflict with one whereby citizens by natural law had to consent to the acts and rulings of their government.

Alexis de Tocqueville proposed the French Revolution as the inevitable result of the radical opposition created in the 18th century between the monarchy and the men of letters of the Enlightenment. These men of letters constituted a sort of "substitute aristocracy that was both all-powerful and without real power". This illusory power came from the rise of "public opinion", born when absolutist centralization removed the nobility and the bourgeoisie from the political sphere. The "literary politics" that resulted promoted a discourse of equality and was hence in fundamental opposition to the monarchical regime. De Tocqueville "clearly designates  ... the cultural effects of transformation in the forms of the exercise of power".

Enlightenment era religious commentary was a response to the preceding century of religious conflict in Europe, especially the Thirty Years' War. Theologians of the Enlightenment wanted to reform their faith to its generally non-confrontational roots and to limit the capacity for religious controversy to spill over into politics and warfare while still maintaining a true faith in God. For moderate Christians, this meant a return to simple Scripture. John Locke abandoned the corpus of theological commentary in favor of an "unprejudiced examination" of the Word of God alone. He determined the essence of Christianity to be a belief in Christ the redeemer and recommended avoiding more detailed debate. In the "Jefferson Bible", Thomas Jefferson went further and dropped any passages dealing with miracles, visitations of angels and the resurrection of Jesus after his death, as he tried to extract the practical Christian moral code of the New Testament.

Enlightenment scholars sought to curtail the political power of organized religion and thereby prevent another age of intolerant religious war. Spinoza determined to remove politics from contemporary and historical theology (e.g., disregarding Judaic law). Moses Mendelssohn advised affording no political weight to any organized religion, but instead recommended that each person follow what they found most convincing. They believed a good religion based in instinctive morals and a belief in God should not theoretically need force to maintain order in its believers, and both Mendelssohn and Spinoza judged religion on its moral fruits, not the logic of its theology.

A number of novel ideas about religion developed with the Enlightenment, including deism and talk of atheism. According to Thomas Paine, deism is the simple belief in God the Creator, with no reference to the Bible or any other miraculous source. Instead, the deist relies solely on personal reason to guide his creed, which was eminently agreeable to many thinkers of the time. Atheism was much discussed, but there were few proponents. Wilson and Reill note: "In fact, very few enlightened intellectuals, even when they were vocal critics of Christianity, were true atheists. Rather, they were critics of orthodox belief, wedded rather to skepticism, deism, vitalism, or perhaps pantheism". Some followed Pierre Bayle and argued that atheists could indeed be moral men. Many others like Voltaire held that without belief in a God who punishes evil, the moral order of society was undermined. That is, since atheists gave themselves to no Supreme Authority and no law and had no fear of eternal consequences, they were far more likely to disrupt society. Bayle (1647–1706) observed that, in his day, "prudent persons will always maintain an appearance of [religion]," and he believed that even atheists could hold concepts of honor and go beyond their own self-interest to create and interact in society. Locke said that if there were no God and no divine law, the result would be moral anarchy: every individual "could have no law but his own will, no end but himself. He would be a god to himself, and the satisfaction of his own will the sole measure and end of all his actions."

The "Radical Enlightenment" promoted the concept of separating church and state, an idea that is often credited to English philosopher John Locke (1632–1704). According to his principle of the social contract, Locke said that the government lacked authority in the realm of individual conscience, as this was something rational people could not cede to the government for it or others to control. For Locke, this created a natural right in the liberty of conscience, which he said must therefore remain protected from any government authority.

These views on religious tolerance and the importance of individual conscience, along with the social contract, became particularly influential in the American colonies and the drafting of the United States Constitution. Thomas Jefferson called for a "wall of separation between church and state" at the federal level. He previously had supported successful efforts to disestablish the Church of England in Virginia and authored the Virginia Statute for Religious Freedom. Jefferson's political ideals were greatly influenced by the writings of John Locke, Francis Bacon, and Isaac Newton, whom he considered the three greatest men that ever lived.

The Enlightenment took hold in most European countries, often with a specific local emphasis. For example, in France it became associated with anti-government and anti-Church radicalism, while in Germany it reached deep into the middle classes, where it expressed a spiritualistic and nationalistic tone without threatening governments or established churches. Government responses varied widely. In France, the government was hostile, and the "philosophes" fought against its censorship, sometimes being imprisoned or hounded into exile. The British government, for the most part, ignored the Enlightenment's leaders in England and Scotland, although it did give Isaac Newton a knighthood and a very lucrative government office.

The very existence of an English Enlightenment has been hotly debated by scholars. The majority of textbooks on British history make little or no mention of an English Enlightenment. Some surveys of the entire Enlightenment include England and others ignore it, although they do include coverage of such major intellectuals as Joseph Addison, Edward Gibbon, John Locke, Isaac Newton, Alexander Pope, Joshua Reynolds and Jonathan Swift. Roy Porter argues that the reasons for this neglect were the assumptions that the movement was primarily French-inspired, that it was largely a-religious or anti-clerical, and that it stood in outspoken defiance to the established order. Porter admits that, after the 1720s, England could claim thinkers to equal Diderot, Voltaire or Rousseau. However, its leading intellectuals such as Edward Gibbon, Edmund Burke and Samuel Johnson were all quite conservative and supportive of the standing order. Porter says the reason was that Enlightenment had come early to England and had succeeded so that the culture had accepted political liberalism, philosophical empiricism, and religious toleration of the sort that intellectuals on the continent had to fight for against powerful odds. Furthermore, England rejected the collectivism of the continent and emphasized the improvement of individuals as the main goal of enlightenment.

In the Scottish Enlightenment, Scotland's major cities created an intellectual infrastructure of mutually supporting institutions such as universities, reading societies, libraries, periodicals, museums and masonic lodges. The Scottish network was "predominantly liberal Calvinist, Newtonian, and 'design' oriented in character which played a major role in the further development of the transatlantic Enlightenment". In France, Voltaire said that "we look to Scotland for all our ideas of civilization". The focus of the Scottish Enlightenment ranged from intellectual and economic matters to the specifically scientific as in the work of William Cullen, physician and chemist; James Anderson, an agronomist; Joseph Black, physicist and chemist; and James Hutton, the first modern geologist.

Several Americans, especially Benjamin Franklin and Thomas Jefferson, played a major role in bringing Enlightenment ideas to the New World and in influencing British and French thinkers. Franklin was influential for his political activism and for his advances in physics. The cultural exchange during the Age of Enlightenment ran in both directions across the Atlantic. Thinkers such as Paine, Locke and Rousseau all take Native American cultural practices as examples of natural freedom. The Americans closely followed English and Scottish political ideas, as well as some French thinkers such as Montesquieu. As deists, they were influenced by ideas of John Toland (1670–1722) and Matthew Tindal (1656–1733). During the Enlightenment there was a great emphasis upon liberty, republicanism and religious tolerance. There was no respect for monarchy or inherited political power. Deists reconciled science and religion by rejecting prophecies, miracles and Biblical theology. Leading deists included Thomas Paine in "The Age of Reason" and by Thomas Jefferson in his short "Jefferson Bible" – from which all supernatural aspects were removed.

Prussia took the lead among the German states in sponsoring the political reforms that Enlightenment thinkers urged absolute rulers to adopt. There were important movements as well in the smaller states of Bavaria, Saxony, Hanover and the Palatinate. In each case, Enlightenment values became accepted and led to significant political and administrative reforms that laid the groundwork for the creation of modern states. The princes of Saxony, for example, carried out an impressive series of fundamental fiscal, administrative, judicial, educational, cultural and general economic reforms. The reforms were aided by the country's strong urban structure and influential commercial groups and modernized pre-1789 Saxony along the lines of classic Enlightenment principles..
Before 1750, the German upper classes looked to France for intellectual, cultural and architectural leadership, as French was the language of high society. By the mid-18th century, the "Aufklärung" (The Enlightenment) had transformed German high culture in music, philosophy, science and literature. Christian Wolff (1679–1754) was the pioneer as a writer who expounded the Enlightenment to German readers and legitimized German as a philosophic language.

Johann Gottfried von Herder (1744–1803) broke new ground in philosophy and poetry, as a leader of the Sturm und Drang movement of proto-Romanticism. Weimar Classicism ("Weimarer Klassik") was a cultural and literary movement based in Weimar that sought to establish a new humanism by synthesizing Romantic, classical and Enlightenment ideas. The movement (from 1772 until 1805) involved Herder as well as polymath Johann Wolfgang von Goethe (1749–1832) and Friedrich Schiller (1759–1805), a poet and historian. Herder argued that every folk had its own particular identity, which was expressed in its language and culture. This legitimized the promotion of German language and culture and helped shape the development of German nationalism. Schiller's plays expressed the restless spirit of his generation, depicting the hero's struggle against social pressures and the force of destiny.

German music, sponsored by the upper classes, came of age under composers Johann Sebastian Bach (1685–1750), Joseph Haydn (1732–1809) and Wolfgang Amadeus Mozart (1756–1791).

In remote Königsberg, philosopher Immanuel Kant (1724–1804) tried to reconcile rationalism and religious belief, individual freedom and political authority. Kant's work contained basic tensions that would continue to shape German thought – and indeed all of European philosophy – well into the 20th century.

The German Enlightenment won the support of princes, aristocrats and the middle classes and it permanently reshaped the culture. However, there was a conservatism among the elites that warned against going too far.

In the 1780s, Lutheran ministers Johann Heinrich Schulz and Karl Wilhelm Brumbey got in trouble with their preaching as they were attacked and ridiculed by Immanuel Kant, Wilhelm Abraham Teller and others. In 1788, Prussia issued an "Edict on Religion" that forbade preaching any sermon that undermined popular belief in the Holy Trinity and the Bible. The goal was to avoid skepticism, deism and theological disputes that might impinge on domestic tranquility. Men who doubted the value of Enlightenment favoured the measure, but so too did many supporters. German universities had created a closed elite that could debate controversial issues among themselves, but spreading them to the public was seen as too risky. This intellectual elite was favoured by the state, but that might be reversed if the process of the Enlightenment proved politically or socially destabilizing.

The Enlightenment played a distinctive, if small, role in the history of Italy. Although most of Italy was controlled by conservative Habsburgs or the pope, Tuscany had some opportunities for reform. Leopold II of Tuscany abolished the death penalty in Tuscany and reduced censorship. From Naples, Antonio Genovesi (1713–1769) influenced a generation of southern Italian intellectuals and university students. His textbook "Diceosina, o Sia della Filosofia del Giusto e dell'Onesto" (1766) was a controversial attempt to mediate between the history of moral philosophy on the one hand and the specific problems encountered by 18th-century commercial society on the other. It contained the greater part of Genovesi's political, philosophical and economic thought – guidebook for Neapolitan economic and social development. Science flourished as Alessandro Volta and Luigi Galvani made break-through discoveries in electricity. Pietro Verri was a leading economist in Lombardy. Historian Joseph Schumpeter states he was "the most important pre-Smithian authority on Cheapness-and-Plenty". The most influential scholar on the Italian Enlightenment has been Franco Venturi. Italy also produced some of the Enlightenment's greatest legal theorists, including Cesare Beccaria, Giambattista Vico and Francesco Mario Pagano. Beccaria in particular is now considered one of the fathers of classical criminal theory as well as modern penology. Beccaria is famous for his masterpiece "On Crimes and Punishments" (1764), a treatise (later translated into 22 languages) that served as one of the earliest prominent condemnations of torture and the death penalty and thus a landmark work in anti-death penalty philosophy.

In Russia, the government began to actively encourage the proliferation of arts and sciences in the mid-18th century. This era produced the first Russian university, library, theatre, public museum and independent press. Like other enlightened despots, Catherine the Great played a key role in fostering the arts, sciences and education. She used her own interpretation of Enlightenment ideals, assisted by notable international experts such as Voltaire (by correspondence) and in residence world class scientists such as Leonhard Euler and Peter Simon Pallas. The national Enlightenment differed from its Western European counterpart in that it promoted further modernization of all aspects of Russian life and was concerned with attacking the institution of serfdom in Russia. The Russian enlightenment centered on the individual instead of societal enlightenment and encouraged the living of an enlightened life. A powerful element was "prosveshchenie" which combined religious piety, erudition and commitment to the spread of learning. However, it lacked the skeptical and critical spirit of the European Enlightenment.

The enlightenment in Portugal ("iluminismo") was marked by the rule of the Prime Minister Marquis of Pombal under King Joseph I of Portugal from 1756 to 1777. Following the 1755 Lisbon earthquake which destroyed great part of Lisbon, the Marquis of Pombal implemented important economic policies to regulate commercial activity (in particular with Brazil and England), and to standardise quality throughout the country (for example by introducing the first integrated industries in Portugal). His reconstruction of Lisbon's riverside district in straight and perpendicular streets, methodically organized to facilitate commerce and exchange (for example by assigning to each street a different product or service), can be seen as a direct application of the Enlightenment ideas to governance and urbanism. His urbanistic ideas, also being the first large-scale example of earthquake engineering, became collectively known as Pombaline style, and were implemented throughout the kingdom during his stay in office. His governance was as enlightened as ruthless, see for example the Távora affair.

In literature, the first Enlightenment ideas in Portugal can be traced back to the diplomat, philosopher, and writer António Vieira (1608-1697), who spent a considerable amount of his life in colonial Brazil denouncing discriminations against New Christians and the Indigenous peoples in Brazil. His works remain today as one of the best pieces of Portuguese literature. During the 18th century, enlightened literary movements such as the Arcádia Lusitana (lasting from 1756 until 1776, then replaced by the Nova Arcádia in 1790 until 1794) surfaced in the academic medium, in particular involving former students of the University of Coimbra. A distinct member of this group was the poet Manuel Maria Barbosa du Bocage.

The ideas of the enlightenment also influenced various economists and anti-colonial intellectuals throughout the Portuguese Empire, such as José de Azeredo Coutinho, José da Silva Lisboa, Cláudio Manoel da Costa, and Tomás de Antônio Gonzaga.

Enlightenment ideas ("oświecenie") emerged late in Poland, as the Polish middle class was weaker and szlachta (nobility) culture (Sarmatism) together with the Polish-Lithuanian Commonwealth political system (Golden Liberty) were in deep crisis. The political system was built on republicanism, but was unable to defend itself against powerful neighbors Russia, Prussia and Austria as they repeatedly sliced off regions until nothing was left of independent Poland. The period of Polish Enlightenment began in the 1730s–1740s and especially in theatre and the arts peaked in the reign of King Stanisław August Poniatowski (second half of the 18th century). Warsaw was a main centre after 1750, with an expansion of schools and educational institutions and the arts patronage held at the Royal Castle. Leaders promoted tolerance and more education. They included King Stanislaw II Poniatowski and reformers Piotr Switkowski, Antoni Poplawski, Josef Niemcewicz and Jósef Pawlinkowski, as well as Baudouin de Cortenay, a Polonized dramatist. Opponents included Florian Jaroszewicz, Gracjan Piotrowski, Karol Wyrwicz and Wojciech Skarszewski.

The movement went into decline with the Third Partition of Poland (1795) – a national tragedy inspiring a short period of sentimental writing – and ended in 1822, replaced by Romanticism.

The Enlightenment has always been contested territory. According to Keith Thomas, its supporters "hail it as the source of everything that is progressive about the modern world. For them, it stands for freedom of thought, rational inquiry, critical thinking, religious tolerance, political liberty, scientific achievement, the pursuit of happiness, and hope for the future." Thomas adds that its detractors accuse it of shallow rationalism, naïve optimism, unrealistic universalism and moral darkness. From the start, conservative and clerical defenders of traditional religion attacked materialism and skepticism as evil forces that encouraged immorality. By 1794, they pointed to the Terror during the French Revolution as confirmation of their predictions. As the Enlightenment was ending, Romantic philosophers argued that excessive dependence on reason was a mistake perpetuated by the Enlightenment because it disregarded the bonds of history, myth, faith, and tradition that were necessary to hold society together.

The term "Enlightenment" emerged in English in the later part of the 19th century, with particular reference to French philosophy, as the equivalent of the French term "Lumières" (used first by Dubos in 1733 and already well established by 1751). From Immanuel Kant's 1784 essay "Beantwortung der Frage: Was ist Aufklärung?" (""), the German term became "Aufklärun"g ("aufklären" = to illuminate; "sich aufklären" = to clear up). However, scholars have never agreed on a definition of the Enlightenment, or on its chronological or geographical extent. Terms like "les Lumières" (French), "illuminism"o (Italian), "ilustración" (Spanish) and "Aufklärung" (German) referred to partly overlapping movements. Not until the late nineteenth century did English scholars agree they were talking about "the Enlightenment".

Enlightenment historiography began in the period itself, from what Enlightenment figures said about their work. A dominant element was the intellectual angle they took. D'Alembert's "Preliminary Discourse of l'Encyclopédie" provides a history of the Enlightenment which comprises a chronological list of developments in the realm of knowledge – of which the "Encyclopédie" forms the pinnacle. In 1783, Jewish philosopher Moses Mendelssohn referred to Enlightenment as a process by which man was educated in the use of reason. Immanuel Kant called Enlightenment "man's release from his self-incurred tutelage", tutelage being "man's inability to make use of his understanding without direction from another". "For Kant, Enlightenment was mankind's final coming of age, the emancipation of the human consciousness from an immature state of ignorance". The German scholar Ernst Cassirer called the Enlightenment "a part and a special phase of that whole intellectual development through which modern philosophic thought gained its characteristic self-confidence and self-consciousness". According to historian Roy Porter, the liberation of the human mind from a dogmatic state of ignorance, is the epitome of what the Age of Enlightenment was trying to capture.

Bertrand Russell saw the Enlightenment as a phase in a progressive development which began in antiquity and that reason and challenges to the established order were constant ideals throughout that time. Russell said that the Enlightenment was ultimately born out of the Protestant reaction against the Catholic counter-reformation and that philosophical views such as affinity for democracy against monarchy originated among 16th-century Protestants to justify their desire to break away from the Catholic Church. Although many of these philosophical ideals were picked up by Catholics, Russell argues that by the 18th century the Enlightenment was the principal manifestation of the schism that began with Martin Luther.

Jonathan Israel rejects the attempts of postmodern and Marxian historians to understand the revolutionary ideas of the period purely as by-products of social and economic transformations. He instead focuses on the history of ideas in the period from 1650 to the end of the 18th century and claims that it was the ideas themselves that caused the change that eventually led to the revolutions of the latter half of the 18th century and the early 19th century. Israel argues that until the 1650s Western civilization "was based on a largely shared core of faith, tradition and authority".

There is little consensus on the precise beginning of the Age of Enlightenment, though several historians and philosophers argue that it was marked by Descartes' 1637 philosophy of "Cogito, ergo sum" ("I think, therefore I Am"), which shifted the epistemological basis from external authority to internal certainty. In France, many cited the publication of Isaac Newton's "Principia Mathematica" (1687). The middle of the 17th century (1650) or the beginning of the 18th century (1701) are often used as epochs. French historians usually place the "Siècle des Lumières" ("Century of Enlightenments") between 1715 and 1789: from the beginning of the reign of Louis XV until the French Revolution. Most scholars use the last years of the century, often choosing the French Revolution of 1789 or the beginning of the Napoleonic Wars (1804–1815) as a convenient point in time with which to date the end of the Enlightenment.

In the 1944 book "Dialectic of Enlightenment", Frankfurt School philosophers Max Horkheimer and Theodor W. Adorno argued: 

Extending Horkheimer and Adorno's argument, intellectual historian Jason Josephson-Storm has argued that any idea of the Age of Enlightenment as a clearly defined period that is separate from the earlier Renaissance and later Romanticism or Counter-Enlightenment constitutes a myth. Josephson-Storm points out that there are vastly different and mutually contradictory periodizations of the Enlightenment depending on nation, field of study, and school of thought; that the term and category of "Enlightenment" referring to the scientific revolution was actually applied after the fact; that the Enlightenment did not see an increase in disenchantment or the dominance of the mechanistic worldview; and that a blur in the early modern ideas of the Humanities and natural sciences makes it hard to circumscribe a Scientific Revolution. Josephson-Storm defends his categorization of the Enlightenment as "myth" by noting the regulative role ideas of a period of Enlightenment and disenchantment play in modern Western culture, such that belief in magic, spiritualism, and even religion appears somewhat taboo in intellectual strata.

In the 1970s, study of the Enlightenment expanded to include the ways Enlightenment ideas spread to European colonies and how they interacted with indigenous cultures and how the Enlightenment took place in formerly unstudied areas such as Italy, Greece, the Balkans, Poland, Hungary and Russia.

Intellectuals such as Robert Darnton and Jürgen Habermas have focused on the social conditions of the Enlightenment. Habermas described the creation of the "bourgeois public sphere" in 18th-century Europe, containing the new venues and modes of communication allowing for rational exchange. Habermas said that the public sphere was bourgeois, egalitarian, rational and independent from the state, making it the ideal venue for intellectuals to critically examine contemporary politics and society, away from the interference of established authority. While the public sphere is generally an integral component of the social study of the Enlightenment, other historians have questioned whether the public sphere had these characteristics.

In contrast to the intellectual historiographical approach of the Enlightenment, which examines the various currents or discourses of intellectual thought within the European context during the 17th and 18th centuries, the cultural (or social) approach examines the changes that occurred in European society and culture. This approach studies the process of changing sociabilities and cultural practices during the Enlightenment.

One of the primary elements of the culture of the Enlightenment was the rise of the public sphere, a "realm of communication marked by new arenas of debate, more open and accessible forms of urban public space and sociability, and an explosion of print culture", in the late 17th century and 18th century. Elements of the public sphere included that it was egalitarian, that it discussed the domain of "common concern," and that argument was founded on reason. Habermas uses the term "common concern" to describe those areas of political/social knowledge and discussion that were previously the exclusive territory of the state and religious authorities, now open to critical examination by the public sphere. The values of this bourgeois public sphere included holding reason to be supreme, considering everything to be open to criticism (the public sphere is critical), and the opposition of secrecy of all sorts.
The creation of the public sphere has been associated with two long-term historical trends: the rise of the modern nation state and the rise of capitalism. The modern nation state, in its consolidation of public power, created by counterpoint a private realm of society independent of the state, which allowed for the public sphere. Capitalism also increased society's autonomy and self-awareness, as well as an increasing need for the exchange of information. As the nascent public sphere expanded, it embraced a large variety of institutions and the most commonly cited were coffee houses and cafés, salons and the literary public sphere, figuratively localized in the Republic of Letters. In France, the creation of the public sphere was helped by the aristocracy's move from the King's palace at Versailles to Paris in about 1720, since their rich spending stimulated the trade in luxuries and artistic creations, especially fine paintings.

The context for the rise of the public sphere was the economic and social change commonly associated with the Industrial Revolution: "Economic expansion, increasing urbanization, rising population and improving communications in comparison to the stagnation of the previous century". Rising efficiency in production techniques and communication lowered the prices of consumer goods and increased the amount and variety of goods available to consumers (including the literature essential to the public sphere). Meanwhile, the colonial experience (most European states had colonial empires in the 18th century) began to expose European society to extremely heterogeneous cultures, leading to the breaking down of "barriers between cultural systems, religious divides, gender differences and geographical areas".

The word "public" implies the highest level of inclusivity – the public sphere by definition should be open to all. However, this sphere was only public to relative degrees. Enlightenment thinkers frequently contrasted their conception of the "public" with that of the people: Condorcet contrasted "opinion" with populace, Marmontel "the opinion of men of letters" with "the opinion of the multitude" and d'Alembert the "truly enlightened public" with "the blind and noisy multitude". Additionally, most institutions of the public sphere excluded both women and the lower classes. Cross-class influences occurred through noble and lower class participation in areas such as the coffeehouses and the Masonic lodges.

Because of the focus on reason over superstition, the Enlightenment cultivated the arts. Emphasis on learning, art and music became more widespread, especially with the growing middle class. Areas of study such as literature, philosophy, science, and the fine arts increasingly explored subject matter to which the general public, in addition to the previously more segregated professionals and patrons, could relate.
As musicians depended more and more on public support, public concerts became increasingly popular and helped supplement performers' and composers' incomes. The concerts also helped them to reach a wider audience. Handel, for example, epitomized this with his highly public musical activities in London. He gained considerable fame there with performances of his operas and oratorios. The music of Haydn and Mozart, with their Viennese Classical styles, are usually regarded as being the most in line with the Enlightenment ideals.

The desire to explore, record and systematize knowledge had a meaningful impact on music publications. Jean-Jacques Rousseau's "Dictionnaire de musique" (published 1767 in Geneva and 1768 in Paris) was a leading text in the late 18th century. This widely available dictionary gave short definitions of words like genius and taste and was clearly influenced by the Enlightenment movement. Another text influenced by Enlightenment values was Charles Burney's "A General History of Music: From the Earliest Ages to the Present Period" (1776), which was a historical survey and an attempt to rationalize elements in music systematically over time. Recently, musicologists have shown renewed interest in the ideas and consequences of the Enlightenment. For example, Rose Rosengard Subotnik's "Deconstructive Variations" (subtitled "Music and Reason in Western Society") compares Mozart's "Die Zauberflöte" (1791) using the Enlightenment and Romantic perspectives and concludes that the work is "an ideal musical representation of the Enlightenment".

As the economy and the middle class expanded, there was an increasing number of amateur musicians. One manifestation of this involved women, who became more involved with music on a social level. Women were already engaged in professional roles as singers and increased their presence in the amateur performers' scene, especially with keyboard music. Music publishers begin to print music that amateurs could understand and play. The majority of the works that were published were for keyboard, voice and keyboard and chamber ensemble. After these initial genres were popularized, from the mid-century on, amateur groups sang choral music, which then became a new trend for publishers to capitalize on. The increasing study of the fine arts, as well as access to amateur-friendly published works, led to more people becoming interested in reading and discussing music. Music magazines, reviews and critical works which suited amateurs as well as connoisseurs began to surface.

The "philosophes" spent a great deal of energy disseminating their ideas among educated men and women in cosmopolitan cities. They used many venues, some of them quite new.

The term "Republic of Letters" was coined in 1664 by Pierre Bayle in his journal "Nouvelles de la Republique des Lettres". Towards the end of the 18th century, the editor of "Histoire de la République des Lettres en France", a literary survey, described the Republic of Letters as being: 

The Republic of Letters was the sum of a number of Enlightenment ideals: an egalitarian realm governed by knowledge that could act across political boundaries and rival state power. It was a forum that supported "free public examination of questions regarding religion or legislation". Immanuel Kant considered written communication essential to his conception of the public sphere; once everyone was a part of the "reading public", then society could be said to be enlightened. The people who participated in the Republic of Letters, such as Diderot and Voltaire, are frequently known today as important Enlightenment figures. Indeed, the men who wrote Diderot's "Encyclopédie" arguably formed a microcosm of the larger "republic".
Many women played an essential part in the French Enlightenment, due to the role they played as "salonnières" in Parisian salons, as the contrast to the male "philosophes". The salon was the principal social institution of the republic and "became the civil working spaces of the project of Enlightenment". Women, as salonnières, were "the legitimate governors of [the] potentially unruly discourse" that took place within. While women were marginalized in the public culture of the Old Regime, the French Revolution destroyed the old cultural and economic restraints of patronage and corporatism (guilds), opening French society to female participation, particularly in the literary sphere.

In France, the established men of letters ("gens de lettres") had fused with the elites ("les grands") of French society by the mid-18th century. This led to the creation of an oppositional literary sphere, Grub Street, the domain of a "multitude of versifiers and would-be authors". These men came to London to become authors, only to discover that the literary market simply could not support large numbers of writers, who in any case were very poorly remunerated by the publishing-bookselling guilds.

The writers of Grub Street, the Grub Street Hacks, were left feeling bitter about the relative success of the men of letters and found an outlet for their literature which was typified by the "libelle". Written mostly in the form of pamphlets, the "libelles" "slandered the court, the Church, the aristocracy, the academies, the salons, everything elevated and respectable, including the monarchy itself". "Le Gazetier cuirassé" by Charles Théveneau de Morande was a prototype of the genre. It was Grub Street literature that was most read by the public during the Enlightenment. According to Darnton, more importantly the Grub Street hacks inherited the "revolutionary spirit" once displayed by the "philosophes" and paved the way for the French Revolution by desacralizing figures of political, moral and religious authority in France.

The increased consumption of reading materials of all sorts was one of the key features of the "social" Enlightenment. Developments in the Industrial Revolution allowed consumer goods to be produced in greater quantities at lower prices, encouraging the spread of books, pamphlets, newspapers and journals – "media of the transmission of ideas and attitudes". Commercial development likewise increased the demand for information, along with rising populations and increased urbanisation. However, demand for reading material extended outside of the realm of the commercial and outside the realm of the upper and middle classes, as evidenced by the Bibliothèque Bleue. Literacy rates are difficult to gauge, but in France the rates doubled over the course of the 18th century. Reflecting the decreasing influence of religion, the number of books about science and art published in Paris doubled from 1720 to 1780, while the number of books about religion dropped to just one-tenth of the total.

Reading underwent serious changes in the 18th century. In particular, Rolf Engelsing has argued for the existence of a "Reading Revolution". Until 1750, reading was done intensively: people tended to own a small number of books and read them repeatedly, often to small audience. After 1750, people began to read "extensively", finding as many books as they could, increasingly reading them alone. This is supported by increasing literacy rates, particularly among women.

The vast majority of the reading public could not afford to own a private library and while most of the state-run "universal libraries" set up in the 17th and 18th centuries were open to the public, they were not the only sources of reading material. On one end of the spectrum was the "Bibliothèque Bleue", a collection of cheaply produced books published in Troyes, France. Intended for a largely rural and semi-literate audience these books included almanacs, retellings of medieval romances and condensed versions of popular novels, among other things. While some historians have argued against the Enlightenment's penetration into the lower classes, the "Bibliothèque Bleue" represents at least a desire to participate in Enlightenment sociability. Moving up the classes, a variety of institutions offered readers access to material without needing to buy anything. Libraries that lent out their material for a small price started to appear and occasionally bookstores would offer a small lending library to their patrons. Coffee houses commonly offered books, journals and sometimes even popular novels to their customers. "The Tatler" and "The Spectator", two influential periodicals sold from 1709 to 1714, were closely associated with coffee house culture in London, being both read and produced in various establishments in the city. This is an example of the triple or even quadruple function of the coffee house: reading material was often obtained, read, discussed and even produced on the premises.
It is extremely difficult to determine what people actually read during the Enlightenment. For example, examining the catalogs of private libraries gives an image skewed in favor of the classes wealthy enough to afford libraries and also ignores censored works unlikely to be publicly acknowledged. For this reason, a study of publishing would be much more fruitful for discerning reading habits.

Across continental Europe, but in France especially, booksellers and publishers had to negotiate censorship laws of varying strictness. For example, the "Encyclopédie" narrowly escaped seizure and had to be saved by Malesherbes, the man in charge of the French censor. Indeed, many publishing companies were conveniently located outside France so as to avoid overzealous French censors. They would smuggle their merchandise across the border, where it would then be transported to clandestine booksellers or small-time peddlers. The records of clandestine booksellers may give a better representation of what literate Frenchmen might have truly read, since their clandestine nature provided a less restrictive product choice. In one case, political books were the most popular category, primarily libels and pamphlets. Readers were more interested in sensationalist stories about criminals and political corruption than they were in political theory itself. The second most popular category, "general works" (those books "that did not have a dominant motif and that contained something to offend almost everyone in authority"), demonstrated a high demand for generally low-brow subversive literature. However, these works never became part of literary canon and are largely forgotten today as a result.

A healthy, legal publishing industry existed throughout Europe, although established publishers and book sellers occasionally ran afoul of the law. For example, the "Encyclopédie" condemned not only by the King, but also by Clement XII, nevertheless found its way into print with the help of the aforementioned Malesherbes and creative use of French censorship law. However, many works were sold without running into any legal trouble at all. Borrowing records from libraries in England, Germany, and North America indicate that more than 70 percent of books borrowed were novels. Less than 1 percent of the books were of a religious nature, indicating the general trend of declining religiosity.

A genre that greatly rose in importance was that of scientific literature. Natural history in particular became increasingly popular among the upper classes. Works of natural history include René-Antoine Ferchault de Réaumur's "Histoire naturelle des insectes" and Jacques Gautier d'Agoty's "La Myologie complète, ou description de tous les muscles du corps humain" (1746). Outside ancien régime France, natural history was an important part of medicine and industry, encompassing the fields of botany, zoology, meteorology, hydrology and mineralogy. Students in Enlightenment universities and academies were taught these subjects to prepare them for careers as diverse as medicine and theology. As shown by Matthew Daniel Eddy, natural history in this context was a very middle class pursuit and operated as a fertile trading zone for the interdisciplinary exchange of diverse scientific ideas.

The target audience of natural history was French polite society, evidenced more by the specific discourse of the genre than by the generally high prices of its works. Naturalists catered to polite society's desire for erudition – many texts had an explicit instructive purpose. However, natural history was often a political affair. As Emma Spary writes, the classifications used by naturalists "slipped between the natural world and the social ... to establish not only the expertise of the naturalists over the natural, but also the dominance of the natural over the social". The idea of taste ("le goût") was a social indicator: to truly be able to categorize nature, one had to have the proper taste, an ability of discretion shared by all members of polite society. In this way natural history spread many of the scientific developments of the time, but also provided a new source of legitimacy for the dominant class. From this basis, naturalists could then develop their own social ideals based on their scientific works.

The first scientific and literary journals were established during the Enlightenment. The first journal, the Parisian "Journal des Sçavans", appeared in 1665. However, it was not until 1682 that periodicals began to be more widely produced. French and Latin were the dominant languages of publication, but there was also a steady demand for material in German and Dutch. There was generally low demand for English publications on the Continent, which was echoed by England's similar lack of desire for French works. Languages commanding less of an international market—such as Danish, Spanish and Portuguese—found journal success more difficult and more often than not a more international language was used instead. French slowly took over Latin's status as the "lingua franca" of learned circles. This in turn gave precedence to the publishing industry in Holland, where the vast majority of these French language periodicals were produced.

Jonathan Israel called the journals the most influential cultural innovation of European intellectual culture. They shifted the attention of the "cultivated public" away from established authorities to novelty and innovation and instead promoted the "enlightened" ideals of toleration and intellectual objectivity. Being a source of knowledge derived from science and reason, they were an implicit critique of existing notions of universal truth monopolized by monarchies, parliaments and religious authorities. They also advanced Christian enlightenment that upheld "the legitimacy of God-ordained authority"—the Bible—in which there had to be agreement between the biblical and natural theories.

Although the existence of dictionaries and encyclopedias spanned into ancient times, the texts changed from simply defining words in a long running list to far more detailed discussions of those words in 18th-century encyclopedic dictionaries. The works were part of an Enlightenment movement to systematize knowledge and provide education to a wider audience than the elite. As the 18th century progressed, the content of encyclopedias also changed according to readers' tastes. Volumes tended to focus more strongly on secular affairs, particularly science and technology, rather than matters of theology.

Along with secular matters, readers also favoured an alphabetical ordering scheme over cumbersome works arranged along thematic lines. Commenting on alphabetization, the historian Charles Porset has said that "as the zero degree of taxonomy, alphabetical order authorizes all reading strategies; in this respect it could be considered an emblem of the Enlightenment". For Porset, the avoidance of thematic and hierarchical systems thus allows free interpretation of the works and becomes an example of egalitarianism. Encyclopedias and dictionaries also became more popular during the Age of Enlightenment as the number of educated consumers who could afford such texts began to multiply. In the later half of the 18th century, the number of dictionaries and encyclopedias published by decade increased from 63 between 1760 and 1769 to approximately 148 in the decade proceeding the French Revolution (1780–1789). Along with growth in numbers, dictionaries and encyclopedias also grew in length, often having multiple print runs that sometimes included in supplemented editions.

The first technical dictionary was drafted by John Harris and entitled "Lexicon Technicum: Or, An Universal English Dictionary of Arts and Sciences". Harris' book avoided theological and biographical entries and instead it concentrated on science and technology. Published in 1704, the "Lexicon technicum" was the first book to be written in English that took a methodical approach to describing mathematics and commercial arithmetic along with the physical sciences and navigation. Other technical dictionaries followed Harris' model, including Ephraim Chambers' "Cyclopaedia" (1728), which included five editions and was a substantially larger work than Harris'. The folio edition of the work even included foldout engravings. The "Cyclopaedia" emphasized Newtonian theories, Lockean philosophy and contained thorough examinations of technologies, such as engraving, brewing and dyeing. In Germany, practical reference works intended for the uneducated majority became popular in the 18th century. The "Marperger Curieuses Natur-, Kunst-, Berg-, Gewerkund Handlungs-Lexicon" (1712) explained terms that usefully described the trades and scientific and commercial education. "Jablonksi Allgemeines Lexicon" (1721) was better known than the "Handlungs-Lexicon" and underscored technical subjects rather than scientific theory. For example, over five columns of text were dedicated to wine while geometry and logic were allocated only twenty-two and seventeen lines, respectively. The first edition of the "Encyclopædia Britannica" (1771) was modelled along the same lines as the German lexicons.

However, the prime example of reference works that systematized scientific knowledge in the age of Enlightenment were universal encyclopedias rather than technical dictionaries. It was the goal of universal encyclopedias to record all human knowledge in a comprehensive reference work. The most well-known of these works is Denis Diderot and Jean le Rond d'Alembert's "Encyclopédie, ou dictionnaire raisonné des sciences, des arts et des métiers". The work, which began publication in 1751, was composed of thirty-five volumes and over 71 000 separate entries. A great number of the entries were dedicated to describing the sciences and crafts in detail and provided intellectuals across Europe with a high-quality survey of human knowledge. In d'Alembert's "Preliminary Discourse to the Encyclopedia of Diderot", the work's goal to record the extent of human knowledge in the arts and sciences is outlined:

The massive work was arranged according to a "tree of knowledge". The tree reflected the marked division between the arts and sciences, which was largely a result of the rise of empiricism. Both areas of knowledge were united by philosophy, or the trunk of the tree of knowledge. The Enlightenment's desacrilization of religion was pronounced in the tree's design, particularly where theology accounted for a peripheral branch, with black magic as a close neighbour. As the "Encyclopédie" gained popularity, it was published in quarto and octavo editions after 1777. The quarto and octavo editions were much less expensive than previous editions, making the "Encyclopédie" more accessible to the non-elite. Robert Darnton estimates that there were approximately 25 000 copies of the "Encyclopédie" in circulation throughout France and Europe before the French Revolution. The extensive, yet affordable encyclopedia came to represent the transmission of Enlightenment and scientific education to an expanding audience.

One of the most important developments that the Enlightenment era brought to the discipline of science was its popularization. An increasingly literate population seeking knowledge and education in both the arts and the sciences drove the expansion of print culture and the dissemination of scientific learning. The new literate population was due to a high rise in the availability of food. This enabled many people to rise out of poverty, and instead of paying more for food, they had money for education. Popularization was generally part of an overarching Enlightenment ideal that endeavoured "to make information available to the greatest number of people". As public interest in natural philosophy grew during the 18th century, public lecture courses and the publication of popular texts opened up new roads to money and fame for amateurs and scientists who remained on the periphery of universities and academies. More formal works included explanations of scientific theories for individuals lacking the educational background to comprehend the original scientific text. Sir Isaac Newton's celebrated "Philosophiae Naturalis Principia Mathematica" was published in Latin and remained inaccessible to readers without education in the classics until Enlightenment writers began to translate and analyze the text in the vernacular.
The first significant work that expressed scientific theory and knowledge expressly for the laity, in the vernacular and with the entertainment of readers in mind, was Bernard de Fontenelle's "Conversations on the Plurality of Worlds" (1686). The book was produced specifically for women with an interest in scientific writing and inspired a variety of similar works. These popular works were written in a discursive style, which was laid out much more clearly for the reader than the complicated articles, treatises and books published by the academies and scientists. Charles Leadbetter's "Astronomy" (1727) was advertised as "a Work entirely New" that would include "short and easie Rules and Astronomical Tables". The first French introduction to Newtonianism and the "Principia" was "Eléments de la philosophie de Newton", published by Voltaire in 1738. Émilie du Châtelet's translation of the "Principia", published after her death in 1756, also helped to spread Newton's theories beyond scientific academies and the university. Writing for a growing female audience, Francesco Algarotti published "Il Newtonianism per le dame", which was a tremendously popular work and was translated from Italian into English by Elizabeth Carter. A similar introduction to Newtonianism for women was produced by Henry Pemberton. His "A View of Sir Isaac Newton's Philosophy" was published by subscription. Extant records of subscribers show that women from a wide range of social standings purchased the book, indicating the growing number of scientifically inclined female readers among the middling class. During the Enlightenment, women also began producing popular scientific works themselves. Sarah Trimmer wrote a successful natural history textbook for children titled "The Easy Introduction to the Knowledge of Nature" (1782), which was published for many years after in eleven editions.

Most work on the Enlightenment emphasizes the ideals discussed by intellectuals, rather than the actual state of education at the time. Leading educational theorists like England's John Locke and Switzerland's Jean Jacques Rousseau both emphasized the importance of shaping young minds early. By the late Enlightenment, there was a rising demand for a more universal approach to education, particularly after the American and French Revolutions.

The predominant educational psychology from the 1750s onward, especially in northern European countries was associationism, the notion that the mind associates or dissociates ideas through repeated routines. In addition to being conducive to Enlightenment ideologies of liberty, self-determination and personal responsibility, it offered a practical theory of the mind that allowed teachers to transform longstanding forms of print and manuscript culture into effective graphic tools of learning for the lower and middle orders of society. Children were taught to memorize facts through oral and graphic methods that originated during the Renaissance.

Many of the leading universities associated with Enlightenment progressive principles were located in northern Europe, with the most renowned being the universities of Leiden, Göttingen, Halle, Montpellier, Uppsala and Edinburgh. These universities, especially Edinburgh, produced professors whose ideas had a significant impact on Britain's North American colonies and later the American Republic. Within the natural sciences, Edinburgh's medical school also led the way in chemistry, anatomy and pharmacology. In other parts of Europe, the universities and schools of France and most of Europe were bastions of traditionalism and were not hospitable to the Enlightenment. In France, the major exception was the medical university at Montpellier.

The history of Academies in France during the Enlightenment begins with the Academy of Science, founded in 1635 in Paris. It was closely tied to the French state, acting as an extension of a government seriously lacking in scientists. It helped promote and organize new disciplines and it trained new scientists. It also contributed to the enhancement of scientists' social status, considering them to be the "most useful of all citizens". Academies demonstrate the rising interest in science along with its increasing secularization, as evidenced by the small number of clerics who were members (13 percent). The presence of the French academies in the public sphere cannot be attributed to their membership, as although the majority of their members were bourgeois, the exclusive institution was only open to elite Parisian scholars. They perceived themselves as "interpreters of the sciences for the people". For example, it was with this in mind that academicians took it upon themselves to disprove the popular pseudo-science of mesmerism.

The strongest contribution of the French Academies to the public sphere comes from the "concours académiques" (roughly translated as "academic contests") they sponsored throughout France. These academic contests were perhaps the most public of any institution during the Enlightenment. The practice of contests dated back to the Middle Ages and was revived in the mid-17th century. The subject matter had previously been generally religious and/or monarchical, featuring essays, poetry and painting. However, by roughly 1725 this subject matter had radically expanded and diversified, including "royal propaganda, philosophical battles, and critical ruminations on the social and political institutions of the Old Regime". Topics of public controversy were also discussed such as the theories of Newton and Descartes, the slave trade, women's education and justice in France.
More importantly, the contests were open to all and the enforced anonymity of each submission guaranteed that neither gender nor social rank would determine the judging. Indeed, although the "vast majority" of participants belonged to the wealthier strata of society ("the liberal arts, the clergy, the judiciary and the medical profession"), there were some cases of the popular classes submitting essays and even winning. Similarly, a significant number of women participated—and won—the competitions. Of a total of 2,300 prize competitions offered in France, women won 49—perhaps a small number by modern standards, but very significant in an age in which most women did not have any academic training. Indeed, the majority of the winning entries were for poetry competitions, a genre commonly stressed in women's education.

In England, the Royal Society of London also played a significant role in the public sphere and the spread of Enlightenment ideas. It was founded by a group of independent scientists and given a royal charter in 1662. The Society played a large role in spreading Robert Boyle's experimental philosophy around Europe and acted as a clearinghouse for intellectual correspondence and exchange. Boyle was "a founder of the experimental world in which scientists now live and operate" and his method based knowledge on experimentation, which had to be witnessed to provide proper empirical legitimacy. This is where the Royal Society came into play: witnessing had to be a "collective act" and the Royal Society's assembly rooms were ideal locations for relatively public demonstrations. However, not just any witness was considered to be credible: "Oxford professors were accounted more reliable witnesses than Oxfordshire peasants". Two factors were taken into account: a witness's knowledge in the area and a witness's "moral constitution". In other words, only civil society were considered for Boyle's public.

It was the place in which philosophes got reunited and talked about old, actual or new ideas. Salons were the place where intellectual and enlightened ideas were built.

Coffeehouses were especially important to the spread of knowledge during the Enlightenment because they created a unique environment in which people from many different walks of life gathered and shared ideas. They were frequently criticized by nobles who feared the possibility of an environment in which class and its accompanying titles and privileges were disregarded. Such an environment was especially intimidating to monarchs who derived much of their power from the disparity between classes of people. If classes were to join together under the influence of Enlightenment thinking, they might recognize the all-encompassing oppression and abuses of their monarchs and because of their size might be able to carry out successful revolts. Monarchs also resented the idea of their subjects convening as one to discuss political matters, especially those concerning foreign affairs—rulers thought political affairs to be their business only, a result of their supposed divine right to rule.

Coffeehouses represent a turning point in history during which people discovered that they could have enjoyable social lives within their communities. Coffeeshops became homes away from home for many who sought, for the first time, to engage in discourse with their neighbors and discuss intriguing and thought-provoking matters, especially those regarding philosophy to politics. Coffeehouses were essential to the Enlightenment, for they were centers of free-thinking and self-discovery. Although many coffeehouse patrons were scholars, a great deal were not. Coffeehouses attracted a diverse set of people, including not only the educated wealthy but also members of the bourgeoisie and the lower class. While it may seem positive that patrons, being doctors, lawyers, merchants, etc. represented almost all classes, the coffeeshop environment sparked fear in those who sought to preserve class distinction. One of the most popular critiques of the coffeehouse claimed that it "allowed promiscuous association among people from different rungs of the social ladder, from the artisan to the aristocrat" and was therefore compared to Noah's Ark, receiving all types of animals, clean or unclean. This unique culture served as a catalyst for journalism when Joseph Addison and Richard Steele recognized its potential as an audience. Together, Steele and Addison published "The Spectator (1711)", a daily publication which aimed, through fictional narrator Mr. Spectator, both to entertain and to provoke discussion regarding serious philosophical matters.

The first English coffeehouse opened in Oxford in 1650. Brian Cowan said that Oxford coffeehouses developed into "penny universities", offering a locus of learning that was less formal than structured institutions. These penny universities occupied a significant position in Oxford academic life, as they were frequented by those consequently referred to as the "virtuosi", who conducted their research on some of the resulting premises. According to Cowan, "the coffeehouse was a place for like-minded scholars to congregate, to read, as well as learn from and to debate with each other, but was emphatically not a university institution, and the discourse there was of a far different order than any university tutorial".

The Café Procope was established in Paris in 1686 and by the 1720s there were around 400 cafés in the city. The Café Procope in particular became a center of Enlightenment, welcoming such celebrities as Voltaire and Rousseau. The Café Procope was where Diderot and D'Alembert decided to create the "Encyclopédie". The cafés were one of the various "nerve centers" for "bruits publics", public noise or rumour. These "bruits" were allegedly a much better source of information than were the actual newspapers available at the time.

The debating societies are an example of the public sphere during the Enlightenment. Their origins include:
In the late 1770s, popular debating societies began to move into more "genteel" rooms, a change which helped establish a new standard of sociability. The backdrop to these developments was "an explosion of interest in the theory and practice of public elocution". The debating societies were commercial enterprises that responded to this demand, sometimes very successfully. Some societies welcomed from 800 to 1,200 spectators a night.

The debating societies discussed an extremely wide range of topics. Before the Enlightenment, most intellectual debates revolved around "confessional" – that is, Catholic, Lutheran, Reformed (Calvinist) or Anglican issues and the main aim of these debates was to establish which bloc of faith ought to have the "monopoly of truth and a God-given title to authority". After this date, everything thus previously rooted in tradition was questioned and often replaced by new concepts in the light of philosophical reason. After the second half of the 17th century and during the 18th century, a "general process of rationalization and secularization set in" and confessional disputes were reduced to a secondary status in favor of the "escalating contest between faith and incredulity".

In addition to debates on religion, societies discussed issues such as politics and the role of women. However, it is important to note that the critical subject matter of these debates did not necessarily translate into opposition to the government. In other words, the results of the debate quite frequently upheld the "status quo". From a historical standpoint, one of the most important features of the debating society was their openness to the public, as women attended and even participated in almost every debating society, which were likewise open to all classes providing they could pay the entrance fee. Once inside, spectators were able to participate in a largely egalitarian form of sociability that helped spread Enlightenment ideas.

Historians have long debated the extent to which the secret network of Freemasonry was a main factor in the Enlightenment. The leaders of the Enlightenment included Freemasons such as Diderot, Montesquieu, Voltaire, Lessing, Pope, Horace Walpole, Sir Robert Walpole, Mozart, Goethe, Frederick the Great, Benjamin Franklin and George Washington. Norman Davies said that Freemasonry was a powerful force on behalf of liberalism in Europe from about 1700 to the twentieth century. It expanded rapidly during the Age of Enlightenment, reaching practically every country in Europe. It was especially attractive to powerful aristocrats and politicians as well as intellectuals, artists and political activists.

During the Age of Enlightenment, Freemasons comprised an international network of like-minded men, often meeting in secret in ritualistic programs at their lodges. They promoted the ideals of the Enlightenment and helped diffuse these values across Britain and France and other places. Freemasonry as a systematic creed with its own myths, values and set of rituals originated in Scotland around 1600 and spread first to England and then across the Continent in the eighteenth century. They fostered new codes of conduct—including a communal understanding of liberty and equality inherited from guild sociability—"liberty, fraternity and equality". Scottish soldiers and Jacobite Scots brought to the Continent ideals of fraternity which reflected not the local system of Scottish customs but the institutions and ideals originating in the English Revolution against royal absolutism. Freemasonry was particularly prevalent in France—by 1789, there were perhaps as many as 100,000 French Masons, making Freemasonry the most popular of all Enlightenment associations. The Freemasons displayed a passion for secrecy and created new degrees and ceremonies. Similar societies, partially imitating Freemasonry, emerged in France, Germany, Sweden and Russia. One example was the Illuminati founded in Bavaria in 1776, which was copied after the Freemasons, but was never part of the movement. The Illuminati was an overtly political group, which most Masonic lodges decidedly were not.

Masonic lodges created a private model for public affairs. They "reconstituted the polity and established a constitutional form of self-government, complete with constitutions and laws, elections and representatives". In other words, the micro-society set up within the lodges constituted a normative model for society as a whole. This was especially true on the continent: when the first lodges began to appear in the 1730s, their embodiment of British values was often seen as threatening by state authorities. For example, the Parisian lodge that met in the mid 1720s was composed of English Jacobite exiles. Furthermore, freemasons all across Europe explicitly linked themselves to the Enlightenment as a whole. For example, in French lodges the line "As the means to be enlightened I search for the enlightened" was a part of their initiation rites. British lodges assigned themselves the duty to "initiate the unenlightened". This did not necessarily link lodges to the irreligious, but neither did this exclude them from the occasional heresy. In fact, many lodges praised the Grand Architect, the masonic terminology for the deistic divine being who created a scientifically ordered universe.

German historian Reinhart Koselleck claimed: "On the Continent there were two social structures that left a decisive imprint on the Age of Enlightenment: the Republic of Letters and the Masonic lodges". Scottish professor Thomas Munck argues that "although the Masons did promote international and cross-social contacts which were essentially non-religious and broadly in agreement with enlightened values, they can hardly be described as a major radical or reformist network in their own right". Many of the Masons values seemed to greatly appeal to Enlightenment values and thinkers. Diderot discusses the link between Freemason ideals and the enlightenment in D'Alembert's Dream, exploring masonry as a way of spreading enlightenment beliefs. Historian Margaret Jacob stresses the importance of the Masons in indirectly inspiring enlightened political thought. On the negative side, Daniel Roche contests claims that Masonry promoted egalitarianism and he argues that the lodges only attracted men of similar social backgrounds. The presence of noble women in the French "lodges of adoption" that formed in the 1780s was largely due to the close ties shared between these lodges and aristocratic society.

The major opponent of Freemasonry was the Roman Catholic Church so that in countries with a large Catholic element, such as France, Italy, Spain and Mexico, much of the ferocity of the political battles involve the confrontation between what Davies calls the reactionary Church and enlightened Freemasonry. Even in France, Masons did not act as a group. American historians, while noting that Benjamin Franklin and George Washington were indeed active Masons, have downplayed the importance of Freemasonry in causing the American Revolution because the Masonic order was non-political and included both Patriots and their enemy the Loyalists.

The art produced during the Enlightenment was about a search for morality that was absent from previous art. At the same time, the Classical art of Greece and Rome became interesting to people again, since archaeological teams discovered Pompeii and Herculaneum. People took inspiration from it and revived the classical art into neo-classical art. This can be especially seen in early American art, where, throughout their art and architecture, they used arches, goddesses, and other classical architectural designs.







</doc>
<doc id="3905278" url="https://en.wikipedia.org/wiki?curid=3905278" title="The All">
The All

The All (also called The One, The Absolute, The Great One, The Creator, The Supreme Mind, The Supreme Good, The Father, and The All Mother) is the Hermetic, pantheistic, pandeistic or panentheistic (and thus also panpsychism/monopsychism/unus mundus/anima mundi) view of God, which is that everything that is, or at least that can be experienced, collectively makes up The All. One Hermetic maxim states, "While All is in The All, it is equally true that The All is in All." The All can also be seen to be androgynous, possessing both masculine and feminine qualities in equal part.

The following is commentary on possibilities about The All but not anything necessarily accepted by Hermeticists in general.

According to The Kybalion, The All is a bit more complicated than simply being the sum total of the universe. Rather than The All being simply the physical universe, it is more correct to say that everything in the universe is within the mind of The All, since the ALL can be looked at as Mind itself. In effect, the universe is partially existent on the Mental plane, and we may in fact all be parts of The All's psychological makeup, representing parts of The All in its dream or meditation.

The Three Initiates (see The Kybalion) strongly caution that we restrain from simply declaring "I am God" for oversimplification purposes. Though you are a part of The All, you are but one small piece of that puzzle. You cannot be equated with God any more than your toenail can be equated with you. You have the potential for perfection and to rejoin God, but you are not the totality of God. However stating "God is me/I (us)" is a more accurate statement.

The All's mind can be seen as infinitely more powerful and vast than any of us could hope to achieve. Therefore, it may be capable of keeping track of each and every particle across the expanse of the Universe, as well as maintain symbolism that applies to many lesser entities such as that seen in astrology and numerology.

Because of this view, some Hermetics also practice theurgy. If the universe is completely a mental construct, then the mind must be able to mold it and shape it, in an experience that can become closer and closer to lucid dreaming as skills improve.

Questions as to why God acts or doesn't act is an ancient question with many divergent answers. The same has been asked by Hermetics of the All, and many reasons have been put forth.

Some Hermetics believe that The All acts so that it may gain something from the action, for it must have a reason for acting, for having created the universe and our own existence. Critics of this idea argue that there is nothing outside of The All for it to gain, it is All. Meanwhile, proponents argue that the critics fail to recognize inner growth that allow the All to change by acting upon itself.

Some Hermetics believe that The All acts because it is internally compelled to do so out of creative urge that is innate. Critics claim that The All is absolute and if this urge were to compel The All then it (the proposed urge) instead would be absolute .

The Kybalion claims simply that "THE ALL ACTS BECAUSE IT ACTS." ("cf." Actus purus) There is no reason but The All itself, therefore its action, itself, and its reason for action are all the same thing.

Though sometimes referred to as The Father, The All is not simply male. In this aspect, The All is called The Father for its active, masculine part in the creation of what is, not because of its physical sex. Similarly, that what it was created out of, is represented as The Mother, for its passive, feminine aspect in that same process. For example, we say Mother Earth and Mother Nature.

The story describing The All here is not meant to be taken literally, but rather has symbolic meaning. Hermetics do not ever claim that the creation story used for this information is to be taken literally. The All has three aspects which are known as The Father and the "Sons of God," put forth in the Corpus Hermeticum:

"Nous" bridges the gap between The All and its contents, and is described having taught Hermes Trismegistus his initial knowledge on God and the divine in Book 1 of the Corpus Hermeticum. Manly P. Hall translates "Nous" differently, instead calling it "Thought (Thoth)", an Egyptian god generally seen as synonymous with Hermes. The terms "Great Dragon," and "Eternal Teacher" also pop up for Nous in his translation.

"Nous" is claimed also to be the Father of the Word, and only comes to pious and religious men. "Nous" claims to be God while the others are "sons of God" It was "Nous" who is said to have created Man, both male and female (or hermaphroditic; some translations claiming "bisexual" used in a way to connote hermaphroditic), 7 of them, which were later broken up into separate men and women after falling in love with Nature, its shadow, and actually merging with Nature, or, in other words, incarnating.

Hermes proclaims that "Nous" is the "cause of existence" and God should be worshipped by those two names, for they belong only to God. "Nous", or God, is also seen as synonymous with the "Supreme Good".

"Poimandres had spoken a Word. The Word was Reason" and "Reason" is given to "The Workman", "The Master-Builder", and "The Maker of Things". "Nous" and "Reason" are truly one, according to the Hermeticum, and their Union is Life. The Word is also known as "The Logos".

The Word is used, by inhabiting the elements, to create destiny, the "seven governors" (Sun, Moon, Mercury, Venus, Mars, Jupiter, and Saturn of astrology) and was used to organize Chaos. The leaving of Reason from the elements is said to give rise to the lower creatures, who were created without "Reason". See also Logos.

"Anthropos" (called the third son of God, while others see Nous—one of these sons of God—as the Father of the other two, and truly being God) is essentially the human soul which comes from God, and is destined to return to God. It is the part of man that is not material, the spiritual part of Man as opposed to the man's body (physical) or nous/mind (mental). It is further said that God is made up of innumerable souls, and if they conduct themselves properly, being true to themselves, they may become Powers of God, which would lend credit to "The All has Something to Gain" theory for action.

The "Kybalions" interpretation of The ALL is that of a Substantial Reality, and transcends names and terms and in essence is unknowable. It can be said that this corresponds to the ideas of or about the Tao, with respect to the interpretation of an all encompassing force above all other. There is little room in this view for a "god", for it is stated that the ALL transcends names and terms. For reasons of logic, the Kybalion goes further in stating that there can be nothing existing outside of the ALL, else the ALL would not be The ALL. Anything finite, changeable, fleeting, and conditioned cannot be The All.

Those seeking a deeper understanding of life will ask the question, "Where did The All come from?" Some Hermeticists, strong adherents of "The Kybalion", go no further than to state "THE ALL must be INFINITE, for there is nothing else to define, confine, bound, limit or restrict THE ALL. It must be infinite in Time, or ETERNAL,-- it must have always continuously existed, for there is nothing else to have ever created it ... if it had ever 'not been,' even for a moment, it would not 'be' now."

In 1975, Summum, an esoteric organization whose philosophy also includes the natural principles described in "The Kybalion", put forth an explanation behind The All's existence and claims the explanation came from "Summa Individuals", beings who appear to be what "The Kybalion" describes as "Unseen Divinities" that intervene and assist with human affairs. Summum rewrote "The Kybalion" to include its explanation along with additional information. Summum refers to The All as "SUMMUM," a Latin term meaning "highest" or "greatest", and in the context of the Summum philosophy means, "the sum total of creation". The explanation Summum offers is based upon what it calls the "Grand Principle of Creation," and via this grand principle, The All (SUMMUM) exists. In summary, according to the Summum philosophy, The All is a union between Nothing and All Possibility, the ultimate opposites, and the nature of that union is without beginning or end for these two opposites automatically and simultaneously create each other. The result is a "cosmic copulation" whose effect is an infinite, living mind.




</doc>
<doc id="60841932" url="https://en.wikipedia.org/wiki?curid=60841932" title="Arationality">
Arationality

Arationality is the state or characteristic of being arational, of being outside the domain of reason. The term is distinct from irrationality, which describes a state that goes "against" reason rather than beyond it. In this regard, that of going beyond reason, arationality is also contrary to positivism, the belief that reality can be understood rationally. 

Arationality is also identified with certain pre-modern modes of thinking, including magic and ritual.

The concept of arationality can be viewed in relation to the question of novelty. In order to develop a theory of how new things come into being, and without reducing them to things that already are, we might need to move beyond the methods that works by way of reduction, i.e. scientific reason and formal logic. A true theory of novelty therefore might need to acknowledge in the creative process, whether artistic or physical, an arational source.

As an example we could think of the event we call the Big Bang. Cosmologists affirm that our universe started with an explosion that brought into existence, not only the matter and energy that constitutes it, but also the very fabric of time and space. This means that the event itself must have happened outside of time and space, in a "non-place" and "non-time". Considering that our logic works exclusively within the categories of time and space, something that happened before these categories even existed is necessarily beyond logic, or in other words, arational.



</doc>
<doc id="14366249" url="https://en.wikipedia.org/wiki?curid=14366249" title="Trigger law">
Trigger law

A trigger law is a nickname for a law that is unenforceable, but may achieve enforceability if a key change in circumstances occurs.

In the United States, six states — Arkansas, Kentucky, Louisiana, Mississippi, North Dakota, and South Dakota — have trigger laws that would automatically ban abortion in the first and second trimesters if the landmark case "Roe v. Wade" were overturned. Illinois formerly had a trigger law (enacted in 1975), but repealed it in 2017. Also, nine states — Alabama, Arizona, Michigan, New Mexico, Oklahoma, West Virginia, and Wisconsin as well as the already mentioned Arkansas and Mississippi, still have their unenforced pre-"Roe" abortion bans on the lawbooks, which are not currently enforceable due to "Roe", but could start being enforced if "Roe" were overturned.


</doc>
<doc id="777042" url="https://en.wikipedia.org/wiki?curid=777042" title="Mercy">
Mercy

Mercy (Middle English, from Anglo-French "merci", from Medieval Latin "merced-", "merces", from Latin, "price paid, wages", from "merc-", "merxi" "merchandise") is benevolence, forgiveness, and kindness in a variety of ethical, religious, social, and legal contexts.

The concept of a merciful God appears in various religions, including Hinduism, Christianity, Judaism and Islam. Performing acts of mercy as a component of religious beliefs is also emphasized through actions such as the giving of alms, and care for the sick and Works of Mercy.

In the social and legal context, mercy may refer both to compassionate behavior on the part of those in power (e.g. mercy shown by a judge toward a convict), or on the part of a humanitarian third party, e.g., a mission of mercy aiming to treat war victims.

"Mercy" can be defined as "compassion or forbearance shown especially to an offender or to one subject to one's power"; and also "a blessing that is an act of divine favor or compassion." "To be at someone's mercy" indicates a person being "without defense against someone."

In a judicial context mercy is often termed "clemency". It is a sovereign prerogative that resides in the executive and is entirely discretionary. John Locke defined it as "the power to act according to discretion, for the public good, without the prescription of the Law, and sometimes even against it." The U.S. Court of Appeals for the Sixth Circuit explained that "The very nature of clemency is that it is grounded solely in the will of the dispenser of clemency. He need give no reasons for granting it or for denying it."

Hebrews 4:16 says, "So let us confidently approach the throne of grace to receive mercy and to find grace for timely help." Grace and mercy are similar in that both are free gifts of God and both are dispensed absent any merit on the part of the recipient. Grace is the favor of God, a divine assistance. Grace is what one receives that they do not deserve while mercy is what one receives when they do "not" get that which they deserve.

An emphasis on mercy appears in the New Testament, for example in the Magnificat and Benedictus (Song of Zechariah), in Luke's Gospel, and in the Beatitudes in : "Blessed are the merciful: for they shall obtain mercy". In Apostle Paul refers to the mercy of God in terms of salvation: "God, being rich in mercy... even when we were dead through our sins, made us alive together with Christ".

Psalm 117 calls upon all nations to praise the Lord, and that on account of his "merciful kindness". This is quoted by the Apostle Paul in Romans 15:11 to show that God has now fulfilled this prophecy and promise through Jesus Christ, who has been merciful in giving his life as a sacrifice for his people, both Jew and Gentile. Thus St Peter writes in 1 Peter 2:9,10:

This devotional element of mercy as part of the Christian tradition was echoed by Saint Augustine who called mercy "ever ancient, ever new". The Works of Mercy (seven corporal and seven spiritual works) are part of the Catholic and Eastern Orthodox traditions.

In the encyclical "Dives in misericordia" ("Rich in Mercy") Pope John Paul II examines the role of mercy—both God's mercy, and also the need for human mercy. He sees in the Parable of the Prodigal Son () "the essence of the divine mercy". Having squandered his patrimony, justice would dictate that the prodigal should only expect to be received back as a hireling. The figure of the father is analogous to God as Father, who goes beyond the requirements of justice to welcome his son with compassion.

The Catechism of the Catholic Church emphasizes the importance of the Works of Mercy (item 2447) and in Roman Catholic teachings, the mercy of God flows through the work of the Holy Spirit. Roman Catholic liturgy includes frequent references to mercy, e.g., as in "Kyrie eleison, Christe eleison": Lord have mercy, Christ have mercy.

Mercy has also been an important subject of Christian iconography. Since the Middle Ages, many representations in art encouraged people to practice the works of mercy and, as the art historian Ralf van Bühren explains using the example of Caravaggio, helped "the audience to explore mercy in their own lives".

In the 20th century, there was new focus on mercy in the Roman Catholic Church, partly due to the Divine Mercy devotion. The primary focus of the Divine Mercy devotion is the merciful love of God and the desire to let that love and mercy flow through one's own heart towards those in need of it. 
Pope John Paul II was a follower of the Divine Mercy devotion, due to Saint Mary Faustina Kowalska (1905–1938), who is known as the "Apostle of Mercy".

A number of Roman Catholic shrines are specifically dedicated to Divine Mercy, e.g.
the Basilica of Divine Mercy in Krakow Poland, and the National Shrine of The Divine Mercy (Stockbridge, Massachusetts). During the dedication of the Basilica of Divine Mercy John Paul II quoted and called mercy the "greatest attribute of God Almighty".

The first "World Apostolic Congress on Mercy" was held in Rome in April 2008 and was inaugurated by Pope Benedict XVI.

On 11 April 2015, at St. Peter's Basillica, in a Papal Bull of Indiction entitled "Misericordiae Vultus" ("The Face of Mercy"), Pope Francis proclaimed a Special and Extraordinary Holy Year Jubilee Year of Mercy, from December 8, 2015: Solemnity of the Immaculate Conception of the Blessed Virgin Mary, until November 21, 2016: the Solemnity of Our Lord Jesus Christ the King. The theme of the Extraordinary Jubilee is taken from Luke 6:36, "Merciful, Like the Father".

In Islam the title "Most Merciful" (al-Rahman) is one of the names of Allah and Compassionate (al-Rahim), is the most common name occurring in the Quran. Rahman and Rahim both derive from the root Rahmat, which refers to tenderness and benevolence. As a form of mercy, the giving of alms (zakat) is the fourth of the Five Pillars of Islam and one of the requirements for the faithful.

The Hebrew word for mercy is "Rachamim" which is always in plural form so that it literally means "mercies". "Mercy includes showing kindness to those who don’t deserve it, and forgiving those that deserve punishment."

Mercy is one of the defining characteristics of God. Exodus 34:6 says: "The Lord, the Lord, a God merciful and gracious, slow to anger, and abounding in steadfast love and faithfulness." This is also emphasized in the context of the Babylonian exile in Isaiah: "For the Lord has comforted his people, and will have compassion on his suffering ones. But Zion said, 'The Lord has forsaken me, my Lord has forgotten me.' Can a woman forget her nursing child, or show no compassion for the child of her womb? Even these may forget, yet I will not forget you." (Isaiah 49:13-15) Also: "It is good to pray and fast, to be merciful and just." (Tobit 12:8)

When David, because of his sin, was told to choose between a three-year famine, pursuit by his enemies for three months, or a three-day pestilence, he chose the pestilence saying, "Let us fall by the hand of God, for he is most merciful; but let me not fall by the hand of man." Psalm 103:8 praises God for his mercy.

Kwan Yin the bodhisattva of mercy and compassion, is one of the best known and most venerated Bodhisattva in Asia.

Karuṇā (often translated as "compassion") is part of the beliefs of both Buddhism and Jainism. Karuṇā is present in all schools of Buddhism and in Jainism it is viewed as one of the reflections of universal friendship.

The spiritual teacher Meher Baba described God as being "all-merciful and eternally benevolent" in his O Parvardigar prayer, and he held that we can approach God through the "invocation of His mercy."





</doc>
<doc id="4720758" url="https://en.wikipedia.org/wiki?curid=4720758" title="Substantive rights">
Substantive rights

Substantive rights are basic human rights possessed by people in an ordered society and include rights granted by natural law as well as the substantive law. Substantive rights involve a right to the substance of being human (life, liberty, happiness), rather than a right to a procedure to enforce that right, which is defined by procedural law.



</doc>
<doc id="25603863" url="https://en.wikipedia.org/wiki?curid=25603863" title="Ordinary law">
Ordinary law

An ordinary law is a normal law, generally distinguished from a constitutional law, organic law, or other similar law. Typically, ordinary laws are subordinate to constitutional and organic laws, and are more easily changed than constitutional or organic laws, though that should not be assumed to be the case in all jurisdictions. (For example, the Constitutional Court of Spain has ruled that Spain's Organic Laws are not hierarchically superior to ordinary laws, but simply apply to different matters.) Ordinary laws often govern areas beyond the scope of constitutional or organic laws.

Normally, in a democracy, an ordinary law must first obtain a simple majority of a congress, parliament, or other legislature, and then be signed into law by the representative of executive power. The process leading to a legislative vote may vary vastly from one jurisdiction to another: the process may be initiated by either house of a bicameral legislature or from the sole house of a unicameral legislature; from the head of government or head of state; or by popular initiative. Different jurisdictions may allow ordinary laws to be proposed by one or all of these means, and may have restrictions on which body may take the initiative for certain types of laws (for example, in some bicameral systems, tax-related laws must begin in the lower chamber of the legislature). In some jurisdictions, the legislature has a means to override an executive veto by a supermajority, or the voting populace have the means to override a law by a referendum.

Under federal systems, ordinary laws may be created at the level of a sovereign state but also by its constituent components: for example, by states of the United States or autonomous communities of Spain.


</doc>
<doc id="4807742" url="https://en.wikipedia.org/wiki?curid=4807742" title="Legal debate">
Legal debate

A legal debate is a discussion between lawyers, legal academics, jurists, politicians, and others who might have an interest or expertise in the law, about a particular legal issue.

Legal debates can take many forms, and do not necessarily need to be face-to-face debates. Most legal debates take place on paper—judges within a court, for example, might debate each other most effectively when the court publishes a decision. Legal debates include (but are not limited to) the following:


Debates in Western societies often follow broad themes, including


In the United States, legal debates over the past decade have concerned the following important topics:


In general, the variety of debates—ranging from basic social policy to grander theory about constitutional design and democratic theory—suggests that legal debates overlap with several other social institutions and expectations.



</doc>
<doc id="6719326" url="https://en.wikipedia.org/wiki?curid=6719326" title="Legal tests">
Legal tests

Legal tests are various kinds of commonly applied methods of evaluation used to resolve matters of jurisprudence. In the context of a trial, a hearing, discovery, or other kinds of legal proceedings, the resolution of certain questions of fact or law may hinge on the application of one or more legal tests.

Legal tests are often formulated from the logical analysis of a judicial decision or a court order where it appears that a finder of fact or the court made a particular decision after contemplating a well-defined set of circumstances. It is assumed that evaluating any given set of circumstances under a legal test will lead to an unambiguous and repeatable result. 







</doc>
<doc id="6042463" url="https://en.wikipedia.org/wiki?curid=6042463" title="Secret law">
Secret law

Secret law refers to legal authorities that require compliance that are classified or otherwise withheld from the public. Such non-promulgated laws were common in the Soviet Union and Eastern Bloc countries. The term has been used in reference to some counterterrorist measures taken by the Bush Administration in the United States following the September 11, 2001 terrorist attacks. The Patriot Act has been referred to as having secret interpretations.

Since about 2015 the branches of the United States federal government have accused one another of creating secret law. Journalists, scholars, and anti-secrecy activists have also made similar allegations. Scholarly analysis has shown that secret law is present in all three branches. One scholar, Professor Dakota Rudesill, recommends that the country affirmatively decide whether to tolerate secret law, and proposes principles for governing it, including: public law’s supremacy over secret law; no secret criminal law; public notification of creation of secret law; presumptive sunset and publication dates; and availability of all secret law to Congress.

In Britain many open places freely accessible by the public are actually privately owned public spaces (POPS). Information on ownership is considered confidential, and not provided either by the owners, or by local councils that have the information. As in any private property the owner may require visitors to abide by specified rules; but people freely accessing the place are not informed of the rules, which may nevertheless be enforced by security guards. Typical prohibitions which do not apply to genuinely public spaces include protesting, and photography.

Councils mostly refused to provide information on existing and planned pseudo-public spaces. They also refused to say how information could be obtained, or to provide information on private restrictions on exercising the other rights people have on genuinely public land. Councils were criticised for being under the influence of property developers and corporate owners. A member of the London Assembly said "Being able to know what rules you are being governed by, and how to challenge them, is a fundamental part of democracy".

Secret laws and their negative effects are described in Franz Kafka's novel "Der Prozess" ("The Trial").



</doc>
<doc id="15826297" url="https://en.wikipedia.org/wiki?curid=15826297" title="Seriousness">
Seriousness

Seriousness (noun; adjective: serious) is an attitude of gravity, solemnity, persistence, and earnestness toward something considered to be of importance. Some notable philosophers and commentators have criticised excessive seriousness, while others have praised it. Seriousness is often contrasted with comedy, as in the seriocomedy. In the theory of humor, one must have a sense of humor and a sense of seriousness to distinguish what is supposed to be taken literally or not, or of being important or not. Otherwise, it may also be contrasted with a sense of play. How children learn a sense of seriousness to form values and differentiate between the serious and that which is not is studied in developmental psychology and educational psychology. There is a distinction between the degree of seriousness of various crimes in sentencing under the law, and also in law enforcement. There is a positive correlation with the degree of seriousness of a crime and viewer ratings of news coverage. What is or is not considered serious varies widely with different cultures.

Sometimes fields studying degrees of seriousness overlap, such as developmental psychology studies of development of the sense of degrees of seriousness as it relates to transgressions, which has overlap with criminology and the seriousness of crimes.

Some use "seriousness" as a term of praise for scholarship or in literary review. 19th century poet, cultural critic, and literary critic, Matthew Arnold said that the most important criteria used to judge the value of a poem were "high truth" and "high seriousness".

Many have expressed an attitude of disdain toward taking things too seriously, as opposed to viewing things with an attitude of humor. Poet, playwright, and philosopher Joseph Addison said that being serious is dull, "we are growing serious, and let me tell you, that's the next step to being dull." Political satirist P.J. O'Rourke said that "Seriousness is stupidity sent to college." Epigramist, poet, and playwright Oscar Wilde said that "life is too important to be taken seriously." In a play on words, novelist Samuel Butler indicated that the "central serious conviction in life" is that nothing should be taken with too much seriousness, "the one serious conviction that a man should have is that nothing is to be taken too seriously."

In some ascetic or puritan religious sects, an attitude of seriousness is always to be taken, and solemnity, sobriety, and puritanism with its hostility to social pleasures and indulgences are the only acceptable attitudes. Perry Miller, "the master of American intellectual history", wrote of excessive seriousness of the Puritans, "simple humanity cries at last for some relief from the interminable high seriousness of the Puritan code."

Existentialist philosopher Jean-Paul Sartre called the "spirit of seriousness’’ the belief that there is an objective and independent goodness in things for people to discover, and that this belief leads to bad faith. He argued that people forget that values are not absolute, but are contingent and subjectively determined. In Sartre’s words, "the spirit of seriousness has two characteristics: it considers values as transcendent ‘'givens’’, independent of human subjectivity, and it transfers the quality of ‘desirable’ from the ontological structure of things to their simple material constitution."

Seriousness is sometimes contrasted with the comical in humor. In the performing arts and literature, the seriocomedy is a genre which blends seriousness with the comical, drama with comedy.

In the theory of humor, one must have a sense of humor and a sense of seriousness to distinguish what is supposed to be taken literally or not. An even more keen sense is needed when humor is used to make a serious point. Psychologists have studied how humor is intended to be taken as having seriousness, as when court jesters used humor to convey serious information. Conversely, when humor is not intended to be taken seriously, bad taste in humor may cross a line after which it is taken seriously, though not intended.

In Developmental psychology and educational psychology, seriousness is studied as it relates to how children develop an ability to distinguish levels of seriousness as it relates to transgressions and expenditure of time; for example, a child must learn to distinguish between levels of seriousness in admonitions such as between "don't fidget" and "don't forget to look both ways when crossing the street", which have the same linguistic and normative structure, but different levels of seriousness.

The degree of seriousness of crimes is an important factor relating to crime. One standard for measurement is the degree to which a crime affects others or society. A felony is generally considered to be a crime of "high seriousness", while a misdemeanor is not.

In criminal law the degree of seriousness is considered when meting out punishment to fit the crime, and in considering to what extent overcrowded prison facilities will be used. Seriousness of a crime is a major factor in considerations of the allocation of scarce law enforcement funds.

The meaning and measurement of seriousness is a major concern in public policy considerations. A quantitative scoring system called the "seriousness score" has been developed for use in allocating law enforcement resources and sentencing.

As to England and Wales, see section 143 of the Criminal Justice Act 2003.

Degrees of seriousness are used in medicine to make decisions about care. Seriousness is related to the effects of delaying or not having medical care. In an emergency hospital, the triage nurse must evaluate levels of seriousness of medical emergencies and rank them to determine order of care. Seriousness of illness is used to make decisions as to whether to perform invasive procedures such as surgery.

There is a positive correlation between the degree of seriousness of a crime and viewer ratings of news coverage.

What is considered serious varies widely across cultures and is studied in sociology, cultural anthropology, and criminology; being of the wrong religious faith may be considered a serious crime in some cultures; smoking marijuana may be a serious crime in some cultures and not others; homosexuality a serious crime in some cultures; and prostitution is a serious crime in some cultures. Perception of seriousness is measured in assessing varying cultural perceptions on health risks.


</doc>
<doc id="61358" url="https://en.wikipedia.org/wiki?curid=61358" title="Oral law">
Oral law

An oral law is a code of conduct in use in a given culture, religion or community application, by which a body of rules of human behaviour is transmitted by oral tradition and effectively respected, or the single rule that is orally transmitted.

Many cultures have an oral law, while most contemporary legal systems have a formal written organisation. The oral tradition (from the Latin "tradere" = to transmit) is the typical instrument of transmission of the oral codes or, in a more general sense, is the complex of what a culture transmits of itself among the generations, "from father to son". This kind of transmission can be due to lack of other means, such as in illiterate or criminal societies, or can be expressly required by the same law.

There has been a continuous debate over oral versus written transmission, with the focus on the perceived higher reliability of written evidence, primarily based on the "linear world of academia" where only written down records are accepted. However, "standard" theories of orality and literacy have been proposed.

From a legal point of view, an oral law can be:
An oral law, intended as a body of rules, can be admitted in jurisprudence as long as it shows some efficacy, therefore it needs that the law is public, the human action is evaluated by a judge (ordinarily producing a sentence according to the general interpretation of the law) and then a punishment has eventually to be put into effect. Some oral laws provide all these elements (for instance, some codes of conduct in use among criminal associations like the Mafia do have a well known law, a judge, a condemnation), while others usually miss some of them.

Although the Hebrew term "Torah" is often translated as "Law", it can just as accurately be translated as "Instruction" or "teaching". Rabbinic Judaism maintains that the books of the Tanakh were transmitted in parallel with an oral tradition, as relayed by God to Moses and from him handed on to the scholarly and other religious leaders of each generation. Thus, in Judaism, the "Written Instruction" ("Torah she-bi-khtav" תורה שבכתב) comprises the Torah and the rest of the Tanakh; the "Oral Instruction" ("Torah she-be'al peh" תורה שבעל פה) was ultimately recorded in the Talmud (lit. "Learning") and Midrashim (lit. "Interpretations"). The interpretation of the Oral Torah is thus considered as the authoritative reading of the Written Torah. Further, Halakha (lit. "The Path", frequently translated as "Jewish Law") is based on a "Written Instruction" together with an "Oral Instruction". Jewish law and tradition is thus not based on a literal reading of the Tanakh, but on the combined oral and written tradition.





</doc>
<doc id="28648059" url="https://en.wikipedia.org/wiki?curid=28648059" title="Rule according to higher law">
Rule according to higher law

The rule according to a higher law is a statement which expresses that no law may be enforced by the government unless it conforms with certain universal principles (written or unwritten) of fairness, morality, and justice. Thus, "the rule according to a higher law" may serve as a practical legal criterion to qualify the instances of political or economical decision-making, when a government, even though acting in conformity with clearly defined and properly enacted legal rules, still produces results which many observers find unfair or unjust.

The idea of a law of ultimate justice over and above the momentary law of the state—a higher law—was first introduced into post-Roman Europe by the Catholic canon law jurists. "Higher law" can be interpreted in this context as the divine or natural law or basic legal values, established in the international law—the choice depending on the viewpoint. But this is definitely a Law above the law. And it is in this capacity that it possesses the equal legal value for both the common and civil law jurisdictions, as opposed to natural law which is largely associated with common law. "To recognize the necessary connection between the rule of law as an ideal and well-constructed constitutional government does not and should not be taken to imply that all states can or should maintain the same constitutional structures in practice".

"The rule according to higher law" is a practical approach to the implementation of the higher law theory which creates a bridge of mutual understanding (with regard to universal legal values) between the English language doctrine of the rule of law, traditional for the countries of common law, and the originally German doctrine of "Rechtsstaat", translated into other languages of continental Europe as "État de droit" (Fr.), "Estado de derecho" (Sp.), "Stato di diritto" (It.), and "Правовое государство" (Ru.). The latter doctrine is the product of continental European legal thought which had adopted it from German legal philosophy. Its name can be translated into English as "state of law"—meaning the state in which the exercise of governmental power is kept in check by the higher law rather than by the changeable law established by this state. Amartya Sen mentioned that the legal theorists in ancient India used term of classical Sanskrit "nyāya" in the sense of not just a matter of judging institutions and rules, but of judging the societies themselves.

Before the U.S. Civil War, African Americans were legally denied equal rights and freedoms pursuant to formally valid codes prescribing the relations between master and slave. Although these codes were "de jure" fully suitable for application in legal practice, their enforcement by the then U.S. government "de facto" violated basic human rights of a significant part of the population. William H. Seward famously proclaimed that slavery is forbidden under "a higher law than the Constitution".

Generally speaking, the occurrence of such "justly enacted unjust laws" fully depends on the stance taken by the country's political leadership towards the rule of law principle.

In some countries, the political leaders assert that the rule of law is purely a procedural concept. Therefore, they argue that any government may strip its subjects of their fundamental freedoms or infringe their vital interests so long as this is done by way of a duly implemented legal mechanism. For example, at the Nuremberg trials, in an attempt to justify their crimes against Jewish and Romany population of Europe during World War II, some of the former leaders of Nazi Germany argued that they had broken none of the laws effective when Hitler had been in power. It was only by invoking the rule according to a higher law that the Allied prosecutors were able to overcome such defenses.

In other countries, conversely, the political leaders assert that all written laws must be kept in line with the universal principles of morality, fairness, and justice. These leaders argue that, as a necessary corollary to the axiom that "no one is above the law," the rule of law requires the government to treat all persons equally under the law. However, the proclaimed right to equal treatment is susceptible to instantly becoming void each time the government denies a sufficient level of respect, dignity, and autonomy to a certain class of individuals or to human rights in general."
Therefore, the unwritten and universally self-explanatory principles of equality, autonomy, dignity, and respect are said to overrule conventional written laws enacted by the government. It is these principles that are often referred to as "natural law". They also constitute the basis of the "higher law theory".

The "Rechtsstaat" doctrine (legal state, state of right, constitutional state, constitutional government) was first introduced by the German philosopher Immanuel Kant in his latest works completed after the U.S. and French constitutions had been adopted in the late 18th century. Kant's approach is based on the supremacy of country's written constitution created using principles of the Higher Law. This supremacy meant creating guarantees for the implementation of his central idea: a permanently peaceful life as a basic condition for the happiness and prosperity of the citizens. Kant was basing his doctrine exclusively on the idea of constitutionalism and constitutional government.

The Russian legal system, born in the 19th century as a result of the transformations initiated by the reforms of the Emperor Alexander II, was (and still is) based primarily upon the German legal tradition. It was from the latter that Russia had adopted the doctrine of "Rechtsstaat", which literally translates as "legal state." Its closest English analogue is "the rule of law". The Russian legal state concept adopts the written constitution as the country's supreme law (the rule of constitution). It is a fundamental but undefined principle that appears in the very first dispositive provision of Russia's post-communist constitution: "The Russian Federation – Russia – constitutes a democratic federative legal state with a republican form of governance." Similarly, the very first dispositive provision of Ukraine's constitution declares that "Ukraine is a sovereign and independent, democratic, social, legal state." Hence, the effort to invest meaning to the "legal state" definition is anything but theoretical.

Valery Zorkin, President of the Constitutional Court of Russia, wrote in 2003, "Becoming a legal state has long been our ultimate goal, and we have certainly made serious progress in this direction over the past several years. However, no one can say now that we have reached this destination. Such a legal state simply cannot exist without a lawful and just society. Here, as in no other sphere of our life, the state reflects the level of maturity reached by the society."

The Russian concept of legal state has adopted many segments of constitutional economics which serves as a practical implementation of the higher law theory in economics.

Economist James M. Buchanan argues that, in the framework of constitutional government, any governmental intervention or regulation must be conditioned by the three following assumptions. First, every failure of the market economy to function smoothly and perfectly can be corrected by governmental intervention. Second, those holding political office and manning the bureaucracies are altruistic upholders of the public interest, unconcerned with their own personal economic well-being. And third, changing the government responsibilities towards more intervention and control will not profoundly and perversely affect the social and economic life.

Buchanan rejects "any organic conception of the state as superior in wisdom, to the individuals who are its members". This philosophical position is the very subject matter of constitutional economics. A constitutional economics approach allows for a combined economic and constitutional analysis, helping to avoid a one-dimensional understanding. Buchanan, together with Kant, believes that a constitution in its capacity as the higher law, intended for use by at least several generations of citizens, must be able to adjust itself for pragmatic economic decisions, while balancing interests of the state and society against those of individuals, with their constitutional rights to personal freedom and private happiness.

Buchanan also outlines importance of protection of the moral principles underlying constitutional norms. He writes that "the ethics of constitutional citizenship is not directly comparable to ethical behavior in interaction with other persons within the constraints imposed by the rules of an existing regime. An individual may be fully responsible, in the standard ethical sense, and yet fail to meet the ethical requirement of constitutional citizenship."




</doc>
<doc id="13831" url="https://en.wikipedia.org/wiki?curid=13831" title="Human rights">
Human rights

Human rights are moral principles or norms that describe certain standards of human behaviour and are regularly protected as natural and legal rights in municipal and international law. They are commonly understood as inalienable, fundamental rights "to which a person is inherently entitled simply because she or he is a human being" and which are "inherent in all human beings", regardless of their nation, location, language, religion, ethnic origin or any other status. They are applicable everywhere and at every time in the sense of being universal, and they are egalitarian in the sense of being the same for everyone. They are regarded as requiring empathy and the rule of law and imposing an obligation on persons to respect the human rights of others, and it is generally considered that they should not be taken away except as a result of due process based on specific circumstances; for example, human rights may include freedom from unlawful imprisonment, torture and execution.

The doctrine of human rights has been highly influential within international law, global and regional institutions. Actions by states and non-governmental organisations form a basis of public policy worldwide. The idea of human rights suggests that "if the public discourse of peacetime global society can be said to have a common moral language, it is that of human rights". The strong claims made by the doctrine of human rights continue to provoke considerable scepticism and debates about the content, nature and justifications of human rights to this day. The precise meaning of the term "right" is controversial and is the subject of continued philosophical debate; while there is consensus that human rights encompasses a wide variety of rights such as the right to a fair trial, protection against enslavement, prohibition of genocide, free speech or a right to education (including the right to comprehensive sexuality education, among others), there is disagreement about which of these particular rights should be included within the general framework of human rights; some thinkers suggest that human rights should be a minimum requirement to avoid the worst-case abuses, while others see it as a higher standard. In the light of emerging neurotechnologies, four new rights were identified: the right to cognitive liberty, the right to mental privacy, the right to mental integrity, and the right to psychological continuity.

Many of the basic ideas that animated the human rights movement developed in the aftermath of the Second World War and the events of the Holocaust, culminating in the adoption of the Universal Declaration of Human Rights in Paris by the United Nations General Assembly in 1948. Ancient peoples did not have the same modern-day conception of universal human rights. The true forerunner of human rights discourse was the concept of natural rights which appeared as part of the medieval natural law tradition that became prominent during the European Enlightenment with such philosophers as John Locke, Francis Hutcheson and Jean-Jacques Burlamaqui and which featured prominently in the political discourse of the American Revolution and the French Revolution. From this foundation, the modern human rights arguments emerged over the latter half of the 20th century, possibly as a reaction to slavery, torture, genocide and war crimes, as a realisation of inherent human vulnerability and as being a precondition for the possibility of a just society.

Ancient peoples did not have the same modern-day conception of universal human rights. The true forerunner of human-rights discourse was the concept of natural rights which appeared as part of the medieval natural law tradition that became prominent during the European Enlightenment. From this foundation, the modern human rights arguments emerged over the latter half of the 20th century.
17th-century English philosopher John Locke discussed natural rights in his work, identifying them as being "life, liberty, and estate (property)", and argued that such fundamental rights could not be surrendered in the social contract. In Britain in 1689, the English Bill of Rights and the Scottish Claim of Right each made illegal a range of oppressive governmental actions. Two major revolutions occurred during the 18th century, in the United States (1776) and in France (1789), leading to the United States Declaration of Independence and the French Declaration of the Rights of Man and of the Citizen respectively, both of which articulated certain human rights. Additionally, the Virginia Declaration of Rights of 1776 encoded into law a number of fundamental civil rights and civil freedoms.

Philosophers such as Thomas Paine, John Stuart Mill and Hegel expanded on the theme of universality during the 18th and 19th centuries. In 1831 William Lloyd Garrison wrote in a newspaper called "The Liberator" that he was trying to enlist his readers in "the great cause of human rights" so the term "human rights" probably came into use sometime between Paine's "The Rights of Man" and Garrison's publication. In 1849 a contemporary, Henry David Thoreau, wrote about human rights in his treatise "On the Duty of Civil Disobedience" which was later influential on human rights and civil rights thinkers. United States Supreme Court Justice David Davis, in his 1867 opinion for Ex Parte Milligan, wrote "By the protection of the law, human rights are secured; withdraw that protection and they are at the mercy of wicked rulers or the clamor of an excited people."

Many groups and movements have managed to achieve profound social changes over the course of the 20th century in the name of human rights. In Western Europe and North America, labour unions brought about laws granting workers the right to strike, establishing minimum work conditions and forbidding or regulating child labour. The women's rights movement succeeded in gaining for many women the right to vote. National liberation movements in many countries succeeded in driving out colonial powers. One of the most influential was Mahatma Gandhi's movement to free his native India from British rule. Movements by long-oppressed racial and religious minorities succeeded in many parts of the world, among them the civil rights movement, and more recent diverse identity politics movements, on behalf of women and minorities in the United States.

The foundation of the International Committee of the Red Cross, the 1864 Lieber Code and the first of the Geneva Conventions in 1864 laid the foundations of International humanitarian law, to be further developed following the two World Wars.

The League of Nations was established in 1919 at the negotiations over the Treaty of Versailles following the end of World War I. The League's goals included disarmament, preventing war through collective security, settling disputes between countries through negotiation, diplomacy and improving global welfare. Enshrined in its Charter was a mandate to promote many of the rights which were later included in the Universal Declaration of Human Rights.

The League of Nations had mandates to support many of the former colonies of the Western European colonial powers during their transition from colony to independent state.

Established as an agency of the League of Nations, and now part of United Nations, the International Labour Organization also had a mandate to promote and safeguard certain of the rights later included in the UDHR:

The Universal Declaration of Human Rights (UDHR) is a non-binding declaration adopted by the United Nations General Assembly in 1948, partly in response to the barbarism of World War II. The UDHR urges member nations to promote a number of human, civil, economic and social rights, asserting these rights are part of the "foundation of freedom, justice and peace in the world". The declaration was the first international legal effort to limit the behavior of states and press upon them duties to their citizens following the model of the rights-duty duality.

The UDHR was framed by members of the Human Rights Commission, with Eleanor Roosevelt as Chair, who began to discuss an "International Bill of Rights" in 1947. The members of the Commission did not immediately agree on the form of such a bill of rights, and whether, or how, it should be enforced. The Commission proceeded to frame the UDHR and accompanying treaties, but the UDHR quickly became the priority. Canadian law professor John Humprey and French lawyer Rene Cassin were responsible for much of the cross-national research and the structure of the document respectively, where the articles of the declaration were interpretative of the general principle of the preamble. The document was structured by Cassin to include the basic principles of dignity, liberty, equality and brotherhood in the first two articles, followed successively by rights pertaining to individuals; rights of individuals in relation to each other and to groups; spiritual, public and political rights; and economic, social and cultural rights. The final three articles place, according to Cassin, rights in the context of limits, duties and the social and political order in which they are to be realized. Humphrey and Cassin intended the rights in the UDHR to be legally enforceable through some means, as is reflected in the third clause of the preamble:

Some of the UDHR was researched and written by a committee of international experts on human rights, including representatives from all continents and all major religions, and drawing on consultation with leaders such as Mahatma Gandhi. The inclusion of both civil and political rights and economic, social and cultural rights was predicated on the assumption that basic human rights are indivisible and that the different types of rights listed are inextricably linked. Though this principle was not opposed by any member states at the time of adoption (the declaration was adopted unanimously, with the abstention of the Soviet bloc, Apartheid South Africa and Saudi Arabia), this principle was later subject to significant challenges.

The onset of the Cold War soon after the UDHR was conceived brought to the fore divisions over the inclusion of both econonic and social rights and civil and political rights in the declaration. Capitalist states tended to place strong emphasis on civil and political rights (such as freedom of association and expression), and were reluctant to include economic and social rights (such as the right to work and the right to join a union). Socialist states placed much greater importance on economic and social rights and argued strongly for their inclusion.

Because of the divisions over which rights to include, and because some states declined to ratify any treaties including certain specific interpretations of human rights, and despite the Soviet bloc and a number of developing countries arguing strongly for the inclusion of all rights in a so-called "Unity Resolution", the rights enshrined in the UDHR were split into two separate covenants, allowing states to adopt some rights and derogate others. Though this allowed the covenants to be created, it denied the proposed principle that all rights are linked which was central to some interpretations of the UDHR.

Although the UDHR is a non-binding resolution, it is now considered to be a central component of international customary law which may be invoked under appropriate circumstances by national and other judiciaries.

In 1966, the International Covenant on Civil and Political Rights (ICCPR) and the International Covenant on Economic, Social and Cultural Rights (ICESCR) were adopted by the United Nations, between them making the rights contained in the UDHR binding on all states. However, they came into force only in 1976, when they were ratified by a sufficient number of countries (despite achieving the ICCPR, a covenant including no economic or social rights, the US only ratified the ICCPR in 1992). The ICESCR commits 155 state parties to work toward the granting of economic, social, and cultural rights (ESCR) to individuals. 
Since then numerous other treaties (pieces of legislation) have been offered at the international level. They are generally known as "human rights instruments". Some of the most significant are:


The United Nations (UN) is the only multilateral governmental agency with universally accepted international jurisdiction for universal human rights legislation. All UN organs have advisory roles to the United Nations Security Council and the United Nations Human Rights Council, and there are numerous committees within the UN with responsibilities for safeguarding different human rights treaties. The most senior body of the UN with regard to human rights is the Office of the High Commissioner for Human Rights. The United Nations has an international mandate to:

The United Nations Human Rights Council, created at the 2005 World Summit to replace the United Nations Commission on Human Rights, has a mandate to investigate violations of human rights. The Human Rights Council is a subsidiary body of the General Assembly and reports directly to it. It ranks below the Security Council, which is the final authority for the interpretation of the United Nations Charter. Forty-seven of the one hundred ninety-one member states sit on the council, elected by simple majority in a secret ballot of the United Nations General Assembly. Members serve a maximum of six years and may have their membership suspended for gross human rights abuses. The Council is based in Geneva, and meets three times a year; with additional meetings to respond to urgent situations.

Independent experts ("rapporteurs") are retained by the Council to investigate alleged human rights abuses and to provide the Council with reports.

The Human Rights Council may request that the Security Council refer cases to the International Criminal Court (ICC) even if the issue being referred is outside the normal jurisdiction of the ICC.

In addition to the political bodies whose mandate flows from the UN charter, the UN has set up a number of "treaty-based" bodies, comprising committees of independent experts who monitor compliance with human rights standards and norms flowing from the core international human rights treaties. They are supported by and are created by the treaty that they monitor, With the exception of the CESCR, which was established under a resolution of the Economic and Social Council to carry out the monitoring functions originally assigned to that body under the Covenant, they are technically autonomous bodies, established by the treaties that they monitor and accountable to the state parties of those treaties – rather than subsidiary to the United Nations, though in practice they are closely intertwined with the United Nations system and are supported by the UN High Commissioner for Human Rights (UNHCHR) and the UN Centre for Human Rights.

Each treaty body receives secretariat support from the Human Rights Council and Treaties Division of Office of the High Commissioner on Human Rights (OHCHR) in Geneva except CEDAW, which is supported by the Division for the Advancement of Women (DAW). CEDAW formerly held all its sessions at United Nations headquarters in New York but now frequently meets at the United Nations Office in Geneva; the other treaty bodies meet in Geneva. The Human Rights Committee usually holds its March session in New York City.

There are many regional agreements and organizations promoting and governing human rights.

The African Union (AU) is a supranational union consisting of fifty-five African states. Established in 2001, the AU's purpose is to help secure Africa's democracy, human rights, and a sustainable economy, especially by bringing an end to intra-African conflict and creating an effective common market.

The African Commission on Human and Peoples' Rights (ACHPR) is a quasi-judicial organ of the African Union tasked with promoting and protecting human rights and collective (peoples') rights throughout the African continent as well as interpreting the African Charter on Human and Peoples' Rights and considering individual complaints of violations of the Charter. The Commission has three broad areas of responsibility:


In pursuit of these goals, the Commission is mandated to "collect documents, undertake studies and researches on African problems in the field of human and peoples, rights, organise seminars, symposia and conferences, disseminate information, encourage national and local institutions concerned with human and peoples' rights and, should the case arise, give its views or make recommendations to governments" (Charter, Art. 45).

With the creation of the African Court on Human and Peoples' Rights (under a protocol to the Charter which was adopted in 1998 and entered into force in January 2004), the Commission will have the additional task of preparing cases for submission to the Court's jurisdiction. In a July 2004 decision, the AU Assembly resolved that the future Court on Human and Peoples' Rights would be integrated with the African Court of Justice.

The Court of Justice of the African Union is intended to be the "principal judicial organ of the Union" (Protocol of the Court of Justice of the African Union, Article 2.2). Although it has not yet been established, it is intended to take over the duties of the African Commission on Human and Peoples' Rights, as well as act as the supreme court of the African Union, interpreting all necessary laws and treaties. The Protocol establishing the African Court on Human and Peoples' Rights entered into force in January 2004 but its merging with the Court of Justice has delayed its establishment. The Protocol establishing the Court of Justice will come into force when ratified by 15 countries.

There are many countries in Africa accused of human rights violations by the international community and NGOs

The Organization of American States (OAS) is an international organization, headquartered in Washington, D.C., United States. Its members are the thirty-five independent states of the Americas. Over the course of the 1990s, with the end of the Cold War, the return to democracy in Latin America, and the thrust toward globalization, the OAS made major efforts to reinvent itself to fit the new context. Its stated priorities now include the following:


The Inter-American Commission on Human Rights (the IACHR) is an autonomous organ of the Organization of American States, also based in Washington, D.C. Along with the Inter-American Court of Human Rights, based in San José, Costa Rica, it is one of the bodies that comprise the inter-American system for the promotion and protection of human rights. The IACHR is a permanent body which meets in regular and special sessions several times a year to examine allegations of human rights violations in the hemisphere. Its human rights duties stem from three documents:


The Inter-Americal Court of Human Rights was established in 1979 with the purpose of enforcing and interpreting the provisions of the American Convention on Human Rights. Its two main functions are thus adjudicatory and advisory. Under the former, it hears and rules on the specific cases of human rights violations referred to it. Under the latter, it issues opinions on matters of legal interpretation brought to its attention by other OAS bodies or member states.

There are no Asia-wide organisations or conventions to promote or protect human rights. Countries vary widely in their approach to human rights and their record of human rights protection.

The Association of Southeast Asian Nations (ASEAN) is a geo-political and economic organization of 10 countries located in Southeast Asia, which was formed in 1967 by Indonesia, Malaysia, the Philippines, Singapore and Thailand. The organisation now also includes Brunei Darussalam, Vietnam, Laos, Myanmar and Cambodia. In October 2009, the ASEAN Intergovernmental Commission on Human Rights was inaugurated, and subsequently, the ASEAN Human Rights Declaration was adopted unanimously by ASEAN members on 18 November 2012.

The Arab Charter on Human Rights (ACHR) was adopted by the Council of the League of Arab States on 22 May 2004.

The Council of Europe, founded in 1949, is the oldest organisation working for European integration. It is an international organisation with legal personality recognised under public international law and has observer status with the United Nations. The seat of the Council of Europe is in Strasbourg in France. The Council of Europe is responsible for both the European Convention on Human Rights and the European Court of Human Rights. These institutions bind the Council's members to a code of human rights which, though strict, are more lenient than those of the United Nations charter on human rights. The Council also promotes the European Charter for Regional or Minority Languages and the European Social Charter. Membership is open to all European states which seek European integration, accept the principle of the rule of law and are able and willing to guarantee democracy, fundamental human rights and freedoms.

The Council of Europe is separate from the European Union, but the latter is expected to accede to the European Convention and potentially the Council itself. The EU also has a separate human rights document; the Charter of Fundamental Rights of the European Union.

The European Convention on Human Rights defines and guarantees since 1950 human rights and fundamental freedoms in Europe. All 47 member states of the Council of Europe have signed this Convention and are therefore under the jurisdiction of the European Court of Human Rights in Strasbourg. In order to prevent torture and inhuman or degrading treatment (Article 3 of the Convention), the European Committee for the Prevention of Torture was established.

Several theoretical approaches have been advanced to explain how and why human rights become part of social expectations.

One of the oldest Western philosophies on human rights is that they are a product of a natural law, stemming from different philosophical or religious grounds.

Other theories hold that human rights codify moral behavior which is a human social product developed by a process of biological and social evolution (associated with Hume). Human rights are also described as a sociological pattern of rule setting (as in the sociological theory of law and the work of Weber). These approaches include the notion that individuals in a society accept rules from legitimate authority in exchange for security and economic advantage (as in Rawls) – a social contract.

Natural law theories base human rights on a "natural" moral, religious or even biological order which is independent of transitory human laws or traditions.

Socrates and his philosophic heirs, Plato and Aristotle, posited the existence of natural justice or natural right ("dikaion physikon", "δικαιον φυσικον", Latin "ius naturale"). Of these, Aristotle is often said to be the father of natural law, although evidence for this is due largely to the interpretations of his work of Thomas Aquinas.

The development of this tradition of natural justice into one of natural law is usually attributed to the Stoics.

Some of the early Church fathers sought to incorporate the until then pagan concept of natural law into Christianity. Natural law theories have featured greatly in the philosophies of Thomas Aquinas, Francisco Suárez, Richard Hooker, Thomas Hobbes, Hugo Grotius, Samuel von Pufendorf, and John Locke.

In the Seventeenth Century Thomas Hobbes founded a contractualist theory of legal positivism on what all men could agree upon: what they sought (happiness) was subject to contention, but a broad consensus could form around what they feared (violent death at the hands of another). The natural law was how a rational human being, seeking to survive and prosper, would act. It was discovered by considering humankind's natural rights, whereas previously it could be said that natural rights were discovered by considering the natural law. In Hobbes' opinion, the only way natural law could prevail was for men to submit to the commands of the sovereign. In this lay the foundations of the theory of a social contract between the governed and the governor.

Hugo Grotius based his philosophy of international law on natural law. He wrote that "even the will of an omnipotent being cannot change or abrogate" natural law, which "would maintain its objective validity even if we should assume the impossible, that there is no God or that he does not care for human affairs." ("De iure belli ac pacis", Prolegomeni XI). This is the famous argument "etiamsi daremus" ("non-esse Deum"), that made natural law no longer dependent on theology.

John Locke incorporated natural law into many of his theories and philosophy, especially in "Two Treatises of Government". Locke turned Hobbes' prescription around, saying that if the ruler went against natural law and failed to protect "life, liberty, and property," people could justifiably overthrow the existing state and create a new one.

The Belgian philosopher of law Frank van Dun is one among those who are elaborating a secular conception of natural law in the liberal tradition. There are also emerging and secular forms of natural law theory that define human rights as derivative of the notion of universal human dignity.

The term "human rights" has replaced the term "natural rights" in popularity, because the rights are less and less frequently seen as requiring natural law for their existence.

The philosopher John Finnis argues that human rights are justifiable on the grounds of their instrumental value in creating the necessary conditions for human well-being. Interest theories highlight the duty to respect the rights of other individuals on grounds of self-interest:

The biological theory considers the comparative reproductive advantage of human social behavior based on empathy and altruism in the context of natural selection.

The most common categorization of human rights is to split them into civil and political rights, and economic, social and cultural rights.

Civil and political rights are enshrined in articles 3 to 21 of the Universal Declaration of Human Rights and in the ICCPR. Economic, social and cultural rights are enshrined in articles 22 to 28 of the Universal Declaration of Human Rights and in the ICESCR. The UDHR included both economic, social and cultural rights and civil and political rights because it was based on the principle that the different rights could only successfully exist in combination:

This is held to be true because without civil and political rights the public cannot assert their economic, social and cultural rights. Similarly, without livelihoods and a working society, the public cannot assert or make use of civil or political rights (known as the "full belly thesis")

Although accepted by the signaturies to the UDHR, most of them do not in practice give equal weight to the different types of rights. Western cultures have often given priority to civil and political rights, sometimes at the expense of economic and social rights such as the right to work, to education, health and housing. For example, in the United States there is no universal access to healthcare free at the point of use. That is not to say that Western cultures have overlooked these rights entirely (the welfare states that exist in Western Europe are evidence of this). Similarly the ex Soviet bloc countries and Asian countries have tended to give priority to economic, social and cultural rights, but have often failed to provide civil and political rights.

Another categorization, offered by Karel Vasak, is that there are "three generations of human rights": first-generation civil and political rights (right to life and political participation), second-generation economic, social and cultural rights (right to subsistence) and third-generation solidarity rights (right to peace, right to clean environment). Out of these generations, the third generation is the most debated and lacks both legal and political recognition. This categorisation is at odds with the indivisibility of rights, as it implicitly states that some rights can exist without others. Prioritisation of rights for pragmatic reasons is however a widely accepted necessity. Human rights expert Philip Alston argues:

He, and others, urge caution with prioritisation of rights:

Some human rights are said to be "inalienable rights." The term inalienable rights (or unalienable rights) refers to "a set of human rights that are fundamental, are not awarded by human power, and cannot be surrendered."

The adherence to the principle of indivisibility by the international community was reaffirmed in 1995:

This statement was again endorsed at the 2005 World Summit in New York (paragraph 121).

The UDHR enshrines, by definition, rights that apply to all humans equally, whichever geographical location, state, race or culture they belong to.

Proponents of cultural relativism suggest that human rights are not all universal, and indeed conflict with some cultures and threaten their survival.

Rights which are most often contested with relativistic arguments are the rights of women. For example, Female genital mutilation occurs in different cultures in Africa, Asia and South America. It is not mandated by any religion, but has become a tradition in many cultures. It is considered a violation of women's and girl's rights by much of the international community, and is outlawed in some countries.

Universalism has been described by some as cultural, economic or political imperialism. In particular, the concept of human rights is often claimed to be fundamentally rooted in a politically liberal outlook which, although generally accepted in Europe, Japan or North America, is not necessarily taken as standard elsewhere.

For example, in 1981, the Iranian representative to the United Nations, Said Rajaie-Khorassani, articulated the position of his country regarding the Universal Declaration of Human Rights by saying that the UDHR was "a secular understanding of the Judeo-Christian tradition", which could not be implemented by Muslims without trespassing the Islamic law. The former Prime Ministers of Singapore, Lee Kuan Yew, and of Malaysia, Mahathir bin Mohamad both claimed in the 1990s that "Asian values" were significantly different from western values and included a sense of loyalty and foregoing personal freedoms for the sake of social stability and prosperity, and therefore authoritarian government is more appropriate in Asia than democracy. This view is countered by Mahathir's former deputy:

and also by Singapore's opposition leader Chee Soon Juan who states that it is racist to assert that Asians do not want human rights.

An appeal is often made to the fact that influential human rights thinkers, such as John Locke and John Stuart Mill, have all been Western and indeed that some were involved in the running of Empires themselves.

Relativistic arguments tend to neglect the fact that modern human rights are new to all cultures, dating back no further than the UDHR in 1948. They also don't account for the fact that the UDHR was drafted by people from many different cultures and traditions, including a US Roman Catholic, a Chinese Confucian philosopher, a French Zionist and a representative from the Arab League, amongst others, and drew upon advice from thinkers such as Mahatma Gandhi.

Michael Ignatieff has argued that cultural relativism is almost exclusively an argument used by those who wield power in cultures which commit human rights abuses, and that those who's human rights are compromised are the powerless. This reflects the fact that the difficulty in judging universalism versus relativism lies in who is claiming to represent a particular culture.

Although the argument between universalism and relativism is far from complete, it is an academic discussion in that all international human rights instruments adhere to the principle that human rights are universally applicable. The 2005 World Summit reaffirmed the international community's adherence to this principle:

Companies, NGOs, political parties, informal groups, and individuals are known as "non-State actors". Non-State actors can also commit human rights abuses, but are not subject to human rights law other than International Humanitarian Law, which applies to individuals.

Multi-national companies play an increasingly large role in the world, and are responsible for a large number of human rights abuses. Although the legal and moral environment surrounding the actions of governments is reasonably well developed, that surrounding multi-national companies is both controversial and ill-defined. Multi-national companies' primary responsibility is to their shareholders, not to those affected by their actions. Such companies are often larger than the economies of the states in which they operate, and can wield significant economic and political power. No international treaties exist to specifically cover the behavior of companies with regard to human rights, and national legislation is very variable. Jean Ziegler, Special Rapporteur of the UN Commission on Human Rights on the right to food stated in a report in 2003:

In August 2003 the Human Rights Commission's Sub-Commission on the Promotion and Protection of Human Rights produced draft "Norms on the responsibilities of transnational corporations and other business enterprises with regard to human rights". These were considered by the Human Rights Commission in 2004, but have no binding status on corporations and are not monitored.

Realism and national loyalties have been described as a destructive influence on the human rights movement because they deny people's innately similar human qualities.

With the exception of non-derogable human rights (international conventions class the right to life, the right to be free from slavery, the right to be free from torture and the right to be free from retroactive application of penal laws as non-derogable), the UN recognises that human rights can be limited or even pushed aside during times of national emergency – although

Rights that cannot be derogated for reasons of national security in any circumstances are known as peremptory norms or "jus cogens". Such International law obligations are binding on all states and cannot be modified by treaty.

The human rights enshrined in the UDHR, the Geneva Conventions and the various enforced treaties of the United Nations are enforceable in law. In practice, many rights are very difficult to legally enforce due to the absence of consensus on the application of certain rights, the lack of relevant national legislation or of bodies empowered to take legal action to enforce them.

There exist a number of internationally recognized organisations with worldwide mandate or jurisdiction over certain aspects of human rights:


The ICC and other international courts (see Regional human rights above exist to take action where the national legal system of a state is unable to try the case itself. If national law is able to safeguard human rights and punish those who breach human rights legislation, it has primary jurisdiction by complementarity. Only when all "local remedies" have been exhausted does international law take effect.

In over 110 countries National human rights institutions (NHRIs) have been set up to protect, promote or monitor human rights with jurisdiction in a given country. Although not all NHRIs are compliant with the Paris Principles, the number and effect of these institutions is increasing. The Paris Principles were defined at the first International Workshop on National Institutions for the Promotion and Protection of Human Rights in Paris on 7–9 October 1991, and adopted by United Nations Human Rights Commission Resolution 1992/54 of 1992 and the General Assembly Resolution 48/134 of 1993. The Paris Principles list a number of responsibilities for national institutions.

Universal jurisdiction is a controversial principle in international law whereby states claim criminal jurisdiction over persons whose alleged crimes were committed outside the boundaries of the prosecuting state, regardless of nationality, country of residence, or any other relation with the prosecuting country. The state backs its claim on the grounds that the crime committed is considered a crime against all, which any state is authorized to punish. The concept of universal jurisdiction is therefore closely linked to the idea that certain international norms are erga omnes, or owed to the entire world community, as well as the concept of jus cogens. In 1993 Belgium passed a "law of universal jurisdiction" to give its courts jurisdiction over crimes against humanity in other countries, and in 1998 Augusto Pinochet was arrested in London following an indictment by Spanish judge Baltasar Garzon under the universal jurisdiction principle. The principle is supported by Amnesty International and other human rights organisations as they believe certain crimes pose a threat to the international community as a whole and the community has a moral duty to act, but others, including Henry Kissinger (who has himself been accused of war crimes by several commentators), argue that state sovereignty is paramount, because breaches of rights committed in other countries are outside states' sovereign interest and because states could use the principle for political reasons.

Human rights violations occur when any state or non-state actor breaches any of the terms of the UDHR or other international human rights or humanitarian law. In regard to human rights violations of United Nations laws. Article 39 of the United Nations Charter designates the UN Security Council (or an appointed authority) as the only tribunal that may determine UN human rights violations.

Human rights abuses are monitored by United Nations committees, national institutions and governments and by many independent non-governmental organizations, such as Amnesty International, Human Rights Watch, World Organisation Against Torture, Freedom House, International Freedom of Expression Exchange and Anti-Slavery International. These organisations collect evidence and documentation of human rights abuses and apply pressure to promote human rights.

Wars of aggression, War crimes and crimes against humanity, including genocide, are breaches of International humanitarian law.





</doc>
<doc id="276167" url="https://en.wikipedia.org/wiki?curid=276167" title="Wrongdoing">
Wrongdoing

A wrong (from Old English "wrang "– "crooked") is an act that is illegal or immoral. Legal wrongs are usually quite clearly defined in the law of a state and/or jurisdiction. They can be divided into civil wrongs and crimes (or "criminal offences") in common law countries, while civil law countries tend to have some additional categories, such as contraventions.

Moral wrong is an underlying concept for legal wrong. Some moral wrongs are punishable by law, for example, rape or murder. Other moral wrongs have nothing to do with law. On the other hand, some legal wrongs, such as parking offences, could hardly be classified as moral wrongs.

In law, a wrong can be a legal injury, which is any damage resulting from a violation of a legal right. A legal wrong can also imply the state of being contrary to the principles of justice or law. It means that something is contrary to conscience or morality and results in treating others unjustly. If the loss caused by a wrong is minor enough, there is no compensation, which principle is known as "de minimis non curat lex". Otherwise, damages apply.

The law of England recognised the concept of a "wrong" before it recognised the distinction between civil wrongs (governed by civil law) and crimes (defined by criminal law), which distinction was developed during the thirteenth century.




</doc>
<doc id="39246512" url="https://en.wikipedia.org/wiki?curid=39246512" title="Administration of justice">
Administration of justice

The administration of justice is the process by which the legal system of a government is executed. The presumed goal of such administration is to provide justice for all those accessing the legal system. The phrase is also used commonly to describe a University degree (as in: a BA in Administration of Justice), which can be a prerequisite for a job in law enforcement or government.

In "Attorney General for New South Wales v Love", the appellant argued that section 24 of the Act 9 Geo 4 c 83 did not have the effect applying the Nullum Tempus Act (9 Geo 3 c 16) (1768) to New South Wales. Counsel for the appellant said that "Whicker v Hume" decided that section 24 referred not to laws generally, but only to laws as to modes of procedure, and that the Nullum Tempus Act did not deal merely with procedure. The Lord Chancellor said that the Act 9 Geo 4 c 83 "prima facie" "applied the Nullum Tempus Act to the Colony in question as much as if it had re-enacted it for that Colony." He then said:

Section 92(14) of the Constitution Act, 1867, also known as the administration of justice power, grants the provincial legislatures of Canada the authority to legislate on:

Section 1 of the Administration of Justice Act (RSO 1990 c A6) provides:

This provision was previously section 1 of the Administration of Justice Act (RSO 1980 c 6), which was previously section 1 of Administration of Justice Act (RSO 1970 c 6), which was previously section 1 of Administration of Justice Act 1968 (SO 1968 c 1) (17 Eliz 2 c 1). Queen's printer copies of the Statutes of the Province of Ontario 1968 describe this provision as "new". This statute replaced the Administration of Justice Expenses Act (RSO 1960 c 5).

"Offence against the administration of justice" is defined by section 7 of the Criminal Procedure Act 2010.

In England, the administration of justice is a prerogative of the Crown. It may be exercised only through duly-appointed judges and courts.

The following matters and things pertain to the administration of justice: the organisation of the courts; the prerogative of justice, the prerogative of mercy, and any prerogative power to create new courts; nolle prosequi; the appointment, tenure and immunity of judges; the immunity of other participants in legal proceedings; contempt of court; the composition and availability of juries, any requirement that their verdict be unanimous, and the allowances they receive; the branches of the legal profession; and the provision of legal aid and advice.

The administration of justice is an act which is normally associated with the carrying on of the business of government. When a government does that act, it is thereby exercising its sovereignty. It would accordingly be a violation of British sovereignty for a foreign government to do that act in British territory without authorisation. Section 2 of the Visiting Forces Act 1952 authorises foreign service courts to exercise their jurisdiction in the United Kingdom.

There are offences against the administration of justice.

For the purpose of section 54 of the Criminal Procedure and Investigations Act 1996, the following are administration of justice offences:

The offence of perverting the course of justice has been referred to as "interfering with the administration of justice" and as "obstructing the administration of justice".

Section 6(c) of the Contempt of Court Act 1981 provides that nothing in the foregoing provisions of that Act restricts liability for contempt of court in respect of conduct intended to impede or prejudice the administration of justice.

An arrestable offence, other than one specified in Schedule 5 to the Police and Criminal Evidence Act 1984, was serious for the purposes of that Act if it led to, or was intended or likely to lead to, amongst other things, serious interference with the administration of justice. An arrestable offence which consisted of making a threat was serious for the purposes of that Act if carrying out the threat would be likely to lead to, amongst other things, serious interference with the administration of justice.

In any legal proceedings held in public, the court may, where it appears to be necessary for avoiding a substantial risk of prejudice to the administration of justice in those proceedings, or in any other proceedings pending or imminent, order that the publication of any report of the proceedings, or any part of the proceedings, be postponed for such period as the court thinks necessary for that purpose.

Information which is not exempt information by virtue of section 30 of the Freedom of Information Act 2000 is exempt information if its disclosure under that Act would, or would be likely to, prejudice the administration of justice.

Roscoe Pound said: "Dissatisfaction with the administration of justice is as old as the law".




</doc>
<doc id="39198876" url="https://en.wikipedia.org/wiki?curid=39198876" title="Child pirate">
Child pirate

In keeping with the Paris Principles definition of a child soldier, the Roméo Dallaire Child Soldiers Initiative defines a "child pirate"' as any person below 18 years of age who is or who has been recruited or used by a pirate gang in any capacity, including children - boys and/or girls - used as gunmen in boarding parties, hostage guards, negotiators, ship captains, messengers, spies or for sexual purposes, whether at sea or on land. It does not only refer to a child who is taking or has taken a direct part in kinetic criminal operations.

Children may volunteer to participate in piratical activities (usually on account of socioeconomic desperation, familial suggestion or peer influence) or they may be forcibly abducted by piratical gangs.

There are a number of reasons why an adult pirate commander would view children as being of significant tactical value. These perceptions render children vulnerable to abduction or forced recruitment. As noted by Carl Conradi:

In other cases, children may volunteer to participate in piratical activities. However, as asserted by the Canada-based Roméo Dallaire Child Soldiers Initiative, "'voluntary' enlistment must be understood in terms of the limited choices and circumstances that may exist in the context of a particular country."’ If a child is extremely poor, has been displaced from his or her home, has been separated from his or her family, has limited educational opportunities or has been exposed to conflict, there is an increased likelihood that he or she will view piracy as a legitimate vehicle for social advancement.

In the absence of specific international legislation on juvenile maritime piracy, the precise age of a child’s criminal responsibility when committing piratical acts differs from country to country. There are, however, a number of international conventions pertaining to either maritime law or children’s rights that may provide some guidance as to the proper handling of child pirates.

While the United Nations Convention on the Law of the Sea (UNCLOS, 1982) does not discuss children’s involvement in maritime criminal activities, it does provide a clear definition of piracy. According to Article 101, piracy is:

UNCLOS does recognise universal jurisdiction over the crime of piracy but it only applies to criminal acts that take place on international waters. If an act of piracy occurs within a country’s territorial waters, it is a matter of state jurisdiction and prosecution.

Article 3 of the International Labour Organisation’s (ILO) Worst Forms of Child Labour Convention (No. 182, 1999) stipulates that:

Insofar as participation in any form of maritime criminality is dangerous (and indeed, potentially lethal), child piracy clearly constitutes a worst form of child labour.

According to the Convention, a child is any person who is below the age of 18.

As of April 2013, eight countries had not signed ILO Convention No. 182. These include Cuba, Eritrea, India, the Marshall Islands, Myanmar, Palau, Somalia and Tuvalu. Two of these countries – India and Somalia – are currently detaining and prosecuting alleged child pirates.

Like ILO Convention No. 182, Article 1 of the United Nations Convention on the Rights of the Child (1990) specifies that a child is any human being below the age of 18 years. However, the same article adds a caveat to the effect that a country’s minimum age of criminal responsibility may be lower than 18, as stipulated by national law.

Other sections that may have some bearing upon the status of child pirates include Article 6, in which, “States Parties recognize that every child has the inherent right to life,” and that, “States Parties shall ensure to the maximum extent possible the survival and development of the child.”

Article 19(1) affirms that, “States Parties shall take all appropriate legislative, administrative, social and educational measures to protect the child from all forms of physical or mental violence, injury or abuse, neglect or negligent treatment, maltreatment or exploitation, including sexual abuse, while in the care of parent(s), legal guardian(s) or any other person who has the care of the child.” This clause may be particularly relevant in cases where a child’s parents have forced him or her to participate in piratical activity, or where the State is responsible for detaining, interrogating, trying and/or incarcerating a captured child pirate.

Article 32(1) echoes ILO Convention No. 182 by stipulating that, “States Parties recognize the right of the child to be protected from economic exploitation and from performing any work that is likely to be hazardous or to interfere with the child’s education, or to be harmful to the child’s health or physical, mental, spiritual, moral or social development.”

Article 35 says that, “State Parties shall take all appropriate national, bilateral and multilateral measures to prevent the abduction of, the sale of or traffic in children for any purpose or in any form.” When a piratical gang permanently separates a child from his or her family, this may constitute an act of child trafficking.

Article 37(a) affirms that, “No child shall be subjected to torture or other cruel, inhuman or degrading treatment or punishment. Neither capital punishment nor life imprisonment without possibility of release shall be imposed for offences committed by persons below eighteen years of age.” Likewise, Article 37(c) states that, “Every child deprived of liberty shall be treated with humanity and respect for the inherent dignity of the human person, and in a manner which takes into account the needs of persons of his or her age. In particular, every child deprived of liberty shall be separated from adults unless it is considered in the child’s best interests not to do so and shall have the right to maintain contact with his or her family through correspondence and visits, save in exceptional circumstances.”

Lastly, Article 39 stipulates that, “State Parties shall take all appropriate measures to promote physical and psychological recovery and social reintegration of a child victim of: any form of neglect, exploitation or abuse; torture or any other form of cruel, inhuman or degrading treatment or punishment; or armed conflicts. Such recovery and reintegration shall take place in an environment which fosters the health, self-respect and dignity of the child.”

The third version of the "Best Management Practices to Deter Piracy off the Coast of Somalia and in the Arabian Sea Area" (June 2010) recommends a sample follow-up report that should be filled by the captain of any vessel that has come under pirate attack. While the report does solicit certain details concerning the offending raiding party – such as the number of constituent pirate members, their physical appearance and the weapons that were used – it does not ask for the estimated ages of pirates.

The Regional Cooperation Agreement on Combating Piracy and Armed Robbery against Ships in Asia (ReCAAP) is a multilateral pact that facilitates information sharing between signatory countries. The reporting mechanism that it establishes does not specifically call for the collection of disaggregated data pertaining to the ages of captured pirates.

According to the UN Office on Drugs and Crime, the UN Contact Group on Piracy off the Coast of Somalia is in the midst of drafting an apprehension and transfer protocol for juvenile pirates who are captured by international navies operating in the Horn of Africa region.

All three of the main Somali sub-regions (i.e., South-Central, Puntland and Somaliland) have signed memoranda of understanding (MoUs) with the governments of Mauritius and the Seychelles, allowing for the transfer of convicted pirates to prison facilities in Somalia. These MoUs, however, do not specify clear standard operating procedures for processing and/or transferring pirates who are determined to be under the age of 18. Kenya is also trying suspected Somali pirates but no prisoner transfer agreement is currently in place.

According to UNICEF-Somalia, some 100 child pirates are currently being detained in a prison in Bosaso, Puntland. A second prison for juvenile pirates with a capacity of 100 is being built in Garoowe, while a 70-person prison for juvenile pirates is being built in Somaliland.

The Republic of Somaliland’s Juvenile Justice Law (2007) raised the age of criminal responsibility for 14 to 15 years and established separate judicial mechanisms for minors, such as child-specific courts of first instance and appellate courts. However, Somaliland’s Law on Combating Piracy (2012) does not make any specific reference to persons under the age of 18.

The Somali sub-region of Puntland does not have any specific legislation pertaining to child protection, though as of April 2013, a policy on orphans and other vulnerable children had been tabled in Parliament.

India’s Piracy Bill (2012) does not make any specific reference to persons under the age of 18.

According to the Roméo Dallaire Child Soldiers Initiative:

One of the most egregious instances of child maritime piracy off the coast of Somalia is recounted on the Canadian Naval Review’s Broadsides forum:

The "Vega 5" hijacking does not appear to be an isolated incident. The Broadsides article continues to report that:

The Roméo Dallaire Child Soldiers Initiative has determined that a significant proportion of those Somali pirates who are currently being tried internationally are actually under the age of 18. In India, 38 out of 61 pirates (62%) facing trial are juveniles; in Germany, 3 out of 10 (30%) are children; and in the United States of America, all three Somali pirates currently facing trial are under the age of 18.

The Roméo Dallaire Child Soldiers Initiative has noted that:


</doc>
<doc id="340401" url="https://en.wikipedia.org/wiki?curid=340401" title="Public interest">
Public interest

The public interest is "the welfare or well-being of the general public" and society.

Economist Lok Sang Ho in his "Public Policy and the Public Interest" argues that the public interest must be assessed impartially and, therefore, defines the public interest as the ""ex ante" welfare of the representative individual." Under a thought experiment, by assuming that there is an equal chance for one to be anyone in society and, thus, could benefit or suffer from a change, the public interest is by definition enhanced whenever that change is preferred to the status quo "ex ante". This approach is "ex ante", in the sense that the change is not evaluated after the fact but assessed before the fact without knowing whether one would actually benefit or suffer from it.

This approach follows the "veil of ignorance" approach, which was first proposed by John Harsanyi but popularized by John Rawls in his 1971 "Theory of Justice". Historically, however, the approach can be traced to John Stuart Mill, who, in his letter to George Grote, explained that "human happiness, even one's own, is in general more successfully pursued by acting on general rules, than by measuring the consequences of each act; and this is still more the case with the general happiness, since any other plan would not only leave everybody uncertain what to expect, but would involve perpetual quarrelling..."

The Institute of Chartered Accountants in England and Wales argues that applying a detailed definition is likely to result in unintended consequences, in Acting in the Public Interest(2012). Instead, each circumstance needs to be assessed based on criteria such as the relevant public, wants, and constraints. The key to assessing any public interest decision is transparency of the decision-making process, including balancing competing interests.

“Public interest law” is a term that became widely adopted in the United States during and after the social turmoil of the 1960s. It built upon a tradition exemplified by Louis Brandeis, who before becoming a U.S. Supreme Court justice incorporated advocacy for the interests of the general public into his legal practice. 
In a celebrated 1905 speech, Brandeis decried the legal profession, complaining that “able lawyers have to a large extent allowed themselves to become adjuncts of great corporations and have neglected their obligation to use their powers for the protection of the people.” In the late 1960s and 1970s, large numbers of American law school graduates began to seek “relevance” in their work — wishing to have an effect on the social issues that were so visibly and hotly debated within American society at that time. They defined themselves as public interest lawyers in order to distinguish themselves from the “corporate adjuncts” referred to by Brandeis.

Public interest law does not describe a body of law or a legal field; the term was adopted to describe whom the public interest lawyers were representing, rather than what matters they would work on. Instead of representing powerful economic interests, they chose to be advocates for otherwise underrepresented individuals. Consequently, a significant current in public interest lawyering has always emphasized the need to provide legal services to those living in poverty. The term has grown, however, to encompass a broader range of activities of lawyers and non-lawyers working toward a multitude of objectives, including civil rights, civil liberties, women’s rights, consumer rights, environmental protection, and so on. Nevertheless, a common denominator for public interest lawyers in the United States and in a growing number of countries remains the ethic of “fighting for the little guy”—that is, representing the underrepresented and vulnerable segments of society.

Public interest has been considered as the core of "democratic theories of government” and often paired with two other concepts, "convenience" and "necessity". Public interest, convenience and necessity appeared for the first time in the Transportation Act of 1920 and also appeared in the Radio Act of 1927. After that, these three concepts became critical criteria for making communication policies and solving some related disputes.



</doc>
<doc id="40437234" url="https://en.wikipedia.org/wiki?curid=40437234" title="Proactive law">
Proactive law

Proactive law seeks a new approach to legal issues in businesses and societies. Instead of perceiving law as a constraint that companies and people in general need to comply with, proactive law considers law as an instrument that can create success and foster sustainable relationships, which in the end carries the potential to increase value for companies, individuals, and societies in general.

The word proactive is the opposite of reactive, meaning that the approach to law is based on an ex ante view rather than an ex post view. According to the dictionary of Merriam-Webster, the word proactive refers to "acting in anticipation of future problems, needs, or changes".
Thus, the proactive law approach challenges the traditional backwards and failure oriented approach to law by acting in anticipation of legal disputes, taking control of potential problems, providing solutions, and self-initiation, instead of reacting to failures and shortcomings.

The hotbed of the proactive law movement is the Nordic countries and Finland in particular. The movement took off in the late 1990s and is almost similar to the American movement – Law as a Competitive Source. Both of these parallel evolutions are founded on the work of Louis M. Brown, developed in the 1950s known as the preventive approach to law.

The proactive law movement has become more visible in recent years, but the idea of an ex ante view is not new. It is generally known that the earlier a dispute or a potential dispute is addressed, the better the chances of a fair, just and prompt solution. Louis M. Brown was the first to introduce the ex ante view in his ground-laying book “Preventive Law”. Although he identified and organized the preventive law into a distinctive way of thinking, he was not the inventor of this approach. It has been, and still is, well known to many legal professionals and every business manager that:

“It usually costs less to avoid getting into trouble than to pay for getting out of trouble.”

To understand the general principles of proactive law requires understanding the core principles of preventive law, as these principles create the foundation for proactive law and proactive contracting. Edward Dauer identifies four core principles of preventive law:


The proactive law movement encompasses the basic principles of preventive law stated above, namely preventing what is not desirable, and keeping problems and risks from materializing. 
Thus, as proactive law consists of preventive law, the characteristics above constitute the foundation of proactive law.

To this preventive dimension of law, proactive law adds a second aspect, which is often neglected in traditional law – known as the "promotive dimension".

The nature of the promotive dimension is positive and constructive and promotes what is desirable while encouraging good behavior. This is where we find the distinction to preventive law. 
In a legal context, proactive law emphasizes the importance of collaboration between legal professionals and other disciplines to achieve the desired goals in circumstances where legal expertise collaborates with other disciplines. Proactive law therefore emphasizes the need for dialogue between different understandings. In a medical context, the preventive law prevents ill health, while proactive law promotes well-being.

The proactive law approach is based on legal certainty, literacy, and cross-professional collaboration to “localize the mines and preventing them from exploding.”

In addition to navigating past the mines, the legal professionals should create economic value, and thus must be outcome-orientated to exploit the promotive dimension. Lawyers and in-house counsel thus must act to achieve results by watching for changes or opportunities and setting improved goals. To do so, legal professionals must highlight opportunities to build a solid business foundation, roadmaps for performance, trust, and better sustainable relationships.

Besides achieving these business goals, it is important to focus on legal risk management to prevent disputes. Many legal disputes arise due to misunderstandings and disappointed expectations. However, careful attention to legal clarity along with early warning mechanisms, and enhanced collaboration between business partners, through establishment of common goals, avoids the business from getting to the stage of dispute.

It is essential in proactive law that legal professionals, managers, and other involved stakeholders collaborate on a cross-professional basis to avoid disputes. In addition to avoiding disputes, it is also important to promote creative thinking. To develop new ideas, and concepts that correspond to the needs, problems or challenges, it is necessary to look towards the future rather than the past, maybe by using already known approaches, but also non-existing approaches. This invites businesses, authorities and researchers to develop solutions through creative thinking.

Thus, proactive law is about problem-solving, detecting real-life causes for potential misunderstandings and failures, but most of all it is about fostering and promoting fruitful and sustainable relationships that enables the stakeholders to reach their goals, creating value for business, individuals, and society as a whole.

An indication that Proactive Law is gaining prominence is the fact that the European Commission has published an opinion on Proactive Law.

The EESC urges a paradigm shift, as the time has come to give up the centuries-old reactive approach to law and to adopt a pro active approach. It is time to look at law in a different way: to look forward rather than back, to focus on how the law is used and oper ates in everyday life and how it is received in the community it seeks to regulate. While responding to and resolving problems remain important, preventing causes of problems is vital, along with serving the needs and facilitating the productive interaction of citizens and businesses.

By its very nature, the Community legal system is precisely the type of area in which the proactive approach should be adopted when planning, drawing up and implementing laws; against this backdrop, the EESC would argue that rules and regu lations are not the only way nor always the best way to achieve the desired objectives; at times, the regulator may best support valuable goals by refraining from regulating and, where appropri ate, encouraging self-regulation and co-regulation. This being the case, the fundamental principles of subsidiarity, proportionality, precaution and sustainability take on new importance and a new dimension.

The EESC believes that the single market can benefit greatly when EU law and its makers — legislators and administrators in the broadest sense — shift their focus from inward, from inside the legal system, rules and institutions, to outward, to the users of the law: to society, citizens and businesses that the legal system is intended to serve.

While the transposition and implementation of laws are important steps towards better regulation at EU level, regulatory success should be measured by how the goals are achieved at the level of the users of the law, EU citizens and businesses. The laws should be communicated in ways that are meaningful to their intended audience, first and foremost to those whose behaviour is affected and not just to the relevant institutions and administrators.

The application of the Proactive Law approach should be considered systematically in all lawmaking and implementation within the EU. The EESC strongly believes that by making this approach not only part of the Better Regulation agenda, and but also a priority for legislators and administrators at the EU, national and regional levels, it would be possible to build a strong legal foundation for individuals and businesses to prosper.

While Proactive Law in general has gained increased attention at the highest legislatory authorities, businesses seem to be the first movers in this developing research field.

When Proactive Law is adapted to businesses the approach is called Proactive Contracting and Proactive Contract Management. The idea is that Proactive Contracting may constitute a sustainable competitive advantage, when implemented thoroughly.

In recent years law has gained increased prominence as a source of competitive advantage to businesses. This prominence originated with the work of scholars and professionals in the United States and Europe. In the US, research of Robert Bird has contributed to the movement of Law as a Competitive Advantage. 
Robert Bird uses a strategy framework to analyze the attributes of law necessary to obtain a competitive advantage. In Europe, the proactive law movement constitutes the same. 
As contracts and contract law are major components of successful R&D, IT, operations management, outsourcing etc., it is important that the contracts and contracting processes involved are successful. 
In the words of Tim Cummins, CEO of the IACCM, “contracts lie at the heart of most business relationships, certainly within Western cultures and economies, and increasingly among all companies or entities that seek to operate in an international market”.

As international trading grows in value and quantity, it is important for businesses to excel in contracting. Businesses that can manage contracting successfully have a competitive advantage ceteris paribus.

By incorporating both a preventive and a promotive focus, the proactive law movement encourages both legal goals, which are often preventive—and business goals, which tend to be promotive.

By combining these two approaches to reaching goals, businesses take advantage of both the preventive focus and the promotive focus.
Tory Higgins has developed a psychological theory called the Regulatory Focus Theory that focuses on motivations and how people tend to achieve their goals.

The two different orientations towards goal achievement, which have been recognized by Tory Higgins, are:

(1) a preventive focus that emphasizes safety, responsibility and security, and

(2) a promotive focus that emphasizes hopes, accomplishments, and advancements.

Thus, the way of businesses to pursuing a goal depends on whether their approach is preventive or promotive. According to Mayer and Weber, people with a preventive focus view goals as minimal targets that produce a low-intensity response when the goal is achieved. On the other hand, people with a promotive approach see goals as maximal targets. Thus, “achievement of the goal results in feelings of high-intensity happiness instead of low-intensity calm”.

If businesses succeed in incorporating both the preventive and promotive approach in reaching their goals, they may able to utilize the advantages of both legal and business goals.


</doc>
<doc id="40851390" url="https://en.wikipedia.org/wiki?curid=40851390" title="Legal opportunity structure">
Legal opportunity structure

Legal opportunity structure or legal opportunity is a concept found in the study of law and social movements. It was first used in order to distinguish it from political opportunity structure or political opportunity, on the basis that law and the courts deserved to be studied in their own right rather than being lumped together with political institutions. Legal opportunities are made up of: access to the courts, which may be affected in particular by the law on standing or "locus standi", and costs rules; 'legal stock' or the set of available precedents on which to hang a case; and judicial receptiveness. Some of these are more obviously structural than others - hence the term legal opportunity is sometimes preferred over legal opportunity structure.

Legal opportunity has been used as an independent variable to help to explain strategy choice by social movement organisations (SMOs) - e.g. why SMOS adopt litigation rather than protest or political lobbying as a strategy. Other variables or explanatory frameworks it is commonly found alongside include framing, resource mobilization and grievance. It can also be employed as a dependent variable.
Legal opportunity theory has been applied to a wide range of policy areas which have seen legal mobilization by social movements, including the environmental, animal rights, women's, LGBT, labor, civil rights, human rights, and disability movements.


</doc>
<doc id="35391721" url="https://en.wikipedia.org/wiki?curid=35391721" title="Public interest law">
Public interest law

Public interest law loosely, refers to legal practices undertaken to help poor or marginalized people, or to effect change in social policies in the public interest, on 'not for profit' terms ("pro bono publico"). In general terms it means a legal action initiated in the court of law for the protection of Public Interest.

It is not a body of law or a legal field, matters lawyers work on. Rather, it denotes the clientele they represent. Instead of serving powerful economic interests, it stands for the advocacy of otherwise under-represented or vulnerable individuals, especially those living in poverty. It has grown to encompass a broader range of activities, typically the field of non-lawyers like civil rights, civil liberties, women's rights, consumer rights, environmental protection, and so on. Nevertheless, a common ethic for public-interest lawyers in a growing number of countries remains “fighting for the little guy”.

At the end of the communist period in the early 1990s, the national legal systems of Central and Eastern Europe were still in a formative stage. The most important source of legal authority for the new human rights groups came from outside the region: the Council of Europe, with its European Convention on Human Rights, and the European Court of Human Rights.

Over time, in the mid-1990s, U.S. experiences became more relevant. The Council of Europe's prerequisite that lawyers use their own country's courts first to seek legal remedies before turning to the European bodies gradually became more than a pro forma exercise, and civil society organizations began to make more effective use of domestic means of adjudication. But by the time local activists were ready to consider the utility of impact litigation, test cases, and other tactics familiar from the U.S. experience, they already understood that their ultimate tactical weapon in any piece of litigation was to use the threat or reality of a supportive decision at the European Court of Human Rights. With this background in mind, it made more sense for the promoters of public interest law in Central and Eastern Europe to talk about "strategic litigation" than about public interest litigation. Using the instrumentality of the European Court of Human Rights effectively required a strategic approach. Not all human rights cases were likely to receive a favorable ruling; a negative ruling could produce more damage to the human rights cause than no ruling at all. The European Court had a rich case law that could provide clues to how a future case might be decided, and there were procedural aspects, such as the requirement to exhaust domestic remedies, to consider.

The core lesson from the U.S. experience for local activists was how courts could be used effectively as a tool for civil society engagement in governance.
The changes to the Italian electoral law from 2014 to 2017 were both "caused by actions born from the bottom (...) the result of a methodical, studied and concerted action. It has been featured by university professors, constitutional and electoral law-makers, parliamentarians and other elected representatives (...), representatives of civil society and ordinary citizens. Their names are, as voters, in more than twenty introductory pleadings (quotations or appeals)", all of them brought pro bono.

Public interest law (公益法) is an accepted term in China, where the basic institutions supporting the rule of law are still extremely nascent. China does not have a common-law system in which lawyers are expected to play a key role in “making law.” Nevertheless, a small but effective community of lawyers has gained acceptance of public interest litigation as a legitimate means of resolving social issues and contributing to a harmonious society, and non-governmental actors have significantly improved the enforcement of rights for migrant workers, women, children and those suffering from environmental degradation, among others. For example, public interest lawyers in China have filed lawsuits in court successfully challenging workplace sexual harassment and the involuntary confinement of healthy people to mental hospitals.

Chinese reformers believe that one avenue for speeding the development of public interest law is implementing an associational standing rule by which organizations can instigate lawsuits to protect the interests of its members. Currently, China’s Civil Procedure Law is undergoing revision. One of the proposed amendments would create a form of associational standing. In theory, the new law would give domestic NGOs the power to file lawsuits in their own name on behalf of their members, but the proposed amendment has engendered spirited debate and its fate is unclear.

In Hong Kong public interest law is an emerging field. The chief vehicle for pursuing public interest claims is judicial review. This is the process by which decisions of the government are challenged in the courts. There has been a surge in judicial review cases since 2000. Environmental issues and minority rights are among the most litigated areas.

One of the pioneers in public interest law in Hong Kong was Pamela Baker. In the late 1980s she litigated a series of landmark courtroom cases challenging the government’s treatment of Vietnamese refugees. In 1995 the Hong Kong Human Rights Monitor was established with the aim of promoting better human rights protection in Hong Kong. Today, the majority of cause lawyers who represent citizens and social groups in human rights and public policy litigation on a consistent basis in Hong Kong are also members of political parties or active participants in social movements outside the courts.

In Hong Kong, the Legal Aid Department provides funding to legal services for those who pass the means and merits test. The two Legal Aid Schemes that it operates, namely the Ordinary Legal Aid Scheme (OLAS) and the Supplementary Legal Aid Scheme (SLAS) have facilitated the practice of public interest law through narrowing the resource inequality between economically disadvantaged litigants and the government. However, NGOs and charitable organizations are not eligible to get legal aid. The NGOs and Charitable organizations contributed to opening of avenues for people who deserved justice but lacked interest to approach courts and helped them in becoming petitioners to get justice.

Apart from legal aid, the Hong Kong Bar Association and The Law Society of Hong Kong jointly provides the Duty Lawyer Scheme which offers free legal representation to eligible defendants on the first day of court appearance. They also run the Free Legal Advice Scheme at their Legal Advice Centres within nine District Offices in Hong Kong with the aim to provide one-off preliminary legal advice to the general public without imposing any means test. The Hong Kong Bar Association and The Law Society of Hong Kong operate their own Bar Free Legal Service Scheme and Free Legal Consultation Scheme respectively where enrolled law firms and barristers specializing in different fields volunteer to give consultations on a pro bono basis.

In addition, unlike in the United States where NGOs and public interest law groups routinely bring public interest lawsuits on behalf of aggrieved individuals, in-house counsel working in NGOs and charities in Hong Kong are not allowed to directly represent the people these organizations serve. Some commentators believe that the inability of NGOs to directly represent clients in legal proceedings has dampened the growth of public interest law in Hong Kong.

Law schools in Hong Kong also organize various programs to promote the idea of "pro bono" legal service to students. Pro bono committees of law firms in Hong Kong also meet on a bimonthly basis in the Hong Kong Legal Community Roundtable, a forum for international law firms to discuss development of pro bono work in Hong Kong and the region.

"Public Interest Litigation" or PIL right since its inception in the Indian judicial system, has shown some good examples of safeguarding the rights of the people of India and has strengthened the position of the Supreme Court of India as preeminent guardian of Fundamental Rights enumerated in the Indian Constitution. It was introduced in India around 1979-80 by the Supreme Court judges, Justice V. R. Krishna Iyer along with Justice P. N. Bhagwati. And since then there had been instances when the Courts are keen to decide the matters of public importance without delay, as the case in Shyam sundar where the court accepted the matter even when the application was made by a letter sent through post.

“Public interest law” is a term that became widely adopted in the United States during and after the social turmoil of the 1960s. It built on a tradition exemplified by Louis Brandeis, who before becoming a U.S. Supreme Court justice incorporated advocacy for the interests of the general public into his legal practice. In a celebrated 1905 speech, Brandeis decried the legal profession, complaining that “able lawyers have to a large extent allowed themselves to become adjuncts of great corporations and have neglected their obligation to use their powers for the protection of the people.” In the late 1960s and 1970s, large numbers of American law school graduates began to seek “relevance” in their work—wishing to affect the social issues that were so visibly and hotly debated within American society at that time. They defined themselves as public interest lawyers in order to distinguish themselves from the “corporate adjuncts” referred to by Brandeis.

Summing up the movement's history in the United States, Stanford University Law Professor Deborah Rhode writes: "Public interest lawyers have saved lives, protected fundamental rights, established crucial principles, transformed institutions, and ensured essential benefits for those who need them most...In virtually every major American social reform movement of the last half century, public interest lawyers have played an important role."
Public interest law is institutionalized in the United States. Nongovernmental organizations that work to promote and protect human rights using the U.S. legal system, fight to protect the environment, or advocate on behalf of consumers, call themselves public interest law organizations. A large community of lawyers practices public interest law in the form of providing legal aid free of charge to those who cannot afford to pay for it. However, the grim reality remains that lawyers are underpaid and grossly overworked, offering perfunctory representation. Clinical legal education, which is well established in the United States, provides opportunities for law students to do practical legal work on basic legal matters as well as more complex public interest issues, such as women’s rights, anti-discrimination law, constitutional rights, and environmental protection, among others. Some law schools have public interest law centers, which advise law students interested in pursuing public interest law careers. Pro bono programs at bar associations and law firms provide opportunities for commercial lawyers to donate time to public interest law activities.

In law, public interest is a defence against certain lawsuits (for instance some libel suits in the United Kingdom) and an exemption from certain laws or regulations (for instance freedom of information laws in the UK). Also, judges in common law systems can make judgements on the grounds of public policy, a related term.


"Note: This Bibliography is adapted from "Public Interest Law Practice: A Selective Bibliography,"a project of the Public Interest Law Committee at Rutgers School of Law, Newark, compiled by Paul Axel-Lute."



</doc>
<doc id="43823562" url="https://en.wikipedia.org/wiki?curid=43823562" title="Framework law">
Framework law

Framework laws are laws that are more specific than constitutional provisions. They lay down general obligations and principles but leave to governing authorities the task of enacting the further legislation and other specific measures, as may be required.


</doc>
<doc id="44497647" url="https://en.wikipedia.org/wiki?curid=44497647" title="Legal mobilisation">
Legal mobilisation

Legal mobilisation is a tool available to paralegal and advocacy groups, to achieve legal empowerment by supporting a marginalized issues of a stakeholder, in negotiating with the other concerned agencies and other stakeholders, by strategic combined use of legal processes along with advocacy, media engagement and social mobilisation. As per Frances Kahen Zemans (1983) " the Legal mobilisation is "a desire or want, which is translated into a demand as an assertion of one's rights"." 

According to Lisa Vanhala (November 2011) Legal mobilisation in its narrowest sense, may refer to high-profile litigation efforts for (or, arguably, against) social change or more broadly, term legal mobilisation has been used to describe any type of process by which an individual or collective actors invoke legal norms, discourse, or symbols to influence policy or behavior. This typically means that there are policies or regulations to mobilize around and a mechanism by which to do so. Legislative activity does create an opportunity for legal mobilization. The courts become particularly relevant when petitioners have grounds to file suit.

The use of the law and legal systems by disadvantaged people to contest the unfair distribution of power and resources is a real-world phenomenon that predates and exists independently of international law and justice assistance.

Particularly in circumstances where traditional power resources, in terms of bargaining power and worker solidarity, are not firmly established, Use of the "legal mobilisation" clearly offers important additional tactics.


</doc>
<doc id="226126" url="https://en.wikipedia.org/wiki?curid=226126" title="Legalism (theology)">
Legalism (theology)

Legalism (or nomism), in Christian theology, is the act of putting law above gospel by establishing requirements for salvation beyond repentance and faith in Jesus Christ and reducing the broad, inclusive and general precepts of the Bible to narrow and rigid moral codes. It is an over-emphasis on discipline of conduct, or legal ideas, usually of misguided rigour, pride, superficiality, the neglect of mercy, and ignorance of the grace of God or emphasizing the letter of law at the expense of the spirit. Legalism is alleged against any view that obedience to law, not faith in God's grace, is the pre-eminent principle of redemption. On the Biblical viewpoint that redemption is not earned by works, but that obedient faith is required to enter and remain in the redeemed state, see Covenantal nomism.

The words 'legalism' or 'legalist' do not occur in the Old or New Testaments. Legalism's root word, "law" (Greek "nomos"), occurs frequently in the New Testament, and sometimes is interpreted as legalism. In 1921, Ernest De Witt Burton stated that in , ""nomou" is here evidently used ... in its legalistic sense, denoting divine law viewed as a purely legalistic system made up of statutes, on the basis of obedience or disobedience to which individuals are approved or condemned as a matter of debt without grace. This is divine law as the legalist defined it." The Greek of Paul's day lacked any term corresponding to the distinct position of "legalism", "legalist", or "legalistic", leading C.E.B. Cranfield to commend "the possibility that Pauline statements which at first sight seem to disparage the law, were really directed not against the law itself but against that misunderstanding and misuse of it for which we now have a convenient terminology" (legalism). Messianic Jewish Bible translator David H. Stern cited these two scholars to support the translation framework that often "<nowiki>'</nowiki>"nomos"<nowiki>'</nowiki> means 'legalism' and not God's "Torah"", especially in Paul's constructs "erga nomou" (literally "works of law", rendered by Stern "legalistic observance of "Torah" commands") and "upo nomon" (literally "under law", rendered by Stern by 13 words, "in subjection to the system which results from perverting the "Torah" into legalism").

One concept of legalism, the belief that salvation can be earned by obedience to laws, is referred to in various New Testament books, including Galatians. In this case, some Jews who had become Christians believed that in order to obtain salvation, both faith in Christ (as Messiah), and obedience to the Mosiac laws were required, such as the cases of the circumcision controversy and the Incident at Antioch. Generally, however, these cases are referred to as the Judaizer controversy, rather than a legalism controversy, but the two are related.

Legalism refers to any doctrine which states salvation comes strictly from adherence to the law. It can be thought of as a works-based religion. Groups in the New Testament said to be falling into this category include the Pharisees, Sadducees, Scribes, Judaizers, and Nicolaitans. They are legalists because they emphasized obeying the Law of Moses, in the case of the Pharisees and Scribes, to the letter without understanding the concept of grace. Jesus condemned their legalism in Matthew 23. The Pharisees love of the praises of men for their strict adherence is said to be a prime example of legalism.

Legalism is sometimes confused with obedience. New Testament books such as Romans, speak of grace and obedience together. An example is found in Romans 1:5 (New American Standard Version) speaking of Christ 'through whom we have received grace and apostleship to bring about the obedience of faith among all the Gentiles, for His name's sake...' The goal of receiving the grace was to bring about obedience of faith. Here grace, faith and obedience are tied together. Other references are in Acts 5:29, 32; Romans 16:19; 2 Corinthians 7:15; Hebrews 5:9.

Legalism is also confused with discipline, which is often spoken of in a positive light. See 1 Corinthians 9:17; 1 Timothy 4:7; 2 Timothy 1:7 and Hebrews 12:5–11.

A third common misunderstanding of legalism is the word law. Law in many places in the Bible refers to the Law of Moses, see also Biblical law in Christianity. In Galatians the Judaizers were trying to insist that salvation required that a person be circumcised prior to obeying the Law of Christ. Galatians 2:16 says, "Knowing that a man is not justified by the works of the law, but by the faith of Jesus Christ, even we have believed in Jesus Christ, that we might be justified by the faith of Christ, and not by the works of the law: for by the works of the law shall no flesh be justified" (King James Version). The faith here is the Law of Christ and the law here is the Law of Moses. The legalism of the Judaizers was that obedience to the law of Moses was necessary to be saved.

Legalism in the New Testament is believed by some as being revealed by the life of Saul prior to his conversion. Some believe that Saul sought to redeem himself by his works of persecution of the church and its ultimate destruction. Acts 26:9–11 reveals, "I verily thought with myself, that I ought to do many things contrary to the name of Jesus of Nazareth. Which thing I also did in Jerusalem: and many of the saints did I shut up in prison, having received authority from the chief priests; and when they were put to death, I gave my voice against them. And I punished them oft in every synagogue, and compelled them to blaspheme; and being exceedingly mad against them, I persecuted them even unto strange cities" (King James Version). Galatians 1:13–14 states, "For ye have heard of my conversation in time past in the Jews' religion, how that beyond measure I persecuted the church of God, and wasted it: And profited in the Jews' religion above many my equals in mine own nation, being more exceedingly zealous of the traditions of my fathers" (King James Version). These two texts emphasize the nature of Saul's religion, works.

However, in this passage the obedience is not tied to the obeying of specific Old Testament laws, such as keeping Sabbath or circumcision.

At the Council of Jerusalem, c. 50, James the Just decreed the "Apostolic Decree":

Though the "Apostolic Decree" is no longer observed by many Christian denominations today, it is still observed in full by the Greek Orthodox. and it was a very effective philosophy during that time.

In Roman Catholicism, good works are done in service to God and one's neighbour, by faith working through love. In contrast, a severity in the imposition of, or overly scrupulous conformity to any rule of piety, may be charged with legalism.

In an attempt to resolve the dispute over legalism, the Joint Declaration on the Doctrine of Justification was a document issued in 1999 by Lutheran-Catholic clerical representatives, declaring a common belief in "Sola gratia", that grace alone can save the faithful, and that there is a "progressive infusion" of grace in the spirit of the believer.

In Protestant, Evangelical, Christian theology, especially in popular versions of the same, the charge of legalism is an accusation of overzealous adherence to the word of the Bible (as law) in all things said, established or accomplished in a believer's life (cf. bibliolatry). In that context, to apply the criticism of legalism to a theological position or religious attitude implies that the accused has overturned the Gospel of salvation through faith and new life in Jesus Christ and has instead substituted some principle of personal works of strict adherence to the word, through action, thought, or speech for the unearned grace of God.

Throughout the history of Christianity, certain beliefs and practices have tended to draw charges of legalism. These include:


Several underlying dynamics appear in these controversies. The permitted scope of veneration of material objects versus claims that such veneration is idolatry, affects the perceived sanctity of ritual spaces and objects, and therefore of the rituals and customs themselves. Teachings about the authority of the church, the sources of legitimacy of that authority, and the role of clergy versus the priesthood of all believers, also affect these debates.




</doc>
<doc id="764323" url="https://en.wikipedia.org/wiki?curid=764323" title="Lawmaking">
Lawmaking

Lawmaking is the process of crafting legislation. In its purest sense, it is the basis of governance. 
This form of law making is also applied in India. It is a process which works in India on the basis of Indian Constitution.
Lawmaking in modern democracies is the work of legislatures, which exist at the local, regional, and national levels and make such laws as are appropriate to their level, and binding over those under their jurisdictions. These bodies are influenced by lobbyists, pressure groups, sometimes partisan considerations, but ultimately by the voters who elected them and to which they are responsible, if the system is working as intended. Even the expenditure of governmental funds is an aspect of lawmaking, as in most jurisdictions the budget is a matter of law.

In dictatorships and absolute monarchies the leader can make law essentially by the stroke of a pen, one of the main objections to such an arrangement. However, a seemingly-analogous event can occur even in a democracy where the executive can make executive orders which have the force of law. In some instance, even regulations issued by executive departments can have the force of law. Libertarians, in particular, are known for denouncing such actions as being anti-democratic, but they have become such a salient feature of modern governance that it is hard to picture a system in which they no longer exist, because it is hard to picture the time involved in every regulation being debated prior to becoming law. That, say libertarians, is precisely the point: if such executive orders and regulations do not stand up to legislative scrutiny, they should never be implemented. In response to this, limits on regulatory authority have been made legislatively, and libertarians still contend for, if not the abolition of executive orders altogether, then their automatic sunset after a fixed period if not legislatively reviewed and confirmed; this policy has been adopted in some jurisdictions.


</doc>
<doc id="44683200" url="https://en.wikipedia.org/wiki?curid=44683200" title="Legal consciousness">
Legal consciousness

Legal consciousness is a "collection" of understood and/or imagined to have understood, legal awareness of ideas, views, feelings and traditions imbibed through legal socialization; which reflects as legal culture among given individual, or a group, or a given society at large. The legal consciousness evaluates the existing law and also bears in mind an image of the desired or ideal law.

Consciousness is not an individual trait nor solely ideational; legal consciousness is a type of social practice reflecting and forming social structures. The study of legal Consciousness documents the forms of participation and interpretation through which act or sustain, reproduce, or amend the circulating contested or hegemonic structures of meanings concerning law. Legal consciousness is the way in which law is experienced and interpreted by specific individuals as they engage, avoid, resist or just assume the law and legal meanings.

Legal consciousness is a state of being, legal socialisation is the process to Legal consciousness; where as legal awareness & legal mobilisation are means to achieve the same.

The Great Soviet Encyclopaedia (1979) defined legal consciousness as " "the sum of views and ideas expressing the attitude of people toward law, legality, and justice and their concept of what is lawful and unlawful. Legal consciousness is a form of social consciousness. Legal ideology, the system of legal views based on certain social and scientific viewpoints, is a concentrated expression of legal consciousness. The customs and feelings of people in relation to legal phenomena constitute the psychological aspect of legal consciousness; among these are a sense of justice and a loathing of crimes and illegal actions" "

Legal consciousness is defined by Ewick and Silbey as the process by which people make sense of their experiences by relying on legal categories and concepts. People do this even when they are not familiar with the details and minutia of law or the legal system. They explain that there are cultural schemas provided by law that people use to make sense of their experiences. They refer to this as legality. The concept of legality includes "the meanings, sources, authority and cultural practices that are commonly recognized as legal, regardless of who employs them or for what ends." These meanings and sources and different ways of knowing and understanding enable people to make sense of what happens to them and what that might mean in terms of their rights and options. This process of understanding legal experiences occurs within a larger ecosystem in which there are disputes over meaning and values. Seron and Munger explain that ""in addition, class may affect legal consciousness: Law may mean different things depending on an individual's location in the various hierarchies of status, prestige, and knowledge associated with membership in a social class.

legal consciousness narratives



</doc>
<doc id="48373223" url="https://en.wikipedia.org/wiki?curid=48373223" title="Gender empowerment">
Gender empowerment

Gender empowerment is the empowerment of people of any gender. While conventionally being reduced to its aspect of empowerment of women, the concept stresses the distinction between biological sex and gender as a role, also referring to other marginalized genders in a particular political or social context.

Gender empowerment has become a significant topic of discussion in regard to development and economics. Entire nations, businesses, communities, and groups can benefit from the implementation of programs and policies that adopt the notion of women empowerment. Empowerment is one of the main procedural concerns when addressing human rights and development. The Human Development and Capabilities Approach, The Millennium Development Goals, and other credible approaches/goals point to empowerment and participation as a necessary step if a country is to overcome the obstacles associated with poverty and development.

Gender empowerment can be measured through the Gender Empowerment Measure, or the GEM. The GEM shows women's participation in a given nation, both politically and economically. Gem is calculated by tracking "the share of seats in parliament held by women; of female legislators, senior officials and managers; and of female profession and technical workers; and the gender disparity in earned income, reflecting economic independence." It then ranks countries given this information. Other measures that take into account the importance of female participation and equality include: the Gender Parity Index and the Gender Development Index (GDI).



</doc>
<doc id="51490" url="https://en.wikipedia.org/wiki?curid=51490" title="Rights">
Rights

Rights are legal, social, or ethical principles of freedom or entitlement; that is, rights are the fundamental normative rules about what is allowed of people or owed to people, according to some legal system, social convention, or ethical theory. Rights are of essential importance in such disciplines as law and ethics, especially theories of justice and deontology.
Rights are often considered fundamental to civilization, for they are regarded as established pillars of society and culture, and the history of social conflicts can be found in the history of each right and its development. According to the "Stanford Encyclopedia of Philosophy", "rights structure the form of governments, the content of laws, and the shape of morality as it is currently perceived".

There is considerable disagreement about what is meant precisely by the term "rights". It has been used by different groups and thinkers for different purposes, with different and sometimes opposing definitions, and the precise definition of this principle, beyond having something to do with normative rules of some sort or another, is controversial.

One way to get an idea of the multiple understandings and senses of the term is to consider different ways it is used. Many diverse things are claimed as rights: 

There are likewise diverse possible ways to categorize rights, such as:

There has been considerable debate about what this term means within the academic community, particularly within fields such as philosophy, law, deontology, logic, political science, and religion.


Some thinkers see rights in only one sense while others accept that both senses have a measure of validity. There has been considerable philosophical debate about these senses throughout history. For example, Jeremy Bentham believed that legal rights were the essence of rights, and he denied the existence of natural rights; whereas Thomas Aquinas held that rights purported by positive law but not grounded in natural law were not properly rights at all, but only a facade or pretense of rights.


Liberty rights and claim rights are the inverse of one another: a person has a liberty right permitting him to do something only if there is no other person who has a claim right forbidding him from doing so. Likewise, if a person has a claim right against someone else, then that other person's liberty is limited. For example, a person has a "liberty right" to walk down a sidewalk and can decide freely whether or not to do so, since there is no obligation either to do so or to refrain from doing so. But pedestrians may have an obligation not to walk on certain lands, such as other people's private property, to which those other people have a claim right. So a person's "liberty right" of walking extends precisely to the point where another's "claim right" limits his or her freedom.

In one sense, a right is a permission to do something or an entitlement to a specific service or treatment from others, and these rights have been called "positive rights". However, in another sense, rights may allow or require inaction, and these are called "negative rights"; they permit or require doing nothing. For example, in some countries, e.g. the United States, citizens have the "positive right" to vote and they have the "negative right" to not vote; people can choose not to vote in a given election without punishment. In other countries, e.g. Australia, however, citizens have a positive right to vote but they don't have a negative right to not vote, since voting is compulsory. Accordingly:

Though similarly named, positive and negative rights should not be confused with "active rights" (which encompass "privileges" and "powers") and "passive rights" (which encompass "claims" and "immunities").

The general concept of rights is that they are possessed by individuals in the sense that they are permissions and entitlements to do things which other persons, or which governments or authorities, can not infringe. This is the understanding of people such as the author Ayn Rand who argued that only individuals have rights, according to her philosophy known as Objectivism. However, others have argued that there are situations in which a group of persons is thought to have rights, or "group rights". Accordingly:


There can be tension between individual and group rights. A classic instance in which group and individual rights clash is conflicts between unions and their members. For example, individual members of a union may wish a wage higher than the union-negotiated wage, but are prevented from making further requests; in a so-called closed shop which has a union security agreement, only the union has a "right" to decide matters for the individual union members such as wage rates. So, do the supposed "individual rights" of the workers prevail about the proper wage? Or do the "group rights" of the union regarding the proper wage prevail? Clearly this is a source of tension.

The Austrian School of Economics holds that only individuals think, feel, and act whether or not members of any abstract group. The society should thus according to economists of the school be analyzed starting from the individual. This methodology is called methodological individualism and is used by the economists to justify individual rights.

Other distinctions between rights draw more on historical association or family resemblance than on precise philosophical distinctions. These include the distinction between civil and political rights and economic, social and cultural rights, between which the articles of the Universal Declaration of Human Rights are often divided. Another conception of rights groups them into three generations. These distinctions have much overlap with that between negative and positive rights, as well as between individual rights and group rights, but these groupings are not entirely coextensive.

Rights are often included in the foundational questions that governments and politics have been designed to deal with. Often the development of these socio-political institutions have formed a dialectical relationship with rights.

Rights about particular issues, or the rights of particular groups, are often areas of special concern. Often these concerns arise when rights come into conflict with other legal or moral issues, sometimes even other rights. Issues of concern have historically included labor rights, LGBT rights, reproductive rights, disability rights, patient rights and prisoners' rights. With increasing monitoring and the information society, information rights, such as the right to privacy are becoming more important.

Some examples of groups whose rights are of particular concern include animals, and amongst humans, groups such as children and youth, parents (both mothers and fathers), and men and women.

Accordingly, politics plays an important role in developing or recognizing the above rights, and the discussion about which behaviors are included as "rights" is an ongoing political topic of importance. The concept of rights varies with political orientation. Positive rights such as a "right to medical care" are emphasized more often by left-leaning thinkers, while right-leaning thinkers place more emphasis on negative rights such as the "right to a fair trial".

Further, the term "equality" which is often bound up with the meaning of "rights" often depends on one's political orientation. Conservatives and libertarians and advocates of free markets often identify equality with equality of opportunity, and want equal and fair rules in the process of making things, while agreeing that sometimes these fair rules lead to unequal outcomes. In contrast, socialists often identify equality with equality of outcome and see fairness when people have equal amounts of goods and services, and therefore think that people have a right to equal portions of necessities such as health care or economic assistance or housing.

In philosophy, meta-ethics is the branch of ethics that seeks to understand the nature of ethical properties, statements, attitudes, and judgments. Meta-ethics is one of the three branches of ethics generally recognized by philosophers, the others being normative ethics and applied ethics.

While normative ethics addresses such questions as "What should one do?", thus endorsing some ethical evaluations and rejecting others, meta-ethics addresses questions such as "What "is" goodness?" and "How can we tell what is good from what is bad?", seeking to understand the nature of ethical properties and evaluations.

Rights ethics is an answer to the meta-ethical question of "what normative ethics is concerned with" (Meta-ethics also includes a group of questions about how ethics comes to be known, true, etc. which is not directly addressed by rights ethics).
Rights ethics holds that normative ethics is concerned with rights. Alternative meta-ethical theories are that ethics is concerned with one of the following:

Rights ethics has had considerable influence on political and social thinking. The Universal Declaration of Human Rights gives some concrete examples of widely accepted rights.

Some philosophers have criticised rights as ontologically dubious entities. For instance, although in favour of the extension of individual legal rights, the utilitarian philosopher Jeremy Bentham opposed the idea of natural law and natural rights, calling them "nonsense upon stilts". Further, one can question the ability of rights to actually bring about justice for all.

The Modern English word "right" derives from Old English "riht" or "reht", in turn from Proto-Germanic "*riχtaz" meaning "right" or "direct", and ultimately from Proto-Indo-European "*reg-to-" meaning "having moved in a straight line", in turn from "*(o)reg'(a)-" meaning "to straighten or direct". In several different Indo-European languages, a single word derived from the same root means both "right" and "law", such as French "droit", Spanish "derecho", German "Recht", and Italian "diritto".

Many other words related to normative or regulatory concepts derive from this same root, including "correct", "regulate", and "rex" (meaning "king"), whence "regal" and thence "royal". Likewise many more geometric terms derive from this same root, such as "erect" (as in "upright"), "rectangle" (literally "right angle"), "straight" and "stretch". Like "right", the English words "rule" and "ruler", deriving still from the same root, have both normative or regulatory and geometric meanings (e.g. a ruler as in a king, or a ruler as in a straightedge).

Several other roots have similar normative and geometric descendants, such as Latin "norma", whence "norm", "normal", and "normative" itself, and also geometric concepts such as "normal vectors"; and likewise Greek "ortho" and Latin "ordo", meaning either "right" or "correct" (as in "orthodox", meaning "correct opinion") or "straight" or "perpendicular" (as in "orthogonal", meaning "perpendicular angle"), and thence "order", "ordinary", etc.

The specific enumeration of rights has differed greatly in different periods of history. In many cases, the system of rights promulgated by one group has come into sharp and bitter conflict with that of other groups. In the political sphere, a place in which rights have historically been an important issue, constitutional provisions of various states sometimes address the question of who has what legal rights.

Historically, many notions of rights were authoritarian and hierarchical, with different people granted different rights, and some having more rights than others. For instance, the right of a father to respected from his son did not indicate a right from the son to receive a return from that respect; and the divine right of kings, which permitted absolute power over subjects, did not leave a lot of room for many rights for the subjects themselves.

In contrast, modern conceptions of rights have often emphasized liberty and equality as among the most important aspects of rights, as was evident in the American and French revolutions.

Important documents in the political history of rights include:



Organisations:



</doc>
<doc id="35097397" url="https://en.wikipedia.org/wiki?curid=35097397" title="Freemen on the land">
Freemen on the land

Freemen-on-the-land (also freemen-of-the-land, the freemen movement or simply freemen) are a loose group of individuals who believe that they are bound by statute laws only if they consent to those laws. They believe that they can therefore declare themselves independent of the government and the rule of law, holding that the only "true" law is their own interpretation of "common law". This belief has been described as a conspiracy theory. Freemen are active in English-speaking countries: the United Kingdom, Ireland, Canada, the United States, Australia, and New Zealand.

In the Canadian court case "Meads v. Meads", Alberta Court of Queen's Bench Associate Chief Justice John D. Rooke used the phrase "Organised Pseudolegal Commercial Arguments" (OPCA) to describe the techniques and arguments used by freemen in court, describing them as frivolous and vexatious. There is no recorded instance of freeman tactics being upheld in a court of law. In refuting each of the arguments used by Meads, Rooke concluded that "a decade of reported cases, many of which he refers to in his ruling, have failed to prove a single concept advanced by OPCA litigants."

The Federal Bureau of Investigation (FBI) in the United States classifies freemen as sovereign citizen extremists and domestic terrorists.

Freemen believe that statute law is a contract, and that individuals can therefore opt out of statute law, choosing instead to live under what they call "common" (case) and "natural" laws. They believe natural laws require only that individuals do not harm others, do not damage the property of others, and do not use "fraud or mischief" in contracts. They say that all people have two parts to their existence: their body and their legal "person". The latter is represented by the individual's birth certificate; some freemen claim that it is entirely limited to the birth certificate. Under this theory, a "strawman" is created when a birth certificate is issued, and this "strawman" is the entity who is subject to statutory law. The physical self is referred to by a slightly different name, such as "John of the family Smith" instead of "John Smith".

Many freemen beliefs are based on idiosyncratic interpretations of admiralty or maritime law, which the freemen claim govern the commercial world. These beliefs stem from fringe interpretations of various nautical-sounding words, such as ownership, citizenship, dock, or birth (berth) certificate. Freemen refer to the court as a "ship", the court's occupants as "passengers" and may claim that those leaving are "men overboard".

Freemen will try to claim common law (as opposed to admiralty law) jurisdiction by asking "Do you have a claim against me?" This, they contend, removes their consent to be governed by admiralty law and turns the court into a common law court, so that proceedings would have to go forward according to their version of common law. This procedure has never been successfully used.

Freemen will often not accept legal representation, believing that to do so would mean contracting with the state. They believe that the United Kingdom and Canada are now operating in bankruptcy and are therefore under admiralty law. They believe that since the abolition of the gold standard, UK currency is backed not by gold but by the people (or the "legal fiction of their persons"). They describe persons as creditors of the UK corporation. Therefore, a court is a place of business, and a summons is an invitation to discuss the matter at hand, with no powers to require attendance or compliance. They may believe that the government controls secret bank accounts in their name as part of this theory, which may be accessed to pay off debts.

Freemen's beliefs are largely based on misunderstandings and wishful thinking, and do not stand up well to legal scrutiny.
None of the beliefs held by freemen have ever been supported by any judgments or verdicts in any criminal or civil court cases anywhere. An English solicitor, writing anonymously, commented:

Freemen believe that since they exist in a common law jurisdiction where equality is paramount and mandatory, the people in the government and courts are not above the law, and that government and court personnel therefore must obtain the consent of the governed. Freemen believe that government employees who do not obtain consent of the governed have abandoned the rule of law. They believe this consent is routinely secured by way of people submitting applications and through acts of registration. They believe the public servants have deceived the population into abandoning their status as freemen in exchange for the status of a "child of the province" or "ward of the state", allowing those children to collect benefits such as welfare, unemployment insurance, and pension plans or old age security.

Freemen believe that the government has to establish "joinder" to link oneself and one's legal person. If one is asked whether one is "John Smith" and one says that is so, one has established joinder and connected the physical and human persons. The next step is to obtain consent. Statutes are merely invitations to enter a contract, and are only legally enforceable if one enters into the contract consensually. Otherwise, statute laws are not applicable. Freemen believe that the government is constantly trying to trick people into entering into a contract with them, so they often return bills, notices, summons and so on with the message "No contract—return to sender".

A "notice of understanding and intent and claim of right" is a document used by freemen to declare their sovereignty. The signed document, often notarised, is sent to the Queen and possibly other authorities such as the Prime Minister and police chiefs. It usually begins with the words "Whereas it is my understanding" and goes on to state their understanding of the law and their lack of consent to it.


The bluntly idiotic substance of Mr. Mead's argument explains the unnecessarily complicated manner in which it was presented. OPCA arguments are never sold to their customers as simple ideas, but instead are byzantine schemes which more closely resemble the plot of a dark fantasy novel than anything else. Latin maxims and powerful sounding language are often used. Documents are often ornamented with many strange markings and seals. Litigants engage in peculiar, ritual‑like in court conduct. All these features appear necessary for gurus to market OPCA schemes to their often desperate, ill‑informed, mentally disturbed, or legally abusive customers. This is crucial to understand the non-substance of any OPCA concept or strategy. The story and process of a OPCA scheme is not intended to impress or convince the Courts, "but rather to impress the guru's customer". 


The whole process meant that a simple matter of driving without insurance took up hours of police time – and ultimately a stint behind bars after being convicted of contempt of court while defending himself. We hope this case acts as a warning that to obstruct the police and the courts is not a wise move.


Lawyers and notaries in British Columbia and Alberta, Canada, have been warned by their professional bodies about dealing with freemen as clients. In particular, lawyers have been advised to be careful not to stamp or notarise the pseudo-legal documents that freemen typically use, so as not to create a perception of authority for such documents.

U.S. police, both speaking personally and as official guidance, have provided advice to law enforcement on dealing with the similar sovereign citizen movement. These have noted the need for caution after a case in which two policemen were murdered by a "sovereign citizen" during a traffic stop.




</doc>
<doc id="25009" url="https://en.wikipedia.org/wiki?curid=25009" title="Privacy">
Privacy

Privacy is the ability of an individual or group to seclude themselves, or information about themselves, and thereby express themselves selectively. The boundaries and content of what is considered private differ among cultures and individuals, but share common themes. When something is private to a "person", it usually means that something is inherently special or sensitive to them. The domain of privacy partially overlaps with security (confidentiality), which can include the concepts of appropriate use, as well as protection of information. Privacy may also take the form of bodily integrity.

The right not to be subjected to unsanctioned invasions of privacy by the government, corporations or individuals is part of many countries' privacy laws, and in some cases, constitutions. All countries have laws which in some way limit privacy. An example of this would be law concerning taxation, which normally requires the sharing of information about personal income or earnings. In some countries individual privacy may conflict with freedom of speech laws and some laws may require public disclosure of information which would be considered private in other countries and cultures. This was a major concern in the United States, with the Supreme Court passage of Citizens United.

Privacy may be voluntarily sacrificed, normally in exchange for perceived benefits and very often with specific dangers and losses, although this is a very strategic view of human relationships. For example, people may be ready to reveal their name, if that allows them to promote trust by others and thus build meaningful social relations. Research shows that people are more willing to voluntarily sacrifice privacy if the data gatherer is seen to be transparent as to what information is gathered and how it is used. In the business world, a person may volunteer personal details (often for advertising purposes) in order to gamble on winning a prize. A person may also disclose personal information as part of being an executive for a publicly traded company in the USA pursuant to federal securities law. Personal information which is voluntarily shared but subsequently stolen or misused can lead to identity theft.

The concept of universal individual privacy is a modern construct primarily associated with Western culture, British and North American in particular, and remained virtually unknown in some cultures until recent times. According to some researchers, this concept sets Anglo-American culture apart even from Western European cultures such as French or Italian. Most cultures, however, recognize the ability of individuals to withhold certain parts of their personal information from wider society—closing the door to one's home, for example.

The distinction or overlap between secrecy and privacy is ontologically subtle, which is why the word "privacy" is an example of an untranslatable lexeme, and many languages do not have a specific word for "privacy". Such languages either use a complex description to translate the term (such as Russian combining the meaning of "уединение"—solitude, "секретность"—secrecy, and "частная жизнь"—private life) or borrow from English "privacy" (as Indonesian "privasi" or Italian "la privacy"). The distinction hinges on the discreteness of interests of parties (persons or groups), which can have emic variation depending on cultural mores of individualism, collectivism, and the negotiation between individual and group rights. The difference is sometimes expressed humorously as, "when "I" withhold information, it is privacy; when "you" withhold information, it is secrecy."

A broad multicultural literary tradition going to the beginnings of recorded history discusses the concept of privacy. One way of categorizing all concepts of privacy is by considering all discussions as one of these concepts:


In 1890 the United States jurists Samuel D. Warren and Louis Brandeis wrote "The Right to Privacy", an article in which they argued for the "right to be let alone", using that phrase as a definition of privacy. There is extensive commentary over the meaning of being "let alone", and among other ways, it has been interpreted to mean the right of a person to choose seclusion from the attention of others if they wish to do so, and the right to be immune from scrutiny or being observed in private settings, such as one's own home. Although this early vague legal concept did not describe privacy in a way that made it easy to design broad legal protections of privacy, it strengthened the notion of privacy rights for individuals and began a legacy of discussion on those rights.

Limited access refers to a person's ability to participate in society without having other individuals and organizations collect information about them.

Various theorists have imagined privacy as a system for limiting access to one's personal information. Edwin Lawrence Godkin wrote in the late 19th century that "nothing is better worthy of legal protection than private life, or, in other words, the right of every man to keep his affairs to himself, and to decide for himself to what extent they shall be the subject of public observation and discussion." Adopting an approach similar to the one presented by Ruth Gavison 9 years earlier, Sissela Bok said that privacy is "the condition of being protected from unwanted access by others—either physical access, personal information, or attention."

Control over one's personal information is the concept that "privacy is the claim of individuals, groups, or institutions to determine for themselves when, how, and to what extent information about them is communicated to others." Charles Fried said that "Privacy is not simply an absence of information about us in the minds of others; rather it is the control we have over information about ourselves. Nevertheless, in the era of big data, control over information is under pressure.

Alan Westin defined four states—or experiences—of privacy: solitude, intimacy, anonymity, and reserve. Solitude is a physical separation from others. Intimacy is a "close, relaxed, and frank relationship between two or more individuals" that results from the seclusion of a pair or small group of individuals. Anonymity is the "desire of individuals for times of 'public privacy.'" Lastly, reserve is the "creation of a psychological barrier against unwanted intrusion"; this creation of a psychological barrier requires others to respect an individual's need or desire to restrict communication of information concerning himself or herself.

In addition to the psychological barrier of reserve, Kirsty Hughes identified three more kinds of privacy barriers: physical, behavioral, and normative. Physical barriers, such as walls and doors, prevent others from accessing and experiencing the individual. (In this sense, "accessing" an individual includes accessing personal information about him or her.) Behavioral barriers communicate to others—verbally, through language, or non-verbally, through personal space, body language, or clothing—that an individual does not want them to access or experience him or her. Lastly, normative barriers, such as laws and social norms, restrain others from attempting to access or experience an individual.

Privacy is sometimes defined as an option to have secrecy. Richard Posner said that privacy is the right of people to "conceal information about themselves that others might use to their disadvantage".

In various legal contexts, when privacy is described as secrecy, a conclusion if privacy is secrecy then rights to privacy do not apply for any information which is already publicly disclosed. When privacy-as-secrecy is discussed, it is usually imagined to be a selective kind of secrecy in which individuals keep some information secret and private while they choose to make other information public and not private.

Privacy may be understood as a necessary precondition for the development and preservation of personhood. Jeffrey Reiman defined privacy in terms of a recognition of one's ownership of his or her physical and mental reality and a moral right to his or her self-determination. Through the "social ritual" of privacy, or the social practice of respecting an individual's privacy barriers, the social group communicates to the developing child that he or she has exclusive moral rights to his or her body—in other words, he or she has moral ownership of his or her body. This entails control over both active (physical) and cognitive appropriation, the former being control over one's movements and actions and the latter being control over who can experience one's physical existence and when.

Alternatively, Stanley Benn defined privacy in terms of a recognition of oneself as a subject with agency—as an individual with the capacity to choose. Privacy is required to exercise choice. Overt observation makes the individual aware of himself or herself as an object with a "determinate character" and "limited probabilities." Covert observation, on the other hand, changes the conditions in which the individual is exercising choice without his or her knowledge and consent.

In addition, privacy may be viewed as a state that enables autonomy, a concept closely connected to that of personhood. According to Joseph Kufer, an autonomous self-concept entails a conception of oneself as a "purposeful, self-determining, responsible agent" and an awareness of one's capacity to control the boundary between self and other—that is, to control who can access and experience him or her and to what extent. Furthermore, others must acknowledge and respect the self's boundaries—in other words, they must respect the individual's privacy.

The studies of psychologists such as Jean Piaget and Victor Tausk show that, as children learn that they can control who can access and experience them and to what extent, they develop an autonomous self-concept. In addition, studies of adults in particular institutions, such as Erving Goffman's study of "total institutions" such as prisons and mental institutions, suggest that systemic and routinized deprivations or violations of privacy deteriorate one's sense of autonomy over time.

Privacy may be understood as a prerequisite for the development of a sense of self-identity. Privacy barriers, in particular, are instrumental in this process. According to Irwin Altman, such barriers "define and limit the boundaries of the self" and thus "serve to help define [the self]." This control primarily entails the ability to regulate contact with others. Control over the "permeability" of the self's boundaries enables one to control what constitutes the self and thus to define what is the self.

In addition, privacy may be seen as a state that fosters personal growth, a process integral to the development of self-identity. Hyman Gross suggested that, without privacy—solitude, anonymity, and temporary releases from social roles—individuals would be unable to freely express themselves and to engage in self-discovery and self-criticism. Such self-discovery and self-criticism contributes to one's understanding of oneself and shapes one's sense of identity.

In a way analogous to how the personhood theory imagines privacy as some essential part of being an individual, the intimacy theory imagines privacy to be an essential part of the way that humans have strengthened or intimate relationships with other humans. Because part of human relationships includes individuals volunteering to self-disclose some information, but withholding other information, there is a concept of privacy as a part of the process by means of which humans establish relationships with each other.

James Rachels advanced this notion by writing that privacy matters because "there is a close connection between our ability to control who has access to us and to information about us, and our ability to create and maintain different sorts of social relationships with different people."

Privacy can mean different things in different contexts; different people, cultures, and nations have different expectations about how much privacy a person is entitled to or what constitutes an invasion of privacy.

Most people have a strong sense of privacy in relation to the exposure of their body to others. This is an aspect of personal modesty. A person will go to extreme lengths to protect this personal modesty, the main way being the wearing of clothes. Other ways include erection of walls, fences, screens, use of cathedral glass, partitions, by maintaining a distance, beside other ways. People who go to those lengths expect that their privacy will be respected by others. At the same time, people are prepared to expose themselves in acts of physical intimacy, but these are confined to exposure in circumstances and of persons of their choosing. Even a discussion of those circumstances is regarded as intrusive and typically unwelcome.

Physical privacy could be defined as preventing "intrusions into one's physical space or solitude."
This would include concerns such as:

An example of the legal basis for the right to physical privacy is the U.S. Fourth Amendment, which guarantees "the right of the people to be secure in their persons, houses, papers, and effects, against unreasonable searches and seizures". Most countries have laws regarding trespassing and property rights also determine the right of physical privacy.

Physical privacy may be a matter of cultural sensitivity, personal dignity, and/or shyness. There may also be concerns about safety, if for example one is wary of becoming the victim of crime or stalking. Civil inattention is a process whereby individuals are able to maintain their privacy within a crowd.

Information or data privacy refers to the evolving relationship between technology and the legal right to, or public expectation of, privacy in the collection and sharing of data about one's self. Privacy concerns exist wherever uniquely identifiable data relating to a person or persons are collected and stored, in digital form or otherwise. In some cases these concerns refer to how data are collected, stored, and associated. In other cases the issue is who is given access to information. Other issues include whether an individual has any ownership rights to data about them, and/or the right to view, verify, and challenge that information.

Various types of personal information are often associated with privacy concerns. Information plays an important role in the decision-action process, which can lead to problems in terms of privacy and availability. First, it allows people to see all the options and alternatives available. Secondly, it allows people to choose which of the options would be best for a certain situation. An information landscape consists of the information, its location in the so-called network, as well as its availability, awareness, and usability. Yet the set-up of the information landscape means that information that is available in one place may not be available somewhere else. This can lead to a privacy situation that leads to questions regarding which people have the power to access and use certain information, who should have that power, and what provisions govern it. For various reasons, individuals may object to personal information such as their religion, sexual orientation, political affiliations, or personal activities being revealed, perhaps to avoid discrimination, personal embarrassment, or damage to their professional reputations.

Financial privacy, in which information about a person's financial transactions is guarded, is important for the avoidance of fraud including identity theft. Information about a person's purchases, for instance, can reveal a great deal about their preferences, places they have visited, their contacts, products (such as medications) they use, their activities and habits, etc. In addition to this, financial privacy also includes privacy over the bank accounts opened by individuals. Information about the bank where the individual has an account with, and whether or not this is in a country that does not share this information with other countries can help countries in fighting tax avoidance.

Internet privacy is the ability to determine what information one reveals or withholds about oneself over the Internet, who has access to such information, and for what purposes one's information may or may not be used. For example, web users may be concerned to discover that many of the web sites which they visit collect, store, and possibly share personally identifiable information about them. Similarly, Internet email users generally consider their emails to be private and hence would be concerned if their email was being accessed, read, stored or forwarded by third parties without their consent. Tools used to protect privacy on the Internet include encryption tools and anonymizing services like I2P and Tor.

Medical privacy Protected Health Information OCR/HIPAA (Health Insurance Portability and Accountability Act of 1996) allows a person to withhold their medical records and other information from others, perhaps because of fears that it might affect their insurance coverage or employment, or to avoid the embarrassment caused by revealing medical conditions or treatments. Medical information could also reveal other aspects of one's personal life, such as sexual preferences or proclivity. A right to sexual privacy enables individuals to acquire and use contraceptives without family, community or legal sanctions.

Political privacy has been a concern since voting systems emerged in ancient times. The secret ballot helps to ensure that voters cannot be coerced into voting in certain ways, since they can allocate their vote as they wish in the privacy and security of the voting booth while maintaining the anonymity of the vote. Secret ballots are nearly universal in modern democracy, and considered a basic right of citizenship, despite the difficulties that they cause (for example the inability to trace votes back to the corresponding voters increases the risk of someone stuffing additional fraudulent votes into the system: additional security controls are needed to minimize such risks).

Corporate privacy refers to the privacy rights of corporate actors like senior executives of large, publicly traded corporations. Desires for corporate privacy can frequently raise issues with obligations for public disclosures under securities and corporate law.

Government agencies, corporations, groups/societies and other organizations may desire to keep their activities or secrets from being revealed to other organizations or individuals, adopting various security practices and controls in order to keep private information confidential. Organizations may seek legal protection for their secrets. For example, a government administration may be able to invoke executive privilege or declare certain information to be classified, or a corporation might attempt to protect valuable proprietary information as trade secrets.

The earliest legislative development of privacy rights began under British common law, which protected "only the physical interference of life and property." Its development from then on became "one of the most significant chapters in the history of privacy law." Privacy rights gradually expanded to include a "recognition of man's spiritual nature, of his feelings and his intellect." Eventually, the scope of those rights broadened even further to include a basic "right to be let alone", and the former definition of "property" would then comprise "every form of possession—intangible, as well as tangible." By the late 19th century, interest in a "right to privacy" grew as a response to the growth of print media, especially newspapers.

Privacy has historical roots in philosophical discussions, the most well-known being Aristotle's distinction between two spheres of life: the public sphere of the "polis", associated with political life, and the private sphere of the "oikos", associated with domestic life. More systematic treatises of privacy in the United States did not appear until the 1890s, with the development of privacy law in America.

As technology has advanced, the way in which privacy is protected and violated has changed with it. In the case of some technologies, such as the printing press or the Internet, the increased ability to share information can lead to new ways in which privacy can be breached. It is generally agreed that the first publication advocating privacy in the United States was the article by Samuel Warren and Louis Brandeis, "The Right to Privacy", 4 "Harvard Law Review" 193 (1890), that was written largely in response to the increase in newspapers and photographs made possible by printing technologies.

New technologies can also create new ways to gather private information. For example, in the United States it was thought that heat sensors intended to be used to find marijuana-growing operations would be acceptable. However, in 2001 in "Kyllo v. United States" (533 U.S. 27) it was decided that the use of thermal imaging devices that can reveal previously unknown information without a warrant does indeed constitute a violation of privacy.

Generally the increased ability to gather and send information has had negative implications for retaining privacy. As large-scale information systems become more common, there is so much information stored in many databases worldwide that an individual has no practical means of knowing of or controlling all of the information about themselves that others may have hold or access. Such information could potentially be sold to others for profit and/or be used for purposes not known to or sanctioned by the individual concerned. The concept of information privacy has become more significant as more systems controlling more information appear. Also the consequences of privacy violations can be more severe. Privacy law in many countries has had to adapt to changes in technology in order to address these issues and, to some extent, maintain privacy rights. But the existing global privacy rights framework has also been criticized as incoherent and inefficient. Proposals such as the APEC Privacy Framework have emerged which set out to provide the first comprehensive legal framework on the issue of global data privacy.

There are various theories about privacy and privacy control. The Invasion Paradigm defines privacy violation as the hostile actions of a wrongdoer who causes direct harm to an individual. This is a reactive view of privacy protection as it waits until there is a violation before acting to protect the violated individual, sometimes through criminal punishments for those who invaded the privacy of others. In the Invasion Paradigm this threat of criminal punishment that is supposed to work as deterrent. The Secrecy paradigm defines a privacy invasion as someone's concealed information or hidden world being revealed through surveillance. The Negative Freedom Paradigm views privacy as freedom from invasion rather than a right, going against the more popular view of a "right to privacy." Finally, the Inaccessibility Paradigm states that privacy is the state where something is completely inaccessible to others. Daniel Solove, a law professor at George Washington University also has a theory of privacy. He believes that a conceptualized view of privacy will not work because there is no one core element. There are many different, interconnected elements involved in privacy and privacy protection. Therefore, Solove proposes looking at these issues from the bottom up, focusing on privacy problems. People may often overlook the fact that certain elements of privacy problems are due to the structure of privacy itself. Therefore, the architecture must change wherein people must learn to view privacy as a social and legal structure. He also states that people have to redefine the relationship between privacy and businesses and the government. Participation in certain privacy elements of the government and businesses should allow people to choose whether they want to be a part of certain aspects of their work that could be considered privacy invasion.

Another trend is the design of privacy aware algorithms and sensors by designers. These include the use of privacy preserving sensors, privacy policies regarding data-sharing in a collaborative and distributive environment and data ownership itself for visual privacy. For example, face detection algorithms are used by Google Streetview to blur out the faces detected while collecting data for Google maps. There has also been an emergence of context-aware visual privacy and sensors that only use depth or thermal imaging data to obfuscate the user and redact sensitive information.

The Internet has brought new concerns about privacy in an age where computers can permanently store records of everything: "where every online photo, status update, Twitter post and blog entry by and about us can be stored forever", writes law professor and author Jeffrey Rosen.

This currently has an effect on employment. Microsoft reports that 75 percent of U.S. recruiters and human-resource professionals now do online research about candidates, often using information provided by search engines, social-networking sites, photo/video-sharing sites, personal web sites and blogs, and Twitter. They also report that 70 percent of U.S. recruiters have rejected candidates based on internet information. This has created a need by many to control various online privacy settings in addition to controlling their online reputations, both of which have led to legal suits against various sites and employers.

The ability to do online inquiries about individuals has expanded dramatically over the last decade. Facebook for example, as of August 2015, was the largest social-networking site, with nearly 1,490 million members, who upload over 4.75 billion pieces of content daily. Over 83.09 million accounts were fake. Twitter has more than 316 million registered users and over 20 million are fake users. The Library of Congress recently announced that it will be acquiring—and permanently storing—the entire archive of public Twitter posts since 2006, reports Rosen.

Importantly, directly observed behaviour, such as browsing logs, search queries, or contents of the Facebook profile can be automatically processed to infer secondary information about an individual, such as sexual orientation, political and religious views, race, substance use, intelligence, and personality. Effectively, individual views and preferences can be revealed even if they were not directly expressed or indicated (e.g. by stating their political views on their Facebook profile, or visiting a gay community website).

According to some experts, many commonly used communication devices may be mapping every move of their users. Senator Al Franken has noted the seriousness of iPhones and iPads having the ability to record and store users' locations in unencrypted files, although Apple denied doing so.

Andrew Grove, co-founder and former CEO of Intel Corporation, offered his thoughts on internet privacy in an interview published in May 2000:
As with other concepts about privacy, there are various ways to discuss what kinds of processes or actions remove, challenge, lessen, or attack privacy. In 1960 legal scholar William Prosser created the following list of activities which can be remedied with privacy protection:

Building from this and other historical precedents, Daniel J. Solove presented another classification of actions which are harmful to privacy, including collection of information which is already somewhat public, processing of information, sharing information, and invading personal space to get private information.

In the context of harming privacy, information collection means gathering whatever information can be obtained by doing something to obtain it. Surveillance is an example of this, when someone decides to begin watching and recording someone or something, and interrogation is another example of this, when someone uses another person as a source of information. Examples of information collection agencies include the NSA and the participants in the Five Eyes program.

It can happen that privacy is not harmed when information is available, but that the harm can come when that information is collected as a set then processed in a way that the collective reporting of pieces of information encroaches on privacy. Actions in this category which can lessen privacy include the following:

Information dissemination is an attack on privacy when information which was shared in confidence is shared or threatened to be shared in a way that harms the subject of the information.

There are various examples of this. Breach of confidentiality is when one entity promises to keep a person's information private, then breaks that promise. Disclosure is making information about a person more accessible in a way that harms the subject of the information, regardless of how the information was collected or the intent of making it available. Exposure is a special type of disclosure in which the information disclosed is emotional to the subject or taboo to share, such as revealing their private life experiences, their nudity, or perhaps private body functions. Increased accessibility means advertising the availability of information without actually distributing it, as in the case of doxxing. Blackmail is making a threat to share information, perhaps as part of an effort to coerce someone. Appropriation is an attack on the personhood of someone, and can include using the value of someone's reputation or likeness to advance interests which are not those of the person being appropriated. Distortion is the creation of misleading information or lies about a person.

Invasion of privacy, a subset of expectation of privacy, is a different concept from the collecting, aggregating, and disseminating information because those three are a misuse of available data, whereas invasion is an attack on the right of individuals to keep personal secrets. An invasion is an attack in which information, whether intended to be public or not, is captured in a way that insults the personal dignity and right to private space of the person whose data is taken.

An intrusion is any unwanted entry into a person's private personal space and solitude for any reason, regardless of whether data is taken during that breach of space. "Decisional interference" is when an entity somehow injects itself into the personal decision making process of another person, perhaps to influence that person's private decisions but in any case doing so in a way that disrupts the private personal thoughts that a person has.

Privacy uses the theory of natural rights, and generally responds to new information and communication technologies. In North America, Samuel D. Warren and Louis D. Brandeis wrote that privacy is the "right to be let alone" (Warren & Brandeis, 1890) focuses on protecting individuals. This citation was a response to recent technological developments, such as photography, and sensationalist journalism, also known as yellow journalism.

Privacy rights are inherently intertwined with information technology. In his widely cited dissenting opinion in "Olmstead v. United States" (1928), Brandeis relied on thoughts he developed in his "Harvard Law Review" article in 1890. But in his dissent, he now changed the focus whereby he urged making personal privacy matters more relevant to constitutional law, going so far as saying "the government [was] identified ... as a potential privacy invader." He writes, "Discovery and invention have made it possible for the Government, by means far more effective than stretching upon the rack, to obtain disclosure in court of what is whispered in the closet." At that time, telephones were often community assets, with shared party lines and the potentially nosey human operators. By the time of Katz, in 1967, telephones had become personal devices with lines not shared across homes and switching was electro-mechanical. In the 1970s, new computing and recording technologies began to raise concerns about privacy, resulting in the Fair Information Practice Principles.

In recent years there have been only few attempts to clearly and precisely define a "right to privacy." Some experts assert that in fact the right to privacy "should not be defined as a separate legal right" at all. By their reasoning, existing laws relating to privacy in general should be sufficient. Other experts, such as Dean Prosser, have attempted, but failed, to find a "common ground" between the leading kinds of privacy cases in the court system, at least to formulate a definition. One law school treatise from Israel, however, on the subject of "privacy in the digital environment", suggests that the "right to privacy should be seen as an independent right that deserves legal protection in itself." It has therefore proposed a working definition for a "right to privacy":
"The right to privacy is our right to keep a domain around us, which includes all those things that are part of us, such as our body, home, property, thoughts, feelings, secrets and identity. The right to privacy gives us the ability to choose which parts in this domain can be accessed by others, and to control the extent, manner and timing of the use of those parts we choose to disclose."

Alan Westin believes that new technologies alter the balance between privacy and disclosure, and that privacy rights may limit government surveillance to protect democratic processes. Westin defines privacy as "the claim of individuals, groups, or institutions to determine for themselves when, how, and to what extent information about them is communicated to others". Westin describes four states of privacy: solitude, intimacy, anonymity, and reserve. These states must balance participation against norms:

Each individual is continually engaged in a personal adjustment process in which he balances the desire for privacy with the desire for disclosure and communication of himself to others, in light of the environmental conditions and social norms set by the society in which he lives.
— Alan Westin, Privacy and Freedom, 1968
Under liberal democratic systems, privacy creates a space separate from political life, and allows personal autonomy, while ensuring democratic freedoms of association and expression.

David Flaherty believes networked computer databases pose threats to privacy. He develops 'data protection' as an aspect of privacy, which involves "the collection, use, and dissemination of personal information". This concept forms the foundation for fair information practices used by governments globally. Flaherty forwards an idea of privacy as information control, "[i]ndividuals want to be left alone and to exercise some control over how information about them is used".

Richard Posner and Lawrence Lessig focus on the economic aspects of personal information control. Posner criticizes privacy for concealing information, which reduces market efficiency. For Posner, employment is selling oneself in the labour market, which he believes is like selling a product. Any 'defect' in the 'product' that is not reported is fraud. For Lessig, privacy breaches online can be regulated through code and law. Lessig claims "the protection of privacy would be stronger if people conceived of the right as a property right", and that "individuals should be able to control information about themselves". Economic approaches to privacy make communal conceptions of privacy difficult to maintain.

There have been attempts to reframe privacy as a fundamental human right, whose social value is an essential component in the functioning of democratic societies. Amitai Etzioni suggests a communitarian approach to privacy. This requires a shared moral culture for establishing social order. Etzioni believes that "[p]rivacy is merely one good among many others", and that technological effects depend on community accountability and oversight (ibid). He claims that privacy laws only increase government surveillance by weakening informal social controls. Furthermore, the government is no longer the only or even principle threat to people's privacy. Etzioni notes that corporate data miners, or "Privacy Merchants," stand to profit by selling massive dossiers personal information, including purchasing decisions and Internet traffic, to the highest bidder. And while some might not find collection of private information objectionable when it is only used commercially by the private sector, the information these corporations amass and process is also available to the government, so that it is no longer possible to protect privacy by only curbing the State.

Priscilla Regan believes that individual concepts of privacy have failed philosophically and in policy. She supports a social value of privacy with three dimensions: shared perceptions, public values, and collective components. Shared ideas about privacy allows freedom of conscience and diversity in thought. Public values guarantee democratic participation, including freedoms of speech and association, and limits government power. Collective elements describe privacy as collective good that cannot be divided. Regan's goal is to strengthen privacy claims in policy making: "if we did recognize the collective or public-good value of privacy, as well as the common and public value of privacy, those advocating privacy protections would have a stronger basis upon which to argue for its protection".

Leslie Regan Shade argues that the human right to privacy is necessary for meaningful democratic participation, and ensures human dignity and autonomy. Privacy depends on norms for how information is distributed, and if this is appropriate. Violations of privacy depend on context. The human right to privacy has precedent in the United Nations Declaration of Human Rights: "Everyone has the right to freedom of opinion and expression; this right includes freedom to hold opinions without interference and to seek, receive and impart information and ideas through any media and regardless of frontiers." Shade believes that privacy must be approached from a people-centered perspective, and not through the marketplace.

Most countries give citizen rights to privacy in their constitutions. Representative examples of this include the "Constitution of Brazil", which says "the privacy, private life, honor and image of people are inviolable"; the "Constitution of South Africa" says that "everyone has a right to privacy"; and the "Constitution of the Republic of Korea" says "the privacy of no citizen shall be infringed." Among most countries whose constitutions do not explicitly describe privacy rights, court decisions have interpreted their constitutions to intend to give privacy rights.

Many countries have broad privacy laws outside their constitutions, including Australia's Privacy Act 1988, Argentina's Law for the Protection of Personal Data of 2000, Canada's 2000 Personal Information Protection and Electronic Documents Act, and Japan's 2003 Personal Information Protection Law.

Beyond national privacy laws, there are international privacy agreements. The United Nations Universal Declaration of Human Rights says "No one shall be subjected to arbitrary interference with his privacy, family, home or correspondence, nor to attacks upon his honor and reputation." The Organisation for Economic Co-operation and Development published its Privacy Guidelines in 1980. The European Union's 1995 Data Protection Directive guides privacy protection in Europe. The 2004 Privacy Framework by the Asia-Pacific Economic Cooperation is a privacy protection agreement for the members of that organization.

In the 1960s people began to consider how changes in technology were bringing changes in the concept of privacy. Vance Packard’s "The Naked Society" was a popular book on privacy from that era and led discourse on privacy at that time.

Approaches to privacy can, broadly, be divided into two categories: free market, and consumer protection. In a free market approach, commercial entities are largely allowed to do what they wish, with the expectation that consumers will choose to do business with corporations that respect their privacy to a desired degree. If some companies are not sufficiently respectful of privacy, they will lose market share. Such an approach may be limited by lack of competition in a market, by enterprises not offering privacy options favorable to the user, or by lack of information about actual privacy practices. Claims of privacy protection made by companies may be difficult for consumers to verify, except when they have already been violated.

One example of the free market approach is to be found in the voluntary OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data. The principles reflected in the guidelines are analysed in an article putting them into perspective with concepts of the GDPR put into law later in the European Union.

In a consumer protection approach, in contrast, it is claimed that individuals may not have the time or knowledge to make informed choices, or may not have reasonable alternatives available. In support of this view, Jensen and Potts showed that most privacy policies are above the reading level of the average person. Therefore, this approach advocates greater government definition and enforcement of privacy standards.

Privacy law is the area of law concerning the protecting and preserving of privacy rights of individuals. While there is no universally accepted privacy law among all countries, some organizations promote certain concepts be enforced by individual countries. For example, the Universal Declaration of Human Rights, article 12, states:

The "Privacy Act 1988" is administered by the Office of the Australian Information Commissioner. Privacy law has been evolving in Australia for a number of years. The initial introduction of privacy law in 1998 extended to the public sector, specifically to Federal government departments, under the Information Privacy Principles. State government agencies can also be subject to state based privacy legislation. This built upon the already existing privacy requirements that applied to telecommunications providers (under Part 13 of the "Telecommunications Act 1997"), and confidentiality requirements that already applied to banking, legal and patient / doctor relationships.

The "Privacy Act 1988" was then extended to include the private sector in 2000 with the introduction of the National Privacy Principles. These took effect in 2001. Small businesses with an annual turnover of $3 million were excluded from meeting the obligations specified in the National Privacy Principles with some exceptions such as those whose primary business was dealing in personal information.

In 2008 the Australian Law Reform Commission (ALRC) conducted a review of Australian Privacy Law. The resulting report "For Your Information". was one of the largest reports ever released by the ALRC. Amongst its many recommendations were the consolidation of both the Information Privacy Principles and the National Privacy Principles to form what is now known as the Australian Privacy Principles.

This recommendation, and many others, were taken up and implemented by the Australian Government via the Privacy Amendment (Enhancing Privacy Protection) Bill 2012

The Australian Privacy Principles, along with other key changes to the overall Act, took effect on 12 March 2014. The new structure of the privacy principles follow the information cycle and incorporate key emerging privacy concepts including privacy by design.

There are currently 14 Australian Privacy Principles:


As of 22 February 2018, the Privacy Amendment (Notifiable Data Breaches) Act 2017 will introduce a mandatory data breach notification obligations for all organisations that are subject to Australia's Privacy Act 1988 (Cth). This includes all Australian-registered companies and foreign-registered companies that carry on business in Australia or that interact with Australian data subjects.

There are a range of other laws that provide privacy protection in Australia. These include, but are not limited to, the "Telecommunications Act 1997", "Spam Act 2006", the "Do Not Call Register Act 2009", general confidentiality obligations arising from certain professional relationships including with doctors, lawyers and other health providers, state based legislation including NSW workplace surveillance laws, state based laws that apply in NSW, Queensland and other states for the handling of health information and the handling of information by state government agencies.

The Constitution of Brazil sets privacy as a major fundamental right. Even the State is not allowed to violate personal data, intimacy, private life, honor and image (article 5, incise X). In extreme situations, a judicial order can authorize some level of disclosure. But some data, such as correspondence, are absolutely inviolable, and not even judicial order can authorize the disclosure.

Criminal Law of the People's Republic of China

Article 245 Whoever unlawfully subjects another person to a body search or a search of his residence or unlawfully intrudes into another person's residence shall be sentenced to fixed-term imprisonment of not more than three years or criminal detention. Any judicial officer who abuses his power and commits the crime mentioned in the preceding paragraph shall be given a heavier punishment.

Article 246 Whoever, by violence or other methods, publicly humiliates another person or invent stories to defame him, if the circumstances are serious, shall be sentenced to fixed-term imprisonment of not more than three years, criminal detention, public surveillance or deprivation of political rights. The crime mentioned in the preceding paragraph shall be handled only upon complaint, except where serious harm is done to public order or to the interests of the State.

Article 252 Whoever conceals, destroys or unlawfully opens another person's letter, thereby infringing upon the citizen's right to freedom of correspondence, if the circumstances are serious, shall be sentenced to fixed-term imprisonment of not more than one year or criminal detention.

Article 253 Any postal worker who opens without authorization or conceals or destroys mail or telegrams shall be sentenced to fixed-term imprisonment of not more than two years or criminal detention. Whoever steals money or property by committing the crime mentioned in the preceding paragraph shall be convicted and given a heavier punishment in accordance with the provisions of Article 264 of this Law.

Canadian privacy law is governed federally by multiple acts, including the Canadian Charter of Rights and Freedoms, and the Privacy Act (Canada). Mostly this legislation concerns privacy infringement by government organizations. Data privacy was first addressed with the Personal Information Protection and Electronic Documents Act, and provincial-level legislation also exists to account for more specific cases personal privacy protection against commercial organizations.

For Europe, Article 8 of the European Convention on Human Rights guarantees the right to respect for private and family life, one's home and correspondence. The European Court of Human Rights in Strasbourg has developed a large body of jurisprudence defining this fundamental right to privacy. The European Union requires all member states to legislate to ensure that citizens have a right to privacy, through directives such as the 1995 Directive 95/46/EC on the protection of personal data. It is regulated in the United Kingdom by the Data Protection Act 1998 and in France data protection is also monitored by the CNIL, a governmental body which must authorize legislation concerning privacy before it can be enacted. In civil law jurisdictions, the right to privacy fell within the ambit of the right to a private life (droit a la vie privee) from which the tort could be claimed. Personality rights and the broader tort based
interpretation of the right to privacy protected correspondence, personal information and dignity. These rights gave rise to causes for damages in most civil law jurisdictions and common law jurisdictions prior to the sui generis development of Data Protection.

Although there are comprehensive regulations for data protection, some studies show that despite the laws, there is a lack of enforcement in that no institution feels responsible to control the parties involved and enforce their laws. The European Union is also championing for the 'Right to be Forgotten' concept (which allows individuals to ask that links leading to information about themselves be removed from internet search engine results) to be adopted by other countries.

India

Due to the introduction of the Aadhaar project inhabitants of India were afraid that their privacy could be invaded. The project was also met with mistrust regarding the safety of the social protection infrastructures. To tackle the fear amongst the people, India's supreme court put a new ruling into action that stated that privacy from then on was seen as a fundamental right. On 24 August 2017 this new law was established.

In Italy the right to privacy is enshrined in Article 15 of the Constitution, which states:

"Freedom and confidentiality of correspondence and of every other form of communication is inviolable. Limitations may only be imposed by judicial decision stating the reasons and in accordance with the guarantees provided by the law."

In the United Kingdom, it is not possible to bring an action for invasion of privacy. An action may be brought under another tort (usually breach of confidence) and privacy must then be considered under EC law. In the UK, it is sometimes a defence that disclosure of private information was in the public interest.
There is, however, the Information Commissioner's Office (ICO), an independent public body set up to promote access to official information and protect personal information. They do this by promoting good practice, ruling on eligible complaints, giving information to individuals and organisations, and taking action when the law is broken. The relevant UK laws include: Data Protection Act 1998; Freedom of Information Act 2000; Environmental Information Regulations 2004; Privacy and Electronic Communications Regulations 2003. The ICO has also provided a "Personal Information Toolkit" online which explains in more detail the various ways of protecting privacy online.

Although the US Constitution does not explicitly include the right to privacy, individual as well as locational privacy are implicitly granted by the Constitution under the 4th Amendment. The Supreme Court of the United States has found that other guarantees have "penumbras" that implicitly grant a right to privacy against government intrusion, for example in "Griswold v. Connecticut" (1965). In the United States, the right of freedom of speech granted in the First Amendment has limited the effects of lawsuits for breach of privacy. Privacy is regulated in the US by the Privacy Act of 1974, and various state laws. The Privacy Act of 1974 only applies to Federal agencies in the executive branch of the Federal government. Certain privacy rights have been established in the United States via legislation such as the Children's Online Privacy Protection Act (COPPA), the Gramm–Leach–Bliley Act (GLB), and the Health Insurance Portability and Accountability Act (HIPAA).
The Electronic Privacy Information Center's Privacy Index puts Brazil, Australia, Japan and South Africa in the higher level of privacy (around 2.2). On the bottom of the list are the United States and United Kingdom (around 1.4).

There are many means to protect one's privacy on the internet. For example, e-mails can be encrypted (via S/MIME or PGP) and anonymizing proxies or anonymizing networks like I2P and Tor can be used to prevent the internet service providers from knowing which sites one visits and with whom one communicates. Covert collection of personally identifiable information has been identified as a primary concern by the U.S. Federal Trade Commission. Although some privacy advocates recommend the deletion of original and third-party HTTP cookies, Anthony Miyazaki, marketing professor at Florida International University and privacy scholar, warns that the "elimination of third-party cookie use by Web sites can be circumvented by cooperative strategies with third parties in which information is transferred after the Web site's use of original domain cookies." As of December 2010, the Federal Trade Commission is reviewing policy regarding this issue as it relates to behavioral advertising.
Another aspect of privacy on the Internet relates to online social networking. Several online social network sites (OSNs) are among the top 10 most visited websites globally. A review and evaluation of scholarly work regarding the current state of the value of individuals' privacy of online social networking show the following results: "first, adults seem to be more concerned about potential privacy threats than younger users; second, policy makers should be alarmed by a large part of users who underestimate risks of their information privacy on OSNs; third, in the case of using OSNs and its services, traditional one-dimensional privacy approaches fall short". This is exacerbated by the research indicating that personal traits such as sexual orientation, race, religious and political views, personality, or intelligence can be inferred based on the wide variety of digital footprint, such as samples of text, browsing logs, or Facebook Likes.

Increasingly, mobile devices facilitate location tracking. This creates user privacy problems. A user's location and preferences constitute personal information. Their improper use violates that user's privacy. A recent MIT study by de Montjoye et al. showed that 4 spatio-temporal points, approximate places and times, are enough to uniquely identify 95% of 1.5M people in a mobility database. The study
further shows that these constraints hold even when the resolution of the dataset is low. Therefore, even coarse or blurred datasets provide little anonymity.

Several methods to protect user privacy in location-based services have been proposed, including the use of anonymizing servers, blurring of information e.a. Methods to quantify privacy have also been proposed, to calculate the equilibrium between the benefit of providing accurate location information and the drawbacks of risking personal privacy. Users of such services may also choose to display more generic location information (i.e. "In the City" or "Philadelphia" or "Work") to some of their more casual acquaintances while only displaying specific location information, such as their exact address, to closer contacts like spouse, relatives, and good friends.

In recent years, seen with the increasing importance of mobile devices and paired with the "National Do Not Call Registry", telemarketers have turned attention to mobiles. The efforts of telemarketers to use mobile devices have been met with both "Federal Trade Commission" and companies like PrivacyStar. Each year, thousands of complaints are filed to the FTC database with the help of companies and consumers.

The principle of privacy by design states that privacy and data protection are embedded throughout the entire life cycle of technologies, from the early design stage to their deployment, use and ultimate disposal.

The practice of constructing, ostensibly, software or information systems that adhere to given privacy policies and relevant compliances is a developing area and is known as Privacy engineering

Privacy self-synchronization is the mode by which the stakeholders of an enterprise privacy program spontaneously contribute collaboratively to the program's maximum success. The stakeholders may be customers, employees, managers, executives, suppliers, partners or investors. When self-synchronization is reached, the model states that the personal interests of individuals toward their privacy is in balance with the business interests of enterprises who collect and use the personal information of those individuals.

The privacy paradox is a phenomenon in which online users state that they are concerned about their privacy but behave as if they were not. While this term was coined as early as 1998, it wasn't used in its current popular sense until the year 2000. In his article titled "'Opting In': A Privacy Paradox," John Schwartz wrote that "It's one of the more puzzling conundrums of online life. While companies that capitalize on the Internet's powerful potential to invade privacy are denounced as villains of the information age, millions of people type out highly personal data and send it off to Web sites they've barely heard of, with no strong legal protection against misuse of the information. …The paradox helps illustrate the complexity of the debate over privacy."

Susan B. Barnes similarly used the term “privacy paradox” to refer to the ambiguous boundary between private and public space on social media. When compared to adults, young people tend to disclose more information on social media. However, this does not mean that they are not concerned about their privacy. Susan B. Barnes gave a case in her article: in a television interview about Facebook, a student addressed her concerns about disclosing personal information online. However, when the reporter asked to see her Facebook page, she put her home address, phone numbers, and pictures of her young son on the page.

Privacy paradox has been studied and scripted in different research settings. Although several studies have shown this inconsistency between privacy attitudes and behavior among online users, the reason for the paradox still remains unclear. A main explanation for the privacy paradox is that users lack awareness of the risks and the degree of protection. Users may underestimate the harm of disclosing information online. On the other hand, some researchers argue the privacy paradox comes from lack of technology literacy and from the design of sites. For example, users may not know how to change their default settings even though they care about their privacy. Psychologists particularly pointed out that the privacy paradox occurs because users must trade-off between their privacy concerns and impression management. Other individual factors such as gender, age, trust and personality, may also account for the paradox.

The 1993 film "The Pelican Brief", based on the novel of the same name, touches on privacy. In one scene, a law professor discusses the Constitutional right to privacy. One of his students, played by Julia Roberts, argues that the majority opinion in Bowers v Hardwick was wrongly decided.

In "Short List", 1999 episode of the TV series "The West Wing", the right to privacy arises during the appointment of a Supreme Court judge. Sam Seabourne ventures the opinion that Internet privacy will be a major social issue in the next two decades.

Selfies are popular today. A search for photos with the hashtag #selfie retrieves over 23 million results on Instagram and "a whopping 51 million with the hashtag #me" However, due to modern corporate and governmental surveillance, this may pose a risk to privacy. In a research which takes a sample size of 3763, researchers found that for selfies, females generally have greater concerns than male social media users. Users who have greater concerns inversely predict their selfie behavior and activity.







</doc>
<doc id="9895310" url="https://en.wikipedia.org/wiki?curid=9895310" title="Legal anthropology">
Legal anthropology

Legal anthropology, also known as the anthropology of laws, is a sub-discipline of anthropology which specializes in "the cross-cultural study of social ordering". The questions that Legal Anthropologists seek to answer concern how is law present in cultures? How does it manifest? How may anthropologists contribute to understandings of law?

Earlier legal anthropological research focused more narrowly on conflict management, crime, sanctions, or formal regulation. Bronisław Malinowski's 1926 work, "Crime and Custom in Savage Society", explored law, order, crime, and punishment among the Trobriand Islanders. The English lawyer Sir Henry Maine is often credited with founding the study of Legal Anthropology through his book "Ancient Law" (1861), and although his evolutionary stance has been widely discredited within the discipline, his questions raised have shaped the subsequent discourse of the study. This ethno-centric evolutionary perspective was pre-eminent in early Anthropological discourse on law, evident through terms applied such as ‘pre-law’ or ‘proto-law’ and applied by so-called armchair anthropologists. However, a turning point was presented in the 1926 publication of "Crime and Custom in Savage Society" by Malinowski based upon his time with the Trobriand Islanders. Through emphasizing the order present in acephelous societies, Malinowski proposed the cross-cultural examining of law through its established functions as opposed to a discrete entity. This has led to multiple researchers and ethnographies examining such aspects as order, dispute, conflict management, crime, sanctions, or formal regulation, in addition (and often antagonistically) to law-centred studies, with small-societal studies leading to insightful self-reflections and better understanding of the founding concept of law.

Legal anthropology remains a lively discipline with modern and recent applications including issues such as human rights, legal pluralism, Islamophobia and political uprisings.

Legal Anthropology provides a definition of law which differs from that found within modern legal systems. Hoebel (1954) offered the following definition of law: "“A social norm is legal if its neglect or infraction is regularly met, in threat or in fact, by the application of physical force by an individual or group possessing the socially recognized privilege of so acting”"

Maine argued that human societies passing through three basic stages of legal development, from a group presided over by a senior agnate, through stages of territorial development and culminating in an elite forming normative laws of society, stating that "“what the juristical oligarchy now claims is to monopolize the knowledge of the laws, to have the exclusive possession of the principles by which quarrels are decided”"

This evolutionary approach, as has been stated, was subsequently replaced within the anthropological discourse by the need to examine the manifestations of law's societal function. As according to Hoebel, law has four functions:

1) to identify socially acceptable lines of behaviour for inclusion in the culture. 
2) To allocate authority and who may legitimately apply force.
3) To settle trouble cases.
4) To redefine relationships as the concepts of life change.

Legal theorist H. L. A. Hart, however, stated that law is a body of rules, and is a union of two sets of rules: 

Within modern English Theory, law is a discrete and specialized topic. Predominantly positivist in character, it is closely linked to notions of a rule-making body, the judiciary and enforcement agencies. The centralized state organisation and isolates are essentials to the attributes of rules, courts and sanctions. To learn more on this view, see Hobbes. 1651 Leviathan, part 2, chapter 26 or Salmond, J. 1902 Jurisprudence.

However, this view of law is not applicable everywhere. There are many acephelous societies around the world where the above control mechanisms are absent. There are no conceptualized and isolated set of normative rules – these are instead embodied in everyday life. Even when there may be a discrete set of legal norms, these are not treated similarly to the English Legal System's unequivocal power and unchallenged pre-eminence. Shamans, fighting and supernatural means are all mechanisms of superimposing rules within other societies. For example, within Rasmussen’s work of Across Arctic America (1927) he recounts Eskimo nith-songs being used as a public reprimand by expressing the wrongdoing of someone guilty.

Thus, instead of focusing upon the explicit manifestations of law, legal anthropologists have taken to examining the functions of law and how it is expressed. A view expressed by Leopold Pospisil and encapsulated by Bronislaw Malinowski:

"“In such primitive communities I personally believe that law ought to be defined by function and not by form, that is we ought to see what are the arrangements, the sociological realities, the cultural mechanisms which act for the enforcement of law”"

Thus, law has been studied in ways that may be categorized by as:

1) prescriptive rules
2) observable regularities
3) Instances of dispute.

Order and regulatory behaviour are required if social life is to be maintained. The scale and shade of this behaviour depends on the values and beliefs held by a society deriving from implicit understandings of the norm developed through socialization. There are socially constructed norms with varying degrees of explicitness and levels of order. Conflict may not be interpreted as an extreme pathological event but as a regulatory acting force.

This processual understanding of conflict and dispute became apparent and subsequently heavily theorized upon by the anthropological discipline within the latter half of the nineteenth century as a gateway to the law and order of a society. Disputes have become to be recognised as necessary and constructive over pathological whilst the stated rules of law only explain some aspects of control and compliance. The context and interactions of a dispute are more informative about a culture than the rules.

Classic studies deriving theories of order from disputes include Evans-Pritchard work Witchcraft, Oracles and Magic among the Azande which focused upon functional disputes surrounding sorcery and witchcraft practices, or Comaroff and Roberts (1981) work among the Tswana which examine the hierarchy of disputes, the patterns of contact and the effect norms affect the course of dispute as norms important to dispute are rarely "“especially organised for jural purpose”" 

Other examples include:

Leach, 1954. Political Systems of Highland Burma.
Barth, 1959. Political Leadership among Swat Pathans.

Within the history of Legal Anthropology there have been various methods of data gathering adopted; ranging from literature review of traveller/missionary accounts, consulting informants and lengthy participant observation.

Furthermore, when evaluating any research it is appropriate to have a robust methodology capable of scientifically analysing the topic at hand.

The broad method of study by legal anthropologists prevails upon the Case Study Approach first developed by Llewellyn and Hoebel in The Cheyenne Way (1941) not as "“a philosophy but a technology”" 

This methodology is applied to situations of cross-cultural conflict and the correlating resolution, which can have sets of legal notions and jural regularities extracted from them 

This method may be safe-guarded against accusations of imposing western ideological structures as it is often an emic sentiment: for example,

"“The Tiv drove me to the case method…what they were interested in. They put a lot of time and effort into cases”"

Regarding law, in Anthropology's characteristically self-conscious manner, the comparative analysis inherent to Legal Anthropology has been speculated upon and most famously debated by Paul Bohannan and Max Gluckman. The discourse highlights one of the primary differences between British and American Anthropology regarding fieldwork approaches and concerns the imposition of Western terminology as ethnological categories of differing societies.

Each author's uses the Case Study Approach, however, the data's presentation in terms of achieving comparativeness is a point of contention between them.

Paul Bohannan promotes the use of native terminology presented with ethnographic meaning as opposed to any Universal categories, which act as barriers to understanding the true nature of a culture's legal system.

Advocating that it is better to appreciate native terms in their own medium, Bohannan critiques Gluckman's work for its inherent bias.

Gluckman has argued that Bohannan's excessive use of native terminology creates barriers when attempting to achieve comparative analysis. He in turn has suggested that in order to further the cross-cultural comparative study of law, we should use English terms and concepts of law which will aid in the refinement of dispute facts and interrelations Thus, all native terms should be described and translated into an Anglo-American conceptual equivalent for the purpose of comparison.

As disputes and order began to be recognised as categories worthy of study, interest in the inherent aspects of conflicts emerged within legal anthropology. The processes and actors involved within the events became an object of study for ethnographers as they embraced conflict as a data-rich source.

One example of such an interest is expressed by Philip Gulliver, 1963, Social Control in an African Society in which the intimate relations between disputes are postulated as being important. He examines the patterns of alliance between actors of a dispute and the strategies that develop as a result, the roles of mediators and the typologies for intervention.

See "Lyon, 2002 Local arbitration and conflict deferment in Punjab, Pakistan" or "Engel, D. 1980. Legal pluralism in an American community: perspectives on a civil trial court."

Political anthropologists have had much to say about the UDHR(Universal Declaration of Human Rights). Original critiques, most notably by the AAA(American Anthropological Association), argued that cultural ideas of rights and entitlement differ between societies. They warned that any attempt to endorse one set of values above all others amounted to a new western imperialism, and would be counter to ideas of cultural relativism. Most anthropologists now agree that universal human rights have a useful place in today's world. Zechenter (1997) argues there are practices, such as Indian 'sati' (the burning of a widow on her husband's funeral pyre) that can be said to be wrong, despite justifications of tradition. This is because such practices are about much more than a culturally established world view, and frequently develop or revive as a result of socio-economic conditions and the balance of power within a community. As culture is not bounded and unchanging, there are multiple discourses and moral viewpoints within any community and among the various actors in such events (Merry 2003). Cultural relativists risk supporting the most powerfully asserted position at the expense of those who are subjugated under it.

More recent contributions to the question of universal human rights include analysis of their use in practice, and how global discourses are translated into local contexts (Merry 2003). Anthropologists such as Merry (2006) note how the legal framework of the UNDHR is not static but is actively used by communities around the globe to construct meaning. As much as the document is a product of western Enlightenment thinking, communities have the capacity to shape its meaning to suit their own agendas, incorporating its principles in ways that empower them to tackle their own local and national discontents.

Female genital cutting (FGC), also known as female circumcision or female genital mutilation remains a hotly debated, controversial issue contested particularly among legal anthropologists and human rights activists. Through her ethnography (1989) on the practice of pharonic circumcision among the Hofriyat of Sudan (1989) Boddy maintains that understanding local cultural norms is of crucial importance when considering intervention to prevent the practice. Human rights activists attempting to eradicate FGC using the legal framework of the Universal Declaration of Human Rights (UNDHR) as their justification, run the risk of imposing a set of ideological principles, alien to the culture attempting to be helped, potentially facing hostile reactions. Moreover, the UNDHR as a legal document, is contested by some as being restrictive in its prescription of what is and is not deemed a violation of a human right (Ross 2003) and overlooks local customary justifications which operate outside of an international legalistic framework (Ross 2003). Increasingly (FGC) is becoming a global issue due to increased mobility. What was once deemed a largely African practice has seen a steady increase in European countries such as Britain. Although made illegal in 1985 there have as yet been no convictions and girls as old as nine continue to have the procedure. Legislation has now also been passed in Sweden, the United States and France where there have been convictions. Black, J. A. and Debelle, G. D. (1995) "Female Genital Mutilation in Britain" "British Medical Journal".

There are a number of useful introductions to the field of legal anthropology, Sally Falk Moore, a leading legal anthropologist, held both a law degree and a PhD in anthropology. An increasing number of legal anthropologists hold both JDs and advanced degrees in anthropology, and some teach in law schools while maintaining scholarly connections within the field of legal anthropology; examples include Rebecca French, John Conley, Elizabeth Mertz, and Annelise Riles. Such combined expertise has also been turned to more applied anthropological pursuits such as tribal advocacy and forensic ethnography by practitioners. There is a growing interest in the intersection of legal and linguistic anthropology.

If looking for Anthropology departments with faculty specializing in legal anthropology in North America, try the following schools and professors:
University of California, Berkeley (Laura Nader), University of California, Irvine (Susan Bibler Coutin, Bill Maurer), University of Chicago (Justin B. Richland), Duke University (William M. O'Barr), Princeton University (Lawrence Rosen, Carol J. Greenhouse), State University of New York at Buffalo (Rebecca French), New York University (Sally Engle Merry), Harvard University (Jean Comaroff and John Comaroff) and Cornell University (Annelise Riles), and George Mason University (Susan Hirsch).

In Europe, the following scholars and schools will be good resources:
Vanja Hamzić (SOAS University of London), Jane Cowan (University of Sussex), Ann Griffiths and Toby Kelly (University of Edinburgh), Sari Wastell (Goldsmiths, University of London), Harri Englund and Yael Navaro (University of Cambridge), and Richard Rottenburg (Martin-Luther Universität).

The Association for Political and Legal Anthropology (APLA), a section of the American Anthropological Association, is the primary professional association in the U.S. for legal anthropologists and also has many overseas members. It publishes "PoLAR: Political and Legal Anthropology Review", the leading U.S. journal in the field of legal anthropology, which is accessible via http://polarjournal.org/ or http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1555-2934

'Allegra: a Virtual Laboratory of Legal Anthropology' is an online experiment by a new generation of legal anthropologists designated to facilitate scholarly collaboration and awareness of the sub-discipline.





</doc>
<doc id="46273308" url="https://en.wikipedia.org/wiki?curid=46273308" title="Legal archaeology">
Legal archaeology

Legal archaeology is an area of legal scholarship "involving detailed historical reconstruction and analysis of important cases." 

While most legal scholars confine their research to published opinions of court cases, legal archaeologists examine the historical and social context in which a court case was decided. These facts may show what social and cultural forces were at work in a particular case. Professors can use legal archaeology to "sensitize students as to how inequality, specifically with regard to race, gender and class affects what occurs throughout the cases they study." A legal archaeologist might also research biographical material on the judges, attorneys, and parties to a court case. Such information might show whether a judge held particular biases in a case, or if one party had superior legal representation that caused the party to prevail in a case.



</doc>
<doc id="42132936" url="https://en.wikipedia.org/wiki?curid=42132936" title="Violation of law">
Violation of law

A violation of law is any act (or, less commonly, failure to act) that fails to abide by existing law. Violations generally include both crimes and civil wrongs. Some acts, such as fraud, can violate both civil and criminal laws. 

Civil law violations usually lead to civil penalties like fines, criminal offenses to more severe punishments. 

The severity of the punishment should reflect the severity of the violation (retributive justice). In realistic situations and for minor violations, however, altruistic punishment was shown not 'to fit the crime'.This subdivision is similar to the distinction between misdemeanours, and felonies.

Other examples of violations of law include:



</doc>
<doc id="51913" url="https://en.wikipedia.org/wiki?curid=51913" title="Legislation">
Legislation

Legislation (or "statutory law") is law which has been promulgated (or "enacted") by a legislature or other governing body or the process of making it. Before an item of legislation becomes law it may be known as a bill, and may be broadly referred to as "legislation", while it remains under consideration to distinguish it from other business. Legislation can have many purposes: to regulate, to authorize, to outlaw, to provide (funds), to sanction, to grant, to declare or to restrict. It may be contrasted with a non-legislative act which is adopted by an executive or administrative body under the authority of a legislative act or for implementing a legislative act.

Under the Westminster system, an item of primary legislation is known as an Act of Parliament after enactment.

Legislation is usually proposed by a member of the legislature (e.g. a member of Congress or Parliament), or by the executive, where upon it is debated by members of the legislature and is often amended before passage. Most large legislatures enact only a small fraction of the bills proposed in a given session. Whether a given bill will be proposed and is generally a matter of the legislative priorities of government.

Legislation is regarded as one of the three main functions of government, which are often distinguished under the doctrine of the separation of powers. Those who have the formal power to "create" legislation are known as legislators; a judicial branch of government will have the formal power to "interpret" legislation (see statutory interpretation); the executive branch of government can act only within the powers and limits set by the law.

The function and procedures are primarily the responsibility of the legislature. However, there are situations where legislation is made by other bodies or means, such as when constitutional law or secondary legislation is enacted. Such other forms of law-making include referendums, orders in council or regulations. The term "legislation" is sometimes used to include these situations, or the term "primary legislation" may be used to exclude these other forms.

The phrase "dead letter" refers to legislation that has not been revoked, but that has become inapplicable, obsolete, or is no longer enforced.




</doc>
<doc id="51261471" url="https://en.wikipedia.org/wiki?curid=51261471" title="Impact litigation">
Impact litigation

Impact litigation or strategic litigation is the practice of bringing lawsuits intended to effect societal change. Impact litigation cases may be class action lawsuits or individual claims with broader significance, and may rely on statutory law arguments or on constitutional claims. Such litigation has been widely and successfully used to influence public policy, especially by left-leaning groups, and often attracts significant media attention.

In the late nineteenth and early twentieth centuries, the American Civil Liberties Union and National Association for the Advancement of Colored People (at times though its Legal Defense Fund) both pursued legal action to advance and protect civil rights in the United States. The ACLU followed a primarily "defensive" strategy, fighting individual violations of rights when they were identified. The NAACP, in contrast, developed a more coordinated plan to actively file suits to challenge discrimination, known as "affirmative" or "strategic" litigation. The NAACP's model became the pattern for "impact litigation" strategies, which applied similar tactics in contexts other than racial discrimination.

Important early impact litigation cases included "Brown v. Board of Education" and "Roe v. Wade". "Brown", a 1954 U.S. school desegregation decision, was carefully prepared by Thurgood Marshall and other NAACP lawyers so that the eventual Supreme Court ruling invalidated official racial discrimination throughout the U.S. government. Many cases since then have closely imitated it, in the course of seeking greater protections for other disadvantaged groups.

Impact litigation has played a major role in the development of American desegregation, abortion, tobacco regulation policy and gay marriage. 

Since the 1980s, impact litigation has been used to seek the reform of U.S. child welfare law, following earlier work which involved the courts in jail and mental hospital reforms, and in school desegregation.

Strategic impact litigation, among other things, has also been used in Nigeria to push for convictions of perpetrators of police brutality and to defeat legal attacks on the freedom of the press.

In a few jurisdictions where attorneys are prohibited from bringing class action lawsuits, citizens have filed "grassroots impact litigation" cases and successfully represented their own claims.

Impact litigation has been criticized by legal scholars and politicians on the bases of judicial legitimacy and competence.

The legitimacy argument holds that, in countries with a constitutional separation of powers, societal changes are to be enacted by democratically elected bodies and are outside the purview of individual judges. The competence argument claims that institutional limitations on the amount and quality of information that can be made available in a court proceeding make the courts poorly prepared to handle complex policy issues. Another version of this argument points out that courts are limited in the scope of their responses, relative to legislative bodies. These debates overlap with those concerning so-called "judicial activism".




</doc>
<doc id="2296282" url="https://en.wikipedia.org/wiki?curid=2296282" title="Lawlessness">
Lawlessness

Lawlessness is a lack of law, in any of the various senses of that word. Lawlessness may describe various conditions.
Anomie is a breakdown of social bonds between an individual and their community, in which individuals do not feel bound by the moral strictures of society. The term was popularized by French sociologist Émile Durkheim in his influential 1897 book "Suicide".

Anarchy (meaning "without leadership") is a condition in which a person or group of people reject societal hierarchies, laws, and other institutions. It often entails the dissolution of government.

Anarchism is a political philosophy that advocates self-governed societies based on voluntary institutions.

Civil disorder, or civil unrest, refers to public disturbances generally involving groups of people, and resulting in danger or damage to persons or property. Civil disorder is a breakdown of civil society, and may be a form of protest. It may take various forms, such as illegal parades, sit-ins, riots, sabotage, and other forms of crime.

Randomness is the lack of pattern or predictability in events.

Antinomianism, in Christianity, is a theological position which takes the principle of salvation by faith and divine grace to the point of asserting that the saved are not bound to follow the Law of Moses.



</doc>
<doc id="55504612" url="https://en.wikipedia.org/wiki?curid=55504612" title="Body image law">
Body image law

Body image law is the developing area of law that, according to Dr Marilyn Bromberg of the University of Western Australia Law School and Cindy Halliwell, a law student at Deakin University, "encompasses the bills, laws and government actions (such as establishing parliamentary inquiries and creating policies) that may help to improve the body image of the general public, and particularly of young people".<ref name="mb/ch"></ref> Among the reasons for implementing law in this area is to prevent the images of unhealthily thin women causing poor body image which can, along with other factors, lead to an eating disorder.

The Israeli government passed a body image law in 2012 which became operational the following year. The law requires models to have a minimum body mass index to work and if an image was photoshopped to make the model appear thinner, it must have a warning. The warning must state that the image was modified and it must take up at least seven percent of the image. Breaches can result in a civil lawsuit. 

The French Government passed a similar law in 2015 which came into effect in 2017. This law requires that models provide their employers with a "medical certificate, valid for up to two years, confirming their general physical well-being and the fact that they are not excessively underweight." The BMI of models older than 16 will also be taken into consideration, when determining their overall health. 

In contrast to the Israeli law, breaching it attracts criminal sanctions. Additionally, any photo that has been digitally altered must be labeled as such; failure to label these photos will result in a "fine of 37,500 euros, or more than $41,000," and hiring a model without the verified medical certificate and requirements "carries a fine of €75,000 and six months in jail." The law dictates that digitally altered images must be labeled "applies only to advertising, not to editorial images in magazines or newspapers." 

The Greater London Authority banned advertisements that promote unhealthy body image on Transport for London public transport in 2016.<ref name="ap/mo"></ref> Similarly, Trondheim in Norway banned advertisements that promote unhealthy body image in public places in 2017. 

The Australian Government's position in this area is that it is up to industry to solve the problem of poor body image. Likewise, the previous Labor Government created a non-binding Voluntary Industry Code of Conduct on Body Image.


</doc>
<doc id="47849771" url="https://en.wikipedia.org/wiki?curid=47849771" title="Women's empowerment">
Women's empowerment

Women's empowerment is the process in which women elaborate and recreate what it is that they can be, do, and accomplish in a circumstance that they previously were denied. Empowerment can be defined in many ways, however, when talking about women's empowerment, empowerment means accepting and allowing people (women) who are on the outside of the decision-making process into it. “This puts a strong emphasis on participation in political structures and formal decision-making and, in the economic sphere, on the ability to obtain an income that enables participation in economic decision-making.” Empowerment is the process that creates power in individuals over their own lives, society, and in their communities. People are empowered when they are able to access the opportunities available to them without limitations and restrictions such as in education, profession and lifestyle. Feeling entitled to make your own decisions creates a sense of empowerment. Empowerment includes the action of raising the status of women through education, raising awareness, literacy, and training. Women's empowerment is all about equipping and allowing women to make life-determining decisions through the different problems in society.

Alternatively, it is the process for women to redefine gender roles that allows for them to acquire the ability to choose between known alternatives whom have otherwise been restricted from such an ability. There are several principles defining women's empowerment such as, for one to be empowered, they must come from a position of disempowerment. Furthermore, one must acquire empowerment themselves rather than have it given to them by an external party. Other studies have found that empowerment definitions entail people having the capability to make important decisions in their lives while also being able to act on them. Lastly, empowerment and disempowerment is relative to other at a previous time; therefore, empowerment is a process, not a product.

Women empowerment has become a significant topic of discussion in development and economics. It can also point to the approaches regarding other trivialized genders in a particular political or social context.

Women's economic empowerment refers to the ability for women to enjoy their right to control and benefit from the 
resources, assets, income and their own time, as well as the ability to manage risk and improve their economic status and well being.

While often interchangeably used, the more comprehensive concept of gender empowerment refers to people of any gender, stressing the distinction between biological and gender as a role.

Entire nations, businesses, communities and groups can benefit from the implementation of programs and policies that adopt the notion of women empowerment. Empowerment of women is a necessity for the very development of a society, since it enhances both the quality and the quantity of human resources available for development. Empowerment is one of the main procedural concerns when addressing human rights and development.

Women's empowerment and achieving gender equality is essential for our society to ensure the sustainable development of the country. Many world leaders and scholars have argued that sustainable development is impossible without gender equality and women's empowerment. Sustainable development accepts environmental protection, social and economic development, and without women's empowerment, women wouldn't feel equally important to the process of development as men. It is widely believed that, the full participation of both men and women is critical for development. Only acknowledging men's participation will not be beneficial to sustainable development. In the context of women and development, empowerment must include more choices for women to make on their own. Without gender equality and empowerment, the country could not be just, and social change wouldn't occur. Therefore, scholars agree that women's empowerment plays a huge role in development and is one of the significant contributions of development. Without the equal inclusion of women in development, women would not be able to benefit or contribute to the development of the country.

Scholars have identified two forms of empowerment, economic empowerment and political empowerment.

Economic empowerment increases women's agency, access to formal government programs, mobility outside the home, economic independence, and purchasing power. Policy makers are suggested to support job training to aid in entrance in the formal markets. One recommendation is to provide more formal education opportunities for women that would allow for higher bargaining power in the home. They would have more access to higher wages outside the home; and as a result, make it easier for women to get a job in the market.

Strengthening women's access to property inheritance and land rights is another method used to economically empower women. This would allow them better means of asset accumulation, capital, and bargaining power needed to address gender inequalities. Often, women in developing and underdeveloped countries are legally restricted from their land on the sole basis of gender. Having a right to their land gives women a sort of bargaining power that they wouldn't normally have; in turn, they gain more opportunities for economic independence and formal financial institutions.

Race has a huge impact on women's empowerment in areas such as employment. Employment can help create empowerment for women. Many scholars suggest that when we discuss women's empowerment, discussing the different barriers that underprivileged women face, which makes it more difficult for them to obtain empowerment in society, is important when examining the impact of race in connection to employment. Significantly examining how opportunities are structured by gender, race, and class can transpire social change. Work opportunities and the work environment can create empowerment for women. Empowerment in the workplace can positively affect job satisfaction and performance, having equality in the work place can greatly increase the sense of empowerment. However, women of color do not have the same accessibility and privileges in work settings. They(Women of color) are faced with more disadvantages in the work place. Patricia Parker argues that African American women's empowerment is their resistance to control, standing up for themselves and not conforming to societal norms and expectations. In connection to power, feminist perspectives look at empowerment as a form of resistance within systems of unequal power relations. Within the societal setting of race, gender, and class politics, African American women's empowerment in work environment “can be seen as resistance to attempts to fix meanings of appropriate identity and behavior, where such meanings are interpreted as controlling, exploitative, and other- wise oppressive to African American women.” When talking about women's empowerment, many scholars suggest examining the social injustices on women in everyday organizational life that are influenced by race, class, and gender.

Another popular methodology for women's economic empowerment also includes microcredit. Microfinance institutions aim to empower women in their community by giving them access to loans that have low interest rates without the requirement of collateral. More specifically, they(microfinance institutions) aim to give microcredit to women who want to be entrepreneurs. The success and efficiency of microcredit and microloans is controversial and constantly debated. Some critiques claim that microcredit alone doesn't guarantee women have control over the way the loan is used. Microfinance institutions don't address cultural barriers that allow men to still control household finances; as a result, microcredit may simply be transferred to the husband. Microcredit doesn't relieve women of household obligations, and even if women have credit, they don't have the time to be as active in the market as men.

Political empowerment supports creating policies that would best support gender equality and agency for women in both the public and private spheres. Popular methods that have been suggested are to create affirmative action policies that have a quota for the number of women in policy making and parliament positions. As of 2017, the global average of women whom hold lower and single house parliament positions is 23.6 percent. Further recommendations have been to increase women's rights to vote, voice opinions, and the ability to run for office with a fair chance of being elected. Because women are typically associated with child care and domestic responsibilities in the home, they have less time dedicated to entering the labour market and running their business. Policies that increase their bargaining power in the household would include policies that account for cases of divorce, policies for better welfare for women, and policies that give women control over resources (such as property rights). However, participation is not limited to the realm of politics. It can include participation in the household, in schools, and the ability to make choices for oneself. Some theorists believe that bargaining power and agency in the household must be achieved before one can move onto broader political participation.

Women empowerment can be measured through the Gender Empowerment Measure (GEM), which shows women's participation in a given nation, both politically and economically. GEM is calculated by tracking "the share of seats in parliament held by women; of female legislators, senior officials and managers; and of female profession and technical workers; and the gender disparity in earned income, reflecting economic independence". It then ranks countries given this information. Other measures that take into account the importance of female participation and equality include: the Gender Parity Index or the Gender-related Development Index (GDI).

Some critiques of GEM is that it is not concerned with factors regarding society, such as gender, religion, cultural context, legal context, and violations of women's rights. Gender empowerment measure attempts to makes a consistent standardized approach to measure women's empowerment; in doing so, it has been critiqued that the GEM doesn't account for variation in historical factors, female autonomy, gender segregation, and women's right to vote.

The Gender-related Development Index (GDI) is a way in which the United Nations Development Programme (UNDP) measures the inequality between genders within a country. Some critique of this measurement is that, because GDI calculations rely solely on the achievement distribution between males and females of a population, GDI doesn't measure gender inequality; rather, it measures absolute levels on income, education and health.

A more qualitative form of assessing women's empowerment is to identify constraints to action. This allows for the identification of power relations between genders. Because this is a participatory process, it facilitates conversation on gender discrimination. Comparing constraints on women at a later time also allows for any changes or expansion to be better identified. The evaluation of the development of women's agency allows for an evaluation of actions taken. These assessments must also be based on the action taken by women, and not external groups. External groups can help facilitate women's empowerment, but cannot bestow it on them.

Many of the barriers to women's empowerment and equity lie ingrained in cultural norms. Many women feel these pressures, while others have become accustomed to being treated inferior to men. Even if legislators, NGOs, etc. are aware of the benefits women's empowerment and participation can have, many are scared of disrupting the status of the women and continue to let societal norms get in the way of development.

Research shows that the increasing access to the internet can also result in an increased exploitation of women. Releasing personal information on websites has put some women's personal safety at risk. In 2010, Working to Halt Online Abuse stated that 73% of women were victimized through such sites. Types of victimization include cyber stalking, harassment, online pornography, and flaming. Sexual harassment in particular is a large barrier for women in the workplace. It appears in almost all industries, but is most notable in the following: business, trade, banking and finance, sales and marketing, hospitality, civil service, and education, lecturing and teaching. According to the International Labour Organisation (ILO), sexual harassment is a clear form of gender discrimination based on sex, a manifestation of unequal power relations between men and women. Furthermore, the UN Convention on the Elimination of All Forms of Discrimination Against Women (CEDAW) is urging for increased measures of protection for women against sexual harassment and violence in the workplace. 54% (272) had experienced some form of workplace sexual harassment. 79% of the victims are women; 21% were men.

Recent studies also show that women face more barriers in the workplace than do men. Gender-related barriers involve sexual harassment, unfair hiring practices, career progression, and unequal pay where women are paid less than men are for performing the same job. When taking the median earnings of men and women who worked full-time, year-round, government data from 2014 showed that women made $0.79 for every dollar a man earned. The average earnings for working mothers came out to even less—$0.71 for every dollar a father made, according to a 2014 study conducted by the National Partnership for Women and Children. While much of the public discussion of the "wage gap" has focused around women getting equal pay for the same work as their male peers, many women struggle with what is called the "pregnancy penalty". The main problem is that it is difficult to measure, but some experts say that the possibility of having a baby can be enough for employers to push women back from their line. Therefore, women are put in a position where they need to make the decision of whether to maintain in the workforce or have children. This problem has sparked the debate over maternity leave in the United States and many other countries in the world.

However, despite the struggle for equal pay in the United States, the tech industry has made progress in helping to encourage equal pay across gender. In March 2016, tech career website Dice released a study of more than 16,000 tech professionals that found that when you compare equivalent education, experience and position, there is no pay gap—and hasn't been for the last six years. This new industry is paving a way for other companies to do the same. However, this industry also struggles to employ women in executive positions. This is partially due to the barrier of sexual harassment and pregnancy that was aforementioned.

Such barriers make it difficult for women to advance in their workplace or receive fair compensation for the work they provide.

It is said that education increases "people's self-confidence and also enables them to find better jobs and they can work shoulder to shoulder with men". They engage in public debate and make demands on government for health care, social security and other entitlements". In particular, education empowers women to make choices that improve their children's health, their well-being, and chances of survival. Education informs others of preventing and containing the disease, and it is an essential element of efforts to reduce malnutrition. Furthermore, it empowers women to make choices that can improve their welfare, including marrying beyond childhood and having fewer children. Crucially, education can increase women's awareness of their rights, boost their self-esteem, and provide them the opportunity to assert their rights.

Despite significant improvements in recent decades, education is not universally available and gender inequalities persist. A major concern in many countries is not only the limited numbers of girls going to school but also the limited educational pathways for those that step into the classroom. More specifically, there should be more efforts to address the lower participation and learning achievement of girls in science, technology, engineering and mathematics (STEM) education.

The growing access of the web in the late 20th century has allowed women to empower themselves by using various tools on the Internet. With the introduction of the World Wide Web, women have begun to use social networking sites like Facebook and Twitter for online activism. Through online activism, women are able to empower themselves by organizing campaigns and voicing their opinions for equality rights without feeling oppressed by members of society. For example, on May 29, 2013, an online campaign started by 100 female advocates forced the leading social networking website, Facebook, to take down various pages that spread hatred about women.

In recent years, blogging has also become a powerful tool for the educational empowerment of women. According to a study done by the University of California, Los Angeles, medical patients who read and write about their disease are often in a much happier mood and more knowledgeable than those who do not. By reading others' experiences, patients can better educate themselves and apply strategies that their fellow bloggers suggest.

With the easy accessibility and affordability of e-learning (electronic learning), women can now study from the comfort of their homes. By empowering themselves educationally through new technologies like e-learning, women are also learning new skills that will come in handy in today's advancing globalized world.

Oftentimes, the internet is very useful as source of empowerment for women through its creation, dispersion, and utilization of hashtags on social media. One prime example of hashtags supporting women empowerment was in 2017 when the #AintNoCinderella hashtag came into existence. This hashtag spread like wildfire on social media after Varnika Kundu (a 29-year-old woman in India) was driving home past midnight on August 4 when she was followed and harassed by two men in a SUV. Kundu was blamed for being out late at night, particularly by the BJP government Vice-President Ramveer Bhatti. This led to women all across India and the world posting pictures of themselves out late at night with the hashtag "#AintNoCinderella" to show that women do not have a particular curfew to which they have to adhere to (like Cinderella did).

The UN came out with a set of goals called the Sustainable Development Goals, or SDGs, to help make the world a better place. Of the 17, the fourth goal works to allow access to education for all people alike. A large effort has been made to include women in schools to better their education. Similarly, the fifth goal focuses on empowering women and girls to achieve gender equality through equal access to various types of opportunities (health care, education, work, etc.).

There are also some prominent non-profits that help empower women:


Domestically, the U.S. empowered women through passings of laws such as allowing women to vote in 1920, banning discrimination based on gender in 1964, banning discrimination against pregnant women in 1978, etc. Additionally, the inclusion of women in politics allowed for more gender equality. The first female speaker of House, the First Lady to run for president, and first women to serve on the Supreme Court were monumental events that proved socially the acceptance of "subservient" women.

The U.S. provides foreign aid to third world countries in various forms, one of which is by providing education programs. There are currently bills in Congress that work to ensure education to girls, one of which is the Protecting Girls' Access to Education Act. These are enacted with the belief that proper education will pull them out of poverty and reduce exploitation.

Another action taken on by the U.S is the PEPFAR program, initiated by the Bush administration in 2003. The U.S. spent more than $1.4 billion in funding sub-Saharan Africa during the duration of the program. This program was taken into effect in response to the global HIV/AIDS crisis, and it promoted abstinence among young girls and women. There was a partnership with DREAMS, and its main purpose with PEPFAR was to allow both girls and women to develop into Determined, Resilient, Empowered, AIDS-free, Mentored, and Safe women. However, there are criticisms that this program did not really do much to reduce HIV risk behavior, and critics such as John Dietrich worried that the context of aid enforced Western beliefs of choosing abstinence before marriage. There was and still is controversy regarding the effectiveness of this program in reducing HIV/AIDS through advocating abstinence and whether this would actually empower women in Africa.




</doc>
<doc id="18342" url="https://en.wikipedia.org/wiki?curid=18342" title="Outline of law">
Outline of law

Law ("article link") is the set of rules and principles (laws) by which a society is governed, through enforcement by governmental authorities. Law is also the field which concerns the creation and administration of laws, and includes any and all legal systems.

Law can be described as all of the following:




Public law







History of law






Sources of law

Legislatures

Courts

Prisons




</doc>
<doc id="5816107" url="https://en.wikipedia.org/wiki?curid=5816107" title="Universal law">
Universal law

In law and ethics, universal law or universal principle refers as concepts of legal legitimacy actions, whereby those principles and rules for governing human beings' conduct which are most universal in their acceptability, their applicability, translation, and philosophical basis, are therefore considered to be most legitimate. One type of Universal Law is the Law of Logic which prohibits logical contradictions known as sophistry. The Law of Logic is based upon the universal idea that logic is defined as that which is not illogical and that which is illogical is that which involves a logical contradiction, such as attempting to assert that an apple and no apple can exist at and in the same time and in the same place, and attempting to assert that A and not A can exist at and in the same time and in the same place.



</doc>
<doc id="56582267" url="https://en.wikipedia.org/wiki?curid=56582267" title="Distributed ledger technology law">
Distributed ledger technology law

Distributed ledger technology law ("DLT law") (also called Blockchain law. or Lex Cryptographia) is not yet defined and recognized but an emerging field of law due to the recent dissemination of distributed ledger technology application in business and governance environment.

Ubiquitous dissemination of information technology and the Internet led to a discussion of two opposite legal theories of the regulation of cyberspace. According to The Law of the Horse theory proposed by Frank H. Easterbrook, general principles of law governing property, transactions and torts apply to any relationship whether in case of the horse or cyberspace and there is no reason to invent new fields of law designated for each. This theory was challenged by Lawrence Lessig, who argued that in case of cyberspace the code may be considered as another way of regulation and therefore the cyberspace may be treated more widely than just another area of relations regulated by conventional legal principles. Employing more liberal approach the DLT law may mean the body of law "characterized by a set of rules administered through self-executing smart contracts and decentralized (and potentially autonomous) organizations".

As of the beginning of 2018 the DLT law does not constitute a separate field of law rather it encompasses aspects of corporate, contract, investment, banking and finance law. According to conservative approach the DLT law may be considered as a part of existent area of law, which may be applied to regulate different aspects of DLT use and new kind of legal relations on blockchain, such as issue of authorisation (electronic signature), admissibility of blockchain evidence in court, status of cryptocurrency and regulation of initial coin offering, use of smart contracts, status of DAO (decentralized autonomous organization) and other.

While in the UK and the EU at the beginning of 2018 the legislators are still silent about blockchain technology, in the United States several states already enacted legislation providing a framework for business and legal application of blockchain technology and enforceability of smart contracts.

On 2 June 2016 Vermont became the first state, which recognised blockchain-based records having legal bearing in a court under the Vermont Rules of Evidence and defined blockchain technology as "mathematically secured, chronological, and decentralized consensus ledger or database, whether maintained via Internet interaction, peer-to-peer network, or otherwise"

In March 2017, Arizona’s Electronic Transactions Act (the AETA) was amended by HB 2417 Act to clarify that “electronic records, electronic signatures, and smart contract terms secured through blockchain technology and governed under UCC Articles 2, 2A and 7 will be considered to be in an electronic form and to be an electronic signature under AETA.” HB 2417 Act also provides a definition of blockchain technology as a “distributed, decentralized, shared and replicated ledger, which may be public or private, permissioned or permissionless, or driven by tokenized crypto economics or tokenless” and definition of smart contract as "event driven program, with state, that runs on a distributed, decentralized, shared and replicated ledger that can take custody over and instruct transfer of assets on that ledger".

The State also identifies areas where blockchain technology should not be used. For instance, the new law adopted in 2017 prohibits the use of blockchain technology to locate or control firearms.

In June 2017 similar legislation has been enacted in Nevada. In addition, "Nevada has become the first state to ban local governments from taxing blockchain use". With regard to the definition of blockchain, the Nevada Senate defines it as "an electronic record created by the use of a decentralized method by multiple parties to verify and store a digital record of transactions which is secured by the use of a cryptographic hash of previous transaction information".

On August 1, 2017, Delaware's blockchain law became effective, which amends the Delaware General Corporation Law explicitly permitting the use of distributed ledger technology in the administration of Delaware corporate records, including records of stock and stockholders. "Before this new law was adopted, there was nothing specifically stopping a Delaware corporation from using blockchain technology to keep track of its stockholders, but there was also a great deal of regulatory uncertainty."

On January 31, 2018, Illinois regarded its role in the development of the blockchain ecosystem as one which "supports the distinct needs of the respective ecosystem stakeholders: entrepreneurs, capital providers, developers, governments, and academics to support and encourage the creation and growth of 15 blockchain companies in Illinois." To accomplish this mission the Illinois Blockchain Initiative created the role of the State of Illinois Blockchain Business Liaison, which is responsible for the engagement of these stakeholders within the ecosystem to identify and conclusively work to resolve their respective needs. Over the past year, the Illinois Blockchain Initiative has compiled a database of over 200 blockchain and distributed ledger technology pilots, projects and strategies announced by public sector entities. The database is an overview of how government at various levels globally 29 are employing blockchain technology in their efforts to govern, improve the competitiveness of their economy and also deliver high-quality services in a more efficient manner. The public sector is one of the most active blockchain sector’s exploring the technology for a wide variety of use cases. Adoption of the technology in the public section is accelerating at an extraordinary pace.

In the legal context DLT and smart contracts are distinct and face their own problems and challenges. Issue of situs is an example which relates to DLT rather than smart contracts. International private law and legislation of various jurisdictions require to identify the location of an asset or place of an agreement in order to solve conflict of law problem and determine the applicable governing law. "However, the distribution of the register across nodes in multiple jurisdictions raises a seemingly intractable problem – under current legal principles at least – as to where the situs should be." Holding something on DLT, including smart contract or title to an asset, does not isolate it from the legal system and laws of respective jurisdiction. "Some blockchain enthusiasts may have misinterpreted the statement ‘code is law’ as implying that code can supersede the law or that decentralised networks create their own legal regimes."

In case of a dispute between the parties of the smart contract within the DLT, the issue arises where the distributed ledger is located in order to determine the place for dispute resolution. "Blockchain also poses questions concerning the ability to identify the parties to a transaction, to the extent a system utilizing this technology remains anonymous, which may rise a host of additional issues related to dispute resolution."

An absence of legal compliance mechanism on DLT, self-executing nature of code on DLT and limited ability to update the code if the law changes create a number of legal issues. There are several possible solutions of addressing these issues. "One method could be a system in which the relevant jurisdiction creates a publicly available database and application programming interface (API) of relevant legal provisions. These would be provisions related to the terms of the contract. The smart contract would call these terms and would be able to update those provisions terms in accord with the jurisdiction's update of the database."

On more conservative side of DLT and law interaction spectrum are two solutions proposed by Alexander Savelyev:

"(1) To introduce the concept of a ‘Superuser’ for government authorities, which will have a right to modify the content of Blockchain databases in accordance with a specified procedure in order to reflect the decisions of state authority.

(2) To enforce decisions of state authorities in ‘offline’ mode by pursuing the specific users and forcing them to include changes in Blockchain themselves as well as by using traditional tort claims, unjust enrichment claims, and specific performance claims."

To facilitate the self-execution, a smart contract needs access to sources of event information through which the execution of its terms and conditions is assessed. "In the interest rate swap example, the distributed ledger must have access to assets of the parties' in order to fulfil the parties' payment obligations, and it must have access to a provider of interest rate information." The solutions to the issue of access to assets vary and may be solved through locking and release of assets in smart contract as it is performed through use of cryptocurrency Ether on Ethereum blockchain or by introducing new mechanism of access to assets like 'cash states' proposed by Corda distributed ledger. The solution to the issue of access to information may require use of so-called 'Oracles' - an external party (or a machine) providing the judgement to determine whether or not respective conditions under the agreement have been met. "Turning again to the interest rate swap example, an oracle could be used to provide interest rate information on a payment calculation date. The oracle's digital signature would be retained on the distributed ledger so that parties could review the payment process and confirm that payments were made correctly."


</doc>
<doc id="57691114" url="https://en.wikipedia.org/wiki?curid=57691114" title="Strawman theory">
Strawman theory

Strawman theory (also called the Strawman illusion) is a pseudolegal theory prevalent in various movements such as sovereign citizen, tax protester, freeman on the land, and the redemption movement. The theory holds that an individual has two personas, one of flesh and the other a separate legal personality (i.e., the "strawman"). The idea is that an individual’s debts, liabilities, taxes and legal responsibilities belong to the strawman rather than the physical individual. The strawman theory is recognized in law as a scam: the FBI considers anyone promoting it a likely fraudster; the Internal Revenue Service (IRS) considers it a frivolous argument and fines people that use the theory on their Federal tax returns.

Strawman theory traces its origins to the ancient Roman legal practice of "capitis deminutio" ("decrease of head"), a term used in Roman trials for the extinguishment of a person's former legal capacity. "Capitis deminutio minima" meant a person ceased to belong to a particular family, without loss of liberty or citizenship. "Capitis deminutio media" involved loss of citizenship and family, but not liberty. "Capitis deminutio maxima" involved loss of family, citizenship and liberty ("i.e.", a slave or a prisoner of war). Strawman theory commonly takes the term "capitis deminutio" spells it "Capitis Diminutio" and claims "capitis diminutio maxima" was represented by an individual’s name being written in capital letters. This led to the idea that individuals had a separate legal personality now called a "strawman".

The theory holds that an individual has two personas. One of them is a physical, tangible human being, and the other is the "legal person", often referred to as a legal fiction. When a baby is born in the U.S., a birth certificate is issued, and the parents apply for a Social Security number. Sovereigns say the government uses that birth certificate to set up a secret Treasury account which it funds with an amount ranging from $600,000 to $20 million, depending on the particular sovereign belief system. Hence, every newborn's rights are split between those held by the flesh-and-blood baby and the corporate shell account.

Proponents of the theory believe the evidence is found on the birth certificate. Because many certificates show all capitals to spell out a baby's name, JOHN DOE (under the Strawman theory) is the name of the "straw man," and John Doe is the baby's "real" name. As the child grows, most legal documents will contain capital letters, which means that his state-issued driver's license, his marriage license, his car registration, his criminal court records, his cable TV bill, correspondence from the IRS, etc., pertain to his strawman and not his sovereign identity. In reality, the use of all capital letters is typically done to make certain statements clear and conspicuous, although this is not always the case.

The main use of strawman theory is in escaping and denying debts, liabilities and legal responsibility. Tax protesters, "commercial redemption" and "get out of debt free" scams claim that one’s debts and taxes are the responsibility of the strawman and not of the real person. They back this claim by misreading the legal definition of "person" and a misunderstanding of the distinction between a "juridicial person" and a "natural person". In accepted legal theory there is a difference between what is known as a "natural person" and that of a "corporate person". A "corporate personhood" applies to business, charities, governments and other recognized organisations. Courts recognize human beings as 'persons', not as a legal fiction joined to a flesh and blood human being but as one and the same. They have never recognized a right to distance oneself from one's person, or the ability to opt out of personhood.

Believers of the theory also extend it to law and legal responsibilities, claiming that only their strawman is required to adhere to statutory laws. They also claim that legal proceedings are taken against strawmen rather than persons and when one appears in court they appear as representing their strawman. The justification for this is the false notion that governments cannot force anybody to do anything. A strawman therefore created which the adherent believes he or she is free to command. Proponents cite a misinterpretation of a passage in chapter 39 of King John's Magna Carta stating in part that, "no freeman will be seized, dispossessed of his property, or harmed except by the law of the land”.

Freemen believe that separating from their strawman or refusing to be identified as such enables escape from their legal liabilities and responsibilities. This is typically attempted by denying they are a 'person' in the same way as their strawman, or by writing their name in non-standard ways, using red ink, and placing finger prints on court documents.

Judge Norman K. Moon found such tactics an unconvincing argument in 2013 when an individual named Brandon Gravatt tried to overturn a drug conviction and get out of prison. The case was summarily dismissed by the court.

It is impossible to dodge the law by insisting that an individual is different from his or her person. If a court can establish a person's identity, regardless of consent or cooperation, the court will engage in proceedings and sanctions against the individual. This is due to the legal principle known as "Idem sonans" (Latin for "sounding the same") which states that similar sounding names are just as valid in referring to a person. The earliest legal precedent is R v Davis in the United Kingdom in 1851.



</doc>
<doc id="53504025" url="https://en.wikipedia.org/wiki?curid=53504025" title="Legal syllogism">
Legal syllogism

Legal syllogism is a legal concept concerning the law and its application, specifically a form of argument based on deductive reasoning and seeking to establish whether a specified act is lawful. 

A syllogism is a form of logical reasoning that hinges on a question, a major premise, a minor premise and a conclusion. If properly plead, every legal action seeking redress of a wrong or enforcement of a right is "a syllogism of which the major premise is the proposition of law involved, the minor premise is the proposition of fact, and the judgment the conclusion." More broadly, many sources suggest that every good legal argument is cast in the form of a syllogism.

Fundamentally, the syllogism may be reduced to a three step process: 1. "law finding", 2. "fact finding", and 3."law applying." See Holding (law). That protocol presupposes someone has done "law making" already. This model is sufficiently broad so that it may be applied in many different nations and legal systems.

In legal theoretic literature, legal syllogism is controversial. It is treated as equivalent to an “interpretational decision.”



</doc>
<doc id="18949668" url="https://en.wikipedia.org/wiki?curid=18949668" title="Law">
Law

Law is a system of rules that are created and enforced through social or governmental institutions to regulate behavior. It has been defined both as "the Science of Justice" and "the Art of Justice". Law is a system that regulates and ensures that individuals or a community adhere to the will of the state. State-enforced laws can be made by a collective legislature or by a single legislator, resulting in statutes, by the executive through decrees and regulations, or established by judges through precedent, normally in common law jurisdictions. Private individuals can create legally binding contracts, including arbitration agreements that may elect to accept alternative arbitration to the normal court process. The formation of laws themselves may be influenced by a constitution, written or tacit, and the rights encoded therein. The law shapes politics, economics, history and society in various ways and serves as a mediator of relations between people.

A general distinction can be made between (a) civil law jurisdictions, in which a legislature or other central body codifies and consolidates their laws, and (b) common law systems, where judge-made precedent is accepted as binding law. Historically, religious laws played a significant role even in settling of secular matters, and is still used in some religious communities. Islamic Sharia law is the world's most widely used religious law, and is used as the primary legal system in some countries, such as Iran and Saudi Arabia.

The adjudication of the law is generally divided into two main areas. Criminal law deals with conduct that is considered harmful to social order and in which the guilty party may be imprisoned or fined. Civil law (not to be confused with civil law jurisdictions above) deals with the resolution of lawsuits (disputes) between individuals and/or organizations.

Law provides a source of scholarly inquiry into legal history, philosophy, economic analysis and sociology. Law also raises important and complex issues concerning equality, fairness, and justice.

Numerous definitions of "law" have been put forward over the centuries. The "Third New International Dictionary" from Merriam-Webster defines law as: "Law is a binding custom or practice of a community; a rule or mode of conduct or action that is prescribed or formally recognized as binding by a supreme controlling authority or is made obligatory by a sanction (as an edict, decree, rescript, order, ordinance, statute, resolution, rule, judicial decision, or usage) made, recognized, or enforced by the controlling authority."

The "Dictionary of the History of Ideas" published by Scribner's in 1973 defined the concept of law accordingly as: "A legal system is the most explicit, institutionalized, and complex mode of regulating human conduct. At the same time, it plays only one part in the congeries of rules which influence behavior, for social and moral rules of a less institutionalized kind are also of great importance."

There have been several attempts to produce "a universally acceptable definition of law". In 1972, one source indicated that no such definition could be produced. McCoubrey and White said that the question "what is law?" has no simple answer. Glanville Williams said that the meaning of the word "law" depends on the context in which that word is used. He said that, for example, "early customary law" and "municipal law" were contexts where the word "law" had two different and irreconcilable meanings. Thurman Arnold said that it is obvious that it is impossible to define the word "law" and that it is also equally obvious that the struggle to define that word should not ever be abandoned. It is possible to take the view that there is no need to define the word "law" (e.g. "let's forget about generalities and get down to cases").

The history of law links closely to the development of civilization. Ancient Egyptian law, dating as far back as 3000 BC, contained a civil code that was probably broken into twelve books. It was based on the concept of Ma'at, characterised by tradition, rhetorical speech, social equality and impartiality. By the 22nd century BC, the ancient Sumerian ruler Ur-Nammu had formulated the first law code, which consisted of casuistic statements ("if … then ..."). Around 1760 BC, King Hammurabi further developed Babylonian law, by codifying and inscribing it in stone. Hammurabi placed several copies of his law code throughout the kingdom of Babylon as stelae, for the entire public to see; this became known as the Codex Hammurabi. The most intact copy of these stelae was discovered in the 19th century by British Assyriologists, and has since been fully transliterated and translated into various languages, including English, Italian, German, and French.

The Old Testament dates back to 1280 BC and takes the form of moral imperatives as recommendations for a good society. The small Greek city-state, ancient Athens, from about the 8th century BC was the first society to be based on broad inclusion of its citizenry, excluding women and the slave class. However, Athens had no legal science or single word for "law", relying instead on the three-way distinction between divine law ("thémis"), human decree ("nomos") and custom ("díkē"). Yet Ancient Greek law contained major constitutional innovations in the development of democracy.

Roman law was heavily influenced by Greek philosophy, but its detailed rules were developed by professional jurists and were highly sophisticated. Over the centuries between the rise and decline of the Roman Empire, law was adapted to cope with the changing social situations and underwent major codification under Theodosius II and Justinian I. Although codes were replaced by custom and case law during the Early Middle Ages, Roman law was rediscovered around the 11th century when medieval legal scholars began to research Roman codes and adapt their concepts to the canon law, giving birth to the "jus commune". Latin legal maxims (called brocards) were compiled for guidance. In medieval England, royal courts developed a body of precedent which later became the common law. A Europe-wide Law Merchant was formed so that merchants could trade with common standards of practice rather than with the many splintered facets of local laws. The Law Merchant, a precursor to modern commercial law, emphasised the freedom to contract and alienability of property. As nationalism grew in the 18th and 19th centuries, the Law Merchant was incorporated into countries' local law under new civil codes. The Napoleonic and German Codes became the most influential. In contrast to English common law, which consists of enormous tomes of case law, codes in small books are easy to export and easy for judges to apply. However, today there are signs that civil and common law are converging. EU law is codified in treaties, but develops through the precedent laid down by the European Court of Justice.

Ancient India and China represent distinct traditions of law, and have historically had independent schools of legal theory and practice. The "Arthashastra", probably compiled around 100 AD (although it contains older material), and the "Manusmriti" (c. 100–300 AD) were foundational treatises in India, and comprise texts considered authoritative legal guidance. Manu's central philosophy was tolerance and pluralism, and was cited across Southeast Asia. This Hindu tradition, along with Islamic law, was supplanted by the common law when India became part of the British Empire. Malaysia, Brunei, Singapore and Hong Kong also adopted the common law. The eastern Asia legal tradition reflects a unique blend of secular and religious influences. Japan was the first country to begin modernising its legal system along western lines, by importing bits of the French, but mostly the German Civil Code. This partly reflected Germany's status as a rising power in the late 19th century. Similarly, traditional Chinese law gave way to westernisation towards the final years of the Qing Dynasty in the form of six private law codes based mainly on the Japanese model of German law. Today Taiwanese law retains the closest affinity to the codifications from that period, because of the split between Chiang Kai-shek's nationalists, who fled there, and Mao Zedong's communists who won control of the mainland in 1949. The current legal infrastructure in the People's Republic of China was heavily influenced by Soviet Socialist law, which essentially inflates administrative law at the expense of private law rights. Due to rapid industrialisation, today China is undergoing a process of reform, at least in terms of economic, if not social and political, rights. A new contract code in 1999 represented a move away from administrative domination. Furthermore, after negotiations lasting fifteen years, in 2001 China joined the World Trade Organization.

The philosophy of law is commonly known as (general) jurisprudence. Normative jurisprudence asks "what should law be?", while analytic jurisprudence asks "what is law?" John Austin's utilitarian answer was that law is "commands, backed by threat of sanctions, from a sovereign, to whom people have a habit of obedience". Natural lawyers on the other side, such as Jean-Jacques Rousseau, argue that law reflects essentially moral and unchangeable laws of nature. The concept of "natural law" emerged in ancient Greek philosophy concurrently and in connection with the notion of justice, and re-entered the mainstream of Western culture through the writings of Thomas Aquinas, notably his "Treatise on Law".

Hugo Grotius, the founder of a purely rationalistic system of natural law, argued that law arises from both a social impulse—as Aristotle had indicated—and reason. Immanuel Kant believed a moral imperative requires laws "be chosen as though they should hold as universal laws of nature". Jeremy Bentham and his student Austin, following David Hume, believed that this conflated the "is" and what "ought to be" problem. Bentham and Austin argued for law's positivism; that real law is entirely separate from "morality". Kant was also criticised by Friedrich Nietzsche, who rejected the principle of equality, and believed that law emanates from the will to power, and cannot be labelled as "moral" or "immoral".

In 1934, the Austrian philosopher Hans Kelsen continued the positivist tradition in his book the "Pure Theory of Law". Kelsen believed that although law is separate from morality, it is endowed with "normativity", meaning we ought to obey it. While laws are positive "is" statements (e.g. the fine for reversing on a highway "is" €500); law tells us what we "should" do. Thus, each legal system can be hypothesised to have a basic norm ("Grundnorm") instructing us to obey. Kelsen's major opponent, Carl Schmitt, rejected both positivism and the idea of the rule of law because he did not accept the primacy of abstract normative principles over concrete political positions and decisions. Therefore, Schmitt advocated a jurisprudence of the exception (state of emergency), which denied that legal norms could encompass all of political experience.

Later in the 20th century, H. L. A. Hart attacked Austin for his simplifications and Kelsen for his fictions in "The Concept of Law". Hart argued law is a system of rules, divided into primary (rules of conduct) and secondary ones (rules addressed to officials to administer primary rules). Secondary rules are further divided into rules of adjudication (to resolve legal disputes), rules of change (allowing laws to be varied) and the rule of recognition (allowing laws to be identified as valid). Two of Hart's students continued the debate: In his book "Law's Empire", Ronald Dworkin attacked Hart and the positivists for their refusal to treat law as a moral issue. Dworkin argues that law is an "interpretive concept", that requires judges to find the best fitting and most just solution to a legal dispute, given their constitutional traditions. Joseph Raz, on the other hand, defended the positivist outlook and criticised Hart's "soft social thesis" approach in "The Authority of Law". Raz argues that law is authority, identifiable purely through social sources and without reference to moral reasoning. In his view, any categorisation of rules beyond their role as authoritative instruments in mediation are best left to sociology, rather than jurisprudence.

One definition is that law is a system of rules and guidelines which are enforced through social institutions to govern behaviour. In "The Concept of Law" Hart argued law is a "system of rules"; Austin said law was "the command of a sovereign, backed by the threat of a sanction"; Dworkin describes law as an "interpretive concept" to achieve justice in his text titled "Law's Empire"; and Raz argues law is an "authority" to mediate people's interests. Holmes said "The prophecies of what the courts will do in fact, and nothing more pretentious, are what I mean by the law." In his "Treatise on Law" Aquinas argues that law is a rational ordering of things which concern the common good that is promulgated by whoever is charged with the care of the community. This definition has both positivist and naturalist elements.

In the 18th century Adam Smith presented a philosophical foundation for explaining the relationship between law and economics. The discipline arose partly out of a critique of trade unions and U.S. antitrust law. The most influential proponents, such as Richard Posner and Oliver Williamson and the so-called Chicago School of economists and lawyers including Milton Friedman and Gary Becker, are generally advocates of deregulation and privatisation, and are hostile to state regulation or what they see as restrictions on the operation of free markets.

The most prominent economic analyst of law is 1991 Nobel Prize winner Ronald Coase, whose first major article, "The Nature of the Firm" (1937), argued that the reason for the existence of firms (companies, partnerships, etc.) is the existence of transaction costs. Rational individuals trade through bilateral contracts on open markets until the costs of transactions mean that using corporations to produce things is more cost-effective. His second major article, "The Problem of Social Cost" (1960), argued that if we lived in a world without transaction costs, people would bargain with one another to create the same allocation of resources, regardless of the way a court might rule in property disputes. Coase used the example of a nuisance case named "Sturges v Bridgman", where a noisy sweetmaker and a quiet doctor were neighbours and went to court to see who should have to move. Coase said that regardless of whether the judge ruled that the sweetmaker had to stop using his machinery, or that the doctor had to put up with it, they could strike a mutually beneficial bargain about who moves that reaches the same outcome of resource distribution. Only the existence of transaction costs may prevent this. So the law ought to pre-empt what "would" happen, and be guided by the most efficient solution. The idea is that law and regulation are not as important or effective at helping people as lawyers and government planners believe. Coase and others like him wanted a change of approach, to put the burden of proof for positive effects on a government that was intervening in the market, by analysing the costs of action.

Sociology of law is a diverse field of study that examines the interaction of law with society and overlaps with jurisprudence, philosophy of law, social theory and more specialised subjects such as criminology. The institutions of social construction, social norms, dispute processing and legal culture are key areas for inquiry in this knowledge field. Sociology of law is sometimes seen as a sub-discipline of sociology, but its ties to the academic discipline of law are equally strong, and it is best seen as a transdisciplinary and multidisciplinary study focused on the theorisation and empirical study of legal practices and experiences as social phenomena. In the United States the field is usually called law and society studies; in Europe it is more often referred to as socio-legal studies. At first, jurists and legal philosophers were suspicious of sociology of law. Kelsen attacked one of its founders, Eugen Ehrlich, who sought to make clear the differences and connections between positive law, which lawyers learn and apply, and other forms of 'law' or social norms that regulate everyday life, generally preventing conflicts from reaching barristers and courts. Contemporary research in sociology of law is much concerned with the way that law is developing outside discrete state jurisdictions, being produced through social interaction in many different kinds of social arenas, and acquiring a diversity of sources of (often competing or conflicting) authority in communal networks existing sometimes within nation states but increasingly also transnationally.

Around 1900 Max Weber defined his "scientific" approach to law, identifying the "legal rational form" as a type of domination, not attributable to personal authority but to the authority of abstract norms. Formal legal rationality was his term for the key characteristic of the kind of coherent and calculable law that was a precondition for modern political developments and the modern bureaucratic state. Weber saw this law as having developed in parallel with the growth of capitalism. Another leading sociologist, Émile Durkheim, wrote in his classic work "The Division of Labour in Society" that as society becomes more complex, the body of civil law concerned primarily with restitution and compensation grows at the expense of criminal laws and penal sanctions. Other notable early legal sociologists included Hugo Sinzheimer, Theodor Geiger, Georges Gurvitch and Leon Petrażycki in Europe, and William Graham Sumner in the U.S.

There are distinguished methods of legal reasoning (applying the law) and methods of interpreting (construing) the law. The former are legal syllogism, which holds sway in civil law legal systems, analogy, which is present in common law legal systems, especially in the US, and argumentative theories that occur in both systems. The latter are different rules (directives) of legal interpretation such as directives of linguistic interpretation, teleological interpretation or systemic interpretation as well as more specific rules, for instance, golden rule or mischief rule. There are also many other arguments and cannons of interpretation which altogether make statutory interpretation possible.

Law professor and former United States Attorney General Edward H. Levi noted that the "basic pattern of legal reasoning is reasoning by example" - that is, reasoning by comparing outcomes in cases resolving similar legal questions. In a U.S. Supreme Court case regarding procedural efforts taken by a debt collection company to avoid errors, Justice Sotomayor cautioned that "legal reasoning is not a mechanical or strictly linear process"".

In general, legal systems can be split between civil law and common law systems. The term "civil law" referring to a legal system should not be confused with "civil law" as a group of legal subjects distinct from criminal or public law. A third type of legal system—accepted by some countries without separation of church and state—is religious law, based on scriptures. The specific system that a country is ruled by is often determined by its history, connections with other countries, or its adherence to international standards. The sources that jurisdictions adopt as authoritatively binding are the defining features of any legal system. Yet classification is a matter of form rather than substance, since similar rules often prevail.

Civil law is the legal system used in most countries around the world today. In civil law the sources recognised as authoritative are, primarily, legislation—especially codifications in constitutions or statutes passed by government—and custom. Codifications date back millennia, with one early example being the Babylonian "Codex Hammurabi". Modern civil law systems essentially derive from the legal practice of the 6th-century Eastern Roman Empire whose texts were rediscovered by late medieval Western Europe. Roman law in the days of the Roman Republic and Empire was heavily procedural, and lacked a professional legal class. Instead a lay magistrate, "iudex", was chosen to adjudicate. Decisions were not published in any systematic way, so any case law that developed was disguised and almost unrecognised. Each case was to be decided afresh from the laws of the State, which mirrors the (theoretical) unimportance of judges' decisions for future cases in civil law systems today. From 529–534 AD the Byzantine Emperor Justinian I codified and consolidated Roman law up until that point, so that what remained was one-twentieth of the mass of legal texts from before. This became known as the "Corpus Juris Civilis". As one legal historian wrote, "Justinian consciously looked back to the golden age of Roman law and aimed to restore it to the peak it had reached three centuries before." The Justinian Code remained in force in the East until the fall of the Byzantine Empire. Western Europe, meanwhile, relied on a mix of the Theodosian Code and Germanic customary law until the Justinian Code was rediscovered in the 11th century, and scholars at the University of Bologna used it to interpret their own laws. Civil law codifications based closely on Roman law, alongside some influences from religious laws such as canon law, continued to spread throughout Europe until the Enlightenment; then, in the 19th century, both France, with the "Code Civil", and Germany, with the "Bürgerliches Gesetzbuch", modernised their legal codes. Both these codes influenced heavily not only the law systems of the countries in continental Europe (e.g. Greece), but also the Japanese and Korean legal traditions. Today, countries that have civil law systems range from Russia and China to most of Central and Latin America. With the exception of Louisiana's Civil Code, the United States follows the common law system described below.

In common law legal systems, decisions by courts are explicitly acknowledged as "law" on equal footing with statutes adopted through the legislative process and with regulations issued by the executive branch. The "doctrine of precedent", or "stare decisis" (Latin for "to stand by decisions") means that decisions by higher courts bind lower courts, and future decisions of the same court, to assure that similar cases reach similar results. In contrast, in "civil law" systems, legislative statutes are typically more detailed, and judicial decisions are shorter and less detailed, because the judge or barrister is only writing to decide the single case, rather than to set out reasoning that will guide future courts.

Common law originated from England and has been inherited by almost every country once tied to the British Empire (except Malta, Scotland, the U.S. state of Louisiana, and the Canadian province of Quebec). In medieval England, the Norman conquest the law varied-shire-to-shire, based on disparate tribal customs. The concept of a "common law" developed during the reign of Henry II during the late 12th century, when Henry appointed judges that had authority to create an institutionalized and unified system of law "common" to the country. The next major step in the evolution of the common law came when King John was forced by his barons to sign a document limiting his authority to pass laws. This "great charter" or "Magna Carta" of 1215 also required that the King's entourage of judges hold their courts and judgments at "a certain place" rather than dispensing autocratic justice in unpredictable places about the country. A concentrated and elite group of judges acquired a dominant role in law-making under this system, and compared to its European counterparts the English judiciary became highly centralized. In 1297, for instance, while the highest court in France had fifty-one judges, the English Court of Common Pleas had five. This powerful and tight-knit judiciary gave rise to a systematized process of developing common law.

However, the system became overly systematized—overly rigid and inflexible. As a result, as time went on, increasing numbers of citizens petitioned the King to override the common law, and on the King's behalf the Lord Chancellor gave judgment to do what was equitable in a case. From the time of Sir Thomas More, the first lawyer to be appointed as Lord Chancellor, a systematic body of equity grew up alongside the rigid common law, and developed its own Court of Chancery. At first, equity was often criticized as erratic, that it varied according to the length of the Chancellor's foot. Over time, courts of equity developed solid principles, especially under Lord Eldon. In the 19th century in England, and in 1937 in the U.S., the two systems were merged.

In developing the common law, academic writings have always played an important part, both to collect overarching principles from dispersed case law, and to argue for change. William Blackstone, from around 1760, was the first scholar to collect, describe, and teach the common law. But merely in describing, scholars who sought explanations and underlying structures slowly changed the way the law actually worked.

Religious law is explicitly based on religious precepts. Examples include the Jewish Halakha and Islamic Sharia—both of which translate as the "path to follow"—while Christian canon law also survives in some church communities. Often the implication of religion for law is unalterability, because the word of God cannot be amended or legislated against by judges or governments. However a thorough and detailed legal system generally requires human elaboration. For instance, the Quran has some law, and it acts as a source of further law through interpretation, "Qiyas" (reasoning by analogy), "Ijma" (consensus) and precedent. This is mainly contained in a body of law and jurisprudence known as Sharia and Fiqh respectively. Another example is the Torah or Old Testament, in the Pentateuch or Five Books of Moses. This contains the basic code of Jewish law, which some Israeli communities choose to use. The Halakha is a code of Jewish law which summarises some of the Talmud's interpretations. Nevertheless, Israeli law allows litigants to use religious laws only if they choose. Canon law is only in use by members of the Catholic Church, the Eastern Orthodox Church and the Anglican Communion.

Canon law (from Greek "kanon", a 'straight measuring rod, ruler') is a set of ordinances and regulations made by ecclesiastical authority (Church leadership), for the government of a Christian organization or church and its members. It is the internal ecclesiastical law governing the Catholic Church (both the Latin Church and the Eastern Catholic Churches), the Eastern Orthodox and Oriental Orthodox churches, and the individual national churches within the Anglican Communion. The way that such church law is legislated, interpreted and at times adjudicated varies widely among these three bodies of churches. In all three traditions, a canon was originally a rule adopted by a church council; these canons formed the foundation of canon law.

The Catholic Church has the oldest continuously functioning legal system in the western world, predating the evolution of modern European civil law and common law systems. The 1983 Code of Canon Law governs the Latin Church "sui juris". The Eastern Catholic Churches, which developed different disciplines and practices, are governed by the "Code of Canons of the Eastern Churches". The canon law of the Catholic Church influenced the common law during the medieval period through its preservation of Roman law doctrine such as the presumption of innocence.

Until the 18th century, Sharia law was practiced throughout the Muslim world in a non-codified form, with the Ottoman Empire's Mecelle code in the 19th century being a first attempt at codifying elements of Sharia law. Since the mid-1940s, efforts have been made, in country after country, to bring Sharia law more into line with modern conditions and conceptions. In modern times, the legal systems of many Muslim countries draw upon both civil and common law traditions as well as Islamic law and custom. The constitutions of certain Muslim states, such as Egypt and Afghanistan, recognise Islam as the religion of the state, obliging legislature to adhere to Sharia. Saudi Arabia recognises Quran as its constitution, and is governed on the basis of Islamic law. Iran has also witnessed a reiteration of Islamic law into its legal system after 1979. During the last few decades, one of the fundamental features of the movement of Islamic resurgence has been the call to restore the Sharia, which has generated a vast amount of literature and affected world politics.

The main institutions of law in industrialised countries are independent courts, representative parliaments, an accountable executive, the military and police, bureaucratic organisation, the legal profession and civil society itself. John Locke, in his "Two Treatises of Government", and Baron de Montesquieu in "The Spirit of the Laws", advocated for a separation of powers between the political, legislature and executive bodies. Their principle was that no person should be able to usurp all powers of the state, in contrast to the absolutist theory of Thomas Hobbes' "Leviathan".

Max Weber and others reshaped thinking on the extension of state. Modern military, policing and bureaucratic power over ordinary citizens' daily lives pose special problems for accountability that earlier writers such as Locke or Montesquieu could not have foreseen. The custom and practice of the legal profession is an important part of people's access to justice, whilst civil society is a term used to refer to the social institutions, communities and partnerships that form law's political basis.

A judiciary is a number of judges mediating disputes to determine outcome. Most countries have systems of appeal courts, answering up to a supreme legal authority. In the United States, this authority is the Supreme Court; in Australia, the High Court; in the UK, the Supreme Court; in Germany, the "Bundesverfassungsgericht"; and in France, the "Cour de Cassation". For most European countries the European Court of Justice in Luxembourg can overrule national law, when EU law is relevant. The European Court of Human Rights in Strasbourg allows citizens of the Council of Europe member states to bring cases relating to human rights issues before it.
Some countries allow their highest judicial authority to overrule legislation they determine to be unconstitutional. For example, in "Brown v. Board of Education", the United States Supreme Court nullified many state statutes that had established racially segregated schools, finding such statutes to be incompatible with the Fourteenth Amendment to the United States Constitution.

A judiciary is theoretically bound by the constitution, just as all other government bodies are. In most countries judges may only interpret the constitution and all other laws. But in common law countries, where matters are not constitutional, the judiciary may also create law under the doctrine of precedent. The UK, Finland and New Zealand assert the ideal of parliamentary sovereignty, whereby the unelected judiciary may not overturn law passed by a democratic legislature.

In communist states, such as China, the courts are often regarded as parts of the executive, or subservient to the legislature; governmental institutions and actors exert thus various forms of influence on the judiciary. In Muslim countries, courts often examine whether state laws adhere to the Sharia: the Supreme Constitutional Court of Egypt may invalidate such laws, and in Iran the Guardian Council ensures the compatibility of the legislation with the "criteria of Islam".

Prominent examples of legislatures are the Houses of Parliament in London, the Congress in Washington D.C., the Bundestag in Berlin, the Duma in Moscow, the Parlamento Italiano in Rome and the "Assemblée nationale" in Paris. By the principle of representative government people vote for politicians to carry out "their" wishes. Although countries like Israel, Greece, Sweden and China are unicameral, most countries are bicameral, meaning they have two separately appointed legislative houses.

In the 'lower house' politicians are elected to represent smaller constituencies. The 'upper house' is usually elected to represent states in a federal system (as in Australia, Germany or the United States) or different voting configuration in a unitary system (as in France). In the UK the upper house is appointed by the government as a house of review. One criticism of bicameral systems with two elected chambers is that the upper and lower houses may simply mirror one another. The traditional justification of bicameralism is that an upper chamber acts as a house of review. This can minimise arbitrariness and injustice in governmental action.

To pass legislation, a majority of the members of a legislature must vote for a bill (proposed law) in each house. Normally there will be several readings and amendments proposed by the different political factions. If a country has an entrenched constitution, a special majority for changes to the constitution may be required, making changes to the law more difficult. A government usually leads the process, which can be formed from Members of Parliament (e.g. the UK or Germany). However, in a presidential system, the government is usually formed by an executive and his or her appointed cabinet officials (e.g. the United States or Brazil).

The executive in a legal system serves as the centre of political authority of the State. In a parliamentary system, as with Britain, Italy, Germany, India, and Japan, the executive is known as the cabinet, and composed of members of the legislature. The executive is led by the head of government, whose office holds power under the confidence of the legislature. Because popular elections appoint political parties to govern, the leader of a party can change in between elections.

The head of state is apart from the executive, and symbolically enacts laws and acts as representative of the nation. Examples include the President of Germany (appointed by members of federal and state legislatures), the Queen of the United Kingdom (an hereditary office), and the President of Austria (elected by popular vote). The other important model is the presidential system, found in the United States and in Brazil. In presidential systems, the executive acts as both head of state and head of government, and has power to appoint an unelected cabinet. Under a presidential system, the executive branch is separate from the legislature to which it is not accountable.

Although the role of the executive varies from country to country, usually it will propose the majority of legislation, and propose government agenda. In presidential systems, the executive often has the power to veto legislation. Most executives in both systems are responsible for foreign relations, the military and police, and the bureaucracy. Ministers or other officials head a country's public offices, such as a foreign ministry or defence ministry. The election of a different executive is therefore capable of revolutionising an entire country's approach to government.

While military organisations have existed as long as government itself, the idea of a standing police force is a relatively modern concept. For example, Medieval England's system of traveling criminal courts, or assizes, used show trials and public executions to instill communities with fear to maintain control. The first modern police were probably those in 17th-century Paris, in the court of Louis XIV, although the Paris Prefecture of Police claim they were the world's first uniformed policemen.

Max Weber famously argued that the state is that which controls the monopoly on the legitimate use of force. The military and police carry out enforcement at the request of the government or the courts. The term failed state refers to states that cannot implement or enforce policies; their police and military no longer control security and order and society moves into anarchy, the absence of government.

The etymology of "bureaucracy" derives from the French word for "office" ("bureau") and the Ancient Greek for word "power" ("kratos"). Like the military and police, a legal system's government servants and bodies that make up its bureaucracy carry out the directives of the executive. One of the earliest references to the concept was made by Baron de Grimm, a German author who lived in France. In 1765 he wrote,

The real spirit of the laws in France is that bureaucracy of which the late Monsieur de Gournay used to complain so greatly; here the offices, clerks, secretaries, inspectors and "intendants" are not appointed to benefit the public interest, indeed the public interest appears to have been established so that offices might exist.

Cynicism over "officialdom" is still common, and the workings of public servants is typically contrasted to private enterprise motivated by profit. In fact private companies, especially large ones, also have bureaucracies. Negative perceptions of "red tape" aside, public services such as schooling, health care, policing or public transport are considered a crucial state function making public bureaucratic action the locus of government power.

Writing in the early 20th century, Max Weber believed that a definitive feature of a developed state had come to be its bureaucratic support. Weber wrote that the typical characteristics of modern bureaucracy are that officials define its mission, the scope of work is bound by rules, and management is composed of career experts who manage top down, communicating through writing and binding public servants' discretion with rules.

A corollary of the rule of law is the existence of a legal profession sufficiently autonomous to invoke the authority of the independent judiciary; the right to assistance of a barrister in a court proceeding emanates from this corollary—in England the function of barrister or advocate is distinguished from legal counselor. As the European Court of Human Rights has stated, the law should be adequately accessible to everyone and people should be able to foresee how the law affects them.

In order to maintain professionalism, the practice of law is typically overseen by either a government or independent regulating body such as a bar association, bar council or law society. Modern lawyers achieve distinct professional identity through specified legal procedures (e.g. successfully passing a qualifying examination), are required by law to have a special qualification (a legal education earning the student a Bachelor of Laws, a Bachelor of Civil Law, or a Juris Doctor degree. Higher academic degrees may also be pursued. Examples include a Master of Laws, a Master of Legal Studies, a Bar Professional Training Course or a Doctor of Laws.), and are constituted in office by legal forms of appointment (being admitted to the bar). There are few titles of respect to signify famous lawyers, such as Esquire, to indicate barristers of greater dignity, and Doctor of law, to indicate a person who obtained a PhD in Law.

Many Muslim countries have developed similar rules about legal education and the legal profession, but some still allow lawyers with training in traditional Islamic law to practice law before personal status law courts. In China and other developing countries there are not sufficient professionally trained people to staff the existing judicial systems, and, accordingly, formal standards are more relaxed.

Once accredited, a lawyer will often work in a law firm, in a chambers as a sole practitioner, in a government post or in a private corporation as an internal counsel. In addition a lawyer may become a legal researcher who provides on-demand legal research through a library, a commercial service or freelance work. Many people trained in law put their skills to use outside the legal field entirely.

Significant to the practice of law in the common law tradition is the legal research to determine the current state of the law. This usually entails exploring case-law reports, legal periodicals and legislation. Law practice also involves drafting documents such as court pleadings, persuasive briefs, contracts, or wills and trusts. Negotiation and dispute resolution skills (including ADR techniques) are also important to legal practice, depending on the field.

The Classical republican concept of "civil society" dates back to Hobbes and Locke. Locke saw civil society as people who have "a common established law and judicature to appeal to, with authority to decide controversies between them." German philosopher Georg Wilhelm Friedrich Hegel distinguished the "state" from "civil society" ("bürgerliche Gesellschaft") in "Elements of the Philosophy of Right".

Hegel believed that civil society and the state were polar opposites, within the scheme of his dialectic theory of history. The modern dipole state–civil society was reproduced in the theories of Alexis de Tocqueville and Karl Marx. Nowadays in post-modern theory civil society is necessarily a source of law, by being the basis from which people form opinions and lobby for what they believe law should be. As Australian barrister and author Geoffrey Robertson QC wrote of international law,

... one of its primary modern sources is found in the responses of ordinary men and women, and of the non-governmental organizations which many of them support, to the human rights abuses they see on the television screen in their living rooms.

Freedom of speech, freedom of association and many other individual rights allow people to gather, discuss, criticise and hold to account their governments, from which the basis of a deliberative democracy is formed. The more people are involved with, concerned by and capable of changing how political power is exercised over their lives, the more acceptable and legitimate the law becomes to the people. The most familiar institutions of civil society include economic markets, profit-oriented firms, families, trade unions, hospitals, universities, schools, charities, debating clubs, non-governmental organisations, neighbourhoods, churches, and religious associations.
All legal systems deal with the same basic issues, but jurisdictions categorise and identify its legal subjects in different ways. A common distinction is that between "public law" (a term related closely to the state, and including constitutional, administrative and criminal law), and "private law" (which covers contract, tort and property). In civil law systems, contract and tort fall under a general law of obligations, while trusts law is dealt with under statutory regimes or international conventions. International, constitutional and administrative law, criminal law, contract, tort, property law and trusts are regarded as the "traditional core subjects", although there are many further disciplines.

International law can refer to three things: public international law, private international law or conflict of laws and the law of supranational organisations.

Constitutional and administrative law govern the affairs of the state. Constitutional law concerns both the relationships between the executive, legislature and judiciary and the human rights or civil liberties of individuals against the state. Most jurisdictions, like the United States and France, have a single codified constitution with a bill of rights. A few, like the United Kingdom, have no such document. A "constitution" is simply those laws which constitute the body politic, from statute, case law and convention. A case named "Entick v Carrington" illustrates a constitutional principle deriving from the common law. Mr Entick's house was searched and ransacked by Sheriff Carrington. When Mr Entick complained in court, Sheriff Carrington argued that a warrant from a Government minister, the Earl of Halifax, was valid authority. However, there was no written statutory provision or court authority. The leading judge, Lord Camden, stated that,

The great end, for which men entered into society, was to secure their property. That right is preserved sacred and incommunicable in all instances, where it has not been taken away or abridged by some public law for the good of the whole ... If no excuse can be found or produced, the silence of the books is an authority against the defendant, and the plaintiff must have judgment.

The fundamental constitutional principle, inspired by John Locke, holds that the individual can do anything except that which is forbidden by law, and the state may do nothing except that which is authorised by law. Administrative law is the chief method for people to hold state bodies to account. People can sue an agency, local council, public service, or government ministry for judicial review of actions or decisions, to ensure that they comply with the law, and that the government entity observed required procedure. The first specialist administrative court was the "Conseil d'État" set up in 1799, as Napoleon assumed power in France.

Criminal law, also known as penal law, pertains to crimes and punishment. It thus regulates the definition of and penalties for offences found to have a sufficiently deleterious social impact but, in itself, makes no moral judgment on an offender nor imposes restrictions on society that physically prevent people from committing a crime in the first place. Investigating, apprehending, charging, and trying suspected offenders is regulated by the law of criminal procedure. The paradigm case of a crime lies in the proof, beyond reasonable doubt, that a person is guilty of two things. First, the accused must commit an act which is deemed by society to be criminal, or "actus reus" (guilty act). Second, the accused must have the requisite malicious intent to do a criminal act, or "mens rea" (guilty mind). However, for so called "strict liability" crimes, an "actus reus" is enough. Criminal systems of the civil law tradition distinguish between intention in the broad sense ("dolus directus" and "dolus eventualis"), and negligence. Negligence does not carry criminal responsibility unless a particular crime provides for its punishment.
Examples of crimes include murder, assault, fraud and theft. In exceptional circumstances defences can apply to specific acts, such as killing in self defence, or pleading insanity. Another example is in the 19th-century English case of "R v Dudley and Stephens", which tested a defence of "necessity". The "Mignonette", sailing from Southampton to Sydney, sank. Three crew members and Richard Parker, a 17-year-old cabin boy, were stranded on a raft. They were starving and the cabin boy was close to death. Driven to extreme hunger, the crew killed and ate the cabin boy. The crew survived and were rescued, but put on trial for murder. They argued it was necessary to kill the cabin boy to preserve their own lives. Lord Coleridge, expressing immense disapproval, ruled, "to preserve one's life is generally speaking a duty, but it may be the plainest and the highest duty to sacrifice it." The men were sentenced to hang, but public opinion was overwhelmingly supportive of the crew's right to preserve their own lives. In the end, the Crown commuted their sentences to six months in jail.

Criminal law offences are viewed as offences against not just individual victims, but the community as well. The state, usually with the help of police, takes the lead in prosecution, which is why in common law countries cases are cited as ""The People" v ..." or ""R" (for Rex or Regina) v ...". Also, lay juries are often used to determine the guilt of defendants on points of fact: juries cannot change legal rules. Some developed countries still condone capital punishment for criminal activity, but the normal punishment for a crime will be imprisonment, fines, state supervision (such as probation), or community service. Modern criminal law has been affected considerably by the social sciences, especially with respect to sentencing, legal research, legislation, and rehabilitation. On the international field, 111 countries are members of the International Criminal Court, which was established to try people for crimes against humanity.

Contract law concerns enforceable promises, and can be summed up in the Latin phrase "pacta sunt servanda" (agreements must be kept). In common law jurisdictions, three key elements to the creation of a contract are necessary: offer and acceptance, consideration and the intention to create legal relations. In "Carlill v Carbolic Smoke Ball Company" a medical firm advertised that its new wonder drug, the smokeball, would cure people's flu, and if it did not, the buyers would get £100. Many people sued for their £100 when the drug did not work. Fearing bankruptcy, Carbolic argued the advert was not to be taken as a serious, legally binding offer. It was an invitation to treat, mere puffery, a gimmick. But the Court of Appeal held that to a reasonable man Carbolic had made a serious offer, accentuated by their reassuring statement, "£1000 is deposited". Equally, people had given good consideration for the offer by going to the "distinct inconvenience" of using a faulty product. "Read the advertisement how you will, and twist it about as you will", said Lord Justice Lindley, "here is a distinct promise expressed in language which is perfectly unmistakable".

"Consideration" indicates the fact that all parties to a contract have exchanged something of value. Some common law systems, including Australia, are moving away from the idea of consideration as a requirement. The idea of estoppel or "culpa in contrahendo", can be used to create obligations during pre-contractual negotiations. In civil law jurisdictions, consideration is not required for a contract to be binding. In France, an ordinary contract is said to form simply on the basis of a "meeting of the minds" or a "concurrence of wills". Germany has a special approach to contracts, which ties into property law. Their 'abstraction principle' ("Abstraktionsprinzip") means that the personal obligation of contract forms separately from the title of property being conferred. When contracts are invalidated for some reason (e.g. a car buyer is so drunk that he lacks legal capacity to contract) the contractual obligation to pay can be invalidated separately from the proprietary title of the car. Unjust enrichment law, rather than contract law, is then used to restore title to the rightful owner.

Torts, sometimes called delicts, are civil wrongs. To have acted tortiously, one must have breached a duty to another person, or infringed some pre-existing legal right. A simple example might be accidentally hitting someone with a cricket ball. Under the law of negligence, the most common form of tort, the injured party could potentially claim compensation for their injuries from the party responsible. The principles of negligence are illustrated by "Donoghue v Stevenson". A friend of Mrs Donoghue ordered an opaque bottle of ginger beer (intended for the consumption of Mrs Donoghue) in a café in Paisley. Having consumed half of it, Mrs Donoghue poured the remainder into a tumbler. The decomposing remains of a snail floated out. She claimed to have suffered from shock, fell ill with gastroenteritis and sued the manufacturer for carelessly allowing the drink to be contaminated. The House of Lords decided that the manufacturer was liable for Mrs Donoghue's illness. Lord Atkin took a distinctly moral approach, and said,

The liability for negligence ... is no doubt based upon a general public sentiment of moral wrongdoing for which the offender must pay ... The rule that you are to love your neighbour becomes in law, you must not injure your neighbour; and the lawyer's question, Who is my neighbour? receives a restricted reply. You must take reasonable care to avoid acts or omissions which you can reasonably foresee would be likely to injure your neighbour.

This became the basis for the four principles of negligence: (1) Mr Stevenson owed Mrs Donoghue a duty of care to provide safe drinks (2) he breached his duty of care (3) the harm would not have occurred but for his breach and (4) his act was the proximate cause of her harm. Another example of tort might be a neighbour making excessively loud noises with machinery on his property. Under a nuisance claim the noise could be stopped. Torts can also involve intentional acts, such as assault, battery or trespass. A better known tort is defamation, which occurs, for example, when a newspaper makes unsupportable allegations that damage a politician's reputation. More infamous are economic torts, which form the basis of labour law in some countries by making trade unions liable for strikes, when statute does not provide immunity.

Property law governs ownership and possession. Real property, sometimes called 'real estate', refers to ownership of land and things attached to it. Personal property, refers to everything else; movable objects, such as computers, cars, jewelry or intangible rights, such as stocks and shares. A right "in rem" is a right to a specific piece of property, contrasting to a right "in personam" which allows compensation for a loss, but not a particular thing back. Land law forms the basis for most kinds of property law, and is the most complex. It concerns mortgages, rental agreements, licences, covenants, easements and the statutory systems for land registration. Regulations on the use of personal property fall under intellectual property, company law, trusts and commercial law. An example of a basic case of most property law is "Armory v Delamirie" [1722]. A chimney sweep's boy found a jewel encrusted with precious stones. He took it to a goldsmith to have it valued. The goldsmith's apprentice looked at it, sneakily removed the stones, told the boy it was worth three halfpence and that he would buy it. The boy said he would prefer the jewel back, so the apprentice gave it to him, but without the stones. The boy sued the goldsmith for his apprentice's attempt to cheat him. Lord Chief Justice Pratt ruled that even though the boy could not be said to own the jewel, he should be considered the rightful keeper ("finders keepers") until the original owner is found. In fact the apprentice and the boy both had a right of "possession" in the jewel (a technical concept, meaning evidence that something "could" belong to someone), but the boy's possessory interest was considered better, because it could be shown to be first in time. Possession may be nine tenths of the law, but not all.

This case is used to support the view of property in common law jurisdictions, that the person who can show the best claim to a piece of property, against any contesting party, is the owner. By contrast, the classic civil law approach to property, propounded by Friedrich Carl von Savigny, is that it is a right good against the world. Obligations, like contracts and torts, are conceptualised as rights good between individuals. The idea of property raises many further philosophical and political issues. Locke argued that our "lives, liberties and estates" are our property because we own our bodies and mix our labour with our surroundings.

Equity is a body of rules that developed in England separately from the "common law". The common law was administered by judges and barristers. The Lord Chancellor on the other hand, as the King's keeper of conscience, could overrule the judge-made law if he thought it equitable to do so. This meant equity came to operate more through principles than rigid rules. For instance, whereas neither the common law nor civil law systems allow people to split the ownership from the control of one piece of property, equity allows this through an arrangement known as a 'trust'. 'Trustees' control property, whereas the 'beneficial' (or 'equitable') ownership of trust property is held by people known as 'beneficiaries'. Trustees owe duties to their beneficiaries to take good care of the entrusted property. In the early case of "Keech v Sandford" [1722] a child had inherited the lease on a market in Romford, London. Mr Sandford was entrusted to look after this property until the child matured. But before then, the lease expired. The landlord had (apparently) told Mr Sandford that he did not want the child to have the renewed lease. Yet the landlord was happy (apparently) to give Mr Sandford the opportunity of the lease instead. Mr Sandford took it. When the child (now Mr Keech) grew up, he sued Mr Sandford for the profit that he had been making by getting the market's lease. Mr Sandford was meant to be trusted, but he put himself in a position of conflict of interest. The Lord Chancellor, Lord King, agreed and ordered Mr Sandford should disgorge his profits. He wrote,

Of course, Lord King LC was worried that trustees might exploit opportunities to use trust property for themselves instead of looking after it. Business speculators using trusts had just recently caused a stock market crash. Strict duties for trustees made their way into company law and were applied to directors and chief executive officers. Another example of a trustee's duty might be to invest property wisely or sell it. This is especially the case for pension funds, the most important form of trust, where investors are trustees for people's savings until retirement. But trusts can also be set up for charitable purposes, famous examples being the British Museum or the Rockefeller Foundation.

Law spreads far beyond the core subjects into virtually every area of life. Three categories are presented for convenience, though the subjects intertwine and overlap.











</doc>
<doc id="56215612" url="https://en.wikipedia.org/wiki?curid=56215612" title="Pseudolaw">
Pseudolaw

Pseudolaw consists of statements, beliefs, or practices that are claimed to be based on accepted law or legal doctrine, but which deviate significantly from most conventional understandings of law and jurisprudence, or which originate from non-existent statutes or legal principles the advocate or adherent of incorrectly believes exist. It is sometimes referred to as "legalistic gibberish". The more extreme examples have been classified as paper terrorism.

Followers of such ideologies can cause problems for courts and government administrators by filing unusual applications that are difficult to process. Courts in Canada refer to such arguments as Organized Pseudolegal Commercial Arguments, and have called them frivolous and vexatious. There is no recorded instance of such tactics being upheld in a court of law.

Common among pseudolegal beliefs is a belief that one is partially or fully sovereign from the country in which they live, and believe that no laws, or only certain laws, apply to them. Groups espousing such pseudolegal beliefs include freemen on the land and the sovereign citizen movement. Some believe that their state itself is illegitimate, such as Reichsbürgerbewegung.

Also under the umbrella of pseudolegal arguments are conspiracy theorists who believe there is a secret parallel legal system that one can access through certain means, like using a secret phrase or by placing stamps on the right place on documents. For example, the redemption movement believes that a secret fund is created for everyone at birth by the government, and that a procedure exists to "redeem" or reclaim money from this fund. See tax protester conspiracy arguments for a discussion of these beliefs related to tax law. Many of these revolve around the "legal name fraud" movement, which believes that birth certificates give the state legal ownership of a personal name and refusing to use this name therefore removes oneself from a court's jurisdiction. Various groups advocate that one can avoid this state ownership by distinguishing between capitalized and non-capitalized versions of one's name, or by adding punctuation to one's name. See strawman theory (also known as the capital letters argument) for more information.



</doc>
<doc id="58947778" url="https://en.wikipedia.org/wiki?curid=58947778" title="Temporary law">
Temporary law

Temporary laws, temporary legislation or sunset legislation are laws whose duration is limited at the time of enactment. Temporary laws are often used to adapt for unusual or peculiar situations. Clauses limiting the duration of such laws are often called "sunset" clauses.

Temporary laws are commonly given temporal validity by the inclusion of an expiration date at which the law ceases to be in effect unless it is extended. But a law can also acquire temporal status by stipulating that it only applies to a certain event. For example, only to the next election or only for victims of a named catastrophe.

Temporary laws are favored by adherents of "Experimentalist governance" because it allows policy makers to conduct experiments and evaluate the effects of introducing legislation.

Temporary laws are often easier to pass since they last for a shorter time.

Temporary law should not be confused with "ratione temporis" or "temporal jurisdiction" which refers to the jurisdiction of a "court" of law in relation to the passage of time. 

Some examples of temporary laws:


</doc>
<doc id="25389252" url="https://en.wikipedia.org/wiki?curid=25389252" title="Index of law articles">
Index of law articles

This collection of lists of law topics collects the names of topics related to law. Everything related to law, even quite remotely, should be included on the alphabetical list, and on the appropriate topic lists. All links on topical lists should also appear in the main alphabetical listing. The process of creating lists is ongoing – these lists are neither complete nor up-to-date – if you see an article that should be listed but is not (or one that shouldn't be listed as legal but is), please update the lists accordingly. You may also want to include talk page banners on the relevant pages.

"a posteriori" –
"ab extra" –
"ab initio" –
Abandoned property –
Abandonment (legal) –
Abduction –
Abet –
Abeyance –
Abolitionism in the United States –
Abolitionism –
Abortion –
Abortion, legal and moral issues –
Abrogate –
Abstention doctrine –
Abstract –
Abstract of judgment –
Abstract of title –
Abuse of discretion –
Abuse of process –
Abut –
Acceleration clause –
Accept –
Acceptance –
Acceptance of service –
Accessory –
Accommodation –
Accomplice –
Accord and satisfaction –
Account stated –
Accountability –
Accounting period –
Accounting reference date –
Accounts payable –
Accounts receivable –
Accrue –
Accusation –
Accused –
Acknowledge –
Acknowledgement of service –
Acknowledgment –
Acquis –
Acquit –
Acquittal –
Act of God –
Act of Parliament –
Action –
Actionable –
Actual controversy –
Actual malice –
Actual notice –
"actus reus" –
"ad colligenda bona" –
"ad hoc" –
"ad idem" –
"ad infinitum" –
"ad litem" –
"ad quod damnum" –
"ad seriatim" –
"ad valorem" –
Addendum –
Adeem –
Ademption –
Adequate remedy –
Adhesion contract –
Adjourn –
Adjournment sine die –
Adjournment in contemplation of dismissal –
Adjudication –
Adjusted basis –
Adjuster –
Administer –
Administration –
administration order –
Administrative hearing –
Administrative law –
Administrative law judge –
Administrative Procedure Act (Japan) –
Administrative Procedure Act (United States) –
Administrator –
Administrator –
Admiralty –
Admiralty actions –
Admiralty court –
Admiralty law –
Admissible evidence –
Admission against interest –
Admission of evidence –
Admission (law) –
Admission to bail –
Admission to the bar –
Adopt –
Adoption –
Adultery –
Advance directive –
Adversary system –
Adverse –
Adverse interest –
Adverse party –
Adverse possession –
Adverse witness –
Advisory opinion –
Advocate –
Affiant –
Affidavit –
Affirm –
Affirmative action –
Affirmative defense –
Affix –
Affreightment –
After-acquired property –
Age discrimination –
Age of consent –
Age of majority –
Agency –
Agency agreement –
Agent –
Agent for acceptance of service –
Aggravated assault –
Agreed statement –
Aid and abet –
Aleatory –
Alias –
Alibi –
Alien –
Alienation –
Alienation of affections –
Alimony –
All the estate I own –
Allegation –
Allege –
Allocation questionnaire –
Allocatur –
Allocution –
Allodial –
Alluvion –
Alodium –
"alter ego" –
Alternate director –
Alternative dispute resolution –
Alternative Minimum Tax –
Alternative pleading –
ALWD Citation Manual –
Ambiguity –
Ambulance chasing –
Amelioration Act 1798 –
Amended complaint –
Amended pleading –
American Academy of Appellate Lawyers –
American Arbitration Association –
American Bar Association –
American Civil Liberties Union –
American Civil Rights Movement –
American Declaration of the Rights and Duties of Man –
American Depositary Receipt –
American Law Institute –
"amicus curiae" –
Amnesty –
Amnesty International –
Amortization –
An eye for an eye –
Ancillary administration –
Ancillary jurisdiction –
Ancillary relief –
Animal rights –
"animus nocendi" –
"Animus revertendi" –
annual general meeting –
Annul –
Annulment –
Anomie –
Answer (law) –
Antecedent (law) –
Antenuptial (prenuptial) agreement –
"Antejuramentum" –
Anticipatory breach –
Antidisestablishmentarianism –
Antinomianism –
Antitrust –
Antitrust laws –
Apartheid –
Apparent authority –
Appeal –
Appeal bond –
Appeals court –
Appear –
Appellant –
Appellate court –
Appellate review –
Appellee –
Appraiser –
Appreciate –
Appreciation –
Apprenticeship 
Approach the bench 
Appurtenances 
Appurtenant 
Arbitrary 
Arbitration –
Arbitration award –
Arbitrator –
"arguendo" –
Argumentative –
Arm's length –
Arraign –
Arraignment –
Arrears –
Arrest –
Arrest warrant –
Arson –
Article I and Article III tribunals –
Articles of Association –
Articles of impeachment –
Articles of Incorporation –
Articles of War –
As is –
Asharite –
Assault –
Asset –
Assignment (law) –
Assigned risk –
Assignee –
Assignment for benefit of creditors –
Assigns –
Assisted person –
Assize Court –
Associate justice –
Association –
Assumption of risk –
Asylum and Immigration Tribunal –
Asylum seeker –
At will –
At will employment –
Attachment –
Attachment of earnings –
Attempt –
Attestation clause –
Attorney at law (or attorney-at-law) –
Attorney general –
Attorney of record –
Attorney's advertising –
Attorney's fee –
Attorney's work product –
Attorney–client privilege –
Attorney-in-fact –
Attractive nuisance doctrine –
Audit –
Auditor –
Australian Constitution –
Australian Constitutional history –
Australian copyright law –
Authorised share capital –
Authoritarianism –
Authorities –
Authority –
Authorize –
Automatic stay –
Autrefois acquit –
Avulsion –
Ayatollah

B.C.L. –
Babylonian law –
Bachelor of Civil Law –
Bachelor of Laws –
Bachelor of Legal Letters –
Back-to-back life sentences –
Bad debt –
Bad faith –
Bail –
Bail bond –
Bail bondsman –
Bail schedule –
Bailee –
Bailiff –
Bailment –
Bailor –
Bait and switch –
Balance due –
Balance sheet –
Ban –
Bank –
Bankrupt –
Bankruptcy –
Bankruptcy court –
Bankruptcy proceedings –
Bankruptcy remote –
Bar –
Bar association –
Bar council –
Bar examination –
Bare trust –
Bargain and sale deed –
Barratry (admiralty law) –
Barratry (common law) –
Barrister –
Basic Law of various jurisdictions –
Battery –
Beach bum trust provision –
Bearer paper –
Belief –
Bench –
Bench memorandum –
Bench trial –
Bench warrant –
Beneficial interest –
Beneficial use –
Beneficiary –
Beneficiary (trust) –
Benefit of counsel –
Bequeath –
Bequest –
Berne three-step test –
Best evidence rule –
Best Interests of the Child –
Bestiality –
Beyond a reasonable doubt –
BFP –
Bias –
Bifurcate –
Bifurcation –
Bigamy –
Bilateral contract –
Bill –
Bill of attainder –
Bill of costs –
Bill of exchange –
Bill of indictment –
Bill of lading –
Bill of particulars –
Bill of rights –
Bill of sale –
Bind over –
Bind over for sentence –
Binding arbitration –
Bioethics –
Black's Law Dictionary –
Blackmail –
Blank endorsement –
Blood libel –
Blue law –
Blue laws –
Blue ribbon jury –
Blue Sky Laws –
Bluebook –
Board of directors –
"bona fide" –
Bona fide purchaser –
"bona vacantia" –
Bond –
Bond for deed –
Booby trap –
Book account –
Book value –
Bootleg recording –
Border control –
Bottomry –
Boycott –
Breach of contract –
Breach of promise –
Breach of the peace –
Breach of warranty –
Breaking and entering –
Bribery –
Bride price –
Brief –
British constitution –
British constitutional law –
British nationality law –
Broker –
Brought to trial –
Building and loan –
Bulk sale –
Bulk sales acts –
Bulk transfer –
Burden –
Burden of proof –
Burgage –
Burglary –
Business –
Business ethics –
Business invitee –
But for rule –
Buy-sell agreement –
Bylaw –
Bylaws –
Bypass trust

Cadastral map –
"cadit quaestio" –
Calendar call –
Caliphate –
Call to the bar –
Calumny –
Campaign finance reform –
Canadian Bill of Rights –
Canadian Charter of Rights and Freedoms –
Caning –
Canon –
Canon law –
Cape (writ) –
"capital" –
Capital account –
Capital assets –
Capital expenditure –
Capital gain –
Capital gain tax –
Capital gains –
Capital investment –
Capital loss –
Capital offense –
Capital punishment –
Capital punishment in the United States –
Capital stock –
Capitalized value –
Capricious –
Carjacking –
Carnal knowledge –
Carrier –
Carrying for hire –
Cartel –
Case –
Case conference –
Case law –
Case law in the United States –
Case number –
Case of first impression –
Case-based reasoning –
Cashier's check –
Casualty insurance –
Casualty loss –
Casuistry –
Catechism –
Categorical Imperative –
Catholic Emancipation –
"cause" –
Cause of action –
"caveat emptor –
Cease and desist order –
Censorship –
Certificate of deposit –
Certificate of incorporation –
Certificate of legal aid costs –
Certificate of title –
Certified check –
"certiorari" –
Writ of Certiorari –
Cessate –
Cestui que trust –
Cestui que use –
"ceteris paribus" –
Chain of title –
Chairman –
Challenge for cause –
Champerty –
Chancellor –
Chancery –
Chancery division –
Change of venue –
Character witness –
Charge –
Charging lien –
Charging order –
Charitable contribution –
Charitable organization –
Charitable remainder trust –
Charitable trust –
Charter –
Chattel –
Chattel mortgage-- Checks and balances –
Cheque –
Chief Justice –
Chief Justice of Canada –
Chief Justice of the United States –
Child –
Child abandonment –
Child abuse –
Child custody –
Child endangerment –
Child neglect –
Child pornography –
Child sexual abuse –
Child support –
Chinese law –
Churning –
Circuit courts –
Circumcision –
Circumstantial evidence –
Citation –
Cite –
Citizen –
Citizen's dividend –
Citizenship –
Civil action –
Civil and social disobedience –
Civil calendar –
Civil code –
Civil Code of Quebec –
Civil commitment –
Civil death –
Civil disobedience –
Civil disorder –
Civil justice reforms –
civil law –
Civil law notary –
Civil liability –
Civil liberties –
Civil penalties –
Civil procedure –
Civil rights –
Civil union –
Claim against a governmental agency –
Claim against an estate –
Claim form –
Claim in bankruptcy –
Claimant –
Class –
Class action –
Class action suit –
Clean hands doctrine –
Cleanup clause –
Clear and convincing evidence –
Clear and present danger –
Clear title –
Clerk –
Close corporation –
Closed shop –
Closing –
Closing argument –
Cloud on title –
Co-trustee –
Code –
Code of Hammurabi –
Code of professional responsibility –
Codefendant –
Codex –
Codicil –
Codification –
Codify –
Coercion –
Cohabitation –
Cohabitation agreement –
Coinsurance –
Collateral –
Collateral attack –
Collateral descendant –
Collateral estoppel –
Collateral Warranty –
Collective agreement –
Collective bargaining agreement –
Collective rights –
Collective trade marks – –
Collusion –
Collusive action –
Color of law –
Color of title –
Comaker –
Comity –
Commencement of action –
Commentaries on the Laws of England –
Commercial frustration –
Commercial law –
Commingling –
Commission of rebellion -
Commissioner of oaths –
Committal –
Common area –
Common carrier –
Common counts –
Common law –
Common property –
Common purpose –
Common stock –
Common-law marriage –
Commons –
Community patent –
Community property –
Commutation –
Company –
Company seal –
Comparative law –
Comparative negligence –
Comparative responsibility –
Compensatory damages –
Competence –
Complainant –
Complaint –
Complete contract –
Compound interest –
Compound question –
Compounding a felony –
Compounding treason –
Compromise –
Compromise verdict –
Concealed weapon –
Conciliation –
Conclusion of fact –
Conclusion of law –
Concubinage –
Concurrent sentence –
Concurrent sentences –
Concurrent writ –
Condemnation action –
Condition precedent –
Condition subsequent –
Conditional bequest –
Conditional discharge –
Conditional dismissal –
Conditional sale –
Condominium –
Conduct money –
Confederate States Constitution –
Confession (law) –
Confession and avoidance –
Confession of judgment –
Confidence game –
Confidential communication –
Confidential information –
Confidentiality –
Confiscate –
Conflict of interest –
Conflict of law –
Conflict of laws –
Confucianism –
Confusingly similar –
Congregation for the Doctrine of the Faith –
Congressional-executive agreement –
Conscientious objector –
Conscious parallelism –
Conscription –
Consecutive sentence –
Consecutive sentences –
Counsul of Force –
Consensu –
Consensual crime –
Consensus –
Consensus ad idem –
Consensus decision-making –
Consent –
Consent decree –
Consent judgment –
Consequential damages –
Consequentialism –
Conservatee –
Conservative Judaism –
Conservator (law) –
Consideration –
Consign –
Consignee –
Consignment –
Consortium –
Conspiracy –
Conspirator –
Constable –
Constitution –
Constitution of France –
Constitution of Spain –
Constitutional amendment –
Constitutional charter –
Constitutional Convention (Australia) –
Constitutional Convention (United States) –
Constitutional law –
Constitutional monarchy –
Constitutional rights –
Construction –
Constructive –
Constructive dismissal –
Constructive eviction –
Constructive fraud –
Constructive notice –
Constructive possession –
Constructive trust –
Construe –
Consuetudinary –
Consultancy –
Consultant –
Consumer protection –
Contact –
Contemplation of death –
Contempt of court –
Contingency –
Contingency fee –
Contingent beneficiary –
Contingent fee –
Contingent interest –
Contingent remainder –
Continuance –
Continuing objection –
Continuing trespass –
"contra bonos mores" –
"contra legem" –
Contraband –
Contract –
Contract (canon law) –
Contract of adhesion –
Contract of sale –
Contract theory –
Contractor –
"Contramandatio placiti" -
Contributory negligence –
Controlled substance –
Controlling law –
Controversy –
Conversion –
Conveyancing –
Convict –
Conviction –
Cooperative –
Cooperative housing –
Cop a plea –
Copartner –
Copyhold –
Copyleft –
Copyright –
Copyright infringement –
Copyright law of the European Union –
Copyright misuse –
"coram nobis" –
"coram non judice" –
Coroner –
Corporate governance –
Corporate haven –
Corporate opportunity –
Corporate personhood –
Corporate state –
Corporation –
Corporations law –
"corpus delicti" –
"corpus juris" –
"corpus juris civilis" –
"corpus juris secundum" –
Correlative rights doctrine –
Corroborate –
Corroborating evidence –
Corroboration –
Cost bill –
Cotenancy –
Cotenant –
Council Tax –
Counsel –
Counsellor –
Count –
Counter offer –
Counterclaim –
Counterfeit –
County court –
Coup d'état –
Cour de cassation –
Course of employment –
Court –
Court calendar –
Court costs –
Court docket –
Court of appeal –
Court of Appeal of England and Wales –
Court of Appeal (France) –
Court of Appeals –
Court of customs and patent appeals –
Court of equity –
Court of last resort –
Court of law –
Court of protection –
Court of record –
Court of Session –
Court order –
Court trial –
Court-martial –
Courtesy –
Courtroom –
Courts of England and Wales –
Courts of the United Kingdom –
Covenant (law) –
Covenant not to compete –
Covenant that runs with the land –
Covenants, conditions and restrictions –
Creature of statute –
Credibility –
Credible witness –
Creditor –
Creditor's claim –
Creditor's rights –
Crime –
Crime against humanity –
Crime against nature –
Crime against peace –
Crime of passion –
Criminal –
Criminal attorney –
Criminal calendar –
Criminal conversion –
Criminal justice –
Criminal law –
Criminal negligence –
Criminal procedure –
Critical legal studies –
Cross examination –
Cross-complaint –
Cross-examination –
Crown copyright –
Crown corporation –
Crown Court –
Crown entity –
Crown land –
Cruel and unusual punishment –
Cruelty –
Cruelty to animals –
"cui bono" –
"cuius regio, eius religio" –
Culpability –
Cumis counsel –
Cumulative sentence (disambiguation) –
Cumulative voting –
Curfew –
Customary estate –
Customary law –
Customs –
"custos morum" –
Cut a check –
Cy pres doctrine –
Cyber law –
Cybersquatting

D.A. –
D.B.A. –
D.U.I. –
D.W.I. –
Damages –
Damnation –
Dangerous weapon –
Data protection –
Date rape –
Daubert standard –
Day in court –
"de bonis asportatis" –
"de bonis non administratis" –
"de facto" –
De facto corporation –
"de futuro" –
"de integro" –
"de jure" –
De jure corporation –
"de lege ferenda" –
"de lege lata" –
"de minimis" –
"de novo" –
Deadlock –
Deadlock provision –
Deadly weapon –Death tax –
Death penalty –
Death row –
Death duty –
Debenture –
Debt –
Debt bondage –
Debtor –
Debtor in possession –
Decapitation –
Deceased –
Deceit –
Deception –
Decide! –
Decision –
Decisory oath -
Declarant –
Declaration of Arbroath –
Declaration of independence –
Declaration of mailing –
Declaration of the Independence of New Zealand –
Declaration of the Rights of Man and of the Citizen –
Declaration of trust –
Declaration of war –
Declaration of war by the United States –
Declaratory judgment –
Declaratory relief –
Declared death "in absentia" –
Decree –
Decree absolute –
Decree nisi –
Decriminalization –
Dedication –
Deduction –
Deed –
Deed poll –
"defalcation" –
Defamation –
Default (law) –
Default judgment –
Default rule –
Defeasance –
Defective title –
Defendant –
Defense –
Defense attorney – –
Defense of infancy –
Deficiency judgment –
Defined benefit plan –
Defined contribution plan –
Deforce –
Defraud –
Degree of kinship –
Deliberate –
Deliberation –
Deliberative body –
Delict –
Demand –
Demand note –
Demesne –
Demise –
Democracy –
Demonstrative evidence –
Demurrer –
Denial –
Deobandi –
Deontology –
Department for Constitutional Affairs –
Dependent –
Deportation –
Deposition –
Depreciate –
Depreciation –
Depreciation reserve –
Derivative action –
Derivative work –
Derivatives law -
Descent and distribution –
Desert –
Desertion –
Detailed Assessment –
Devi –
Devil's Advocate –
Devisee –
Devolution –
Devolve –
Devolved government –
"dicta" –
"dictum" –
Digital signature –
Diligence –
Diminished capacity –
Diminished responsibility –
Diminished responsibility in English law –
Diminution in value –
Diplomatic immunity –
Diplomatic recognition –
Direct and proximate cause –
Direct evidence –
Direct examination –
Directed verdict –
Directors register –
Disability –
Disbar –
Disbarment –
Discharge in bankruptcy –
Disciplinary procedure –
Disclaimer –
Discovery –
Discovery of documents –
Discretion –
Discretionary trust –
Discrimination –
Disembowelment –
Disfigure –
Dishonor –
Disinheritance –
Disjunctive allegations –
Dismissal –
Dismissal with prejudice –
Dismissal without prejudice –
Disobbedienti –
Disorderly conduct –
Disorderly house – –
Disposing mind and memory –
Disposition –
Dispossess –
Dispute resolution –
Dissent –
Dissenting opinion –
Dissolution (law) –
Dissolution of corporation –
Dissolution of the Monasteries –
Distinguish –
Distribute –
Distribution of property –
Distributive justice –
District attorney –
District court –
Diversity of citizenship –
Divestiture –
Divestment –
Dividend –
Dividend tax –
Divine Right of Kings –
Division of property –
Divisional court (disambiguation) –
Divorce –
DNA –
Document –
Documentary evidence –
"doli incapax" –
Domestic partner –
Domestic partners –
Domestic relations –
Domestic violence –
Dominant estate –
Dominant tenement –
"Donatio mortis causa" –
Donation –
Donative intent –
Donee –
Doom book –
Double jeopardy –
Double taxation –
Dower –
Dowry –
Draft document –
Drainage law –
Dram shop rule –
Drawer –
Drawing and quartering –
Dreyfus affair –
Driver's license –
Driving under the influence –
Driving while intoxicated –
Droit du seigneur –
Drop dead date –
Drug –
Dubitante –
"duces tecum" –
Due and owing –
Due care –
Due diligence –
Due process –
Due process of law –
Due, owing and unpaid –
Duress –
Duress in English law –
Duty –
Duty of care –
Duty of care in English law –
Duty to warn –
Dying declaration

Early Muslim philosophy –
Earned income tax credit –
Earnest payment –
Easement –
Ecclesia –
Ecclesiastical court –
Ecumenical council –
Edict –
Edict of Fontainebleau –
Edict of Milan –
Edict of Nantes –
Edict of Worms –
"ei incumbit probatio qui" –
Either –
Ejectment –
"ejusdem generis" –
Elder law –
Election of remedies –
Election under the will –
Elective share –
Electoral reform –
Electric chair –
Emancipation –
Emancipation Proclamation –
Embezzlement –
Embezzler –
Emblements –
Emergency –
Eminent domain –
Emolument –
Employee –
Employer –
Employers' liability –
Employment –
Employment contract –
Employment law –
En banc –
Enabling clause –
Enclosure –
Encumbrance –
End user license agreement –
Endowment –
Enfeoff –
Enfeoffment –
Enforcement –
English Bill of Rights –
English law –
Enjoin –
Enjoyment –
Enrolled Bill doctrine –
Entail –
Enter a judgment –
Entertainment law –
Entity –
Entrapment –
Entry of judgment –
Environmental Impact Report –
Environmental impact statement –
Environmental law –
Ephebophilia –
Equal Access Act –
Equal opportunity –
Equal Protection Clause –
Equitable distribution –
Equitable estoppel –
Equitable lien –
Equitable remedy –
Equity (law) –
Equity of redemption –
Equivalent –
"erga omnes" –
"erratum" –
Error –
Escalator clause –
Escape clause –
Escheat –
Escrow –
Escrow account –
Escrow agent –
Escrow instructions –
Espionage –
Esquire –
Essential facilities doctrine –
Establishment clause –
Estate –
Estate by entirety –
Estate in land –
Inheritance tax –
"estoppel" –
"et al." –
"et cetera" –
"et seq" –
Eternity clause
Ethical calculus –
Ethical code –
Ethics –
Ethics in religion –
Ethnic cleansing –
European Convention on Human Rights –
European Court of Human Rights –
European Court of Justice –
European Patent Convention –
European Patent Organisation –
European Union directive –
Directive (EU) –
European Union Law –
European Union regulation –
Regulation (EU) –
Euthanasia –
Evasion of tax –
Evasion of the law –
Eviction –
Evidence –
"ex aequo et bono" –
"ex cathedra" –
"ex delicto" –
"ex facie" –
"ex gratia" –
"ex officio" –
"ex parte" –
"ex post facto" –
Ex post facto law –
"ex rel" –
Examination –
Exception in deed –
Excessive bail –
Excise –
Exclusionary rule –
Excommunication –
Exculpatory –
Excusable neglect –
Excuse –
Execution –
Execution –
Execution warrant –
Executioner –
Executive –
Executive clemency –
Executive privilege –
Executor –
Executory contract –
Executory interest –
"executrix" –
Exegesis –
Exemplary damages –
Exempt –
Exempt employees –
Exempt property –
Exemption –
Exhibit –
exigent circumstances –
Exile –
Expectancy –
Expense –
Expert determination –
Expert testimony –
Expert witness –
Express contract –
Express warranty –
Extension –
Extenuating circumstances –
Extinguishment –
Extortion –
Extradition –
Extrajudicial –
Extraordinary General Meeting –
Extraordinary resolution –
Extreme cruelty –
Extrinsic fraud

FOB (shipping) –
Fabrica –
Fabricate –
Fabula –
Face –
Facere –
Facies –
Facile –
Fact –
Facto –
Factory –
Factum –
Faculties, Court of –
Faculty (instrument) –
Faculty of a college – –
Faculty of Advocates –
Faggot voter –
Fail –
Failure –
Failure of consideration –
Failure of issue –
Faint action –
Fair –
Fair Play Men –
Fair pleader –
Faith –
Falang –
Falda –
Faldstool –
Falesia –
Falk-land –
Fall –
Fallo
False action –
False imprisonment –
False pretenses –
False swearing –
Falsehood –
Falsify –
Falsing –
Falsum –
Falsus in uno, falsus in omnibus –
Familia –
Family –
Famosus –
Famosus libelus –
Fanatics –
Fakir –
Farm –
Farmer –
Faro –
Farrier –
Fasti –
Father –
Father-in-law –
Fathom –
Fatuity –
Fatuus –
Faubourg –
Fautor –
Fealty –
Fear –
Feciales –
Federal government –
Fee –
Fee-simple –
Fenian –
Feodal –
Feodal system –
Feodary –
Feodum –
Feoffee –
Feoffment –
Feoh –
Feria –
Feriae –
Ferling –
Ferry –
Ferryman –
Feu (land tenure) –
Feud –
Fishing law –
Flag –
Flag of the United States –
Flagrante delicto –
Flem –
Fleta –
Flight –
Floating capital –
Floor –
Florin –
Flotsam –
Fluctus –
Face amount –
Face value –
Fact –
Factum –
Faculty of law –
Failure of consideration –
Failure of issue –
Fair comment –
Fair dealing –
Fair market value –
Fair trade laws –
Fair use –
Fairness Doctrine –
False arrest –
False Claims Law –
False imprisonment –
False pretenses –
Family –
Family law –
Family court –
Family law –
Family patrimony –
Family purpose doctrine –
Fatwa –
Fault auto insurance system –
Federal Communications Commission –
Federal Constitutional Court (Germany) –
United States federal courts –
Federal judge –
Federal jurisdiction (United States) –
Federal law –
Federal question –
Federal tort claims act –
Federalism –
Fee –
Fee simple –
Fee tail –
Felicific calculus –
Felony –
Felonious –
Felony –
Felony murder rule –
Feme covert –
Feoff –
Feoffee –
Feoffment –
Fertile octogenarian –
Feud –
Feudal land tenure –
Feudal system –
Feudalism –
Fiat –
Fictitious defendants –
"fiduciary" –
Fiduciary duty –
Fiduciary relationship –
Fief –
Fieri –
"fieri facias" –
Fighting words –
File –
Final judgment –
Finder of fact –
Findings of fact –
Fine –
Fiqh –
Firm offer –
First degree murder –
First impression –
First to file and first to invent –
Fixture –
Fixtures –
Flight –
Floating charge –
Floating easement –
FOB –
Fostering –
Foujdar –
Four corners –
Fourierism –
Fox's Libel Act –
Frais –
Franc –
Francia –
Francus –
Frank-marriage –
Franking privilege –
Fraternity –
Fratricide –
Fraud –
Fraus –
Fraxinetum –
Free-bench –
Free and clear –
Free socage –
Free warren –
Freedman –
Freedom –
Freedom of speech –
Freedom of the press –
Free on board –
Freight –
Freighter –
Frenchman –
Frequent –
Frere –
Fresca –
Fresh pursuit –
Fretum Britannicum –
Friend of the court –
Friendly societies –
Friendly suit –
Frigidity –
Frith –
Frivolous –
Frontage –
Frontier –
Fructus industriales –
Fructus naturales –
Fruges –
Fruit –
Folkways –
For value received –
Forbearance –
Force majeure –
Forced heirship –
Forced sale –
Forcible entry –
Foreclosure –
Foreclosure sale –
Foreign corporation –
Forensic –
Forensic medicine –
Forensic testimony –
Forensics –
Foreseeability –
Foreseeable risk –
Forfeit –
Forger –
Forgery –
Formal contract –
Fornication –
"forum conveniens" –
"forum non conveniens" –
Forum shopping –
Foster child –
Four Cardinal Virtues –
Four corners of an instrument –
Franc-tireur –
Franchise –
Franchise tax –
Franchising –
Fraud –
Fraud in the inducement –
Fraudulent conveyance –
Fraudulent trading –
Free and clear –
Free economic zone –
Free on board –
Free port –
Free software license –
Free speech –
Free will –
Freedom of assembly –
Freedom of association –
Freedom of expression –
Freedom of Information Act –
Freedom of religion –
Freedom of speech –
Freedom of speech by country –
Freedom of the press –
Freedom of thought –
Freehold –
French law on secularity and conspicuous religious symbols in schools –
Fresh pursuit –
Friendly suit –
Frisking –
Frivolous –
Frivolous lawsuit –
Fructus naturales –
Fruit of the poisonous tree –
Frustration of purpose –
Fugitive from justice –
Full faith and credit –
Fully paid –
"functus officio" –
Fundamental justice –
Fundamentalism –
Fungible things –
Future interest –
Futuwa –
Fyrd

Gag order –
Gallows –
Game law –
Gaps and gores –
Garnish –
Garnishee –
Garnishment –
Gas chamber –
Gasoline tax –
Gemara –
Gender bias –
General Agreement on Tariffs and Trade –
General appearance –
General assignment –
General Counsel –
General damages –
General denial –
General meeting –
General order –
General partnership –
General plan –
General strike –
General Synod –
Generation skipping –
Geneva Conventions –
Genocide –
German town law –
Gibbet –
Gift –
Gift in contemplation of death –
Gift tax –
Glasnost –
Go bail –
Going concern –
Good cause –
Good faith –
Good governance –
Good samaritan rule –
Good title –
Goods –
Goseibai Shikimoku –
Government –
Government-granted monopoly –
Governmental immunity –
Grace period –
Grand Inquisitor –
Grand jury –
Grand larceny –
Grand theft –
Grandfather clause –
Grandfathered in –
Grandparent visitation –
Grant –
Grant deed –
Grantor-grantee index –
Gratuitous –
"gravamen" –
Green card –
Gross income –
Gross negligence –
Grounds for divorce –
Group boycott –
Group Litigation Order –
Guanxi –
Guarantee –
Guarantees –
Guarantor –
Guaranty –
Guardian –
Guardian "ad litem" –
Guest statute –
Guild –
Guillotine –
Guilt –
Guilty

Habeas corpus –
Habeas corpus ad deliberandum et recipiendum –
Habeas corpus ad faciendum et recipiendum –
Habeas corpus ad prosequendum –
Habeas corpus ad respondendum –
Habeas corpus ad satisfaciendum –
Habeas corpus ad subjiciendum –
Habeas corpus ad testificandum –
Habeas corpus cum causa –
Habitant –
Habitation (see Dwelling) –
Habitual Criminals Act –
Hable –
Hacienda –
Habitable – –
Habitual criminal –
Hadith –
Hague Convention –
Hague-Visby Rules –
Halaal –
Halakha (Jewish law) –
Jewish law (Halakha) –
Half blood –
Halsbury's Laws of England –
Hanafi –
Hanbali –
Hanging –
Haram –
Harass –
Harassment –
Harm reduction –
Harmless error –
Hate speech –
Head of household –
Headnote –
Headright –
Heads of loss -
Health care proxy –
Hearing –
Hearsay –
Hearsay rule –
Heat of passion –
Heir –
Heir apparent –
Heiress –
Heirs –
Heirs of the body –
Hell or high water clause –
Hereditament –
Herem (censure) –
Herem (priestly gift) –
Herem (war or property) –
Heresy –
Hidden asset –
High court judge –
High Court of Australia –
Royal High Court of Bhutan –
High Court of Justice (England and Wales) –
Court of High Commission (ecclesiastical court in England) –
High Court of Fiji –
High Court (Hong Kong) –
High Courts of India, several courts –
High Court (Ireland) –
High Court (Isle of Man) –
High Court of Malaya –
High Court of New Zealand –
High Court of Cassation and Justice (Romania) –
High Court of Justiciary (Scotland) –
High Court of Sabah and Sarawak –
High Court of Singapore –
High Court of South Africa –
Highway –
Highwayman –
Hima –
Himalaya clause –
Hit and run –
Hobby loss –
Hold harmless –
Holder in due course –
Holding –
Holding company –
Holdover tenancy –
Holographic will –
Home Rule –
Home Secretary –
Homestead Act –
Homestead exemption –
Homestead principle –
Hometowned –
Homicide –
Hong Kong trademark law –
Hornbook law –
Hostile environment sexual harassment –
Hostile possession –
Hostile witness –
Hot pursuit –
Hotch-pot –
House counsel –
House of Lords –
Household –
Housing tenure –
Human rights –
Human Rights Committee –
Human rights issues in the United States –
Humanism –
Hung jury –
Hypothecate

Idea-expression divide –
"idem" –
"ignorantia juris non excusat" –
Ijma –
Ijtihad –
Illegal combatant –
Illegal drug trade –
Illegal immigrant –
Illegitimacy –
Illusory promise –
Ilm ar-Rijal –
Imam –
Immediately –
Immigrant visa –
Immigration –
Immigration Appellate Authority –
Immunity –
Impanel –
Impaneling –
Impeach –
Impeachment –
Impleader –
Implied Bill of Rights –
Implied consent –
Implied contract –
Implied covenant of good faith and fair dealing –
Implied terms –
Implied warranty –
Implied warranty of fitness for a particular purpose –
Implied warranty of habitability –
Implied warranty of merchantability –
Importation right –
Impossibility –
Impotence –
Imputation –
"in camera" –
In chambers –
"in curia" –
"in delicto" –
"in esse" –
In fee simple –
"in flagrante delicto" –
"in forma pauperis" –
"in haec verba" –
In kind –
In lieu –
"in limine" –
"in loco parentis" –
"in pari delicto" –
"in personam" –
in pro per –
"in prope persona" –
"in propria persona" –
"in re" –
"in rem" –
"in situ" –
"in terrorem" –
"in terrorem clause" –
"in toto" –
Incapacity –
Incest –
Inchoate offense –
Incidental beneficiary –
Income –
Income tax –
Incompetent evidence –
Incontrovertible evidence –
Incorporation (business) –
Incorporate by reference –
Incorporation (business) –
Incorporeal –
Incriminate –
Incumbrance –
Indecent exposure –
Indefeasible –
Indefeasible estate –
Indemnify –
Indemnity –
Indenture –
Indentured servant –
Independent contractor –
Indeterminacy debate in legal theory –
Indeterminate sentence –
Indictable offence –
Indictable offense –
Indictment –
Indigent –
Indispensable party –
Individual capital –
Individual rights –
Indorse –
Industrial design rights –
Industrial tribunal –
Infancy –
Infant –
Infanticide Act –
Inference –
Information –
Information and belief –
Informed consent –
Infraction –
Infractions –
Infringement –
Ingress –
Inherit –
Inheritance –
Inheritance tax –
Injunction –
Injunctive relief –
Injury –
Inkan –
Innocence –
Innocent –
Inns of Court –
"innuendo" –
Inquest –
Inquisition –
Inquisitor –
Inquisitorial system –
Insanity –
Insanity defense –
Insider –
Insider trading –
Insolvency –
Insolvent –
Inspection of documents –
Installment contract –
Instruction –
Instructional capital –
Insufficient evidence –
Insurance –
Insured –
Insurer –
Intangible property –
Integrated criminal justice information system –
Integration –
Intellectual capital –
Intellectual property –
Intellectual rights –
Intendant of New France –
Intent –
"inter alia" –
"inter se" –
"inter vivos" –
Inter vivos trust –
Interest –
Interference proceeding –
Interim order –
Interlineation –
"interlocutory" –
International Business Companies Act –
Interlocutory decree –
Interlocutory order –
Intermediate sanctions –
Internal affairs doctrine –
International Business Companies Act –
International constitutional law –
International Court of Justice –
International Covenant on Civil and Political Rights –
International crime –
International Criminal Court –
International Criminal Tribunal for Rwanda –
International Criminal Tribunal for the Former Yugoslavia –
International environmental law –
International human rights instruments –
International human rights law –
International law –
International relations –
International trade –
International trade law –
Internment –
Interpleader –
Interrogation –
Interrogatories –
Interstate commerce –
Intertemporal Law –
Intervene –
Intervening cause –
Intervention –
Intestacy –
Intestate –
Intestate succession –
Intoxication –
"intra fauces terra" –
"intra vires" –
Intrinsic fraud –
Inure –
Invasion of privacy –
Inventor –
Inventor's notebook –
Inverse condemnation –
Invest –
Investiture –
Investment –
Invitation to treat –
Invitee –
Involuntary commitment –
"ipse dixit" –
"ipsissima verba" –
"ipso facto" –
Irreconcilable differences –
Irrelevant –
Irreparable damage or injury –
Irresistible impulse –
Islamic Law (Sharia) –
Sharia (Islamic law) –
Islamic philosophy –
Isnad –
Issue –
Issue preclusion –
Issued shares

Juris Doctor (J.D.) –
Jafari –
Jane Doe –
Jaywalking –
Jeopardy –
Jewish principles of faith –
Jewish Theological Seminary of America –
Jim Crow laws –
John Doe –
Joinder –
Joinder of issue –
Joint –
Joint adventure –
Joint and several –
Joint and several liability –
Joint custody –
Joint liability –
Joint property –
Joint tenancy –
Joint tortfeasors –
Joint venture –
Jointure –
Jones act –
Journeyman –
Joyride –
Judge –
Judge advocate –
Judge Advocate General –
Judgment –
Judgment by default –
Judgment debtor –
Judgment in Berlin –
Judgment non obstante veredicto –
Judgment notwithstanding the verdict –
Judgment notwithstanding verdict –
Judicial –
Judicial Committee of the Privy Council –
Judicial discretion –
Judicial economy –
Judicial foreclosure –
Judicial functions of the House of Lords –
Judicial independence –
Judicial interference –
Judicial notice –
Judicial review –
Jump bail –
Junior barrister –
"jurat" –
Jurisdiction –
Jurisdictional amount –
Jurisprudence –
Jurist –
Juror –
Jury –
Jury box –
Jury charge –
Jury fees –
Jury instructions –
Jury nullification –
Jury of one's peers –
Jury panel –
Jury selection –
Jury stress –
Jury tampering –
Jury trial –
"jus ad bellum" –
"jus ad bellum" –
"jus civile" –
"jus cogens" –
"jus commune" –
"jus gentium" –
"jus inter gentes" –
"jus naturale" –
"jus primae noctis" –
"jus sanguines" –
"jus sanguinis" –
"jus soli" –
Just cause –
Just compensation –
Just war –
Justice –
Justice of the Peace –
Justiciable –
Justifiable homicide –
Justification –
Juvenile –
Juvenile court –
Juvenile delinquent

Kangaroo court –
Karaites –
Karma –
Kosher law –
Kellogg-Briand Pact –
Kidnapping –
King's Bench –
Know-how –
Kollel

Labor and materials –
Labor law –
labor union –
Laches –
"lacunae" –
Land use –
Land value tax –
Landlady –
Landlocked –
Landlord –
Landlord and tenant –
Landlord and Tenant Act –
Landlord's lien –
Lapse –
Larceny –
Last antecedent rule –
Last clear chance –
Last will and testament –
Latent defect –
Law –
Law and economics –
Law and literature –
Law and motion calendar –
Law basic topics –
Law book –
Law dictionary –
Law French –
Law lords –
Law of admiralty –
Law of Canada –
Law of costs –
Law of Ireland –
Law library –
Law of obligations –
Law of the case –
Law of the land –
Law of the Russian Federation –
Law of the Sea –
Law of the Soviet Union –
Law of the United Kingdom –
Law of the United States –
Law of treaties –
Law school –
Law Society –
Laws of war –
Lawsuit –
Lawyer –
Lay a foundation –
Lay assessor –
Laïcité –
Leading –
Leading question –
Leading the witness –
Lease –
Lease and release –
Leasehold –
Legal –
Legal abuse –
Legal action –
Legal advertising –
Legal age –
Legal aid –
Legal Aid Society –
Legal code –
Legal consequences of marriage and civil partnership in the United Kingdom –
Legal custody –
Legal debate –
Legal dualism –
Legal entity –
Artificial person –
Legal fiction –
Legal formalism –
Legal history –
Legal instrument –
Legal Latin –
Legal lexicography –
Legal personal representative –
Legal positivism –
Legal pluralism –
Legal realism –
Legal separation –
Legal technicality –
Legal tender –
Legal translation –
Legalese –
Legalism (Western philosophy) –
Legalism (Chinese philosophy) –
Legalism (theology) –
Legalization –
Legatee –
Legislation –
Legislature –
Legitimacy (family law) –
Legitimacy (political science) –
"legitime" –
Lemon law –
Lessee –
Lesser crime –
Lesser included offenses –
Lesser-included offense –
Let –
Lethal injection –
Letter of credit –
Letter of marque –
Letter of wishes –
Letters –
Letters of administration –
Letters patent –
Letters testamentary –
Leverage –
Leviticus –
"lex lata" –
"lex scripta" –
Liable –
Libel –
Libel per se –
Libertarian theories of law –
Liberty –
Licence –
License –
Licensee –
Lie detector test –
Lien –
Lienor –
Life –
Life estate –
Life without possibility of parole –
Limitation of actions –
Limitations clause, Constitution of Canada –
Limited company –
Limited jurisdiction –
Limited liability –
Limited liability company –
Limited partner –
Limited partnership –
Line of succession –
Lineal descendant –
Lineup –
Liquidate –
Liquidated damages –
Liquidation –
Liquidator (law) –
"lis pendens" –
List of Roman laws –
Listed building –
Literary property –
Litigant –
Litigation –
Litigious –
Liturgy –
Livery –
Livery of seizin –
"living trust" –
Living will –
LL.B. –
LL.M. –
Loanshark –
Lockout –
"locus delicti" –
"locus in quo" –
Loiter (law) –
Long cause –
Long vacation –
Long-arm statute –
Lord Chancellor –
Lord Chancellor's Department –
Lord Chief Justice –
Lord Chief Justice of England and Wales –
Lord Justice General –
Lord Justice of appeal –
Lord Keeper of the Great Seal –
Lord President of the Council –
Lord Steward –
Loss of consortium –
Loss of use –
Lost volume seller –
Lower court –
Lübeck law

M'Naghten Rules –
Madhhab –
Madrassa –
Magdeburg rights –
Magdeburg law –
Magistrate –
"magna carta" –
Mail box rule –
Maim –
Maintenance –
Maintenance –
Maintenance –
Majority –
Mala fides –
"male fide" –
Malfeasance –
Malice aforethought –
Malicious prosecution –
Maliki –
Malpractice –
"malum in se" –
"malum prohibitum" –
"mandamus" –
Writ of mandamus –
Mandate (criminal law) –
Mandate (international law) –
Mandate of Heaven –
Mandatory joinder –
Mandatory sentence –
Mann act –
Manorialism –
Manslaughter –
Manslaughter in English law –
Manumission –
Manusmriti –
"mare clausum" –
"mare liberum" –
Marital deduction –
Marital life estate –
Marital rights –
Maritime law –
Marked for identification –
Market value –
Marketable title –
Marriage –
Marriageable age –
Marshal –
Martial law –
Mask work –
Masoretes –
Masoretic Text –
Masorti –
Massachusetts trust –
Master –
Master and servant –
Master of Laws –
Master of the Rolls –
Master of the Rolls in Ireland –
Materiality –
Material witness –
Matrimonial regime –
Matter –
Maturity –
Maxims –
Maxims of equity –
Maxims of law –
May –
Mayhem –
Mechanic's lien –
Mechanics lien –
Mediation –
Mediator –
Medical directive –
Medical ethics –
Medieval Inquisition –
Meet and confer –
Meeting of the minds –
Meforshim –
Megan's Law –
Memorandum –
Memorandum of Association –
"mens rea" –
Mental cruelty –
Mental health law –
Mental suffering –
Mercantile law –
Merchantable –
Merger –
Mesne –
"mesne assignment" –
Mesne profits –
Messuage –
Metes and bounds –
Military alliance –
Military dictatorship –
Military law –
Military tribunal –
Militia –
Mining claim –
Ministerial act –
minor –
Minutes –
Miranda warning –
Mirror wills –
Misappropriation –
Mischief –
Misdemeanor –
Misfeasance –
Mishnah Berurah –
Mishnah –
Hebrew law (Mishpat Ivri) –
Mishpat Ivri (Hebrew law) –
Misjoinder –
Misnomer –
Misprision of a felony –
Misprision of treason –
Misrepresentation –
Mistake of law –
Mistrial –
Mitigating circumstances –
Mitigating factors –
Mitzvah –
Mock trial –
Modern Islamic philosophy –
"modus operandi" –
Moiety title –
Monarch –
Money laundering –
Monopoly –
Monopoly on the legitimate use of physical force –
Month-to-month –
Monument –
Moot court –
Moot point –
Mootness –
Mopery –
Moral absolutism –
Moral certainty –
Moral code –
Moral core –
Moral relativism –
Moral rights –
Moral turpitude –
Moral universalism –
Morality –
Moratorium –
Mores –
Morganatic marriage –
Mortgage law –
Mortgagee –
Mortgagor –
Motion –
Motion for a summary judgment –
Motion for more definite statement –
Motion for directed verdict –
Motion for dismissal –
Motion for summary judgment –
"motion in limine" –
Motion to dismiss –
Motion to Strike –
Motion to suppress –
Motion to suppress evidence –
Motive –
Motor vehicle exception--Motor vehicle theft –
Movant –
Mujtahid –
Mullah –
Multiple citizenship –
Multiplicity of suits –
Municipal –
Muniment of title –
Murder –
Murder in English law –
Muslim dietary laws –
Mutation –
"mutatis mutandis" –
Mutiny –
Mutual wills

N.O.V. –
Name change –
Named plaintiffs –
Napoleonic code –
Narcotic –
National Insurance contributions –
National Labor Relations Board –
National trade union center –
Nationality –
Natural law –
Natural person –
Natural resource law –
"ne exeat" –
Necessary party –
Negative pledge –
Negative pregnant –
Negligence –
Negligence "per se" –
Negligent –
Negotiable instrument –
Negotiation –
"nemo dat quod non habet" –
"nemo judex in sua causa" –
Neutral country –
Next friend –
Next of kin –
Night and Fog prisoner –
"nihil dicit" –
"nisi prius" –
No contest –
No fault divorce –
No fault insurance –
No-par stock –
Noble Eightfold Path –
"nolle prosequi" –
"nolo contendere" –
Nominal damages –
Nominal party –
Nominal value –
Nominee –
"non compos mentis" –
"non constat" –
"non est factum" –
"non liquet" –
"non obstante verdicto" –
Non-binding arbitration –
Non-conforming use –
Non-contestability clause –
Non-disclosure agreement –
Non-executive director –
Non-feasance –
Non-profit corporation –
Non-profit organization –
Non-suit –
Nonimmigrant visa –
Nonviolence –
Not guilty –
Not guilty by reason of insanity –
Not-for-profit corporation –
"nota bene" –
Notary public –
Notice –
Notice of appeal –
Notice of default –
Notice to quit –
Notorious possession –
Notwithstanding clause (Canadian Constitution) –
Novation –
Nuisance –
"nulla bona" –
"nulla poena sine lege" –
Nullity (conflict) –
"nullum crimen, nulla poena sine praevia lege poenali" –
"nunc pro tunc" –
Nuremberg Code –
Nuremberg Trials

O.R. –
O.S.C. –
Oath –
"obiter dicta" is plural; see the singular "obiter dictum" –
Object –
Objectivist philosophy –
Obligation –
Obligations of confidentiality –
Obligee –
Obligor –
Obscene –
Obscenity –
Obstruction of justice –
Occupancy –
Occupant –
Occupational disease –
Occupational hazard –
Occupy the field –
Of counsel –
Offender –
Offer of proof –
Offeree –
Offeror –
Officer of the court –
Officers of a corporation –
Official –
Official misconduct –
Official receiver –
Official Solicitor –
Officious intermeddler –
Offshore corporation –
Ombudsman –
Omission –
Omnibus clause –
On all fours –
"onus probandi" –
Open adoption –
Open court –
Open-source license –
Opening statement –
Operation of law –
"opinio juris sive necessitatis" –
Opinion –
Oppression remedy –
Oral argument –
Oral contract –
Oral examination –
Oral law –
Order –
Order in Council –
Order to show cause –
Ordinary (officer) –
Ordinary course of business –
Ordinary resolution –
Ordinary shares –
Organized crime –
Original jurisdiction –
Original sin –
Originating application –
Orphan –
Ostensible agent –
Ostensible authority –
Out of court –
Out-of-pocket expenses –
Outlaw –
Output contract –
Over-the-counter drug –
Overcharge –
Overt act –
Owe –
Own –
Own recognizance –
Owner –
Owner-occupier –
Ownership

"pacta sunt servanda" –
Pain and suffering –
Palimony –
Panderer –
"par delictum" –
Paralegal –
Paramount title –
Paraphilia –
Pardon –
"parens patriae" –
Parent –
Parent company –
Pari delicto –
Pari passu –
Paris Convention for the Protection of Industrial Property –
Parish –
Parliament –
Parliamentary procedure –
Parliamentary supremacy –
Parliamentary system –
Parody –
Parol –
Parol evidence rule –
Parole –
Parquet –
Partial breach –
Partial verdict –
Particulars –
Partition –
Partner –
Partnership –
Party –
Party of the first part –
Party of the second part –
Party wall –
Passenger –
Passing off –
Patent –
Patent ambiguity –
Patent Cooperation Treaty –
Patent infringement –
Patent pending –
Patentability –
Patently unreasonable –
Paternity –
Paternity suit –
Patient –
Patrimony of affectation –
Patronage –
Pay as you earn (paye) –
Payable –
Payee –
Payor –
Peace bond –
Peaceable possession –
Peculation –
Pecuniary –
Pedophilia –
Peeping tom –
Peer group –
Peerage –
Peer review –
Penal –
Penal code –
Penal colony –
Penal law –
Penal notice –
Penal transportation –
Penalty phase –
Penance –
Pendent jurisdiction –
"pendente lite" –
Pension plan –
Pension scheme –
People's Republic of China's trademark law –
"per capita" –
"per curiam" –
"per diem" –
"per minas" –
"per pro" –
"per quod" –
"per stirpes" –
Peremptory challenge –
Peremptory challenges –
Peremptory norm –
Peremptory writ of mandate –
Perfect –
Perfection (law) –
Perform –
Performance –
Perjurer –
Perjury –
Permanent Court of Arbitration –
Permanent injunction –
Permissive –
Perpetuity –
Person –
Person having ordinary skill in the art –
"persona non grata" –
Personal effects –
Personal jurisdiction –
Personal property –
Personal recognizance –
Personal representative –
Personal service –
Personality rights –
Personalty –
Perversion –
Petit jury –
Petition –
Petition for probate –
Petition to make special –
Petitioner –
Petty larceny –
Petty offenses –
Philosophy of law –
Physical custody –
Physician-patient privilege –
Picketing –
Pierce the corporate veil –
Piercing the corporate veil –
Pilferage –
Pillory –
Pimp –
Piracy –
Plagiarism –
Plain error –
Plain view doctrine –
Plaint note –
Plaint number –
Plaintiff –
Plc –
Plea –
Plea bargain –
Plea in abatement –
Plead –
Pleading –
Pleadings –
Plenary authority –
Police –
Police brutality –
Police oppression –
Police powers (United States constitutional law) –
Police state –
Corruption –
Political prisoner –
Political question –
Political science –
Poll tax (disambiguation) –
Polyandry –
Polygamy –
Bigamy –
Polygraph –
Pornography –
Port of entry –
Positive law –
Possession –
Possession of stolen goods –
Possession proceedings –
Possessory –
Possessory interest –
Possibility of a reverter –
"post mortem" –
Postdated check –
Pot –
Pour over will –
Poverty law –
Power –
Power of appointment –
Power of arrest –
Power of attorney –
Practice –
Practice Direction –
Practice of law –
Praemunire –
"praetor peregrinus" –
Pre-emption rights –
Precedent –
Preemption of state and local laws in the United States –
Preemptive right –
Preference –
Preferential creditor –
Preferred dividend –
Preferred stock –
Pregnant denial –
Preliminary hearing –
Preliminary injunction –
Premeditation –
Premises –
Prenuptial agreement –
Preponderance of the evidence –
Prerogative writ –
Prescription drug –
Prescriptive easement –
President of the family division –
Presiding judge –
Presumption –
Presumption of innocence –
Pretermitted heir –
Pretrial discovery –
Price fixing –
"prima facie" –
Prima facie case –
Prima impressionis –
Prime suspect –
"primogeniture" –
Prior restraint –
Prison –
Prisoner of war –
Privacy –
Private bill –
Private carrier –
Private company –
Private Express Statutes –
Private international law –
Private law –
Private nuisance –
Private parts –
Private property –
Private road –
Privateer –
Privilege (evidence) –
Privilege (legal ethics) –
Privilege against self incrimination –
Privileged communication –
Privity –
Privy Council –
Privy Council of Sweden –
"pro bono" –
"pro bono publico" –
"pro forma" –
"pro hac vice" –
"pro per" –
"pro se" –
"pro tanto" –
"pro tem" –
"pro tempore" –
Probable cause –
Probate –
Probation –
Probative –
Probative value –
Procedendo –
Procedural defense –
Procedural justice –
Procedural law –
Procedure –
Proceeding –
Process –
Process server –
Proctor –
Product liability –
Professional corporation –
Professional negligence –
Proffer –
Prohibition –
Writ of prohibition –
Promise –
Promissory estoppel –
Promissory note –
Property –
Property damage –
Property law –
Property tax –
"propria persona" –
Proprietary rights –
Proprietor –
Prosecute –
Prosecution –
Prosecutor –
Prostitute –
Prostitution –
Protective custody –
Protective order –
Protest –
Protocol –
Provisional remedy –
Proximate cause –
Prudent man rule –
Public –
Public administrator –
Public benefit corporation –
Public company –
Public corporation (disambiguation) –
Public defender –
Public domain –
Public figure –
Public limited company –
Public nuisance –
Public order –
Public property –
Public record –
Public trust doctrine –
Public trustee –
Public use –
Public utility –
Publication –
Publici juris –
Publish –
Puffery –
Puisne judge –
Punitive damages –
Putative father –
Putative father registry

"quaere" –
"quantum meruit" –
Quash –
"quasi" –
Quasi community property –
Quasi contract –
Quasi corporation –
Quasi in rem –
Quasi-contract –
Quasi-criminal –
Quasi-delict –
Quasi-judicial –
Queen's bench –
Queen's Privy Council for Canada –
Queens bench division –
Queen's counsel –
Question of fact –
Question of law –
"qui tam action" –
"quid pro quo" –
"quid pro quo sexual harassment" –
Quiet enjoyment –
Quiet title action –
Quitclaim deed –
Quitrent –
"quo warranto" –
Quorum –
Quotient verdict –
Qur'an

Rabbi –
Rabbinic literature –
Rabbinical Assembly –
Race to the courthouse –
Racial discrimination –
Racial segregation –
Racism –
Racketeer influenced corrupt organization (RICO) statute –
Racketeering –
Radical transparency –
Ransom –
Rape –
Ratification –
Ratify –
"ratio decidendi" –
"ratio scripta" –
Rational basis –
"Ratum sed non consummatum" –
Real estate –
Real estate investment trust –
Real party in interest –
Real property –
Realty –
Reasonable –
Reasonable care –
Reasonable doubt –
Reasonable man doctrine –
Reasonable time –
Rebbe –
"rebus sic stantibus" –
Rebuttable presumption –
Rebuttal –
Recapture –
Receipt –
Receivership –
Recharacterisation –
Recidivist –
Reciprocal discovery –
Reckless –
Reckless disregard –
Reckless driving –
Recklessness –
Recognisance –
Reconstructionist Judaism –
Reconveyance –
Recorder –
Recording acts –
Recoupment –
Recover –
Recoverable –
Recusal –
Rectification (law) –
Recuse –
Redemption (bonds) –
Redemption of shares –
Redemption value –
Redetermination –
Redirect examination –
Redundancy –
Reentry –
Referee –
Referendum –
Reform Judaism –
Refugee –
Refundable tax credit –
Registered office –
Registered trade mark –
Registration statement –
Registry of deeds –
Regulation –
Regulations –
Regulatory taking –
Rehearing –
Reichstag Fire Decree –
Reid technique –
Release –
Release on one's own recognizance –
Relevancy –
Relief –
Religion and heterosexuality –
Religion and homosexuality –
Religious law –
Remainder –
Remainderman –
Remand (court procedure) –
Remittitur –
Rent –
Rent control –
Rental value –
Reorganization –
Repair –
Repeal –
Repentance –
Replevin –
Reply brief –
Reports –
Repossess –
Represent –
Representation –
Reprisal –
Reputation –
Requirements contract –
"res adjudicata" –
"res gestae" –
"res ipsa loquitur" –
"res judicata" –
"res nulis" –
"res publica christiana" –
Resale –
Rescind –
Rescission –
Rescue doctrine –
Reservation –
Reserved decision –
Resident –
Resident alien –
Residuary bequest –
Residuary estate –
Residuary legatee –
Residue –
Resistance movement –
Resisting arrest –
Resolution –
Resolution of disputes –
"respondeat superior" –
Responsa –
Responsibility –
Restatement of the law –
Restitution –
Restorative justice –
Restraining order –
Restraint of trade –
Restraint on alienation –
Restrictive covenant –
Result –
Resulting trust –
Retaining lien –
Retention of title clause –
Retire –
Retraction –
Retrial –
Retributive justice –
Return of service –
Revenue ruling –
Reversible error –
Reversion –
Review –
Revocable living trust –
Revocation –
Revoke –
RICO –
Right of audience –
Right of eminent domain –
Right of survivorship –
Right of the first night –
Right-of-way –
Right to privacy –
Right to silence –
Right-to-work laws –
Rights –
Riot –
Riot control agent –
Riparian –
Riparian rights –
Risk –
Risk of loss –
Ritual –
Roadside test –
Robbery –
Robert's Rules of Order –
Rocket docket –
Rogatory letters –
Roman Forum –
Roman Inquisition –
Roman law –
Room –
Royal Assent –
Royal Charter –
Royal Commission –
Royal Courts of Justice –
Royal Prerogative –
Royal Warrant –
Royalties –
Rule –
Rule against perpetuities –
Rule by decree –
Rule in Allhusen v Whittell –
Rule in Re Atkinson –
Rule in Bartlett v Barclays Bank –
Rule in Clayton's Case –
Rule in Dearle v Hall –
Rule in Dumpor's Case –
Rule in Howe v Earl of Dartmouth –
Rule in Saunders v Vautier –
Rule in Shelley's Case –
Rule in Wild's Case –
Rule of law –
Rulemaking –
Rules of evidence –
Ruling –
Rum-running –
Running with the land –
Ruse of war

Sabotage –
Sacred text –
Salafi –
Sales tax –
Samaritan Pentateuch –
Same-sex marriage –
Sanctions –
Sanhedrin –Sasine –
Satyagraha –
Save harmless –
Savings and loan –
Scapegoat –
School of law –
Sciens –
"scienter" –
"scire facias" –
Scope of employment –
Scots law –
Scrivener –
Scutage –
"se defendendo" –
Seal –
Sealed verdict –
Sealing of records –
Search and seizure –
Search warrant –
Second degree murder –
Secondary boycott –
Secret police –
Secret rebate –
Secret tribunal –
Secret trust –
Secretary of State for the Home Department –
Secularism –
Secured creditor –
Secured transaction –
Security –
Security agreement –
Security deposit –
Security for costs –
Security interest –
Security of tenure –
Sedition –
Seduction –
Seigniorage –
Seised –
Seisin –
Seized –
Seizure –
Self-dealing –
Self-defense –
Self-determination –
Self-help –
Self-incrimination –
Seller –
Semble –
Semicha –
Senior lien –
Sentence (law) –
Separate property –
Separation –
Separation of church and state –
Separation of powers –
Separatism –
Septuagint –
Serf –
"seriatim" –
Servant –
Service –
Service by fax –
Service by mail –
Service by publication –
Service mark –
Service of process –
Services –
Servient estate –
Set-aside –
Set-off –
Setting –
Settle –
Settlement –
Settlement agreement –
Settlor –
Seven deadly sins –
Severable contract –
Several liability –
Sex offender –
Sex offender registries in the United States –
Sex tourism –
Sex worker –
Sex-related court cases –
Sexual abuse –
Sexual assault –
Sexual discrimination –
Sexual harassment –
Sexual morality –
Sexual norm –
Shafi'i –
Shaikh –
Shall –
Shame –
Share –
Share capital –
Share certificate –
Shareholder –
Shareholders agreement –
Shareholders' agreement –
Shareholders' derivative action –
Shareholders' meeting –
Sharia law –Sharp practice –
Shepardize –
Sheriff –
Sheriff's sale –
Shield laws –
Shifting the burden of proof –
Shoplifting –
Short cause –
Shortening time –
Show cause order –
Shulkhan Arukh –
Sick pay –
Sidebar –
Sign –
Signature –
Signing bonus –
Silk –
Simple trust –
Simultaneous death act –
Sin –
Sin-offering –
"sine die" –
"sine qua non" –
Single life annuity –
Situated ethics –
Situational ethics –
"situs (law)" –
Slander –
Slander of title –
Slavery –
Slavery at common law –
Small claims court –
Small claims track –
Smuggling –
Socage –
Social capital –
Social control –
Social justice –
Socialist law –
Sodomy –
Sodomy law –
Software license –
Software patent –
Copyright infringement of software –
Sole proprietorship –
Solicitation –
Solicitor –
Solitary confinement –
Solvency –
Solvent –
Sound mind and memory –
Sounds in –
Southern Poverty Law Center –
Sovereign immunity –
Sovereignty –
Spanish Constitution of 1978 –
Spanish Inquisition –
Speaking demurrer –
Special administrator –
Special appearance –
Special damages –
Special master –
Special prosecutor –
Special resolution –
Special verdict –
Specific bequest –
Specific devise –
Specific finding –
Specific legacy –
Specific performance –
Speculative damages –
Speed limit –
Speed trap –
Speedy trial –
Spendthrift clause –
Spendthrift trust –
Spoliation of evidence –
Spontaneous exclamation –
Spot zoning –
Spousal abuse –
Spousal support –
Springing interest –
Squatter –
Squatting –
Stakeholder –
Stamp duty –
Standard form contract –
Standard of care –
Standing –
Star Chamber –
Star chamber proceedings –
"stare decisis" –
State action –
State of domicile –
State of Emergency –
State religion –
State-owned enterprise –
Stationhouse bail –
Statism –
Status conference –
Statute –
Statute of frauds –
Statute of limitations –
Statutes of fraud –
Statutes of limitations –
Statutory Instrument –
Statutory law –
Statutory offer of settlement –
Statutory rape –
Stay away order –
Stay of execution –
Stay of proceedings –
Stet –
Stipendiary magistrate –
Stipulation –
Stock –
Stock certificate –
Stock in trade –
Stock option –
Stockholder –
Stockholders' derivative action –
Stoning –
Stop and frisk –
Strata title –
Strategic lawsuits against public participation –
Straw deed –
Straw man –
Street –
Strict construction –
Strict liability –
Strike –
Strike action –
Structure –
"sua sponte" –
"sub judice" –
"sub modo" –
"sub nomine" –
"sub silentio" –
Sub-tenant –
Subchapter S corporation –
Subcontractor –
Sublease –
Sublet –
Submitted –
Subordination –
Subordination agreement –
Subornation of perjury –
"subpoena" –
"subpoena ad testificum" –
"subpoena duces tecum" –
Subrogation –
Subrogee –
Subrogor –
Subscribe –
Subscribers –
Subsidiary company –
Substantial performance –
Substantive law –
Substituted service –
Substitution of attorney –
Succession –
Successive sentences –
Suffering –
Suffrage –
Suggestion of death -
"sui generis" –
Suicide –
Suitor –
Sum certain –
Summary adjudication of issues –
Summary assessment –
Summary dismissal –
Summary judgment –
Summary offence –
Summation –
Summing –
Summons –
Sunnah –
Superior court –
"supersedeas" –
Superseding cause –
Suppression of evidence –
Supremacy clause –
Supreme court –
Supreme Court of Canada –
Supreme Court of India –
Supreme Court of judicature –
Supreme Court of New Zealand –
Surety –
Surplusage –
Surrebutal –
Surrender –
Surrogate court –
Survivorship –
Suspended sentence –
Sustain –
Syndicate –
Synod –
Synthetic lease

T.R.O. –
Table A –
Tacking (law) –
Tainted evidence –
Taking the fifth –
Tallage –
Talmud –
Tangible personal property –
Tangible property –
Taqlid –
Targeting civilians –
Targum –
Tax –
Tax avoidance –
Tax costs –
Tax credit –
Tax deduction –
Tax evasion –
Tax haven –
Tax law –
Tax sale –
Tax treaty –
Taxation in the United States –
Taxation of costs –
Temporary injunction –
Temporary insanity –
Ten Commandments –
Tenancy –
Tenancy at sufferance –
Tenancy at will –
Tenancy by the entirety –
Tenancy in common –
Tenement –
Tentative trust –
Tenure –
Terms and conditions of employment –
Terms and conditions of purchase –
Terms and conditions of sale –
Terms of disparagement –
"terra nullius" –
Territorial integrity –
Terrorism –
Test Act –
Testacy –
Testamentary –
Testamentary capacity –
Testamentary disposition –
Testamentary trust –
Testate –
Testator –
Testatrix –
Testify –
Testimony –
Texas Declaration of Independence –
Crown –
Old Bailey –
The problem of evil –
Theft –
Theocracy –
Third-party beneficiary –
Thirty-day notice –
Three strikes law –
Three theological virtues –
Tide lands –
Time is of the essence –
Time served –
Timeshare –
Tipstaff –
Tithe –
Title –
Title abstract –
Title insurance –
Title report –
Title search –
Toll –
Toll bridge –
Toll road –
Tontine –
Tools of trade –
Torah –
Torah study –
Torrens title –
Tort –
Tort claims act –
Tortfeasor –
Tortious –
Torture –
Tosafists –
Tosefta –
Total depravity –
Totalitarian democracy –
Totalitarianism –
Totten doctrine –
Totten trust –
Tracing (law) –
Trade –
Trade fixture –
Trade name –
Trade secret –
Trade union –
Trade-Related aspects of Intellectual Property rights –
Trademark –
Trademarks registry –
Tragedy of the commons –
Transfer agent –
Transfer in contemplation of death –
Transfer of shares –
Transferred intent –
Transparency –
Treason –
Treasure trove –
Treasury security –
Treasury stock –
Treaty –
Treaty of Waitangi –
Treble damages –
Trespass –
Trial –
Trial advocacy –
Trial by combat –
Trial by ordeal –
Trial court –
Trial de novo –
Trial "in absentia" –
Tribunal –
Tribute –
Trier of fact –
"trinoda necessitas" –
Triple net lease –
Truancy –
True bill –
Trust law –
Trust fund –
Trust instrument –
Trustee –
Trustee in bankruptcy –
Trustor –
Trusts and estates –
Truth in Lending Act –
Try title –
Turn state's evidence –
Twelve Tables –
Twinkie defense

Uberrima fides –
UCC-1 –
Ulema –
Ultimate fact –
"ultra vires" –
Ultrahazardous activity –
Unclean hands –
Unconscionable –
Unconstitutional –
Under the influence –
Underground Railroad –
Underwrite –
Underwriter –
Underwriting agreement –
Undisclosed principal –
Undivided interest –
Undue influence –
Unfair competition –
Unfair dismissal –
Unfree labour –
Unified estate and gift tax –
Uniform Code of Military Justice –
Uniform Commercial Code –
Uniform reciprocal enforcement of support act –
Unilateral contract –
Uninsured motorist clause –
Unissued stock –
Unitary state –
United Nations Charter –
United Nations Convention Against Torture –
United States bankruptcy court –
United States Bill of Rights –
United States Code –
United States Constitution –
United States constitutional law –
United States court of appeals –
United States Declaration of Independence –
United States Department of Justice –
United States district court –
United States Federal Income Tax Personal Exemption –
United States federal judicial circuit –
United States federal judicial district –
United States Office of the Independent Counsel –
United States Patent and Trademark Office –
United States prison population –
United States Supreme Court –
United States tax reform –
Trademark Law (United States) –
Universal Declaration of Human Rights –
Universal jurisdiction –
Unjust enrichment –
Unjust taking –
Unlawful –
Unlawful assembly –
Unlawful detainer –
"uno flatu" –
Unofficial law –
Unreasonable search and seizure –
Unspecified claim –
Use tax –
Usucaption –
Usufruct –
Usurious –
Usury –
"uti possidetis" –
Utilitarianism –
Utility (patent)

Vacate –
"Vacatio legis" –
Valid claim –
Valuable consideration –
Variance –
Vehicular manslaughter –
"vel non" –
Vendee –
Vendor –
"venire" –
Venue (law) –
Verdict –
Vest –
Vested –
Vested remainder –
Vested right –
Vexatious litigation –
Vicarious liability –
Vice-Chancellor (UK legal system) –
"vice versa" –
"vide" –
"videlicet" –
Vienna Convention on Diplomatic Relations –
Vienna Convention on the Law of Treaties –
Vigilante –
Violence –
Virginia Declaration of Rights –
Virtue ethics –
Virtue jurisprudence –
Visitation right –
"viz." –
Void –
Void for vagueness –
Void marriage –
Voidable –
Voidable marriage –
Voir dire –
Volens –
Voluntary association –
Voluntary bankruptcy –
Voting trust –
Vulgate

Wage execution –
Wahhabism –
Waive –
Waiver –
Walking possession –
Waqf –
War crime –
War Crimes Law (Belgium) –
War on Drugs –
War Powers Resolution –
War reparations –
Ward (legal) –
Ward of court –
Wardship –
Warrant (legal) –
Warrant of committal –
Warrant of delivery –
Warrant of execution –
Warrant of possession –
Warranty –
Warranty deed –
Waste –
Watered stock –
Weimar constitution –
West American Digest System –
Wet reckless –
Whiplash (medicine) –
Whistleblower –
White collar crime –
Widow –
Widow's election –
Widower –
Will –
Will contest –
Willful –
Willfully –
Winding up –
Window tax –
Wiretap –
Witchhunt –
Witness –
Witness stand –
Witness statement –
Words of art –
Work stoppage –
Workers' compensation –
Workers' compensation acts –
Workmen's compensation –
World Intellectual Property Organization –
World Trade Organization –
Writ –
Writ of attachment –
Writ of coram nobis –
Writ of execution –
Writ of mandate –
Wrongful death –
Wrongful discharge –
Wrongful dismissal –
Wrongful termination –
Wrongful trading

Nothing Law related seems to begin with X, if you find something please add it!

Yellow Dog contract –
Yeshiva –
Your honor –
Youthful offender

Zoning


</doc>
<doc id="59350352" url="https://en.wikipedia.org/wiki?curid=59350352" title="Case theory (in law)">
Case theory (in law)

A case theory (aka theory of case, theory of a case, or theory of the case) is “a detailed, coherent, accurate story of what occurred" involving both a legal theory (i.e., claims/causes of action or affirmative defenses) and a factual theory (i.e., an explanation of how a particular course of events could have happened).

That is, a case theory is a logical description of events that the attorney wants the judge or jury to adopt as their own perception of the underlying situation. The theory is often expressed in a story that should be compellingly probable. Case theory is distinguished from jurisprudence (aka legal theory) as general theory of law not specific to a case.


</doc>
<doc id="1704112" url="https://en.wikipedia.org/wiki?curid=1704112" title="Legal case">
Legal case

A legal case is a dispute between opposing parties resolved by a court, or by some equivalent legal process. A legal case may be either civil or criminal law. In each legal case there is an accuser and one or more defendants.

A civil case, more commonly known as a lawsuit or controversy, begins when a plaintiff files a document called a complaint with a court, informing the court of the wrong that the plaintiff has allegedly suffered because of the defendant, and requesting a remedy. The remedy sought may be money, an injunction, which requires the defendant to perform or refrain from performing some action, or a declaratory judgment, which determines that the plaintiff has certain legal rights. The remedy will be prescribed by the court if the plaintiff wins the case. A civil case can also be arbitrated through arbitration, which may result in a faster settlement, with lower costs, than could be obtained by going through a trial.

The plaintiff must make a genuine effort to inform the defendant of the case through service of process, by which the plaintiff delivers to the defendant the same documents that the plaintiff filed with the court.

At any point during the case, the parties can agree to a settlement, which will end the case, although in some circumstances, such as in class actions, a settlement requires court approval in order to be binding.

Cases involving separation including asset division, support (a.k.a. maintenance or alimony), and matters related to children are handled differently in different jurisdictions. Often, the court's procedure for dealing with family cases is very similar to that of a civil case (it requires service and disclosure, and will issue judgments).

Divorce and separation from a spouse is one of the most stressful situations, as rated by the Holmes and Rahe Stress Scale, and so family proceedings are increasingly being "divorced" from the often very formal and impersonal process of civil proceedings, and given special treatment.

A criminal case, in common law jurisdictions, begins when a person suspected of a crime is indicted by a grand jury or otherwise charged with the offense by a government official called a prosecutor or district attorney.

A criminal case may in some jurisdictions be settled before a trial through a plea bargain. Typically, in a plea bargain, the defendant agrees to plead guilty to a lesser charge than that which was originally brought by the grand jury or prosecutor. A defendant who goes to trial risks greater penalties than would normally be imposed through a plea bargain.

Legal cases, whether criminal or civil, are premised on the idea that a dispute will be fairly resolved when a legal procedure exists by which the dispute can be brought to a factfinder not otherwise involved in the case, who can evaluate evidence to determine the truth with respect to claims of guilt, innocence, liability, or lack of fault. Details of the procedure may depend on both the kind of case and the kind of system in which the case is brought - whether, for example, it is an inquisitorial system or a solo

In most systems, the governing body responsible for overseeing the courts assigns a unique number/letter combination or similar designation to each case in order to track the various disputes that are or have been before it. The outcome of the case is recorded, and can later be reviewed by obtaining a copy of the documents associated with the designation previously assigned to the case.

However, it is often more convenient to refer to casesparticularly landmark and other notable casesby a title of the form "Claimant v Defendant" (e.g. "Arkell v Pressdram"). Where a legal proceeding does not have formally designated adverse parties, a form such as "In re", "Re" or "In the matter of" is used (e.g. "In re Gault"). The "v" separating the parties is an abbreviation of the Latin versus, but, when spoken in Commonwealth countries, it is normally rendered as "and" or "against" (as in, for example, Charles Dickens' "Jarndyce and Jarndyce"). Where it is considered necessary to protect the anonymity of a natural person, some cases may have one or both parties replaced by a standard pseudonym (Jane Roe in "Roe v. Wade") or by an initial ("D v D"). In titles such as "R v Adams", however, the initial "R" is usually an abbreviation for the Latin Rex or Regina, i.e. for the Crown. (For an explanation of other terms that may appear in case titles, see the Glossary of legal terms.)



</doc>
<doc id="60874044" url="https://en.wikipedia.org/wiki?curid=60874044" title="Frank v. United States">
Frank v. United States

Frank v. United States, , was a U.S. Supreme Court case in which it was held that when an offender is placed on probation, and the maximum sentence for violating probation is no more than six months, the crime falls into the category of a petty offense, and therefore the defendant is not entitled to a jury trial.



</doc>
<doc id="57255413" url="https://en.wikipedia.org/wiki?curid=57255413" title="Hemp Industries Association v. Drug Enforcement Administration">
Hemp Industries Association v. Drug Enforcement Administration

Hemp Industries Association v. Drug Enforcement Administration refers to two lawsuits concerning the legality of cannabis extracts and other products from the hemp plant that have very low or nonexistent natural THC levels, including CBD oil, in the United States. The first is from 2004 and the second is from 2018. 

In the 2004 case the 9th Circuit Court of Appeals established that the DEA had made illegal regulations intended to implement laws creating separate legal regimes for marijuana and THC. The court found the DEA's rules infringed upon legal trade in parts of the hemp plant exempted from regulation by Congress and against the will of Congress when Congress passed the marijuana and THC related legislation.

Specifically, the DEA chose to ban trade parts of the hemp plant legally exempted from the definition of "marihuana" by using THC related legislation. The THC legislation was passed without repealing the marijuana legislation superficially creating two contradictory legal regimes for the same substance. When the court looked into the history of the legislation, the court found Congress was attempting to ban synthetic THC which had recently been synthesized in a lab. Because Congress chose not to repeal the marijuana legislation with the exemptions, the court concluded that the natural plant was intended to be covered by the marijuana legislation and the synthetic lab derived THC was intended to be banned by the THC legislation.

The court further found that even if it regulation was legal, the DEA didn't follow the Congressionally mandated process for a federal agency to create regulations to implement laws so the regulations were struck down.

In 2018 Hemp Industries Association alleged the DEA for created and was enforcing a similar regulation to the one that the ninth circuit court of appeals struck down in 2004. The parties reached a settlement in which the DEA would clarify the new regulation in light of certain Congressional Acts and the Ninth Circuits previous ruling and distribute this statement to the public and its partner agencies that the plaintiff alleges were violating the 2004 ruling.

The plaintiff, Hemp Industries Association (HIA) claimed that CBD is not regulated by the Controlled Substances Act; the Drug Enforcement Administration took steps in December, 2016 to index "marihuana extract" as a substance under its purview, with code number 7350. Part of the legal challenge stipulates that the DEA's action contravenes the Agricultural Act of 2014 (also called the 2014 Farm Bill) which allows hemp farming under certain conditions. After the lawsuit was begun a public statement was released. It started "Because [of] recent public inquiries that DEA has received following the publication of the Final Rule suggest[ing] there may be some misunderstanding about the source of cannabinoids in the cannabis plant", the DEA issued a clarification of the code which stated it did not apply to products derived from "parts of the cannabis plant excluded from the CSA definition of marijuana, such as the flowering tops, resin, and leaves". 

The 9th Circuit Court of Appeals heard the case in February, 2018. A number of members of the U.S. Congress filed an amicus brief supporting HIA.



</doc>
<doc id="53289527" url="https://en.wikipedia.org/wiki?curid=53289527" title="Organizational footprint">
Organizational footprint

Organizational footprint defines the geographic, functional, and divisional range over which an organization operates.


</doc>
<doc id="105070" url="https://en.wikipedia.org/wiki?curid=105070" title="Organization">
Organization

An organization or organisation is an entity comprising multiple people, such as an institution or an association, that has a particular purpose.

The word is derived from the Greek word "organon", which means tool or instrument, musical instrument, and organ.

There are a variety of legal types of organisations, including corporations, governments, non-governmental organisations, political organisations, international organisations, armed forces, charities, not-for-profit corporations, partnerships, cooperatives, and educational institutions.

A hybrid organisation is a body that operates in both the public sector and the private sector simultaneously, fulfilling public duties and developing commercial market activities.

A voluntary association is an organisation consisting of volunteers. Such organisations may be able to operate without legal formalities, depending on jurisdiction, including informal clubs or coordinating bodies with a goal in mind which they may express in the form of an Manifesto,Mission statement,or in an informal manner reflected in what they do because remember every action done by an organization both legal and illegal reflects a goal in mind. 

Organisations may also operate secretly or illegally in the case of secret societies, criminal organisations and resistance movements. And in some cases may have obstacles from other organizations (ex: MLK's organization) but what makes an organization an organization is not the paperwork that makes it official but to be an organization there must be four things:


But what makes an organization recognized by the government is either filling out Incorporation (business) or recognition in the form of either societal pressure (ex: Advocacy group), causing concerns (ex: Resistance movement) or being considered the spokesperson of a group of people subject to negotiation (ex: the Polisario Front being recognized as the sole representative of the Sahawri people and forming a partially recognized state.) 

Compare the concept of social groups, which may include non-organizations.

The study of organisations includes a focus on optimising organisational structure. According to management science, most human organisations fall roughly into four types:

These consist of a group of peers who decide as a group, perhaps by voting. The difference between a jury and a committee is that the members of the committee are usually assigned to perform or lead further actions after the group comes to a decision, whereas members of a jury come to a decision. In common law countries, legal juries render decisions of guilt, liability and quantify damages; juries are also used in athletic contests, book awards and similar activities. Sometimes a selection committee functions like a jury. In the Middle Ages, juries in continental Europe were used to determine the law according to consensus among local notables.

Committees are often the most reliable way to make decisions. Condorcet's jury theorem proved that if the average member votes better than a roll of dice, then adding more members increases the number of majorities that can come to a correct vote (however correctness is defined). The problem is that if the average member is subsequently "worse" than a roll of dice, the committee's decisions grow worse, not better; therefore, staffing is crucial.

Parliamentary procedure, such as Robert's Rules of Order, helps prevent committees from engaging in lengthy discussions without reaching decisions.

This organisational structure promotes internal competition. Inefficient components of the organisation starve, while effective ones get more work. Everybody is paid for what they actually do, and so runs a tiny business that has to show a profit, or they are fired.

Companies who utilise this organisation type reflect a rather one-sided view of what goes on in ecology. It is also the case that a natural ecosystem has a natural border - ecoregions do not, in general, compete with one another in any way, but are very autonomous.

The pharmaceutical company GlaxoSmithKline talks about functioning as this type of organisation in this external article from "The Guardian".
By:Bastian Batac De Leon.

This organisational type assigns each worker two bosses in two different hierarchies. One hierarchy is "functional" and assures that each type of expert in the organisation is well-trained, and measured by a boss who is super-expert in the same field. The other direction is "executive" and tries to get projects completed using the experts. Projects might be organised by products, regions, customer types, or some other schemes.

As an example, a company might have an individual with overall responsibility for products X and Y, and another individual with overall responsibility for engineering, quality control, etc. Therefore, subordinates responsible for quality control of project X will have two reporting lines.

A hierarchy exemplifies an arrangement with a leader who leads other individual members of the organisation. This arrangement is often associated with basis that there are enough imagine a real pyramid, if there are not enough stone blocks to hold up the higher ones, gravity would irrevocably bring down the monumental structure. So one can imagine that if the leader does not have the support of his subordinates, the entire structure will collapse. Hierarchies were satirised in "The Peter Principle" (1969), a book that introduced "hierarchiology" and the saying that "in a hierarchy every employee tends to rise to his level of incompetence."

In the social sciences, organisations are the object of analysis for a number of disciplines, such as sociology, economics, political science, psychology, management, and organisational communication. The broader analysis of organisations is commonly referred to as organisational structure, organisational studies, organisational behaviour, or organisation analysis. A number of different perspectives exist, some of which are compatible:

Sociology can be defined as the science of the institutions of modernity; specific institutions serve a function, akin to the individual organs of a coherent body. In the social and political sciences in general, an "organisation" may be more loosely understood as the planned, coordinated and purposeful action of human beings working through collective action to reach a common goal or construct a tangible product. This action is usually framed by formal membership and form (institutional rules). Sociology distinguishes the term organisation into planned formal and unplanned informal (i.e. spontaneously formed) organisations. Sociology analyses organisations in the first line from an institutional perspective. In this sense, organisation is an enduring arrangement of elements. These elements and their actions are determined by rules so that a certain task can be fulfilled through a system of coordinated division of labour.

Economic approaches to organisations also take the division of labour as a starting point. The division of labour allows for (economies of) specialisation. Increasing specialisation necessitates coordination. From an economic point of view, markets and organisations are alternative coordination mechanisms for the execution of transactions.

An organisation is defined by the elements that are part of it (who belongs to the organisation and who does not?), its communication (which elements communicate and how do they communicate?), its autonomy (which changes are executed autonomously by the organisation or its elements?), and its rules of action compared to outside events (what causes an organisation to act as a collective actor?).

By coordinated and planned cooperation of the elements, the organisation is able to solve tasks that lie beyond the abilities of the single elements. The price paid by the elements is the limitation of the degrees of freedom of the elements. Advantages of organisations are enhancement (more of the same), addition (combination of different features) and extension. Disadvantages can be inertness (through co-ordination) and loss of interaction.

Among the theories that are or have been influential are:


A leader in a formal, hierarchical organisation, is appointed to a managerial position and has the right to command and enforce obedience by virtue of the authority of his position. However, he must possess adequate personal attributes to match his authority, because authority is only potentially available to him. In the absence of sufficient personal competence, a manager may be confronted by an emergent leader who can challenge his role in the organisation and reduce it to that of a figurehead. However, only authority of position has the backing of formal sanctions. It follows that whoever wields personal influence and power can legitimise this only by gaining a formal position in the hierarchy, with commensurate authority.

An organisation that is established as a means for achieving defined objectives has been referred to as a formal organisation. Its design specifies how goals are subdivided and reflected in subdivisions of the organisation. Divisions, departments, sections, positions, jobs, and tasks make up this work structure. Thus, the formal organisation is expected to behave impersonally in regard to relationships with clients or with its members. According to Weber's definition, entry and subsequent advancement is by merit or seniority. Each employee receives a salary and enjoys a degree of tenure that safeguards him from the arbitrary influence of superiors or of powerful clients. The higher his position in the hierarchy, the greater his presumed expertise in adjudicating problems that may arise in the course of the work carried out at lower levels of the organisation. It is this bureaucratic structure that forms the basis for the appointment of heads or chiefs of administrative subdivisions in the organisation and endows them with the authority attached to their position.

In contrast to the appointed head or chief of an administrative unit, a leader emerges within the context of the informal organisation that underlies the formal structure. The informal organisation expresses the personal objectives and goals of the individual membership. Their objectives and goals may or may not coincide with those of the formal organisation. The informal organisation represents an extension of the social structures that generally characterise human life – the spontaneous emergence of groups and organisations as ends in themselves.

In prehistoric times, man was preoccupied with his personal security, maintenance, protection, and survival. Now man spends a major portion of his waking hours working for organisations. His need to identify with a community that provides security, protection, maintenance, and a feeling of belonging continues unchanged from prehistoric times. This need is met by the informal organisation and its emergent, or unofficial, leaders.

Leaders emerge from within the structure of the informal organisation. Their personal qualities, the demands of the situation, or a combination of these and other factors attract followers who accept their leadership within one or several overlay structures. Instead of the authority of position held by an appointed head or chief, the emergent leader wields influence or power. Influence is the ability of a person to gain cooperation from others by means of persuasion or control over rewards. Power is a stronger form of influence because it reflects a person's ability to enforce action through the control of a means of punishment.





</doc>
<doc id="13692155" url="https://en.wikipedia.org/wiki?curid=13692155" title="Philosophy">
Philosophy

Philosophy (from Greek , "philosophia", literally "love of wisdom") is the study of general and fundamental questions about existence, knowledge, values, reason, mind, and language. Such questions are often posed as problems to be studied or resolved. The term was probably coined by Pythagoras (c. 570 – 495 BCE). Philosophical methods include questioning, critical discussion, rational argument, and systematic presentation. Classic philosophical questions include: Is it possible to know anything and to prove it? What is most real? Philosophers also pose more practical and concrete questions such as: Is there a best way to live? Is it better to be just or unjust (if one can get away with it)? Do humans have free will?

Historically, "philosophy" encompassed any body of knowledge. From the time of Ancient Greek philosopher Aristotle to the 19th century, "natural philosophy" encompassed astronomy, medicine, and physics. For example, Newton's 1687 "Mathematical Principles of Natural Philosophy" later became classified as a book of physics. In the 19th century, the growth of modern research universities led academic philosophy and other disciplines to professionalize and specialize. In the modern era, some investigations that were traditionally part of philosophy became separate academic disciplines, including psychology, sociology, linguistics, and economics.

Other investigations closely related to art, science, politics, or other pursuits remained part of philosophy. For example, is beauty objective or subjective? Are there many scientific methods or just one? Is political utopia a hopeful dream or hopeless fantasy? Major sub-fields of academic philosophy include metaphysics ("concerned with the fundamental nature of reality and being"), epistemology (about the "nature and grounds of knowledge [and]...its limits and validity"), ethics, aesthetics, political philosophy, logic and philosophy of science.

Traditionally, the term "philosophy" referred to any body of knowledge. In this sense, philosophy is closely related to religion, mathematics, natural science, education and politics. Newton's 1687 "Mathematical Principles of Natural Philosophy" is classified in the 2000s as a book of physics; he used the term "natural philosophy" because it used to encompass disciplines that later became associated with sciences such as astronomy, medicine and physics.

In the first part of the first book of his "Academics", Cicero introduced the division of philosophy into logic, physics, and ethics; in section thirteen of the first book of his "Lives and Opinions of the Eminent Philosophers", the 3rd-century Diogenes Laërtius, the first historian of philosophy, established the traditional division of philosophical inquiry into three parts:

This division is not obsolete but has changed. Natural philosophy has split into the various natural sciences, especially astronomy, physics, chemistry, biology, and cosmology. Moral philosophy has birthed the social sciences, but still includes value theory (including aesthetics, ethics, political philosophy, etc.). Metaphysical philosophy has birthed formal sciences such as logic, mathematics and philosophy of science, but still includes epistemology, cosmology and others.

Many philosophical debates that began in ancient times are still debated today. Colin McGinn and others claim that no philosophical progress has occurred during that interval. Chalmers and others, by contrast, see progress in philosophy similar to that in science, while Talbot Brewer argued that "progress" is the wrong standard by which to judge philosophical activity.

In one general sense, philosophy is associated with wisdom, intellectual culture and a search for knowledge. In that sense, all cultures and literate societies ask philosophical questions such as "how are we to live" and "what is the nature of reality". A broad and impartial conception of philosophy then, finds a reasoned inquiry into such matters as reality, morality and life in all world civilizations.

Western philosophy is the philosophical tradition of the Western world and dates to Pre-Socratic thinkers who were active in Ancient Greece in the 6th century BCE such as Thales (c. 624 – 546 BCE) and Pythagoras (c. 570 – 495 BCE) who practiced a "love of wisdom" ("philosophia") and were also termed "physiologoi" (students of "physis", or nature). Socrates was a very influential philosopher, who insisted that he possessed no "wisdom" but was a "pursuer of" wisdom. Western philosophy can be divided into three eras: Ancient (Greco-Roman), Medieval philosophy (Christian European), and Modern philosophy.

The Ancient era was dominated by Greek philosophical schools which arose out of the various pupils of Socrates, such as Plato, who founded the Platonic Academy and his student Aristotle, founding the Peripatetic school, who were both extremely influential in Western tradition. Other traditions include Cynicism, Stoicism, Greek Skepticism and Epicureanism. Important topics covered by the Greeks included metaphysics (with competing theories such as atomism and monism), cosmology, the nature of the well-lived life (eudaimonia), the possibility of knowledge and the nature of reason (logos). With the rise of the Roman empire, Greek philosophy was also increasingly discussed in Latin by Romans such as Cicero and Seneca.

Medieval philosophy (5th–16th centuries) is the period following the fall of the Western Roman Empire and was dominated by the rise of Christianity and hence reflects Judeo-Christian theological concerns as well as retaining a continuity with Greco-Roman thought. Problems such as the existence and nature of God, the nature of faith and reason, metaphysics, the problem of evil were discussed in this period. Some key Medieval thinkers include St. Augustine, Thomas Aquinas, Boethius, Anselm and Roger Bacon. Philosophy for these thinkers was viewed as an aid to Theology ("ancilla theologiae") and hence they sought to align their philosophy with their interpretation of sacred scripture. This period saw the development of Scholasticism, a text critical method developed in medieval universities based on close reading and disputation on key texts. The Renaissance period saw increasing focus on classic Greco-Roman thought and on a robust Humanism.

Early modern philosophy in the Western world begins with thinkers such as Thomas Hobbes and René Descartes (1596–1650). Following the rise of natural science, Modern philosophy was concerned with developing a secular and rational foundation for knowledge and moved away from traditional structures of authority such as religion, scholastic thought and the Church. Major modern philosophers include Spinoza, Leibniz, Locke, Berkeley, Hume, and Kant. 19th-century philosophy is influenced by the wider movement termed the Enlightenment, and includes figures such as Hegel a key figure in German idealism, Kierkegaard who developed the foundations for existentialism, Nietzsche a famed anti-Christian, John Stuart Mill who promoted Utilitarianism, Karl Marx who developed the foundations for Communism and the American William James. The 20th century saw the split between Analytic philosophy and Continental philosophy, as well as philosophical trends such as Phenomenology, Existentialism, Logical Positivism, Pragmatism and the Linguistic turn.

The regions of the fertile Crescent, Iran and Arabia are home to the earliest known philosophical Wisdom literature and is today mostly dominated by Islamic culture. Early wisdom literature from the fertile crescent was a genre which sought to instruct people on ethical action, practical living and virtue through stories and proverbs. In Ancient Egypt, these texts were known as sebayt ('teachings') and they are central to our understandings of Ancient Egyptian philosophy. Babylonian astronomy also included much philosophical speculations about cosmology which may have influenced the Ancient Greeks. Jewish philosophy and Christian philosophy are religio-philosophical traditions that developed both in the Middle East and in Europe, which both share certain early Judaic texts (mainly the Tanakh) and monotheistic beliefs. Jewish thinkers such as the Geonim of the Talmudic Academies in Babylonia and Maimonides engaged with Greek and Islamic philosophy. Later Jewish philosophy came under strong Western intellectual influences and includes the works of Moses Mendelssohn who ushered in the Haskalah (the Jewish Enlightenment), Jewish existentialism and Reform Judaism.

Pre-Islamic Iranian philosophy begins with the work of Zoroaster, one of the first promoters of monotheism and of the dualism between good and evil. This dualistic cosmogony influenced later Iranian developments such as Manichaeism, Mazdakism, and Zurvanism.

After the Muslim conquests, Early Islamic philosophy developed the Greek philosophical traditions in new innovative directions. This Islamic Golden Age influenced European intellectual developments. The two main currents of early Islamic thought are Kalam which focuses on Islamic theology and Falsafa which was based on Aristotelianism and Neoplatonism. The work of Aristotle was very influential among the falsafa such as al-Kindi (9th century), Avicenna (980 – June 1037) and Averroes (12th century). Others such as Al-Ghazali were highly critical of the methods of the Aristotelian falsafa. Islamic thinkers also developed a scientific method, experimental medicine, a theory of optics and a legal philosophy. Ibn Khaldun was an influential thinker in philosophy of history.

In Iran several schools of Islamic philosophy continued to flourish after the Golden Age and include currents such as Illuminationist philosophy, Sufi philosophy, and Transcendent theosophy. The 19th- and 20th-century Arab world saw the Nahda (awakening or renaissance) movement which influenced contemporary Islamic philosophy.

Indian philosophy (; 'world views', 'teachings') refers to the diverse philosophical traditions that emerged since the ancient times on the Indian subcontinent. Jainism and Buddhism originated at the end of the Vedic period, while Hinduism emerged as a fusion of diverse traditions, starting after the end of the Vedic period.

Hindus generally classify these traditions as either orthodox or heterodox – āstika or nāstika – depending on whether they accept the authority of the Vedas and the theories of Brahman and Atman (soul, self) therein. The orthodox schools include the Hindu traditions of thought, while the heterodox schools include the Buddhist and the Jain traditions. Other schools include the Ajñana, Ajivika and Cārvāka which became extinct over their history.

Important Indian philosophical concepts shared by the Indian philosophies include dharma, karma, artha, kama, dukkha (suffering), anitya (anicca, impermanence), dhyana (jhana, meditation), renunciation (with or without monasticism or asceticism), various samsara with cycles of rebirth, moksha (nirvana, kaivalya, liberation from rebirth), and virtues such as ahimsa.

Jain philosophy accepts the concept of a permanent soul (jiva) as one of the five "astikayas", or eternal infinite categories that make up the substance of existence. The other four being "dharma", "adharma", "akasha" (space) and "pudgala" (matter). The Jain thought separates matter from the soul completely. It has two major subtraditions: Digambara (sky dressed, naked) and Svetambara (white dressed), along with several more minor traditions such as Terapanthis. Asceticism is a major monastic virtue in Jainism. Jain texts such as the "Tattvartha Sutra" state that right faith, right knowledge and right conduct is the path to liberation. The Jain thought holds that all existence is cyclic, eternal and uncreated. The "Tattvartha Sutra" is the earliest known, most comprehensive and authoritative compilation of Jain philosophy.

Buddhist philosophy begins with the thought of Gautama Buddha (fl. between sixth and fourth centuries BCE) and is preserved in the early Buddhist texts. It originated in India and later spread to East Asia, Tibet, Central Asia, and Southeast Asia, developing syncretic traditions in these regions. The Mahayana branches of Buddhist thought is the dominant philosophical tradition in East Asian regions such as China, Korea and Japan. The Theravada forms are dominant in Southeast Asian countries such as Sri Lanka, Burma and Thailand.

Because ignorance to the true nature of things is considered one of the roots of suffering (dukkha), Buddhist philosophy is concerned with epistemology, metaphysics, ethics and psychology. Buddhist philosophical texts must also be understood within the context of meditative practices which are supposed to bring about certain cognitive shifts. Key innovative concepts include the Four Noble Truths as an analysis of dukkha, Anicca (impermanence) and Anatta (not-self).

After the death of the Buddha, various groups began to systematize his main teachings, eventually developing comprehensive philosophical systems termed 'Abhidharma'. Following the Abhidharma schools, Mahayana philosophers such as Nagarjuna and Vasubandhu developed the theories of Shunyata (emptiness of all phenomena) and Vijñapti-matra (appearance only), a form of phenomenology or transcendental idealism. The Dignāga school of Pramāṇa (lit. means of knowledge) promoted a complex form of epistemology and Buddhist logic.

There were numerous schools, sub-schools and traditions of Buddhist philosophy in India. According to Oxford professor of Buddhist philosophy Jan Westerhoff, the major Indian schools from 300 BCE to 1000 CE were:


After the disappearance of Buddhism from India, some of these philosophical traditions continued to develop in the Tibetan Buddhist, East Asian Buddhist and Theravada Buddhist traditions.

The Vedas-based orthodox schools are a part of the Hinduism traditions and they are traditionally classified into six "darsanas": Nyaya, Vaisheshika, Samkhya, Yoga, Mīmāṃsā and Vedanta. The Vedas as a knowledge source were interpreted differently by these six schools of Hindu philosophy, with varying degrees of overlap. They represent a "collection of philosophical views that share a textual connection", according to Chadha. They also reflect a tolerance for a diversity of philosophical interpretations within Hinduism while sharing the same foundation.

Some of the earliest surviving Hindu mystical and philosophical texts are the Upanishads of the later Vedic period (1000–500 BCE). Hindu philosophers of the six schools developed systems of epistemology (pramana) and investigated topics such as metaphysics, ethics, psychology ("guna"), hermeneutics and soteriology within the framework of the Vedic knowledge, while presenting a diverse collection of interpretations. These schools of philosophy accepted the Vedas and the Vedic concept of "Atman" and "Brahman", differed from the following Indian religions that rejected the authority of the Vedas:

The commonly named six orthodox schools over time led to what has been called the "Hindu synthesis" as exemplified by its scripture the "Bhagavad Gita".

East Asian philosophical thought began in Ancient China, and Chinese philosophy begins during the Western Zhou Dynasty and the following periods after its fall when the "Hundred Schools of Thought" flourished (6th century to 221 BCE). This period was characterized by significant intellectual and cultural developments and saw the rise of the major philosophical schools of China, Confucianism, Legalism, and Daoism as well as numerous other less influential schools. These philosophical traditions developed metaphysical, political and ethical theories such Tao, Yin and yang, Ren and Li which, along with Chinese Buddhism, directly influenced Korean philosophy, Vietnamese philosophy and Japanese philosophy (which also includes the native Shinto tradition). Buddhism began arriving in China during the Han Dynasty (206 BCE – 220 CE), through a gradual Silk road transmission and through native influences developed distinct Chinese forms (such as Chan/Zen) which spread throughout the East Asian cultural sphere. During later Chinese dynasties like the Ming Dynasty (1368–1644) as well as in the Korean Joseon dynasty (1392–1897) a resurgent Neo-Confucianism led by thinkers such as Wang Yangming (1472–1529) became the dominant school of thought, and was promoted by the imperial state.

In the Modern era, Chinese thinkers incorporated ideas from Western philosophy. Chinese Marxist philosophy developed under the influence of Mao Zedong, while a Chinese pragmatism under Hu Shih and New Confucianism's rise was influenced by Xiong Shili. Modern Japanese thought meanwhile developed under strong Western influences such as the study of Western Sciences (Rangaku) and the modernist Meirokusha intellectual society which drew from European enlightenment thought. The 20th century saw the rise of State Shinto and also Japanese nationalism. The Kyoto School, an influential and unique Japanese philosophical school developed from Western phenomenology and Medieval Japanese Buddhist philosophy such as that of Dogen.

African philosophy is philosophy produced by African people, philosophy that presents African worldviews, ideas and themes, or philosophy that uses distinct African philosophical methods. Modern African thought has been occupied with Ethnophilosophy, with defining the very meaning of African philosophy and its unique characteristics and what it means to be African. During the 17th century, Ethiopian philosophy developed a robust literary tradition as exemplified by Zera Yacob. Another early African philosopher was Anton Wilhelm Amo (c. 1703–1759) who became a respected philosopher in Germany. Distinct African philosophical ideas include Ujamaa, the Bantu idea of 'Force', Négritude, Pan-Africanism and Ubuntu. Contemporary African thought has also seen the development of Professional philosophy and of Africana philosophy, the philosophical literature of the African diaspora which includes currents such as black existentialism by African-Americans. Modern African thinkers have been influenced by Marxism, African-American literature, Critical theory, Critical race theory, Postcolonialism and Feminism.

Indigenous American philosophy is the philosophy of the Indigenous people of the Americas. There is a wide variety of beliefs and traditions among these different American cultures. Among some of the Native Americans in the United States there is a belief in a metaphysical principle called the "Great Mystery" (Siouan: Wakan Tanka, Algonquian: Gitche Manitou). Another widely shared concept was that of Orenda or "spiritual power". According to Peter M. Whiteley, for the Native Americans, "Mind is critically informed by transcendental experience (dreams, visions and so on) as well as by reason." The practices to access these transcendental experiences are termed Shamanism. Another feature of the indigenous American worldviews was their extension of ethics to non-human animals and plants.

In Mesoamerica, Aztec philosophy was an intellectual tradition developed by individuals called Tlamatini ('those who know something') and its ideas are preserved in various Aztec codices. The Aztec worldview posited the concept of an ultimate universal energy or force called Ometeotl which can be translated as "Dual Cosmic Energy" and sought a way to live in balance with a constantly changing, "slippery" world. The theory of Teotl can be seen as a form of Pantheism. Aztec philosophers developed theories of metaphysics, epistemology, values, and aesthetics. Aztec ethics was focused on seeking "tlamatiliztli" (knowledge, wisdom) which was based on moderation and balance in all actions as in the Nahua proverb "the middle good is necessary".

The Inca civilization also had an elite class of philosopher-scholars termed the Amawtakuna who were important in the Inca education system as teachers of religion, tradition, history and ethics. Key concepts of Andean thought are Yanantin and Masintin which involve a theory of “complementary opposites” that sees polarities (such as male/female, dark/light) as interdependent parts of a harmonious whole.

Philosophical questions can be grouped into categories. These groupings allow philosophers to focus on a set of similar topics and interact with other thinkers who are interested in the same questions. The groupings also make philosophy easier for students to approach. Students can learn the basic principles involved in one aspect of the field without being overwhelmed with the entire set of philosophical theories.

Various sources present different categorical schemes. The categories adopted in this article aim for breadth and simplicity.

These five major branches can be separated into sub-branches and each sub-branch contains many specific fields of study.

These divisions are neither exhaustive, nor mutually exclusive. (A philosopher might specialize in Kantian epistemology, or Platonic aesthetics, or modern political philosophy.) Furthermore, these philosophical inquiries sometimes overlap with each other and with other inquiries such as science, religion or mathematics.

Metaphysics is the study of the most general features of reality, such as existence, time, objects and their properties, wholes and their parts, events, processes and causation and the relationship between mind and body. Metaphysics includes cosmology, the study of the world in its entirety and ontology, the study of being.

A major point of debate is between realism, which holds that there are entities that exist independently of their mental perception and idealism, which holds that reality is mentally constructed or otherwise immaterial. Metaphysics deals with the topic of identity. Essence is the set of attributes that make an object what it fundamentally is and without which it loses its identity while accident is a property that the object has, without which the object can still retain its identity. Particulars are objects that are said to exist in space and time, as opposed to abstract objects, such as numbers, and universals, which are properties held by multiple particulars, such as redness or a gender. The type of existence, if any, of universals and abstract objects is an issue of debate.

Epistemology is the study of knowledge (Greek episteme). Epistemologists study the putative sources of knowledge, including intuition, a priori reason, memory, perceptual knowledge, self-knowledge and testimony. They also ask: What is truth? Is knowledge justified true belief? Are any beliefs justified? Putative knowledge includes propositional knowledge (knowledge that something is the case), know-how (knowledge of how to do something) and acquaintance (familiarity with someone or something). Epistemologists examine these and ask whether knowledge is really possible.

Skepticism is the position which doubts claims to knowledge. The regress argument, a fundamental problem in epistemology, occurs when, in order to completely prove any statement, its justification itself needs to be supported by another justification. This chain can go on forever, called infinitism, it can eventually rely on basic beliefs that are left unproven, called foundationalism, or it can go in a circle so that a statement is included in its own chain of justification, called coherentism.

Rationalism is the emphasis on reasoning as a source of knowledge. It is associated with a priori knowledge, which is independent of experience, such as math and logical deduction. Empiricism is the emphasis on observational evidence via sensory experience as the source of knowledge.

Among the numerous topics within metaphysics and epistemology, broadly construed are:

Value theory (or axiology) is the major branch of philosophy that addresses topics such as goodness, beauty and justice. Value theory includes ethics, aesthetics, political philosophy, feminist philosophy, philosophy of law and more.

Ethics, or "moral philosophy", studies and considers what is good and bad conduct, right and wrong values, and good and evil. Its primary investigations include how to live a good life and identifying standards of morality. It also includes meta-investigations about whether a best way to live or related standards exists. The main branches of ethics are normative ethics, meta-ethics and applied ethics.

A major area of debate involves consequentialism, in which actions are judged by the potential results of the act, such as to maximize happiness, called utilitarianism, and deontology, in which actions are judged by how they adhere to principles, irrespective of negative ends.

Aesthetics is the "critical reflection on art, culture and nature." It addresses the nature of art, beauty and taste, enjoyment, emotional values, perception and with the creation and appreciation of beauty. It is more precisely defined as the study of sensory or sensori-emotional values, sometimes called judgments of sentiment and taste. Its major divisions are art theory, literary theory, film theory and music theory. An example from art theory is to discern the set of principles underlying the work of a particular artist or artistic movement such as the Cubist aesthetic. The philosophy of film analyzes films and filmmakers for their philosophical content and explores film (images, cinema, etc.) as a medium for philosophical reflection and expression.

Political philosophy is the study of government and the relationship of individuals (or families and clans) to communities including the state. It includes questions about justice, law, property and the rights and obligations of the citizen. Politics and ethics are traditionally linked subjects, as both discuss the question of how people should live together.

Other branches of value theory:

Many academic disciplines generated philosophical inquiry. The relationship between "X" and the "philosophy of X" is debated. Richard Feynman argued that the philosophy of a topic is irrelevant to its primary study, saying that "philosophy of science is as useful to scientists as ornithology is to birds." Curtis White, by contrast, argued that philosophical tools are essential to humanities, sciences and social sciences.

The topics of philosophy of science are numbers, symbols and the formal methods of reasoning as employed in the social sciences and natural sciences.

Logic is the study of reasoning and argument. An argument is ""a" "connected series of statements intended to establish a proposition"." The connected series of statements are "premises" and the proposition is the conclusion. For example:
Deductive reasoning is when, given certain premises, conclusions are unavoidably implied. Rules of inference are used to infer conclusions such as, modus ponens, where given “A” and “If A then B”, then “B” must be concluded.

Because sound reasoning is an essential element of all sciences, social sciences and humanities disciplines, logic became a formal science. Sub-fields include mathematical logic, philosophical logic, Modal logic, computational logic and non-classical logics. A major question in the philosophy of mathematics is whether mathematical entities are objective and discovered, called mathematical realism, or invented, called mathematical antirealism.

This branch explores the foundations, methods, history, implications and purpose of science. Many of its sub-divisions correspond to a specific branch of science. For example, philosophy of biology deals specifically with the metaphysical, epistemological and ethical issues in the biomedical and life sciences. The philosophy of mathematics studies the philosophical assumptions, foundations and implications of mathematics.

Some philosophers specialize in one or more historical periods. The history of philosophy (study of a specific period, individual or school) is related to but not the same as the philosophy of history (the theoretical aspect of history, which deals with questions such as the nature of historical evidence and the possibility of objectivity).

Hegel's "Lectures on the Philosophy of History" influenced many philosophers to interpret truth in light of history, a view called historicism.

Philosophy of religion deals with questions that involve religion and religious ideas from a philosophically neutral perspective (as opposed to theology which begins from religious convictions). Traditionally, religious questions were not seen as a separate field from philosophy proper, the idea of a separate field only arose in the 19th century.

Issues include the existence of God, the relationship between reason and faith, questions of religious epistemology, the relationship between religion and science, how to interpret religious experiences, questions about the possibility of an afterlife, the problem of religious language and the existence of souls and responses to religious pluralism and diversity.

Some philosophers specialize in one or more of the major philosophical schools, such as Continental philosophy, Analytical philosophy, Thomism, Asian philosophy or African philosophy.

A variety of other academic and non-academic approaches have been explored.

The ideas conceived by a society have profound repercussions on what actions the society performs. Weaver argued that ideas have consequences. Philosophy yields applications such as those in ethics – applied ethics in particular – and political philosophy. The political and economic philosophies of Confucius, Sun Tzu, Chanakya, Ibn Khaldun, Ibn Rushd, Ibn Taymiyyah, Machiavelli, Leibniz, Hobbes, Locke, Rousseau, Adam Smith, John Stuart Mill, Marx, Tolstoy, Gandhi and Martin Luther King Jr. have been used to shape and justify governments and their actions. Progressive education as championed by Dewey had a profound impact on 20th-century US educational practices. Descendants of this movement include efforts in philosophy for children, which are part of philosophy education. Clausewitz's political philosophy of war has had a profound effect on statecraft, international politics and military strategy in the 20th century, especially around World War II. Logic is important in mathematics, linguistics, psychology, computer science and computer engineering.

Other important applications can be found in epistemology, which aid in understanding the requisites for knowledge, sound evidence and justified belief (important in law, economics, decision theory and a number of other disciplines). The philosophy of science discusses the underpinnings of the scientific method and has affected the nature of scientific investigation and argumentation. Philosophy thus has fundamental implications for science as a whole. For example, the strictly empirical approach of B.F. Skinner's behaviorism affected for decades the approach of the American psychological establishment. Deep ecology and animal rights examine the moral situation of humans as occupants of a world that has non-human occupants to consider also. Aesthetics can help to interpret discussions of music, literature, the plastic arts and the whole artistic dimension of life. In general, the various philosophies strive to provide practical activities with a deeper understanding of the theoretical or conceptual underpinnings of their fields.

Some of those who study philosophy become professional philosophers, typically by working as professors who teach, research and write in academic institutions. However, most students of academic philosophy later contribute to law, journalism, religion, sciences, politics, business, or various arts. For example, public figures who have degrees in philosophy include comedians Steve Martin and Ricky Gervais, filmmaker Terrence Malick, Pope John Paul II, Wikipedia co-founder Larry Sanger, technology entrepreneur Peter Thiel, Supreme Court Justice Stephen Bryer and vice presidential candidate Carly Fiorina.

Recent efforts to avail the general public to the work and relevance of philosophers include the million-dollar Berggruen Prize, first awarded to Charles Taylor in 2016.

Germany was the first country to professionalize philosophy. The doctorate of philosophy (PhD) developed in Germany as the terminal Teacher's credential in the mid 17th century. At the end of 1817, Georg Wilhelm Friedrich Hegel was the first philosopher to be appointed Professor by the State, namely by the Prussian Minister of Education, as an effect of Napoleonic reform in Prussia. In the United States, the professionalization grew out of reforms to the American higher-education system largely based on the German model.
Within the last century, philosophy has increasingly become a professional discipline practiced within universities, like other academic disciplines. Accordingly, it has become less general and more specialized. In the view of one prominent recent historian: "Philosophy has become a highly organized discipline, done by specialists primarily for other specialists. The number of philosophers has exploded, the volume of publication has swelled, and the subfields of serious philosophical investigation have multiplied. Not only is the broad field of philosophy today far too vast to be embraced by one mind, something similar is true even of many highly specialized subfields." Some philosophers argue that this professionalization has negatively affected the discipline.

The end result of professionalization for philosophy has meant that work being done in the field is now almost exclusively done by university professors holding a doctorate in the field publishing in highly technical, peer-reviewed journals. While it remains common among the population at large for a person to have a set of religious, political or philosophical views that they consider their "philosophy", these views are rarely informed by or connected to the work being done in professional philosophy today. Furthermore, unlike many of the sciences for which there has come to be a healthy industry of books, magazines, and television shows meant to popularize science and communicate the technical results of a scientific field to the general populace, works by professional philosophers directed at an audience outside the profession remain rare. Philosopher Michael Sandel's book "Justice: What's the Right Thing to Do?" and Harry Frankfurt's "On Bullshit" are examples of works that hold the uncommon distinction of having been written by professional philosophers but directed at and ultimately popular among a broader audience of non-philosophers. Both works became "'New York Times" best sellers.

Many inquiries outside of academia are philosophical in the broad sense. Novelists, playwrights, filmmakers, and musicians, as well as scientists and others engage in recognizably philosophical activity.

Although men have generally dominated philosophical discourse, women have engaged in philosophy throughout history. Women philosophers have contributed since ancient times–notably Hipparchia of Maroneia (active c. 325 BCE) and Arete of Cyrene (active 5th–4th centuries BCE). More were accepted during the ancient, medieval and modern eras, but no women philosophers became part the Western canon until the 20th and 21st century, when some sources indicate that Susanne Langer, G.E.M. Anscombe, Hannah Arendt and Simone de Beauvoir entered the canon.

In the early 1800s, some colleges and universities in the UK and US began admitting women, producing more female academics. Nevertheless, U.S. Department of Education reports from the 1990s indicate that few women ended up in philosophy, and that philosophy is one of the least gender-proportionate fields in the humanities. In 2014, "Inside Higher Education" described the philosophy "...discipline's own long history of misogyny and sexual harassment" of women students and professors. University of Sheffield philosophy professor Jennifer Saul stated in 2015 that women are "...leaving philosophy after being harassed, assaulted, or retaliated against."

In the early 1990s, the Canadian Philosophical Association noted a gender imbalance and gender bias in the academic field of philosophy. In June 2013, a US sociology professor stated that "out of all recent citations in four prestigious philosophy journals, female authors comprise just 3.6 percent of the total." Susan Price argues that the philosophical "...canon remains dominated by white males – the discipline that...still hews to the myth that genius is tied to gender." Morgan Thompson suggests that discrimination, differences in abilities, grade differences and the lack of role models in philosophy could be potential factors for the gender gap. According to Saul, "[p]hilosophy, the oldest of the humanities, is also the malest (and the whitest). While other areas of the humanities are at or near gender parity, philosophy is actually more overwhelmingly male than even mathematics." Similarly, research into professional participation in Australian philosophy indicates only a minor increase of women in senior positions since the 1960s, as well as a patterned under-citation of female philosophers.

In 2000, the Open Court Publishing Company began publishing a series of books on philosophy and popular culture. Each book consists of essays written by philosophers for general readers. The books "explore the meanings, concepts and puzzles within television shows, movies, music and other icons of popular culture" analyzing topics such as the TV shows "Seinfeld" and "The Simpsons", "The Matrix" and "Star Wars" movies and related media and new technological developments such as the iPod and Facebook. Their most recent publication () is titled "Louis C.K. and Philosophy"; its subject is the comedian Louis C.K..

"The Matrix" makes numerous references to philosophy including Buddhism, Vedanta, Advaita Hinduism, Christianity, Messianism, Judaism, Gnosticism, existentialism and nihilism. The film's premise resembles Plato's Allegory of the cave, Descartes's evil demon, Kant's reflections on the Phenomenon versus the Ding an sich, Zhuangzi's "Zhuangzi dreamed he was a butterfly", Marxist social theory and the brain in a vat thought experiment. Many references to Baudrillard's "Simulacra and Simulation" appear in the film, although Baudrillard himself considered this a misrepresentation.












</doc>
<doc id="52997369" url="https://en.wikipedia.org/wiki?curid=52997369" title="Projet de communauté philosophe">
Projet de communauté philosophe

Projet de communauté philosophe (translated as Project for a Philosophical Community) is a book written by the French philosopher Victor d'Hupay, published in 1777.

This book can be seen as a cornerstone in the history of communism, as it describes for the first time how "communists" (people living in a "commune") should understand this philosophy. 
In this work, the author advises to "share all economic and material products between inhabitants of the 'commune', so that all may benefit from everybody's work".

Restif de la Bretonne, a contemporary and friend of d'Hupay, thus describes him as a "communist" in a 1785 publication.

The book was partly written in d'Hupay's own bastide in Meyreuil, near Aix-en-Provence, where he was determined to set his own commune and live by the communist philosophy, with neighbours and friends.

There is currently only one known public copy of this original edition, which is kept at the Diderot Library in Lyon.



</doc>
<doc id="28737250" url="https://en.wikipedia.org/wiki?curid=28737250" title="Preference">
Preference

A preference is a technical term in psychology, economics and philosophy usually used in relation to choosing between alternatives. For example, someone prefers A over B if they would rather choose A than B.

Preference can also be used in insolvency terms.

In psychology, preferences refer to an individual’s attitude towards a set of objects, typically reflected in an explicit decision-making process (Lichtenstein & Slovic, 2006). The term is also used to mean evaluative judgment in the sense of liking or disliking an object (e.g., Scherer, 2005) which is the most typical definition employed in psychology. However, it does not mean that a preference is necessarily stable over time. Preference can be notably modified by decision-making processes, such as choices (Brehm, 1956; Sharot, De Martino, & Dolan, 2009), even unconsciously (see Coppin, Delplanque, Cayeux, Porcherot, & Sander, 2010). Consequently, preference can be affected by a person's surroundings and upbringing in terms of geographical location, cultural background, religious beliefs, and education. These factors are found to affect preference as repeated exposure to a certain idea or concept correlates with a positive preference.

In economics and other social sciences, "preference" refers to the set of assumptions related to ordering some alternatives, based on the degree of happiness, satisfaction, gratification, enjoyment, or utility they provide, a process which results in an optimal "choice" (whether real or imagined). Although economists are usually not interested in choices or preferences in themselves, they are interested in the theory of choice because it serves as a background for empirical demand analysis. 

The so-called Expected Utility Theory (EUT), which was introduced by John von Neumann and Oskar Morgenstern in 1944, explains that so long as an agent's preferences over risky options follow a set of axioms, then he is maximizing the expected value of a utility function. This theory specifically identified four axioms that determine an individual's preference when selecting an alternative out of a series of choices that maximizes expected utility for him. These include Completeness, Transitivity, Independence, and, Continuity.

"Preference" may also refer to non-choices, such as genetic and biological explanations for one's preference. Sexual orientation, for example, is no longer considered a sexual preference by most individuals, but is debatable based on philosophical and/or scientific ideas.

In Insolvency, the term can be used to describe when a company pays a specific creditor or group of creditors. From doing this, that creditor(s) is made better off, than other creditors. After paying the 'preferred creditor', the company seeks to go into a formal insolvency like an administration or liquidation. There must be a desire to make the creditor better off, for them to be a preference. If the preference is proven, legal action can occur. It is a wrongful act of trading. Disqualification is a risk. Preference arises within the context of the principle maintaining that one of the main objectives in the winding up of an insolvent company is to ensure the equal treatment of creditors. The rules on preferences allow paying up their creditors as insolvency looms, but that it must prove that the transaction is a result of ordinary commercial considerations. Also, under the English Insolvency Act 1986, if a creditor was proven to have forced the company to pay, the resulting payment would not be considered a preference since it would not constitute unfairness.





</doc>
<doc id="55234353" url="https://en.wikipedia.org/wiki?curid=55234353" title="Philosophical ethology">
Philosophical ethology

Philosophical ethology is a rather young multidisciplinary research field gathering natural sciences, social science, human studies and dedicates to the issue of animal subjectivity. It is about an ontological concept needing a philosophical place other than a descriptive issue, just as it was in the 19th century.

Philosophical ethology develops from the thought of continental philosophers, which researches involve ethology, philosophy and anthropology. Those authors had taken up the challenges coming from biology, phenomenology, critical theory, the Animal Studies and post-human philosophy. These are all disciplines dealing, each in its own way, with non-human animals and the interactions among living beings, in order to propose a new paradigm able to go beyond the tricks of the anthropocentrism, still alive and kicking underneath the traditional theories.

The mean critics by those authors is the Cartesian heiress of automata: whereas the classical ethology and behaviourism have described how the animal machine would work and which were the mechanisms regulating processes, nevertheless these authors did not challenge the mean idea, that is an animal is not a machine. Hence the need to elaborate a new multidisciplinary approach able to interpret the animal subjectivity ontologically speaking, and the different ontology correlated issues, such as the cultural dimensions, symbolicity and materiality in non-human animals and their intra and interspecific relationship.

Three recent issues of magazine "Angelaki. Journal of the Theoretical Humanities" have explored the thought of three scholars considered among the most influential voices in the field of philosophical ethology by di editors of the magazine, Brett Buchanan, Jeffrey Bussolini and Matthew Chrulew: the three authos are Vinciane Despret, Dominique Lestel and Roberto Marchesini.

Belgian philosopher and professo at the university of liege, Vinciane Despret has written many essays and articles about the history of ethology, psicology and human-animal relationship. All along her career, Despert has worked together with few authors from different disciplines (ethology, arts, literature) and with many non-human animals (elephants, mice, rats, monkeys). These encounters allowed her to build a unique research path.

In Despret’s writings, what is peculiar is the methodological approach and her anecdotal and idiosyncratic style: the author chooses to tell stories about animals (or, better, stories of relationship among animals, humans included) rather than to write about animals.
Focal point to the authors is "making the right questions" to non-human animals. This means that animals are not texts to hermeneutically interpret, not object to quest via scientific experiments, but they are subjects able to provide their own answers to the questions interesting to them.

Within philosophical ethology, Despret has stressed the repetitivity of any interspecific dialogue: non-human animals are being transformed by the encounter with the human beings, and, in the same way, human beings result transformed by the dialogue with the non-human. Despret’s stories are full of examples got by researchers, farmers, trainers – along with likewise important autobiographical reports – proving the enrichment coming from the encounter with the non-human animals.

A French philosopher and ethologist, Lestel is "Maître de conférences" at École Normale Supérieure of Paris and director of a research team about eco-anthropology and etnonlogy at the Muséum national d’histoire naturelle.

His credit is stressing how a cultural phenomenon is not a human peculiarity. To Lestel, it necessary to see at anthropo-poiesis with an evolutionary and pluralist lens and at culture as a domain no longer apart from nature. It is necessary to become aware that we live in a multi-species society where each species produces their own kind of culture. This proximity of space and time among beings from different species allows the emergence of few sincere friendship and relationship, that have a historical, ethical and political importance, to Lestel.

In 2016, during the International days of study GIS about human-animal held in Bologna, Lestel has rolled out his zoo-futurism, a philosophical artistic trend aiming to "re-animalise" the human being.

An Italian philosopher, ethologist and zooanthopologist, Marchesini is director of Siua (School of Human-Animal interaction), of Study Centre of post-human philosophy and professor at few Italian universities. For over 20 years, he is leading a multidisciplinary project research about Zooanthropology, posts-human philosophy and bioethics to demonstrate that non-human animals have a referent role during the identity structuring (anthropo-poiesis) and the philosophical consequences coming from this kind of relationship.

Main concepts in Marchesini’s thought are Zootropy and animal epiphany. With the term zootropy, Marchesini underlines the natural human tendency to turn to non-humans, like a kind of "biophilia" rooted in our species that see in ethero-specifics some social counterparts able to contribute to anthropo-poiesis processes.

On the other side, with the concept of "animal epiphany", Marchesini points out the characteristic of enunciation and revelation coming from humans-non humans relationship. Animal diversity let human being imagine new existential paths – in the flight of a bird, human being cannot see just the phenomenon per se, but perceive a new dimension of the thinking "it is possible to fly" – and experiment an hybridational tension leading to identity slidings.

With the essay "Philosophical ethology", Marchesini focus on subjectivity. To him, subjectivity is foundation to conscience, not the opposite. Animals get constantly engaged from the external world through new occurrences asking for creativity and initiative not explicable with any automatism. From this point of view, to Marchesini, desire connects animals and the world, desire make them acting in their present.


</doc>
<doc id="56221881" url="https://en.wikipedia.org/wiki?curid=56221881" title="Fides quaerens intellectum">
Fides quaerens intellectum

Fides quaerens intellectum means "faith seeking understanding" or "faith seeking intelligence". It is the theological method stressed by Augustine (354–430) and Anselm of Canterbury ( – 1109) in which one begins with belief in faith and on the basis of that faith moves on to further understanding of Christian truth. 
Anselm uses this expression for the first time in his Proslogion (II–IV). It articulates the close relationship between faith and human reason. This is the key to Anselm's theological thought and philosophical thinking. He would understand all things in faith. It means to understand intellectually what we already believe. Chronologically, faith precedes understanding, like when small children first trust their parents and believe what they state, and just later on, when they grow up, they want to examine and understand the reality by themselves. In the words of Anselm of Canterbury : "Neque enim quaero intelligere ut credam, sed credo ut intelligam" ("I do not seek to understand in order that I may believe, but rather, I believe in order that I may understand").




</doc>
<doc id="229661" url="https://en.wikipedia.org/wiki?curid=229661" title="Pseudophilosophy">
Pseudophilosophy

Pseudophilosophy (or cod philosophy) is a philosophical idea or system which does not meet an expected set of standards. 

The term has been used against many different targets, including:

According to Christopher Heumann, an 18th-century scholar, pseudo-philosophy has six characteristics:

According to Michael Oakeshott, pseudo-philosophy "is theorizing that proceeds partly within and partly outside a given mode of inquiry."

Josef Pieper noted that there cannot be a closed system of philosophy, and that any philosophy that claims to have discovered a "cosmic formula" is a pseudo-philosophy. In this he follows Kant, who rejected the postulation of a "highest principle" from which to develop transcendental idealism, calling this pseudo-philosophy and mysticism.

Nicholas Rescher, in "The Oxford Companion to Philosophy", described "pseudo-philosophy" as "deliberations that masquerade as philosophical but are inept, incompetent, deficient in intellectual seriousness, and reflective of an insufficient commitment to the pursuit of truth." Rescher adds that the term is particularly appropriate when applied to "those who use the resources of reason to substantiate the claim that rationality is unachievable in matters of inquiry."

The term "pseudo-philosophy" appears to have been coined by Jane Austen.

Ernest Newman, an English music critic and musicologist, who aimed at intellectual objectivity in his style of criticism, in contrast to the more subjective approach of other critics, published in 1897 "Pseudo-Philosophy at the End of the Nineteenth Century", a critique of imprecise and subjective writing.

According to Josef Pieper, for Pythagoras, Plato and Aristotle philosophy is the human search "oriented toward wisdom such as God possesses". It suggests that philosophy includes, in its essence, an orientation toward theology. Pieper notes:
The term is almost always used pejoratively and is often contentious, due to differing criteria for demarcating pseudophilosophy (see also: Demarcation problem).

According to physicist and philosopher of science Mario Bunge,
For Kant, intellectual knowledge is discursive knowledge, not intuitive knowledge. According to Kant, intuition is limited to the realm of senses, while knowledge is "essentially realised in the acts of researching, relating, comparing, differentiating, inferring, proving". Kant criticised Romantic philosophy, which is based on feeling and intuition, and not on "philosophical work":
Kant called Romantic philosophy pseudo-philosophy, "in which one is entitled not to work, but only to heed and enjoy the oracle in oneself in order to take complete possession of that wisdom toward which philosophy aims".

Mysticism has a long history. In the Age of Enlightenment mysticism had fallen into disrepute. Kant called mysticism pseudophilosophy. In the 19th century, with the rise of Romanticism, interest in mysticism was renewed. Rationalists and Lutherans wrote histories of mysticism to reject its claims, but there was a widespread interest in spiritualism and related phenomena.

Interest in Eckhart's works was revived in the early nineteenth century, especially by German Romantics and Idealist philosophers. Since the 1960s debate has been going on in Germany whether Eckhart should be called a "mystic". The philosopher Karl Albert had already argued that Eckhart had to be placed in the tradition of philosophical mysticism of Parmenides, Plato, Plotinus, Porphyry, Proclus and other neo-Platonistic thinkers. Heribert Fischer argued in the 1960s that Eckhart was a mediaeval theologian.

Arthur Schopenhauer wrote the following about Georg Wilhelm Friedrich Hegel:
A hundred and fifty years after Schopenhauer's death, physicist and philosopher of science Mario Bunge recommended "avoiding the pseudo-subtleties of Hegelian dialectics", and wrote of "Hegel's disastrous legacy": "It is true that Marx and Engels criticized Hegel's idealism, but they did not repudiate his cult of nonsense and his rejection of all modern science from Newton on." Bunge noted,
Soccio notes that analytical inclined philosophers tend to dismiss Heidegger's philosophy as pseudophilosophy. According to Christensen, Heidegger himself called the philosophy of Husserl "scheinphilosophy".

Dietrich von Hildebrand used the term to critique the central place modern science is occupying in western society:

Journalist Jonathan Chait used the term to criticize the work of Ayn Rand in "Ayn Rand's Pseudo-Philosophy", an article in "The New Republic", in which he wrote, "She was a true amateur who insisted on seeing herself as the greatest human being who ever lived because she was almost completely unfamiliar with the entire philosophical canon." Physicist and philosopher of science Mario Bunge classified Rand as a "mercenary", among those who "seek to defend or propagate a doctrine rather than an analyzing ideas or searching for new truths", while science writer and skeptic Michael Shermer claimed that "it becomes clear that Objectivism was (and is) a cult, as are many other, non-religious groups". The "Stanford Encyclopedia of Philosophy" said of Rand, "For all her popularity, however, only a few professional philosophers have taken her work seriously."





</doc>
<doc id="56121990" url="https://en.wikipedia.org/wiki?curid=56121990" title="Dualism (cybernetics)">
Dualism (cybernetics)

Dualism in cybernetics refers to systems or problems in which one or more intelligent adversaries attempt to exploit the weaknesses of the investigator. Examples could include a game-playing opponent, adversarial law, evolutionary systems of predator/parasite and prey/host, or politics/enslavement attempts. Norbert Wiener, the founder of cybernetics, contrasted "Manichean devils" (dualistic adversarial systems) with "Augustinian devils"—systems or problems that, though very complex and difficult to figure out, did not feature an adversary with contrary intent.

Victories or "expansions of knowledge" in the latter type of system were able to be built upon incrementally, through science (experimentation expanding empirical knowledge bases). Wiener noted that temporary weaknesses (such as errors to perceive all components of a system) were not fatal in attempts to defeat "Augustinian devils" because another experiment could simply be pursued (and he noted that he had personally defeated many "Augustinian devils" with his contributions to science and engineering). By contrast, Wiener observed that temporary lapses in judgment against "Manichean devils" were more often fatal or destructive, due to the desire of the opponent to "win/survive at all costs", even by introducing deception into the system. He said that he had been defeated by many "Manichean devils", such as on occasions when he was temporarily careless in chess.

Although this duality between complexity (in the case of the Augustinian devils) and opposition (in the case of Manichean devils) may seem obvious, it holds deep implications for many areas of science, such as game theory, political science, computer science, network science, security science, military science, evolutionary biology, and cryptography.


</doc>
<doc id="276872" url="https://en.wikipedia.org/wiki?curid=276872" title="Critical thinking">
Critical thinking

Critical thinking is the analysis of facts to form a judgment. The subject is complex, and several different definitions exist, which generally include the rational, skeptical, unbiased analysis, or evaluation of factual evidence. Critical thinking is self-directed, self-disciplined, self-monitored, and self-corrective thinking. It presupposes assent to rigorous standards of excellence and mindful command of their use. It entails effective communication and problem-solving abilities as well as a commitment to overcome native egocentrism and sociocentrism.

The earliest documentation of critical thinking are the teachings of Socrates recorded by Plato. Socrates established the fact that one cannot depend upon those in "authority" to have sound knowledge and insight. He demonstrated that persons may have power and high position and yet be deeply confused and irrational. He established the importance of asking deep questions that probe profoundly into thinking before we accept ideas as worthy of belief.

He established the importance of seeking evidence, closely examining reasoning and assumptions, analyzing basic concepts, and tracing out implications not only of what is said but of what is done as well. His method of questioning is now known as "Socratic questioning" and is the best known critical thinking teaching strategy. In his mode of questioning, Socrates highlighted the need for thinking for clarity and logical consistency. Socrates asked people questions to reveal their irrational thinking or lack of reliable knowledge. Socrates demonstrated that having authority does not ensure accurate knowledge. He established the method of questioning beliefs, closely inspecting assumptions and relying on evidence and sound rationale. Plato recorded Socrates' teachings and carried on the tradition of critical thinking. Aristotle and subsequent Greek skeptics refined Socrates' teachings, using systematic thinking and asking questions to ascertain the true nature of reality beyond the way things appear from a glance.

Socrates set the agenda for the tradition of critical thinking, namely, to reflectively question common beliefs and explanations, carefully distinguishing beliefs that are reasonable and logical from those that—however appealing to our native egocentrism, however much they serve our vested interests, however comfortable or comforting they may be—lack adequate evidence or rational foundation to warrant belief.

Critical thinking was described by Richard W. Paul as a movement in two waves (1994). The "first wave" of critical thinking is often referred to as 
a 'critical analysis' that is clear, rational thinking involving critique. Its details vary amongst those who define it. According to Barry K. Beyer (1995), critical thinking means making clear, reasoned judgments. During the process of critical thinking, ideas should be reasoned, well thought out, and judged. The U.S. National Council for Excellence in Critical Thinking defines critical thinking as the "<nowiki>intellectually disciplined process of actively and skillfully conceptualizing, applying, analyzing, synthesizing, or evaluating information gathered from, or generated by, observation, experience, reflection, reasoning, or communication, as a guide to belief and action.</nowiki>"

In the term "critical thinking", the word "critical", (Grk. κριτικός = "kritikos" = "critic") derives from the word "critic" and implies a critique; it identifies the intellectual capacity and the means "of judging", "of judgement", "for judging", and of being "able to discern". The intellectual roots of critical thinking are as ancient as its etymology, traceable, ultimately, to the teaching practice and vision of Socrates 2,500 years ago who discovered by a method of probing questioning that people could not rationally justify their confident claims to knowledge.

Traditionally, critical thinking has been variously defined as follows:

Contemporary critical thinking scholars have expanded these traditional definitions to include qualities, concepts, and processes such as creativity, imagination, discovery, reflection, empathy, connecting knowing, feminist theory, subjectivity, ambiguity, and inconclusiveness. Some definitions of critical thinking exclude these subjective practices.

The ability to reason logically is a fundamental skill of rational agents, hence the study of the form of correct argumentation is relevant to the study of critical thinking.

"First wave" logical thinking consisted of understanding the connections between two concepts or points in thought. It followed a philosophy where the thinker was removed from the train of thought and the connections and the analysis of the connect was devoid of any bias of the thinker. Kerry Walters describes this ideology in his essay Beyond Logicism in Critical Thinking, "A logistic approach to critical thinking conveys the message to students that thinking is legitimate only when it conforms to the procedures of informal (and, to a lesser extent, formal) logic and that the good thinker necessarily aims for styles of examination and appraisal that are analytical, abstract, universal, and objective. This model of thinking has become so entrenched in conventional academic wisdom that many educators accept it as canon". The adoption of these principals parallels themselves with the increasing reliance on a quantitative understanding of the world.

In the ‘second wave’ of critical thinking, as defined by Kerry S. Walters (Re-thinking Reason, 1994, p. 1), many authors moved away from the logocentric mode of critical thinking that the ‘first wave’ privileged, especially in institutions of higher learning. Walters summarizes logicism as "the unwarranted assumption that good thinking is reducible to logical thinking".

"A logistic approach to critical thinking conveys the message to students that thinking is legitimate only when it conforms to the procedures of informal (and, to a lesser extent, formal) logic and that the good thinker necessarily aims for styles of examination and appraisal that are analytical, abstract, universal, and objective."
As the ‘second wave’ took hold, scholars began to take a more inclusive view of what constituted as critical thinking. Rationality and logic are still widely accepted in many circles as the primary examples of critical thinking.

There are three types of logical reasoning Informally, two kinds of logical reasoning can be distinguished in addition to formal deduction: induction and abduction.

 e.g., X is human and all humans have a face so X has a face.

e.g. The sum of even integers is even.

Let formula_1 then formula_2 are even by definition. formula_3 which is even so summing two even numbers results in an even number. 

 e.g., I observe sheep in a field, and they appear white from my viewing angle, so sheep are white.
 Contrast with the deductive statement:"Some sheep are white on at least one side."
Kerry S. Walters (Re-thinking Reason, 1994) argues that rationality demands more than just logical or traditional methods of problem solving and analysis or what he calls the "calculus of justification" but also considers "cognitive acts such as imagination, conceptual creativity, intuition and insight" (p. 63). These "functions" are focused on discovery, on more abstract processes instead of linear, rules-based approaches to problem-solving. The linear and non-sequential mind must both be engaged in the rational mind.

The ability to critically analyze an argument – to dissect structure and components, thesis and reasons – is essential. But so is the ability to be flexible and consider non-traditional alternatives and perspectives. These complementary functions are what allow for critical thinking to be a practice encompassing imagination and intuition in cooperation with traditional modes of deductive inquiry.

The list of core critical thinking skills includes observation, interpretation, analysis, inference, evaluation, explanation, and metacognition. According to Reynolds (2011), an individual or group engaged in a strong way of critical thinking gives due consideration to establish for instance:

In addition to possessing strong critical-thinking skills, one must be disposed to engage problems and decisions using those skills. Critical thinking employs not only logic but broad intellectual criteria such as clarity, credibility, accuracy, precision, relevance, depth, breadth, significance, and fairness.

Critical thinking calls for the ability to:

In sum:

"A persistent effort to examine any belief or supposed form of knowledge in the light of the evidence that supports or refutes it and the further conclusions to which it tends."

The habits of mind that characterize a person strongly disposed toward critical thinking include a desire to follow reason and evidence wherever they may lead, a systematic approach to problem solving, inquisitiveness, even-handedness, and confidence in reasoning.

According to a definition analysis by Kompf & Bond (2001), critical thinking involves problem solving, decision making, metacognition, rationality, rational thinking, reasoning, knowledge, intelligence and also a moral component such as reflective thinking. Critical thinkers therefore need to have reached a level of maturity in their development, possess a certain attitude as well as a set of taught skills.

Edward M. Glaser proposed that the ability to think critically involves three elements:

Educational programs aimed at developing critical thinking in children and adult learners, individually or in group problem solving and decision making contexts, continue to address these same three central elements.

The Critical Thinking project at Human Science Lab, London, is involved in scientific study of all major educational system in prevalence today to assess how the systems are working to promote or impede critical thinking.

Contemporary cognitive psychology regards human reasoning as a complex process that is both reactive and reflective.

The relationship between critical thinking skills and critical thinking dispositions is an empirical question. Some people have both in abundance, some have skills but not the disposition to use them, some are disposed but lack strong skills, and some have neither. A measure of critical thinking dispositions is the California Measure of Mental Motivation and the California Critical Thinking Dispositions Inventory. The CriTT is an alternative measure that examines student beliefs and attitudes about critical thinking

John Dewey is one of many educational leaders who recognized that a curriculum aimed at building thinking skills would benefit the individual learner, the community, and the entire democracy.

Critical thinking is significant in academics due to being significant in learning. Critical thinking is significant in the learning process of internalization, in the construction of basic ideas, principles, and theories inherent in content. And critical thinking is significant in the learning process of application, whereby those ideas, principles, and theories are implemented effectively as they become relevant in learners' lives.

Each discipline adapts its use of critical thinking concepts and principles. The core concepts are always there, but they are embedded in subject-specific content. For students to learn content, intellectual engagement is crucial. All students must do their own thinking, their own construction of knowledge. Good teachers recognize this and therefore focus on the questions, readings, activities that stimulate the mind to take ownership of key concepts and principles underlying the subject.

Historically, teaching of critical thinking focused only on logical procedures such as formal and informal logic. This emphasized to students that good thinking is equivalent to logical thinking. However, a second wave of critical thinking, urges educators to value conventional techniques, meanwhile expanding what it means to be a critical thinker. In 1994, Kerry Walters compiled a conglomeration of sources surpassing this logical restriction to include many different authors’ research regarding connected knowing, empathy, gender-sensitive ideals, collaboration, world views, intellectual autonomy, morality and enlightenment. These concepts invite students to incorporate their own perspectives and experiences into their thinking.

In the English and Welsh school systems, "Critical Thinking" is offered as a subject that 16- to 18-year-olds can take as an A-Level. Under the OCR exam board, students can sit two exam papers for the AS: "Credibility of Evidence" and "Assessing and Developing Argument". The full Advanced GCE is now available: in addition to the two AS units, candidates sit the two papers "Resolution of Dilemmas" and "Critical Reasoning". The A-level tests candidates on their ability to think critically about, and analyze, arguments on their deductive or inductive validity, as well as producing their own arguments. It also tests their ability to analyze certain related topics such as credibility and ethical decision-making. However, due to its comparative lack of subject content, many universities do not accept it as a main A-level for admissions. Nevertheless, the AS is often useful in developing reasoning skills, and the full Advanced GCE is useful for degree courses in politics, philosophy, history or theology, providing the skills required for critical analysis that are useful, for example, in biblical study.

There used to also be an Advanced Extension Award offered in Critical Thinking in the UK, open to any A-level student regardless of whether they have the Critical Thinking A-level. Cambridge International Examinations have an A-level in Thinking Skills.

From 2008, Assessment and Qualifications Alliance has also been offering an A-level Critical Thinking specification.

OCR exam board have also modified theirs for 2008. Many examinations for university entrance set by universities, on top of A-level examinations, also include a critical thinking component, such as the LNAT, the UKCAT, the BioMedical Admissions Test and the Thinking Skills Assessment.

In Qatar, critical thinking was offered by AL-Bairaq—an outreach, non-traditional educational program that targets high school students and focuses on a curriculum based on STEM fields. The idea behind AL-Bairaq is to offer high school students the opportunity to connect with the research environment in the Center for Advanced Materials (CAM) at Qatar University. Faculty members train and mentor the students and help develop and enhance their critical thinking, problem-solving, and teamwork skills.

In 1995, a meta-analysis of the literature on teaching effectiveness in higher education was undertaken.
The study noted concerns from higher education, politicians, and business that higher education was failing to meet society's requirements for well-educated citizens. It concluded that although faculty may aspire to develop students' thinking skills, in practice they have tended to aim at facts and concepts utilizing lowest levels of cognition, rather than developing intellect or values.

In a more recent meta-analysis, researchers reviewed 341 quasi- or true-experimental studies, all of which used some form of standardized critical thinking measure to assess the outcome variable. The authors describe the various methodological approaches and attempt to categorize the differing assessment tools, which include standardized tests (and second-source measures), tests developed by teachers, tests developed by researchers, and tests developed by teachers who also serve the role as the researcher. The results emphasized the need for exposing students to real-world problems and the importance in encouraging open dialogue within a supportive environment. Effective strategies for teaching critical thinking are thought to be possible in a wide variety of educational settings. One attempt to assess the humanities' role in teaching critical thinking and reducing belief in pseudoscientific claims was made at North Carolina State University. Some success was noted and the researchers emphasized the value of the humanities in providing the skills to evaluate current events and qualitative data in context.

Scott Lilienfeld notes that there is some evidence to suggest that basic critical thinking skills might be successfully taught to children at a younger age than previously thought.

Critical thinking is an important element of all professional fields and academic disciplines (by referencing their respective sets of permissible questions, evidence sources, criteria, etc.). Within the framework of scientific skepticism, the process of critical thinking involves the careful acquisition and interpretation of information and use of it to reach a well-justified conclusion. The concepts and principles of critical thinking can be applied to any context or case but only by reflecting upon the nature of that application. Critical thinking forms, therefore, a system of related, and overlapping, modes of thought such as anthropological thinking, sociological thinking, historical thinking, political thinking, psychological thinking, philosophical thinking, mathematical thinking, chemical thinking, biological thinking, ecological thinking, legal thinking, ethical thinking, musical thinking, thinking like a painter, sculptor, engineer, business person, etc. In other words, though critical thinking principles are universal, their application to disciplines requires a process of reflective contextualization.

Critical thinking is considered important in the academic fields because it enables one to analyze, evaluate, explain, and restructure their thinking, thereby decreasing the risk of adopting, acting on, or thinking with, a false belief. However, even with knowledge of the methods of logical inquiry and reasoning, mistakes can happen due to a thinker's inability to apply the methods or because of character traits such as egocentrism. Critical thinking includes identification of prejudice, bias, propaganda, self-deception, distortion, misinformation, etc. Given research in cognitive psychology, some educators believe that schools should focus on teaching their students critical thinking skills and cultivation of intellectual traits.

Critical thinking skills can be used to help nurses during the assessment process. Through the use of critical thinking, nurses can question, evaluate, and reconstruct the nursing care process by challenging the established theory and practice. Critical thinking skills can help nurses problem solve, reflect, and make a conclusive decision about the current situation they face. Critical thinking creates "new possibilities for the development of the nursing knowledge." Due to the sociocultural, environmental, and political issues that are affecting healthcare delivery, it would be helpful to embody new techniques in nursing. Nurses can also engage their critical thinking skills through the Socratic method of dialogue and reflection. This practice standard is even part of some regulatory organizations such as the College of Nurses of Ontario – Professional Standards for Continuing Competencies (2006).
It requires nurses to engage in Reflective Practice and keep records of this continued professional development for possible review by the College.

Critical thinking is also considered important for human rights education for toleration. The Declaration of Principles on Tolerance adopted by UNESCO in 1995 affirms that "education for tolerance could aim at countering factors that lead to fear and exclusion of others, and could help young people to develop capacities for independent judgement, "critical thinking" and ethical reasoning."

Critical thinking is used as a way of deciding whether a claim is true, partially true, or false. It is a tool by which one can come about reasoned conclusions based on a reasoned process.

The advent and rising popularity of online courses has prompted some to ask if computer-mediated communication (CMC) promotes, hinders, or has no effect on the amount and quality of critical thinking in a course (relative to face-to-face communication). There is some evidence to suggest a fourth, more nuanced possibility: that CMC may promote some aspects of critical thinking but hinder others. For example, Guiller et al. (2008) found that, relative to face-to-face discourse, online discourse featured more justifications, while face-to-face discourse featured more instances of students expanding on what others had said. The increase in justifications may be due to the asynchronous nature of online discussions, while the increase in expanding comments may be due to the spontaneity of ‘real time’ discussion. Newman et al. (1995) showed similar differential effects. They found that while CMC boasted more important statements and linking of ideas, it lacked novelty. The authors suggest that this may be due to difficulties participating in a brainstorming-style activity in an asynchronous environment. Rather, the asynchrony may promote users to put forth “considered, thought out contributions.”

Researchers assessing critical thinking in online discussion forums often employ a technique called Content Analysis, where the text of online discourse (or the transcription of face-to-face discourse) is systematically coded for different kinds of statements relating to critical thinking. For example, a statement might be coded as “Discuss ambiguities to clear them up” or “Welcoming outside knowledge” as positive indicators of critical thinking. Conversely, statements reflecting poor critical thinking may be labeled as “Sticking to prejudice or assumptions” or “Squashing attempts to bring in outside knowledge.” The frequency of these codes in CMC and face-to-face discourse can be compared to draw conclusions about the quality of critical thinking.

Searching for evidence of critical thinking in discourse has roots in a definition of critical thinking put forth by Kuhn (1991), which emphasizes the social nature of discussion and knowledge construction. There is limited research on the role of social experience in critical thinking development, but there is some evidence to suggest it is an important factor. For example, research has shown that 3- to 4-year-old children can discern, to some extent, the differential creditability and expertise of individuals. Further evidence for the impact of social experience on the development of critical thinking skills comes from work that found that 6- to 7-year-olds from China have similar levels of skepticism to 10- and 11-year-olds in the United States. If the development of critical thinking skills was solely due to maturation, it is unlikely we would see such dramatic differences across cultures.




</doc>
<doc id="58397336" url="https://en.wikipedia.org/wiki?curid=58397336" title="Polanyi’s paradox">
Polanyi’s paradox

Polanyi’s paradox, named in honour of the British-Hungarian philosopher Michael Polanyi, is the theory that human knowledge of how the world functions and capability are, to a large extent, beyond our explicit understanding. The theory was articulated by Michael Polanyi in his book "The Tacit Dimension" in 1966, but it was economist David Autor that named it as Polanyi’s paradox in his 2014 research paper on “Polanyi’s Paradox and the Shape of Employment Growth”.

Summarised in the slogan ‘We can know more than we can tell’, Polanyi’s paradox is mainly to explain the cognitive phenomenon that there exist many tasks which we, human beings, understand intuitively how to perform but cannot verbalize the rules or procedures behind it. This "self-ignorance" is common to many human activities, from driving a car in traffic to face recognition. As Polanyi argues, humans are relying on their tacit knowledge, which is difficult to adequately express by verbal means, when engaging these tasks. Polanyi's paradox has been widely considered a major obstacle in the fields of AI and automation, since the absence of consciously accessible knowledge creates tremendous difficulty in programming.

British-Hungarian philosopher Michael Polanyi regularly studied the causes behind human ability to acquire knowledge that they cannot explain through logical deduction. In his work "The Tacit Dimension" (1966)"," Polanyi explored the 'tacit' dimension to human knowledge and developed the concept of "tacit knowledge", as opposed to the term "explicit knowledge".

Tacit knowledge can be defined as knowledge people learn from experiences and internalize unconsciously, which is therefore difficult to articulate and codify it in a tangible form. Explicit knowledge, the opposite of tacit knowledge, is knowledge that can be readily verbalized and formalized. Tacit knowledge is largely acquired through implicit learning, the process by which information is learned independently of the subjects' awareness. For example, native speakers tacitly acquire their language in early childhood without consciously studying specific grammar rules (explicit knowledge), but with extensive exposure to television and day-to-day communication. Besides, people can only limitedly transfer their tacit knowledge through close interactions (sharing experiences with one another or observing others' behaviors). A certain level of trust needs to be established between individuals to capture tacit knowledge.

Tacit knowledge comprises a range of conceptual and sensory information that is featured with strong personal subjectivity. It is implicitly reflected in human actions; as argued by Polanyi, "tacit knowledge dwells in our awareness". People's skills, experiences, insight, creativity and judgement all fall into this dimension. Tacit knowledge can also be described as "know-how," distinguishing from "know-that" or "facts." Before Polanyi, Gilbert Ryle published a paper in 1945 drawing the distinction between "knowing-that (knowledge of proposition)" and "knowing-how." According to Ryle, this "know-how" knowledge is the instinctive and intrinsic knowledge ingrained in the individual's human capability.

Since tacit knowledge cannot be stated in propositional or formal form, Polanyi concludes such inability in articulation in the slogan ‘We can know more than we can tell’. Daily activities based on tacit knowledge include recognizing a face, driving a car, riding a bike, writing a persuasive paragraph, developing a hypothesis to explain a poorly understood phenomenon. Take facial recognition as an illustration: we can recognize our acquaintance's face out of a million others while we are not conscious about the knowledge of his face. It would be difficult for us to describe the precise arrangement of his eyes, nose and mouth, since we memorize the face unconsciously.

As a prelude to "The Tacit Dimension", in his book "Personal Knowledge" (1958), Polanyi claims that all knowing is personal, emphasizing the profound effects of personal feelings and commitments on the practice of science and knowledge. Arguing against the then dominant Empiricists view that minds and experiences are reducible to sense data and collections of rules, he advocates a post-positivist approach that recognizes human knowledge is often beyond their explicit expression. Any attempt to specify tacit knowing only leads to self-evident axioms that cannot tell us why we should accept them.

Polanyi's observation has deep implications in the AI field since the paradox he identified that "our tacit knowledge of how the world works often exceeds our explicit understanding" accounts for many of the challenges for computerization and automation over the past five decades. Automation requires high levels of exactness to inform the computer what is supposed to be done while tacit knowledge cannot be conveyed in a propositional form. Therefore, machines cannot provide successful outcomes in many cases: they have explicit knowledge (raw data) but nevertheless, do not know how to use such knowledge to understand the task as whole. This discrepancy between human reasoning and AI learning algorithms makes it difficult to automate tasks that demand common sense, flexibility, adaptability and judgment — human intuitive knowledge.

MIT economist David Autor is one of the leading sceptics who doubt the prospects for machine intelligence. Despite the exponential growth in computational resources and the relentless pace of automation since the 1990s, Autor argues, Polanyi's paradox impedes modern algorithms to replace human labor in a range of skilled jobs. The extent of machine substitution of human labor, therefore, has been overestimated by journalists and expert commentators. Although contemporary computer science strives for prevailing over Polanyi's paradox, the ever-changing, unstructured nature of some activities currently presents intimidating challenges for automation. Despite years of time and billions of investment spent on the development of self-driving cars and cleaning robots, these machine learning systems continue to struggle with their low adaptability and interpretability, from self-driving cars' inability to make an unexpected detour to cleaning robots' vulnerability to unmonitored pets or kids. Instead, to let self-driving cars function optimally, we have to change current road infrastructure significantly, minimizing the need for human capabilities in the whole driving process.

The increasing occupational polarisation in the past few decades —the growth of both high-paid, high-skill abstract jobs and lower-paid, low-skill manual jobs — has been a manifestation of Polanyi's paradox. According to Autor, there are two types of tasks proven stubbornly challenging for artificial intelligence (AI): abstract tasks that require problem-solving capabilities, intuition, creativity and persuasion on the one hand, and manual tasks demanding situational adaptability, visual recognition, language understanding, and in-person interactions on the other. Abstract tasks are characteristic of professional, managerial, and technical occupations, while service and laborer occupations involve many manual tasks (e.g. cleaning, lifting and throwing). These jobs tend to be complemented by machines rather than substituted.

By contrast, as the price of computing power declines, computers extensively substitute for routine tasks that can be codified into clear sets of instructions, resulting in a dramatical decline in employment of routine task-­intensive jobs. This polarization has resulted in a shrinking middle class across industrialized economies since many middle-income occupations in sales, office and administrative work and repetitive production work are task-­intensive. Moreover, the subsequent growth in income inequality and wealth disparity has recently emerged as a major socio-economic issue in developed countries.

Some technological optimists argue that recent advances in machine learning have overcome Polanyi's paradox. Instead of relaying on programmer’s algorithms to instruct them in human knowledge, computer systems are now able to learn tacit rules from context, abundant data, and applied statistics on their own. Since machines can infer the tacit knowledge that human beings draw upon from examples without human assistance, they are no longer limited by those rules tacitly applied but not explicitly understood by humans.

AlphaGo program built by the Google subsidiary DeepMind is a great example of how advances in AI have allowed mindless machines to perform tasks based on tacit knowledge outstandingly. In the 2016 tournament of the strategy game Go, DeepMind’s AlphaGo program successfully defeated one of the world’s top GO players, Lee Se-dol, four games to one. DeepMind team employed an approach known as deep learning to build human-type judgment into AI systems; therefore, they can figure out complex winning strategies by seeing vast examples of Go matches.

On the other hand, as Carr argues, the assumption that computers need to be able to reproduce tacit knowledge applied by humans to perform complicated tasks is essentially doubtable. When performing demanding tasks, it is not necessary for systems and machines to reflect the rules that human beings follow at all. The requirement is to replicate our outcomes for practical purposes, rather than our means.

Jerry Kaplan, a Silicon Valley entrepreneur and AI expert, also illustrates this point in his book "Humans Need Not Apply" by discussing four resources and capabilities required to accomplish any given task: awareness, energy, reasoning and means. Humans' biological system (the brain-body complex) naturally integrates all these four properties, while in the electronic domain machines nowadays are given these abilities by accelerating developments in robotics, machine learning, and perception powering systems. For example, sensory data provided by a wide network of sensors enable AI to perceive various aspects of the environment and respond instantly in chaotic and complex real-world situations (awareness); orders and signals for actuating devices can be centralised and managed in server clusters or on the 'cloud' (reasoning). Kaplan's argument directly supports the proposition that Polanyi's paradox can no longer impede further levels of automation, whether in performing routine jobs or manual jobs. As Kaplan puts it, "Automation is blind to the colour of your collar."

One example confirms Kaplan's argument is the introduction of Cloud AutoML, an automated system that could help every business design AI software, by Google Brain AI research group in 2017. The learning algorithms of AutoML automates the process of building machine-learning models that can take on a particular task, aiming to democratize AI to the largest possible community of developers and businesses. According to Google’s CEO, Cloud AutoML has taken over some of the work of programmers (which is, in the words of Autor, "abstract task") and thereby offered one solution to the shortage in machine-learning experts.

Moravec’s paradox is very closed related to Polanyi's paradox, which claims that compared with sophisticated tasks demanding high-level reasoning, it is harder for computers to master low-level physical and cognitive skills that are natural and easy for humans to perform. Examples include natural language processing and dextrous physical movements (e.g. running over rough terrain).

Robotics experts have, therefore, discovered that machines are difficult to master the skills of even the least-trained manual worker, since these jobs require perception and mobility (tacit knowledge). In the words of the cognitive scientist Steven Pinker from his book "The Language Instinct," "The main lesson of thirty-five years of AI research is that the hard problems are easy and the easy problems are hard."

Corresponding to David Autor's discussion on jobs polarization, Pinker maintains that the appearance of the new generation's intelligent machines would place stock analysts, petrochemical engineers and parole board members in danger of being replaced. Gardeners, receptionists, and cooks are, by contrast, currently secure.

Moore's Law is the observation articulated by Gordon Moore in 1965 that the number of transistors that could be fitted onto an integrated circuit doubles every two years. Moore's law has significantly contributed to the advancement of machine learning and AI. The larger and larger capacity of a chip allows for the advent of extremely small data-collecting devices, which could be placed on any intelligent machine. Innovations resulted from the exponentially growing power of computer chips include mobile apps, video games, spreadsheets, and accurate weather forecasts.

Moore’s Law changes the way people are valued. As machines can do more and more tasks for free, people become correspondingly expensive. On the other hand, Moore's Law to some extents erases the line between an ordinary person and a skilled person.

Although Moore’s prediction had been realized until around 2012, Intel announced in 2015 that the pace was slowing to a halt. Thomas Wenisch, an assistant professor at the University of Michigan, thinks the stagnant development of chips with denser transistors would create a problem for areas like mobile devices, data centers, and self-driving cars on different timescales. Without Moore's Law as the feedstock of innovation in computing, technology companies have to work harder to achieve new development levels (e.g. to get a new breakthrough on Polanyi's paradox).


</doc>
<doc id="49901" url="https://en.wikipedia.org/wiki?curid=49901" title="Virtue">
Virtue

Virtue (, "arete") is moral excellence. A virtue is a trait or quality that is deemed to be morally good and thus is valued as a foundation of principle and good moral being. Personal virtues are characteristics valued as promoting collective and individual greatness. In other words, it is a behavior that shows high moral standards. Doing what is right and avoiding what is wrong. The opposite of virtue is vice.

The four classic cardinal virtues in Christianity are temperance, prudence, courage, and justice. Christianity derives the three theological virtues of faith, hope and love (charity) from 1 Corinthians. Together these make up the seven virtues. Buddhism's four brahmavihara ("Divine States") can be regarded as virtues in the European sense. The Japanese Bushidō code is characterized by up to ten virtues, including rectitude, courage, and benevolence.

The ancient Romans used the Latin word "virtus" (derived from "vir", their word for "man") to refer to all of the "excellent qualities of men, including physical strength, valorous conduct, and moral rectitude." The French words "vertu" and "virtu" came from this Latin root. In the 13th century, the word "virtue" was "borrowed into English".

During Egyptian civilization, Maat or Ma'at (thought to have been pronounced *[muʔ.ʕat]), also spelled māt or mayet, was the ancient Egyptian concept of truth, balance, order, law, morality, and justice. Maat was also personified as a goddess regulating the stars, seasons, and the actions of both mortals and the deities. The deities set the order of the universe from chaos at the moment of creation. Her (ideological) counterpart was Isfet, who symbolized chaos, lies, and injustice.

The four classic cardinal virtues are:

This enumeration is traced to Greek philosophy and was listed by Plato in addition to piety: (hosiotēs), with the exception that wisdom replaced prudence as virtue. Some scholars consider either of the above four virtue combinations as mutually reducible and therefore not cardinal.

It is unclear whether multiple virtues were of later construct, and whether Plato subscribed to a unified view of virtues. In "Protagoras" and "Meno", for example, he states that the separate virtues cannot exist independently and offers as evidence the contradictions of acting with wisdom, yet in an unjust way; or acting with bravery (fortitude), yet without wisdom.

In his work "Nicomachean Ethics", Aristotle defined a virtue as a point between a deficiency and an excess of a trait. The point of greatest virtue lies not in the exact middle, but at a golden mean sometimes closer to one extreme than the other. However, the virtuous action is not simply the "mean" (mathematically speaking) between two opposite extremes. As Aristotle says in the Nicomachean Ethics: "at the right times, about the right things, towards the right people, for the right end, and in the right way, is the intermediate and best condition, and this is proper to virtue." This is not simply splitting the difference between two extremes. For example, generosity is a virtue between the two extremes of miserliness and being profligate. Further examples include: courage between cowardice and foolhardiness, and confidence between self-deprecation and vanity. In Aristotle's sense, virtue is excellence at being human.

Seneca, the Roman Stoic, said that perfect prudence is indistinguishable from perfect virtue. Thus, in considering all consequences, a prudent person would act in the same way as a virtuous person. The same rationale was expressed by Plato in Meno, when he wrote that people only act in ways that they perceive will bring them maximum good. It is the lack of wisdom that results in the making of a bad choice instead of a prudent one. In this way, wisdom is the central part of virtue. Plato realized that because virtue was synonymous with wisdom it could be taught, a possibility he had earlier discounted. He then added "correct belief" as an alternative to knowledge, proposing that knowledge is merely correct belief that has been thought through and "tethered".

The term "virtue" itself is derived from the Latin "virtus" (the personification of which was the deity Virtus), and had connotations of "manliness", "honour", worthiness of deferential respect, and civic duty as both citizen and soldier. This virtue was but one of many virtues which Romans of good character were expected to exemplify and pass on through the generations, as part of the Mos Maiorum; ancestral traditions which defined "Roman-ness". Romans distinguished between the spheres of private and public life, and thus, virtues were also divided between those considered to be in the realm of private family life (as lived and taught by the paterfamilias), and those expected of an upstanding Roman citizen.

Most Roman concepts of virtue were also personified as a numinous deity. The primary Roman virtues, both public and private, were:

In 410 CE, Aurelius Prudentius Clemens listed seven "heavenly virtues" in his book Psychomachia (Battle of Souls) which is an allegorical story of conflict between vices and virtues. The virtues depicted were:

In the 8th Century, upon the occasion of his coronation as Holy Roman Emperor Charlemagne published a list of knightly virtues:


Virtues are philosophical concepts which have a singular focus and inform the beliefs and behaviors of people.

Loving God and obeying his laws, in particular the Ten Commandments, are central to Jewish conceptions of virtue. Wisdom is personified in the first eight chapters of the Book of Proverbs and is not only the source of virtue but is depicted as the first and best creation of God (Proverbs 8:12-31).

A classic articulation of the Golden Rule came from the first century Rabbi Hillel the Elder. Renowned in the Jewish tradition as a sage and a scholar, he is associated with the development of the Mishnah and the Talmud and, as such, one of the most important figures in Jewish history. Asked for a summary of the Jewish religion in the most concise terms, Hillel replied (reputedly while standing on one leg): "That which is hateful to you, do not do to your fellow. That is the whole Torah. The rest is commentary; go and learn."

In Christianity, the three theological virtues are faith, hope and love, a list which comes from 1 Corinthians 13:13 ( "pistis" (faith), "elpis" (hope), "agape" (love), ). The same chapter describes love as the greatest of the three, and further defines love as "patient, kind, not envious, boastful, arrogant, or rude." (The Christian virtue of love is sometimes called charity and at other times a Greek word agape is used to contrast the love of God and the love of humankind from other types of love such as friendship or physical affection.)

Christian scholars frequently add the four Greek cardinal virtues (prudence, justice, temperance, and courage) to the theological virtues to give the seven virtues; for example, these seven are the ones described in the "Catechism of the Catholic Church", sections 1803–1829.

The Bible mentions additional virtues, such as in the "Fruit of the Holy Spirit," found in Galatians 5:22-23: "By contrast, the fruit of the Spirit it is benevolent-love: joy, peace, longsuffering, kindness, benevolence, faithfulness, gentleness, and self-control. There is absolutely no law against such a thing."

The medieval and renaissance periods saw a number of models of sin listing the seven deadly sins and the virtues opposed to each.

In Islam, the Qur'an is believed to be the literal word of God, and the definitive description of virtue while Muhammad is considered an ideal example of virtue in human form. The foundation of Islamic understanding of virtue was the understanding and interpretation of the Qur'an and the practices of Muhammad. Its meaning has always been in context of active submission to God performed by the community in unison. The motive force is the notion that believers are to "enjoin that which is virtuous and forbid that which is vicious" ("al-amr bi-l-maʿrūf wa-n-nahy ʿani-l-munkar") in all spheres of life (). Another key factor is the belief that mankind has been granted the faculty to discern God's will and to abide by it. This faculty most crucially involves reflecting over the meaning of existence. Therefore, regardless of their environment, humans are believed to have a moral responsibility to submit to God's will. Muhammad's preaching produced a "radical change in moral values based on the sanctions of the new religion and the present religion, and fear of God and of the Last Judgment". Later Muslim scholars expanded the religious ethics of the scriptures in immense detail.

In the Hadith (Islamic traditions), it is reported by An-Nawwas bin Sam'an:
Wabisah bin Ma’bad reported:
Virtue, as seen in opposition to sin, is termed "thawāb" (spiritual merit or reward) but there are other Islamic terms to describe virtue such as "faḍl" ("bounty"), "taqwa" ("piety") and "ṣalāḥ" ("righteousness"). For Muslims fulfilling the rights of others are valued as an important building block of Islam. According to Muslim beliefs, God will forgive individual sins but the bad treatment of people and injustice with others will only be pardoned by them and not by God.

In Jainism, attainment of enlightenment is possible only if the seeker possesses certain virtues. All Jains are supposed to take up the five vows of ahimsa (non violence), satya (truthfulness), asteya (non stealing), aparigraha (non attachment) and brahmacharya (celibacy) before becoming a monk. These vows are laid down by the Tirthankaras. Other virtues which are supposed to be followed by both monks as well as laypersons include forgiveness, humility, self-restraint and straightforwardness. These vows assists the seeker to escape from the karmic bondages thereby escaping the cycle of birth and death to attain liberation.

Virtue is a much debated and an evolving concept in ancient scriptures of Hinduism. The essence, need and value of virtue is explained in Hindu philosophy as something that cannot be imposed, but something that is realized and voluntarily lived up to by each individual. For example, Apastamba explained it thus: "virtue and vice do not go about saying - here we are!; neither the Gods, Gandharvas, nor ancestors can convince us - this is right, this is wrong; virtue is an elusive concept, it demands careful and sustained reflection by every man and woman before it can become part of one's life.

Virtues lead to "punya" (Sanskrit: पुण्य, holy living) in Hindu literature; while vices lead to "pap" (Sanskrit: पाप, sin). Sometimes, the word "punya" is used interchangeably with virtue.

The virtues that constitute a dharmic life - that is a moral, ethical, virtuous life - evolve in vedas and upanishads. Over time, new virtues were conceptualized and added by ancient Hindu scholars, some replaced, others merged. For example, Manusamhita initially listed ten virtues necessary for a human being to live a "dharmic" life: "Dhriti" (courage), "Kshama" (forgiveness), "Dama" (temperance), "Asteya" (Non-covetousness/Non-stealing), "Saucha" (inner purity), "Indriyani-graha" (control of senses), "dhi" (reflective prudence), "vidya" (wisdom), "satyam" (truthfulness), "akrodha" (freedom from anger). In later verses, this list was reduced to five virtues by the same scholar, by merging and creating a more broader concept. The shorter list of virtues became: "Ahimsa" (Non-violence), "Dama" (self restraint), "Asteya" (Non-covetousness/Non-stealing), "Saucha" (inner purity), "Satyam" (truthfulness).

The Bhagavad Gita - considered one of the epitomes of historic Hindu discussion of virtues and an allegorical debate on what is right and what is wrong - argues some virtues are not necessarily always absolute, but sometimes relational; for example, it explains a virtue such as Ahimsa must be re-examined when one is faced with war or violence from the aggressiveness, immaturity or ignorance of others.

Buddhist practice as outlined in the Noble Eightfold Path can be regarded as a progressive list of virtues.

Buddhism's four "brahmavihara" ("Divine States") can be more properly regarded as virtues in the European sense. They are:

There are also the Paramitas ("perfections"), which are the culmination of having acquired certain virtues. In Theravada Buddhism's canonical Buddhavamsa there are Ten Perfections ("dasa pāramiyo"). In Mahayana Buddhism, the Lotus Sutra ("Saddharmapundarika"), there are Six Perfections; while in the Ten Stages ("Dasabhumika") Sutra, four more "Paramitas" are listed.

In the Bahá'í Faith, virtues are direct spiritual qualities that the human soul possesses, inherited from the world of God. The development and manifestation of these virtues is the theme of the "Hidden Words" of Bahá'u'lláh and are discussed in great detail as the underpinnings of a divinely-inspired society by `Abdu'l-Bahá in such texts as "The Secret of Divine Civilization".

"Virtue", translated from Chinese "de" (), is also an important concept in Chinese philosophy, particularly Daoism. "De" () originally meant normative "virtue" in the sense of "personal character; inner strength; integrity", but semantically changed to moral "virtue; kindness; morality". Note the semantic parallel for English "", with an archaic meaning of "inner potency; divine power" (as in "by virtue of") and a modern one of "moral excellence; goodness".

In early periods of Confucianism, moral manifestations of "virtue" include "ren" ("humanity"), "xiao" ("filial piety"), and "li" ("proper behavior, performance of rituals"). The notion of ren - according to Simon Leys - means "humanity" and "goodness". Ren originally had the archaic meaning in the Confucian Book of Poems of "virility", but progressively took on shades of ethical meaning. Some scholars consider the virtues identified in early Confucianism as non-theistic philosophy.

The Daoist concept of "De", compared to Confucianism, is more subtle, pertaining to the "virtue" or ability that an individual realizes by following the Dao ("the Way"). One important normative value in much of Chinese thinking is that one's social status should result from the amount of virtue that one demonstrates, rather than from one's birth. In the "Analects", Confucius explains "de" as follows: "He who exercises government by means of his virtue may be compared to the north polar star, which keeps its place and all the stars turn towards it." In later periods, particularly from the Tang dynasty period, Confucianism as practiced, absorbed and melded its own concepts of virtues with those from Daoism and Buddhism.

In Hagakure, Yamamoto Tsunetomo encapsulates his views on 'virtue' in the four vows he makes daily:

Yamamoto goes on to say:
If one dedicates these four vows to the gods and Buddhas every morning, he will have the strength of two men and never slip backward. One must edge forward like the inchworm, bit by bit. The gods and Buddhas, too, first started with a vow.

The Bushidō code is typified by seven virtues:

Others that are sometimes added to these:

While religious scriptures generally consider "dharma" or "aṟam" (the Tamil term for virtue) as a divine virtue, Valluvar describes it as a way of life rather than any spiritual observance, a way of harmonious living that leads to universal happiness. For this reason, Valluvar keeps "aṟam" as the cornerstone throughout the writing of the Kural literature. Valluvar considered justice as a facet or product of "aram." While ancient Greek philosophers such as Plato, Aristotle, and their descendants opined that justice cannot be defined and that it was a divine mystery, Valluvar positively suggested that a divine origin is not required to define the concept of justice. In the words of V. R. Nedunchezhiyan, justice according to Valluvar "dwells in the minds of those who have knowledge of the standard of right and wrong; so too deceit dwells in the minds which breed fraud."

For the Rationalist philosopher René Descartes, virtue consists in the correct reasoning that should guide our actions. Men should seek the sovereign good that Descartes, following Zeno, identifies with virtue, as this produces a solid blessedness or pleasure. For Epicurus the sovereign good was pleasure, and Descartes says that in fact this is not in contradiction with Zeno's teaching, because virtue produces a spiritual pleasure, that is better than bodily pleasure. Regarding Aristotle's opinion that happiness depends on the goods of fortune, Descartes does not deny that these goods contribute to happiness, but remarks that they are in great proportion outside one's own control, whereas one's mind is under one's complete control.

Immanuel Kant, in his "Observations on the Feeling of the Beautiful and Sublime", expresses true virtue as different from what commonly is known about this moral trait. In Kant's view, to be goodhearted, benevolent and sympathetic is not regarded as true virtue. The only aspect that makes a human truly virtuous is to behave in accordance with moral principles. Kant presents an example for more clarification; suppose that you come across a needy person in the street; if your sympathy leads you to help that person, your response does not illustrate your virtue. In this example, since you do not afford helping all needy ones, you have behaved unjustly, and it is out of the domain of principles and true virtue. Kant applies the approach of four temperaments to distinguish truly virtuous people. According to Kant, among all people with diverse temperaments, a person with melancholy frame of mind is the most virtuous whose thoughts, words and deeds are one of principles.

Friedrich Nietzsche's view of virtue is based on the idea of an order of rank among people. For Nietzsche, the virtues of the strong are seen as vices by the weak and slavish, thus Nietzsche's virtue ethics is based on his distinction between master morality and slave morality. Nietzsche promotes the virtues of those he calls "higher men", people like Goethe and Beethoven. The virtues he praises in them are their creative powers (“the men of great creativity” - “the really great men according to my understanding” (WP 957)).
According to Nietzsche these higher types are solitary, pursue a "unifying project", revere themselves and are healthy and life-affirming. Because mixing with the herd makes one base, the higher type “strives instinctively for a citadel and a secrecy where he is saved from the crowd, the many, the great majority…” (BGE 26). The 'Higher type' also "instinctively seeks heavy responsibilities" (WP 944) in the form of an "organizing idea" for their life, which drives them to artistic and creative work and gives them psychological health and strength. The fact that the higher types are "healthy" for Nietzsche does not refer to physical health as much as a psychological resilience and fortitude. Finally, a Higher type affirms life because he is willing to accept the eternal return of his life and affirm this forever and unconditionally.

In the last section of "Beyond Good and Evil", Nietzsche outlines his thoughts on the noble virtues and places solitude as one of the highest virtues:

And to keep control over your four virtues: courage, insight, sympathy, solitude. Because solitude is a virtue for us, since it is a sublime inclination and impulse to cleanliness which shows that contact between people (“society”) inevitably makes things unclean. Somewhere, sometime, every
community makes people – “base.” (BGE §284)

Nietzsche also sees truthfulness as a virtue:

Genuine honesty, assuming that this is our virtue and we cannot get rid of it, we free spirits – well then, we will want to work on it with all the love and malice at our disposal and not get tired of ‘perfecting’ ourselves in our virtue, the only one we have left: may its glory come to rest like a gilded, blue evening glow of mockery over this aging culture and its dull and dismal seriousness! (Beyond Good and Evil, §227)

These are the virtues that Benjamin Franklin used to develop what he called 'moral perfection'. He had a checklist in a notebook to measure each day how he lived up to his virtues.

They became known through Benjamin Franklin's autobiography.


Marc Jackson in his book "Emotion and Psyche" puts forward a new development of the virtues. He identifies the virtues as what he calls the good emotions "The first group consisting of love, kindness, joy, faith, awe and pity is good" These virtues differ from older accounts of the virtues because they are not character traits expressed by action, but emotions that are to be felt and developed by feeling not acting.
Ayn Rand held that her morality, the , contained a single axiom: existence exists, and a single choice: to live. All values and virtues proceed from these. To live, man must hold three fundamental values that one develops and achieves in life: Reason, Purpose, and Self-Esteem. A value is "that which one acts to gain and/or keep ... and the virtue[s] [are] the act[ions] by which one gains and/or keeps it." The primary virtue in Objectivist ethics is rationality, which as Rand meant it is "the recognition and acceptance of reason as one's only source of knowledge, one's only judge of values and one's only guide to action." These values are achieved by passionate and consistent action and the virtues are the policies for achieving those fundamental values. Ayn Rand describes seven virtues: rationality, productiveness, pride, independence, integrity, honesty and justice. The first three represent the three primary virtues that correspond to the three fundamental values, whereas the final four are derived from the virtue of rationality. She claims that virtue is not an end in itself, that virtue is not its own reward nor sacrificial fodder for the reward of evil, that life is the reward of virtue and happiness is the goal and the reward of life. Man has a single basic choice: to think or not, and that is the gauge of his virtue. Moral perfection is an unbreached rationality, not the degree of your intelligence but the full and relentless use of your mind, not the extent of your knowledge but the acceptance of reason as an absolute.

Christopher Peterson and Martin Seligman, two leading researchers in positive psychology, recognizing the deficiency inherent in psychology's tendency to focus on dysfunction rather than on what makes a healthy and stable personality, set out to develop a list of "Character Strengths and Virtues". After three years of study, 24 traits (classified into six broad areas of virtue) were identified, having "a surprising amount of similarity across cultures and strongly indicat[ing] a historical and cross-cultural convergence." These six categories of virtue are courage, justice, humanity, temperance, transcendence, and wisdom. Some psychologists suggest that these virtues are adequately grouped into fewer categories; for example, the same 24 traits have been grouped into simply: Cognitive Strengths, Temperance Strengths, and Social Strengths.

The opposite of a virtue is a vice. Vice is a habitual, repeated practice of wrongdoing. One way of organizing the vices is as the corruption of the virtues.

As Aristotle noted, however, the virtues can have several opposites. Virtues can be considered the mean between two extremes, as the Latin maxim dictates "in medio stat virtus" - in the centre lies virtue. For instance, both cowardice and rashness are opposites of courage; contrary to prudence are both over-caution and insufficient caution; the opposites of pride (a virtue) are undue humility and excessive vanity. A more "modern" virtue, tolerance, can be considered the mean between the two extremes of narrow-mindedness on the one hand and over-acceptance on the other. Vices can therefore be identified as the opposites of virtues - but with the caveat that each virtue could have many different opposites, all distinct from each other.




</doc>
<doc id="6978" url="https://en.wikipedia.org/wiki?curid=6978" title="Concept">
Concept

Concepts are mental representations, abstract objects or abilities that make up the fundamental building blocks of thoughts and beliefs. They play an important role in all aspects of cognition.

In contemporary philosophy, there are at least three prevailing ways to understand what a concept is:


Concepts can be organized into a hierarchy, higher levels of which are termed "superordinate" and lower levels termed "subordinate". Additionally, there is the "basic" or "middle" level at which people will most readily categorize a concept. For example, a basic-level concept would be "chair", with its superordinate, "furniture", and its subordinate, "easy chair".

A concept is instantiated (reified) by all of its actual or potential instances, whether these are things in the real world or other ideas.

Concepts are studied as components of human cognition in the cognitive science disciplines of linguistics, psychology and, philosophy, where an ongoing debate asks whether all cognition must occur through concepts. Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence where they are sometimes called classes, schema or categories. In informal use the word "concept" often just means any idea.

Within the framework of the representational theory of mind, the structural position of concepts can be understood as follows: Concepts serve as the building blocks of what are called "mental representations" (colloquially understood as "ideas in the mind"). Mental representations, in turn, are the building blocks of what are called "propositional attitudes" (colloquially understood as the stances or perspectives we take towards ideas, be it "believing", "doubting", "wondering", "accepting", etc.). And these propositional attitudes, in turn, are the building blocks of our understanding of thoughts that populate everyday life, as well as folk psychology. In this way, we have an analysis that ties our common everyday understanding of thoughts down to the scientific and philosophical understanding of concepts.

A central question in the study of concepts is the question of what they "are". Philosophers construe this question as one about the ontology of concepts – what they are like. The ontology of concepts determines the answer to other questions, such as how to integrate concepts into a wider theory of the mind, what functions are allowed or disallowed by a concept's ontology, etc. There are two main views of the ontology of concepts: (1) Concepts are abstract objects, and (2) concepts are mental representations.

Platonist views of the mind construe concepts as abstract objects,

There is debate as to the relationship between concepts and natural language. However, it is necessary at least to begin by understanding that the concept "dog" is philosophically distinct from the things in the world grouped by this concept – or the reference class or extension. Concepts that can be equated to a single word are called "lexical concepts".

Study of concepts and conceptual structure falls into the disciplines of linguistics, philosophy, psychology, and cognitive science.

In the simplest terms, a concept is a name or label that regards or treats an abstraction as if it had concrete or material existence, such as a person, a place, or a thing. It may represent a natural object that exists in the real world like a tree, an animal, a stone, etc. It may also name an artificial (man-made) object like a chair, computer, house, etc. Abstract ideas and knowledge domains such as freedom, equality, science, happiness, etc., are also symbolized by concepts. It is important to realize that a concept is merely a symbol, a representation of the abstraction. The word is not to be mistaken for the thing. For example, the word "moon" (a concept) is not the large, bright, shape-changing object up in the sky, but only "represents" that celestial object. Concepts are created (named) to describe, explain and capture reality as it is known and understood.

Kant maintained the view that human minds possess pure or "a priori" concepts. Instead of being abstracted from individual perceptions, like empirical concepts, they originate in the mind itself. He called these concepts categories, in the sense of the word that means predicate, attribute, characteristic, or quality. But these pure categories are predicates of things "in general", not of a particular thing. According to Kant, there are twelve categories that constitute the understanding of phenomenal objects. Each category is that one predicate which is common to multiple empirical concepts. In order to explain how an "a priori" concept can relate to individual phenomena, in a manner analogous to an "a posteriori" concept, Kant employed the technical concept of the schema. He held that the account of the concept as an abstraction of experience is only partly correct. He called those concepts that result from abstraction "a posteriori concepts" (meaning concepts that arise out of experience). An empirical or an "a posteriori" concept is a general representation ("Vorstellung") or non-specific thought of that which is common to several specific perceived objects (Logic, I, 1., §1, Note 1)

A concept is a common feature or characteristic. Kant investigated the way that empirical "a posteriori" concepts are created.
In cognitive linguistics, abstract concepts are transformations of concrete concepts derived from embodied experience. The mechanism of transformation is structural mapping, in which properties of two or more source domains are selectively mapped onto a blended space (Fauconnier & Turner, 1995; see conceptual blending). A common class of blends are metaphors. This theory contrasts with the rationalist view that concepts are perceptions (or "recollections", in Plato's term) of an independently existing world of ideas, in that it denies the existence of any such realm. It also contrasts with the empiricist view that concepts are abstract generalizations of individual experiences, because the contingent and bodily experience is preserved in a concept, and not abstracted away. While the perspective is compatible with Jamesian pragmatism, the notion of the transformation of embodied concepts through structural mapping makes a distinct contribution to the problem of concept formation.

Plato was the starkest proponent of the realist thesis of universal concepts. By his view, concepts (and ideas in general) are innate ideas that were instantiations of a transcendental world of pure forms that lay behind the veil of the physical world. In this way, universals were explained as transcendent objects. Needless to say this form of realism was tied deeply with Plato's ontological projects. This remark on Plato is not of merely historical interest. For example, the view that numbers are Platonic objects was revived by Kurt Gödel as a result of certain puzzles that he took to arise from the phenomenological accounts.

Gottlob Frege, founder of the analytic tradition in philosophy, famously argued for the analysis of language in terms of sense and reference. For him, the sense of an expression in language describes a certain state of affairs in the world, namely, the way that some object is presented. Since many commentators view the notion of sense as identical to the notion of concept, and Frege regards senses as the linguistic representations of states of affairs in the world, it seems to follow that we may understand concepts as the manner in which we grasp the world. Accordingly, concepts (as senses) have an ontological status (Morgolis:7).

According to Carl Benjamin Boyer, in the introduction to his "The History of the Calculus and its Conceptual Development", concepts in calculus do not refer to perceptions. As long as the concepts are useful and mutually compatible, they are accepted on their own. For example, the concepts of the derivative and the integral are not considered to refer to spatial or temporal perceptions of the external world of experience. Neither are they related in any way to mysterious limits in which quantities are on the verge of nascence or evanescence, that is, coming into or going out of existence. The abstract concepts are now considered to be totally autonomous, even though they originated from the process of abstracting or taking away qualities from perceptions until only the common, essential attributes remained.

In a physicalist theory of mind, a concept is a mental representation, which the brain uses to denote a class of things in the world. This is to say that it is literally, a symbol or group of symbols together made from the physical material of the brain. Concepts are mental representations that allow us to draw appropriate inferences about the type of entities we encounter in our everyday lives. Concepts do not encompass all mental representations, but are merely a subset of them. The use of concepts is necessary to cognitive processes such as categorization, memory, decision making, learning, and inference.

Concepts are thought to be stored in long term cortical memory, in contrast to episodic memory of the particular objects and events which they abstract, which are stored in hippocampus. Evidence for this separation comes from hippocampal damaged patients such as patient HM. The abstraction from the day's hippocampal events and objects into cortical concepts is often considered to be the computation underlying (some stages of) sleep and dreaming. Many people (beginning with Aristotle) report memories of dreams which appear to mix the day's events with analogous or related historical concepts and memories, and suggest that they were being sorted or organised into more abstract concepts. ("Sort" is itself another word for concept, and "sorting" thus means to organise into concepts.)

The classical theory of concepts, also referred to as the empiricist theory of concepts, is the oldest theory about the structure of concepts (it can be traced back to Aristotle), and was prominently held until the 1970s. The classical theory of concepts says that concepts have a definitional structure. Adequate definitions of the kind required by this theory usually take the form of a list of features. These features must have two important qualities to provide a comprehensive definition. Features entailed by the definition of a concept must be both "necessary" and "sufficient" for membership in the class of things covered by a particular concept. A feature is considered necessary if every member of the denoted class has that feature. A feature is considered sufficient if something has all the parts required by the definition. For example, the classic example "bachelor" is said to be defined by "unmarried" and "man". An entity is a bachelor (by this definition) if and only if it is both unmarried and a man. To check whether something is a member of the class, you compare its qualities to the features in the definition. Another key part of this theory is that it obeys the "law of the excluded middle", which means that there are no partial members of a class, you are either in or out.

The classical theory persisted for so long unquestioned because it seemed intuitively correct and has great explanatory power. It can explain how concepts would be acquired, how we use them to categorize and how we use the structure of a concept to determine its referent class. In fact, for many years it was one of the major activities in philosophy – concept analysis. Concept analysis is the act of trying to articulate the necessary and sufficient conditions for the membership in the referent class of a concept. For example, Shoemaker's classic "Time Without Change" explored whether the concept of the flow of time can include flows where no changes take place, though change is usually taken as a definition of time.

Given that most later theories of concepts were born out of the rejection of some or all of the classical theory, it seems appropriate to give an account of what might be wrong with this theory. In the 20th century, philosophers such as Wittgenstein and Rosch argued against the classical theory. There are six primary arguments summarized as follows:

Prototype theory came out of problems with the classical view of conceptual structure. Prototype theory says that concepts specify properties that members of a class tend to possess, rather than must possess. Wittgenstein, Rosch, Mervis, Berlin, Anglin, and Posner are a few of the key proponents and creators of this theory. Wittgenstein describes the relationship between members of a class as "family resemblances". There are not necessarily any necessary conditions for membership, a dog can still be a dog with only three legs. This view is particularly supported by psychological experimental evidence for prototypicality effects. Participants willingly and consistently rate objects in categories like 'vegetable' or 'furniture' as more or less typical of that class. It seems that our categories are fuzzy psychologically, and so this structure has explanatory power. We can judge an item's membership to the referent class of a concept by comparing it to the typical member – the most central member of the concept. If it is similar enough in the relevant ways, it will be cognitively admitted as a member of the relevant class of entities. Rosch suggests that every category is represented by a central exemplar which embodies all or the maximum possible number of features of a given category. According to Lech, Gunturkun, and Suchan explain that categorization involves many areas of the brain, some of these are; visual association areas, prefrontal cortex, basal ganglia, and temporal lobe.

Theory-theory is a reaction to the previous two theories and develops them further. This theory postulates that categorization by concepts is something like scientific theorizing. Concepts are not learned in isolation, but rather are learned as a part of our experiences with the world around us. In this sense, concepts' structure relies on their relationships to other concepts as mandated by a particular mental theory about the state of the world. How this is supposed to work is a little less clear than in the previous two theories, but is still a prominent and notable theory. This is supposed to explain some of the issues of ignorance and error that come up in prototype and classical theories as concepts that are structured around each other seem to account for errors such as whale as a fish (this misconception came from an incorrect theory about what a whale is like, combining with our theory of what a fish is). When we learn that a whale is not a fish, we are recognizing that whales don't in fact fit the theory we had about what makes something a fish. In this sense, the Theory–Theory of concepts is responding to some of the issues of prototype theory and classic theory.

According to the theory of ideasthesia (or "sensing concepts"), activation of a concept may be the main mechanism responsible for creation of phenomenal experiences. Therefore, understanding how the brain processes concepts may be central to solving the mystery of how conscious experiences (or qualia) emerge within a physical system e.g., the sourness of the sour taste of lemon. This question is also known as the hard problem of consciousness. Research on ideasthesia emerged from research on synesthesia where it was noted that a synesthetic experience requires first an activation of a concept of the inducer. Later research expanded these results into everyday perception.

There is a lot of discussion on the most effective theory in concepts. Another theory is semantic pointers, which use perceptual and motor representations and these representations are like symbols.

The term "concept" is traced back to 1554–60 (Latin "" – "something conceived").



</doc>
<doc id="24390" url="https://en.wikipedia.org/wiki?curid=24390" title="Paradox">
Paradox

A paradox is a statement that, despite apparently valid reasoning from true premises, leads to an apparently-self-contradictory or logically unacceptable conclusion. A paradox involves contradictory-yet-interrelated elements that exist simultaneously and persist over time.

Some logical paradoxes are known to be invalid arguments but are still valuable in promoting critical thinking.

Some paradoxes have revealed errors in definitions assumed to be rigorous, and have caused axioms of mathematics and logic to be re-examined. One example is Russell's paradox, which questions whether a "list of all lists that do not contain themselves" would include itself, and showed that attempts to found set theory on the identification of sets with properties or predicates were flawed. Others, such as Curry's paradox, are not yet resolved.

Examples outside logic include the ship of Theseus from philosophy (questioning whether a ship repaired over time by replacing each and all of its wooden parts, one at a time, would remain the same ship). Paradoxes can also take the form of images or other media. For example, M.C. Escher featured perspective-based paradoxes in many of his drawings, with walls that are regarded as floors from other points of view, and staircases that appear to climb endlessly.

In common usage, the word "paradox" often refers to statements that are ironic or unexpected, such as "the paradox that standing is more tiring than walking".

Common themes in paradoxes include self-reference, infinite regress, circular definitions, and confusion between different levels of abstraction.

Patrick Hughes outlines three laws of the paradox:

Other paradoxes involve false statements ("'impossible' is not a word in my vocabulary", a simple paradox) or half-truths and the resulting biased assumptions. This form is common in howlers.

For example, consider a situation in which a father and his son are driving down the road. The car crashes into a tree and the father is killed. The boy is rushed to the nearest hospital where he is prepared for emergency surgery. Upon entering the surgery-suite, the surgeon says, "I can't operate on this boy. He's my son."

The apparent paradox is caused by a hasty generalization, for if the surgeon is the boy's father, the statement cannot be true. The paradox is resolved if it is revealed that the surgeon is a woman—the boy's mother.

Paradoxes which are not based on a hidden error generally occur at the fringes of context or language, and require extending the context or language in order to lose their paradoxical quality. Paradoxes that arise from apparently intelligible uses of language are often of interest to logicians and philosophers. "This sentence is false" is an example of the well-known liar paradox: it is a sentence which cannot be consistently interpreted as either true or false, because if it is known to be false, then it is known that it must be true, and if it is known to be true, then it is known that it must be false. Russell's paradox, which shows that the notion of "the set of all those sets that do not contain themselves" leads to a contradiction, was instrumental in the development of modern logic and set theory.

Thought-experiments can also yield interesting paradoxes. The grandfather paradox, for example, would arise if a time-traveler were to kill his own grandfather before his mother or father had been conceived, thereby preventing his own birth. This is a specific example of the more general observation of the butterfly effect, or that a time-traveller's interaction with the past—however slight—would entail making changes that would, in turn, change the future in which the time-travel was yet to occur, and would thus change the circumstances of the time-travel itself.

Often a seemingly paradoxical conclusion arises from an inconsistent or inherently contradictory definition of the initial premise. In the case of that apparent paradox of a time-traveler killing his own grandfather, it is the inconsistency of defining the past to which he returns as being somehow different from the one which leads up to the future from which he begins his trip, but also insisting that he must have come to that past from the same future as the one that it leads up to.

W. V. Quine (1962) distinguished between three classes of paradoxes:

A fourth kind has sometimes been described since Quine's work.

A taste for paradox is central to the philosophies of Laozi, Zeno of Elea, Zhuangzi, Heraclitus, Bhartrhari, Meister Eckhart, Hegel, Kierkegaard, Nietzsche, and G.K. Chesterton, among many others. Søren Kierkegaard, for example, writes in the "Philosophical Fragments" that
But one must not think ill of the paradox, for the paradox is the passion of thought, and the thinker without the paradox is like the lover without passion: a mediocre fellow. But the ultimate potentiation of every passion is always to will its own downfall, and so it is also the ultimate passion of the understanding to will the collision, although in one way or another the collision must become its downfall. This, then, is the ultimate paradox of thought: to want to discover something that thought itself cannot think.

A paradoxical reaction to a drug is the opposite of what one would expect, such as becoming agitated by a sedative or sedated by a stimulant. Some are common and are used regularly in medicine, such as the use of stimulants such as Adderall and Ritalin in the treatment of attention deficit hyperactivity disorder (also known as ADHD) while others are rare and can be dangerous as they are not expected, such as severe agitation from a benzodiazepine.




</doc>
<doc id="3143" url="https://en.wikipedia.org/wiki?curid=3143" title="Axiology">
Axiology

Axiology (from Greek , "axia", "value, worth"; and , "-logia") is the philosophical study of value. It is either the collective term for ethics and aesthetics, philosophical fields that depend crucially on notions of worth, or the foundation for these fields, and thus similar to value theory and meta-ethics. The term was first used by Paul Lapie, in 1902, and Eduard von Hartmann, in 1908.

Axiology studies mainly two kinds of values: ethics and aesthetics. Ethics investigates the concepts of "right" and "good" in individual and social conduct. Aesthetics studies the concepts of "beauty" and "harmony." Formal axiology, the attempt to lay out principles regarding value with mathematical rigor, is exemplified by Robert S. Hartman's science of value.

Between the 5th and 6th centuries BC, it was important in Greece to be knowledgeable if you were to be successful. Philosophers began to recognize that differences existed between the laws and morality of society. Socrates believed that knowledge had a vital connection to virtue, making morality and democracy closely intertwined. Socrates' student, Plato furthered the belief by establishing virtues which should be followed by all. With the fall of the government, values became individual, causing skeptic schools of thought to flourish, ultimately shaping a pagan philosophy that is thought to have influenced and shaped Christianity. During the medieval period, Thomas Aquinas made the distinction between natural and supernatural (theological) virtues. This concept led philosophers to distinguish between judgments based on fact and judgments based on values, creating division between science and philosophy.





</doc>
<doc id="24269" url="https://en.wikipedia.org/wiki?curid=24269" title="Process philosophy">
Process philosophy

Process philosophy — also ontology of becoming, processism, or philosophy of organism — identifies metaphysical reality with change. In opposition to the classical model of change as illusory (as argued by Parmenides) or accidental (as argued by Aristotle), process philosophy regards change as the cornerstone of reality—the cornerstone of being thought of as becoming.

Since the time of Plato and Aristotle, some philosophers have posited true reality as "timeless", based on permanent substances, while processes are denied or subordinated to timeless substances. If Socrates changes, becoming sick, Socrates is still the same (the substance of Socrates being the same), and change (his sickness) only glides over his substance: change is accidental, whereas the substance is essential. Therefore, classic ontology denies any full reality to change, which is conceived as only accidental and not essential. This classical ontology is what made knowledge and a theory of knowledge possible, as it was thought that a science of something in becoming was an impossible feat to achieve.

Philosophers who appeal to process rather than substance include Heraclitus, Karl Marx, Friedrich Nietzsche, Henri Bergson, Martin Heidegger, Charles Sanders Peirce, William James, Alfred North Whitehead, Alfred Korzybski, R. G. Collingwood, Alan Watts, Robert M. Pirsig, Charles Hartshorne, Arran Gare, Nicholas Rescher, Colin Wilson, Jacques Derrida, and Gilles Deleuze. In physics, Ilya Prigogine distinguishes between the "physics of being" and the "physics of becoming". Process philosophy covers not just scientific intuitions and experiences, but can be used as a conceptual bridge to facilitate discussions among religion, philosophy, and science.

Process philosophy is sometimes classified as closer to Continental philosophy than analytic philosophy, because it is usually only taught in Continental departments. However, other sources state that process philosophy should be placed somewhere in the middle between the poles of analytic versus Continental methods in contemporary philosophy.

Heraclitus proclaimed that the basic nature of all things is change.

The quotation from Heraclitus appears in Plato's "Cratylus" twice; in 401d as:
"Ta onta ienai te panta kai menein ouden""All entities move and nothing remains still"and in 402a

"Panta chōrei kai ouden menei kai dis es ton auton potamon ouk an embaies"
"Everything changes and nothing remains still ... and ... you cannot step twice into the same stream"

Heraclitus considered fire as the most fundamental element.

"All things are an interchange for fire, and fire for all things, just like goods for gold and gold for goods."

The following is an interpretation of Heraclitus's concepts into modern terms by Nicholas Rescher.

"...reality is not a constellation of things at all, but one of processes. The fundamental "stuff" of the world is not material substance, but volatile flux, namely "fire", and all things are versions thereof (puros tropai). Process is fundamental: the river is not an object, but a continuing flow; the sun is not a thing, but an enduring fire. Everything is a matter of process, of activity, of change (panta rhei)."

An early expression of this viewpoint is in Heraclitus's fragments. He posits strife, "ἡ ἔρις" (strife, conflict), as the underlying basis of all reality defined by change. The balance and opposition in strife were the foundations of change and stability in the flux of existence.

In early twentieth century, the philosophy of mathematics was undertaken to develop mathematics as an airtight, axiomatic system in which every truth could be derived logically from a set of axioms. In the foundations of mathematics, this project is variously understood as logicism or as part of the formalist program of David Hilbert. Alfred North Whitehead and Bertrand Russell attempted to complete, or at least facilitate, this program with their seminal book Principia Mathematica, which purported to build a logically consistent set theory on which to found mathematics. After this, Whitehead extended his interest to natural science, which he held needed a deeper philosophical basis. He intuited that natural science was struggling to overcome a traditional ontology of timeless material substances that does not suit natural phenomena. According to Whitehead, material is more properly understood as 'process'. In 1929, he produced the most famous work of process philosophy, "Process and Reality", continuing the work begun by Hegel but describing a more complex and fluid dynamic ontology.

Process thought describes truth as "movement" in and through substance (Hegelian truth), rather than substances as fixed concepts or "things" (Aristotelian truth). Since Whitehead, process thought is distinguished from Hegel in that it describes entities that arise or coalesce in "becoming", rather than being simply dialectically determined from prior posited determinates. These entities are referred to as "complexes of occasions of experience". It is also distinguished in being not necessarily conflictual or oppositional in operation. Process may be integrative, destructive or both together, allowing for aspects of interdependence, influence, and confluence, and addressing coherence in universal as well as particular developments, i.e., those aspects not befitting Hegel's system. Additionally, instances of determinate occasions of experience, while always ephemeral, are nonetheless seen as important to define the type and continuity of those occasions of experience that flow from or relate to them.

Alfred North Whitehead began teaching and writing on process and metaphysics when he joined Harvard University in 1924.

In his book "Science and the Modern World" (1925), Whitehead noted that the human intuitions and experiences of science, aesthetics, ethics, and religion influence the worldview of a community, but that in the last several centuries science dominates Western culture. Whitehead sought a holistic, comprehensive cosmology that provides a systematic descriptive theory of the world which can be used for the diverse human intuitions gained through ethical, aesthetic, religious, and scientific experiences, and not just the scientific.

Whitehead's influences were not restricted to philosophers or physicists or mathematicians. He was influenced by the French philosopher Henri Bergson (1859–1941), whom he credits along with William James and John Dewey in the preface to "Process and Reality".

For Whitehead, metaphysics is about logical frameworks for the conduct of discussions of the character of the world. It is not directly and immediately about facts of nature, but only indirectly so, in that its task is to explicitly formulate the language and conceptual presuppositions that are used to describe the facts of nature. Whitehead thinks that discovery of previously unknown facts of nature can in principle call for reconstruction of metaphysics.

The process metaphysics elaborated in "Process and Reality" posits an ontology which is based on the two kinds of existence of an entity, that of actual entity and that of abstract entity or abstraction, also called 'object'.

Actual entity is a term coined by Whitehead to refer to the entities that really exist in the natural world. For Whitehead, actual entities are spatiotemporally extended events or processes. An actual entity is how something is happening, and how its happening is related to other actual entities. The actually existing world is a multiplicity of actual entities overlapping one another.

The ultimate abstract principle of actual existence for Whitehead is creativity. Creativity is a term coined by Whitehead to show a power in the world that allows the presence of an actual entity, a new actual entity, and multiple actual entities. Creativity is the principle of novelty. It is manifest in what can be called 'singular causality'. This term may be contrasted with the term 'nomic causality'. An example of singular causation is that I woke this morning because my alarm clock rang. An example of nomic causation is that alarm clocks generally wake people in the morning. Aristotle recognizes singular causality as efficient causality. For Whitehead, there are many contributory singular causes for an event. A further contributory singular cause of my being awoken by my alarm clock this morning was that I was lying asleep near it till it rang.

An actual entity is a general philosophical term for an utterly determinate and completely concrete individual particular of the actually existing world or universe of considered in terms of singular causality, about which categorical statements can be made. Whitehead's most far-reaching and radical contribution to metaphysics is his invention of a better way of choosing the actual entities. Whitehead chooses a way of defining the actual entities that makes them all alike, "qua" actual entities, with a single exception.

For example, for Aristotle, the actual entities were the substances, such as Socrates. Besides Aristotle's ontology of substances, another example of an ontology that posits actual entities is in the monads of Leibniz, which are said to be 'windowless'.

For Whitehead's ontology of processes as defining the world, the actual entities exist as the only fundamental elements of reality.

The actual entities are of two kinds, temporal and atemporal.

With one exception, all actual entities for Whitehead are temporal and are occasions of experience (which are not to be confused with consciousness). An entity that people commonly think of as a simple concrete object, or that Aristotle would think of as a substance, is, in this ontology, considered to be a temporally serial composite of indefinitely many overlapping occasions of experience. A human being is thus composed of indefinitely many occasions of experience.

The one exceptional actual entity is at once both temporal and atemporal: God. He is objectively immortal, as well as being immanent in the world. He is objectified in each temporal actual entity; but He is not an eternal object.

The occasions of experience are of four grades. The first grade comprises processes in a physical vacuum such as the propagation of an electromagnetic wave or gravitational influence across empty space. The occasions of experience of the second grade involve just inanimate matter; "matter" being the composite overlapping of occasions of experience from the previous grade. The occasions of experience of the third grade involve living organisms. Occasions of experience of the fourth grade involve experience in the mode of presentational immediacy, which means more or less what are often called the qualia of subjective experience. So far as we know, experience in the mode of presentational immediacy occurs in only more evolved animals. That some occasions of experience involve experience in the mode of presentational immediacy is the one and only reason why Whitehead makes the occasions of experience his actual entities; for the actual entities must be of the ultimately general kind. Consequently, it is inessential that an occasion of experience have an aspect in the mode of presentational immediacy; occasions of the grades one, two, and three, lack that aspect.

There is no mind-matter duality in this ontology, because "mind" is simply seen as an abstraction from an occasion of experience which has also a material aspect, which is of course simply another abstraction from it; thus the mental aspect and the material aspect are abstractions from one and the same concrete occasion of experience. The brain is part of the body, both being abstractions of a kind known as "persistent physical objects", neither being actual entities. Though not recognized by Aristotle, there is biological evidence, written about by Galen, that the human brain is an essential seat of human experience in the mode of presentational immediacy. We may say that the brain has a material and a mental aspect, all three being abstractions from their indefinitely many constitutive occasions of experience, which are actual entities.

Inherent in each actual entity is its respective dimension of time. Potentially, each Whiteheadean occasion of experience is causally consequential on every other occasion of experience that precedes it in time, and has as its causal consequences every other occasion of experience that follows it in time; thus it has been said that Whitehead's occasions of experience are 'all window', in contrast to Leibniz's 'windowless' monads. In time defined relative to it, each occasion of experience is causally influenced by prior occasions of experiences, and causally influences future occasions of experience. An occasion of experience consists of a process of prehending other occasions of experience, reacting to them. This is the process in process philosophy.

Such process is never deterministic. Consequently, free will is essential and inherent to the universe.

The causal outcomes obey the usual well-respected rule that the causes precede the effects in time. Some pairs of processes cannot be connected by cause-and-effect relations, and they are said to be spatially separated. This is in perfect agreement with the viewpoint of the Einstein theory of special relativity and with the Minkowski geometry of spacetime. It is clear that Whitehead respected these ideas, as may be seen for example in his 1919 book "An Enquiry concerning the Principles of Natural Knowledge" as well as in "Process and Reality". Time in this view is relative to an inertial reference frame, different reference frames defining different versions of time.

The actual entities, the occasions of experience, are logically atomic in the sense that an occasion of experience cannot be cut and separated into two other occasions of experience. This kind of logical atomicity is perfectly compatible with indefinitely many spatio-temporal overlaps of occasions of experience. One can explain this kind of atomicity by saying that an occasion of experience has an internal causal structure that could not be reproduced in each of the two complementary sections into which it might be cut. Nevertheless, an actual entity can completely contain each of indefinitely many other actual entities.

Another aspect of the atomicity of occasions of experience is that they do not change. An actual entity is what it is. An occasion of experience can be described as a process of change, but it is itself unchangeable.

The reader should bear in mind that the atomicity of the actual entities is of a simply logical or philosophical kind, thoroughly different in concept from the natural kind of atomicity that describes the atoms of physics and chemistry.

Whitehead's theory of extension was concerned with the spatio-temporal features of his occasions of experience. Fundamental to both Newtonian and to quantum theoretical mechanics is the concept of momentum. The measurement of a momentum requires a finite spatiotemporal extent. Because it has no finite spatiotemporal extent, a single point of Minkowski space cannot be an occasion of experience, but is an abstraction from an infinite set of overlapping or contained occasions of experience, as explained in "Process and Reality". Though the occasions of experience are atomic, they are not necessarily separate in extension, spatiotemporally, from one another. Indefinitely many occasions of experience can overlap in Minkowski space.

Nexus is a term coined by Whitehead to show the network actual entity from universe. In the universe of actual entities spread actual entity. Actual entities are clashing with each other and form other actual entities. The birth of an actual entity based on an actual entity, actual entities around him referred to as nexus.

An example of a nexus of temporally overlapping occasions of experience is what Whitehead calls an enduring physical object, which corresponds closely with an Aristotelian substance. An enduring physical object has a temporally earliest and a temporally last member. Every member (apart from the earliest) of such a nexus is a causal consequence of the earliest member of the nexus, and every member (apart from the last) of such a nexus is a causal antecedent of the last member of the nexus. There are indefinitely many other causal antecedents and consequences of the enduring physical object, which overlap, but are not members, of the nexus. No member of the nexus is spatially separate from any other member. Within the nexus are indefinitely many continuous streams of overlapping nexūs, each stream including the earliest and the last member of the enduring physical object. Thus an enduring physical object, like an Aristotelian substance, undergoes changes and adventures during the course of its existence.

In some contexts, especially in the theory of relativity in physics, the word 'event' refers to a single point in Minkowski or in Riemannian space-time. A point event is not a process in the sense of Whitehead's metaphysics. Neither is a countable sequence or array of points. A Whiteheadian process is most importantly characterized by extension in space-time, marked by a continuum of uncountably many points in a Minkowski or a Riemannian space-time. The word 'event', indicating a Whiteheadian actual entity, is not being used in the sense of a point event.

Whitehead's abstractions are conceptual entities that are abstracted from or derived from and founded upon his actual entities. Abstractions are themselves not actual entities. They are the only entities that can be real but are not actual entities. This statement is one form of Whitehead's 'ontological principle'.

An abstraction is a conceptual entity that refers to more than one single actual entity. Whitehead's ontology refers to importantly structured collections of actual entities as nexuses of actual entities. Collection of actual entities into a nexus emphasizes some aspect of those entities, and that emphasis is an abstraction, because it means that some aspects of the actual entities are emphasized or dragged away from their actuality, while other aspects are de-emphasized or left out or left behind.

'Eternal object' is a term coined by Whitehead. It is an abstraction, a possibility, or pure potential. It can be ingredient into some actual entity. It is a principle that can give a particular form to an actual entity.

Whitehead admitted indefinitely many eternal objects. An example of an eternal object is a number, such as the number 'two'. Whitehead held that eternal objects are abstractions of a very high degree of abstraction. Many abstractions, including eternal objects, are potential ingredients of processes.

For Whitehead, besides its temporal generation by the actual entities which are its contributory causes, a process may be considered as a concrescence of abstract ingredient eternal objects. God enters into every temporal actual entity.

Whitehead's ontological principle is that whatever reality pertains to an abstraction is derived from the actual entities upon which it is founded or of which it is comprised.

Concrescence is a term coined by Whitehead to show the process of jointly forming an actual entity that was without form, but about to manifest itself into an entity Actual full ("satisfaction") based on datums or for information on the universe. The process of forming an actual entity is the case based on the existing datums. Concretion process can be regarded as "subjectification process."

Datum is a term coined by Whitehead to show the different variants of information possessed by actual entity. In process philosophy, datum is obtained through the events of concrescence. Every actual entity has a variety of datum.

Whitehead is not an idealist in the strict sense. Whitehead's thought may be regarded as related to the idea of panpsychism (also known as panexperientialism, because of Whitehead's emphasis on experience).

Whitehead's philosophy is very complex, subtle and nuanced and in order to comprehend his thinking regarding what is commonly referred to by many religions as "God", it is recommended that one read from "Process and Reality Corrected Edition", wherein regarding "God" the authors elaborate Whitehead's conception.
"He is the unconditioned actuality of conceptual feeling at the base of things; so that by reason of this primordial actuality, there is an order in the relevance of eternal objects to the process of creation (343 of 413) (Location 7624 of 9706 Kindle ed.) Whitehead continues later with, "The particularities of the actual world presuppose it ; while it merely presupposes the general metaphysical character of creative advance, of which it is the primordial exemplification (344 of 413) (Location 7634 of 9706 Kindle Edition)." 

Process philosophy, might be considered according to some theistic forms of religion to give a God a special place in the universe of occasions of experience. Regarding Whitehead's use of the term, "occasions" in reference to, "God" it is explained in "Process and Reality Corrected Edition" that "'Actual entities'-also termed 'actual occasions'-are the final real things of which the world is made up. There is no going behind actual entities to find anything [28] more real. They differ among themselves: God is an actual entity, and so is the most trivial puff of existence in far-off empty space. But, though there are gradations of importance, and diversities of function, yet in the principles which actuality exemplifies all are on the same level. The final facts are, all alike, actual entities; and these actual entities are drops of experience, complex and interdependent.

It can be also be assumed within some forms of theology that a God encompasses all the other occasions of experience but also transcends them and this might lead to it being argued that Whitehead endorses some form of panentheism. Since, it is argued theologically, that "free will" is inherent to the nature of the universe, Whitehead's God is not omnipotent in Whitehead's metaphysics. God's role is to offer enhanced occasions of experience. God participates in the evolution of the universe by offering possibilities, which may be accepted or rejected. Whitehead's thinking here has given rise to process theology, whose prominent advocates include Charles Hartshorne, John B. Cobb, Jr., and Hans Jonas, who was also influenced by the non-theological philosopher Martin Heidegger. However, other process philosophers have questioned Whitehead's theology, seeing it as a regressive Platonism.

Whitehead enumerated three essential "natures of God". The "primordial" nature of God consists of all potentialities of existence for actual occasions, which Whitehead dubbed eternal objects. God can offer possibilities by ordering the relevance of eternal objects. The "consequent" nature of God prehends everything that happens in reality. As such, God experiences all of reality in a sentient manner. The last nature is the "superjective". This is the way in which God's synthesis becomes a sense-datum for other actual entities. In some sense, God is prehended by existing actual entities.

In plant morphology, Rolf Sattler developed a process morphology (dynamic morphology) that overcomes the structure/process (or structure/function) dualism that is commonly taken for granted in biology. According to process morphology, structures such as leaves of plants do not have processes, they "are" processes.

In evolution and in development, the nature of the changes of biological objects are considered by many authors to be more radical than in physical systems. In biology, changes are not just changes of state in a pre-given space, instead the space and more generally the mathematical structures required to understand object change over time.

With its perspective that everything is interconnected, that all life has value, and that non-human entities are also experiencing subjects, process philosophy has played an important role in discourse on ecology and sustainability. The first book to connect process philosophy with environmental ethics was John B. Cobb, Jr.'s 1971 work, "Is It Too Late: A Theology of Ecology". In a more recent book (2018) edited by John B. Cobb, Jr. and Wm. Andrew Schwartz, "Putting Philosophy to Work: Toward an Ecological Civilization" contributors explicitly explore the ways in which process philosophy can be put to work to address the most urgent issues facing our world today, by contributing to a transition toward an ecological civilization. That book emerged out of the largest international conference held on the theme of ecological civilization ("Seizing an Alternative: Toward an Ecological Civilization") which was organized by the Center for Process Studies in June 2015. The conference brought together roughly 2,000 participants from around the world and featured such leaders in the environmental movement as Bill McKibben, Vandana Shiva, John B. Cobb, Jr., Wes Jackson, and Sheri Liao. The notion of ecological civilization is often affiliated with the process philosophy of Alfred North Whitehead--especially in China.

In the philosophy of mathematics, some of Whitehead's ideas re-emerged in combination with cognitivism as the cognitive science of mathematics and embodied mind theses.

Somewhat earlier, exploration of mathematical practice and quasi-empiricism in mathematics from the 1950s to 1980s had sought alternatives to metamathematics in social behaviours around mathematics itself: for instance, Paul Erdős's simultaneous belief in Platonism and a single "big book" in which all proofs existed, combined with his personal obsessive need or decision to collaborate with the widest possible number of other mathematicians. The process, rather than the outcomes, seemed to drive his explicit behaviour and odd use of language, as if the synthesis of Erdős and collaborators in seeking proofs, creating sense-datum for other mathematicians, was itself the expression of a divine will. Certainly, Erdős behaved as if nothing else in the world mattered, including money or love, as emphasized in his biography "The Man Who Loved Only Numbers".

Several fields of science and especially medicine seem to make liberal use of ideas in process philosophy, notably the theory of pain and healing of the late 20th century. The philosophy of medicine began to deviate somewhat from scientific method and an emphasis on repeatable results in the very late 20th century by embracing population thinking, and a more pragmatic approach to issues in public health, environmental health and especially mental health. In this latter field, R. D. Laing, Thomas Szasz and Michel Foucault were instrumental in moving medicine away from emphasis on "cures" and towards concepts of individuals in balance with their society, both of which are changing, and against which no benchmarks or finished "cures" were very likely to be measurable.

In psychology, the subject of imagination was again explored more extensively since Whitehead, and the question of feasibility or "eternal objects" of thought became central to the impaired theory of mind explorations that framed postmodern cognitive science. A biological understanding of the most eternal object, that being the emerging of similar but independent cognitive apparatus, led to an obsession with the process "embodiment", that being, the emergence of these cognitions. Like Whitehead's God, especially as elaborated in J. J. Gibson's perceptual psychology emphasizing affordances, by ordering the relevance of eternal objects (especially the cognitions of other such actors), the world becomes. Or, it becomes simple enough for human beings to begin to make choices, and to prehend what happens as a result. These experiences may be summed in some sense but can only approximately be shared, even among very similar cognitions with identical DNA. An early explorer of this view was Alan Turing who sought to prove the limits of expressive complexity of human genes in the late 1940s, to put bounds on the complexity of human intelligence and so assess the feasibility of artificial intelligence emerging. Since 2000, Process Psychology has progressed as an independent academic and therapeutic discipline: In 2000, Michel Weber created the Whitehead Psychology Nexus: an open forum dedicated to the cross-examination of Alfred North Whitehead's process philosophy and the various facets of the contemporary psychological field.





</doc>
<doc id="25754129" url="https://en.wikipedia.org/wiki?curid=25754129" title="Theory of forms">
Theory of forms

The theory of Forms or theory of Ideas is a philosophical theory, concept, or world-view, attributed to Plato, that the physical world is not as real or true as timeless, absolute, unchangeable ideas. According to this theory, ideas in this sense, often capitalized and translated as "Ideas" or "Forms", are the non-physical essences of all things, of which objects and matter in the physical world are merely imitations. Plato speaks of these entities only through the characters (primarily Socrates) of his dialogues who sometimes suggest that these Forms are the only objects of study that can provide knowledge. The theory itself is contested from within Plato's dialogues, and it is a general point of controversy in philosophy. Whether the theory represents Plato's own views is held in doubt by modern scholarship. However, the theory is considered a classical solution to the problem of universals.

The early Greek concept of form precedes attested philosophical usage and is represented by a number of words mainly having to do with vision, sight, and appearance. Plato uses these aspects of sight and appearance from the early Greek concept of the form in his dialogues to explain the Forms and the Good.

The meaning of the term ("eidos"), "visible form", and related terms μορφή ("morphē"), "shape", and φαινόμενα ("phainomena"), "appearances", from φαίνω ("phainō"), "shine", Indo-European ""*bʰeh₂-"" or "*bhā-" remained stable over the centuries until the beginning of philosophy, when they became equivocal, acquiring additional specialized philosophic meanings. The pre-Socratic philosophers, starting with Thales, noted that appearances change, and began to ask what the thing that changes "really" is. The answer was substance, which stands under the changes and is the actually existing thing being seen. The status of appearances now came into question. What is the form really and how is that related to substance?

The Forms are expounded upon in Plato's dialogues and general speech, in that every object or quality in reality has a form: dogs, human beings, mountains, colors, courage, love, and goodness. Form answers the question, "What is that?" Plato was going a step further and asking what Form itself is. He supposed that the object was essentially or "really" the Form and that the phenomena were mere shadows mimicking the Form; that is, momentary portrayals of the Form under different circumstances. The problem of universals – how can one thing in general be many things in particular – was solved by presuming that Form was a distinct singular thing but caused plural representations of itself in particular objects. For example, in the dialogue Parmenides, Socrates states: "Nor, again, if a person were to show that all is one by partaking of one, and at the same time many by partaking of many, would that be very astonishing. But if he were to show me that the absolute one was many, or the absolute many one, I should be truly amazed." Matter is considered particular in itself. For Plato, forms, such as beauty, are more real than any objects that imitate them. Though the forms are timeless and unchanging, physical things are in a constant change of existence. Where forms are unqualified perfection, physical things are qualified and conditioned.

These Forms are the essences of various objects: they are that without which a thing would not be the kind of thing it is. For example, there are countless tables in the world but the Form of tableness is at the core; it is the essence of all of them. Plato's Socrates held that the world of Forms is transcendent to our own world (the world of substances) and also is the essential basis of reality. Super-ordinate to matter, Forms are the most pure of all things. Furthermore, he believed that true knowledge/intelligence is the ability to grasp the world of Forms with one's mind.

A Form is "aspatial" (transcendent to space) and "atemporal" (transcendent to time). Atemporal means that it does not exist within any time period, rather it provides the formal basis for time. It therefore formally grounds beginning, persisting and ending. It is neither eternal in the sense of existing forever, nor mortal, of limited duration. It exists transcendent to time altogether. Forms are aspatial in that they have no spatial dimensions, and thus no orientation in space, nor do they even (like the point) have a location. They are non-physical, but they are not in the mind. Forms are extra-mental (i.e. real in the strictest sense of the word).

A Form is an objective "blueprint" of perfection. The Forms are perfect and unchanging representations of objects and qualities. For example the Form of beauty or the Form of a triangle. For the form of a triangle say there is a triangle drawn on a blackboard. A triangle is a polygon with 3 sides. The triangle as it is on the blackboard is far from perfect. However, it is only the intelligibility of the Form "triangle" that allows us to know the drawing on the chalkboard is a triangle, and the Form "triangle" is perfect and unchanging. It is exactly the same whenever anyone chooses to consider it; however, time only effects the observer and not of the triangle. It follows that the same attributes would exist for the Form of beauty and for all Forms.

The words, εἶδος ("eidos") and ἰδέα ("idea") come from the Indo-European root or "*weid-" "see" (cognate with Sanskrit "vétti"). "Eidos" (though not "idea") is already attested in texts of the Homeric era, the earliest Greek literature. This transliteration and the translation tradition of German and Latin lead to the expression "theory of Ideas." The word is however not the English "idea," which is a mental concept only.

The theory of matter and form (today's hylomorphism) started with Plato and possibly germinal in some of the presocratic writings. The forms were considered as being "in" something else, which Plato called nature ("physis"). The latter seemed as carved "wood", ὕλη ("hyle") in Greek, corresponding to "materia" in Latin, from which the English word "matter" is derived, shaped by receiving (or exchanging) forms.

The English word "form" may be used to translate two distinct concepts that concerned Plato—the outward "form" or appearance of something, and "Form" in a new, technical nature, that never...assumes a form like that of any of the things which enter into her; ... But the forms which enter into and go out of her are the likenesses of real existences modelled after their patterns in a wonderful and inexplicable manner... The objects that are seen, according to Plato, are not real, but literally "mimic" the real Forms. In the Allegory of the Cave expressed in "Republic", the things that are ordinarily perceived in the world are characterized as shadows of the real things, which are not perceived directly. That which the observer understands when he views the world mimics the archetypes of the many types and properties (that is, of universals) of things observed.

Plato often invokes, particularly in his dialogues "Phaedo", "Republic" and "Phaedrus", poetic language to illustrate the mode in which the Forms are said to exist. Near the end of the "Phaedo", for example, Plato describes the world of Forms as a pristine region of the physical universe located above the surface of the Earth ("Phd." 109a-111c). In the "Phaedrus" the Forms are in a "place beyond heaven" ("huperouranios topos") ("Phdr." 247c ff); and in the "Republic" the sensible world is contrasted with the intelligible realm ("noēton topon") in the famous Allegory of the Cave.

It would be a mistake to take Plato's imagery as positing the intelligible world as a literal physical space apart from this one. Plato emphasizes that the Forms are not beings that extend in space (or time), but subsist apart from any physical space whatsoever. Thus we read in the "Symposium" of the Form of Beauty: "It is not anywhere in another thing, as in an animal, or in earth, or in heaven, or in anything else, but itself by itself with itself," (211b). And in the "Timaeus" Plato writes: "Since these things are so, we must agree that that which keeps its own form unchangingly, which has not been brought into being and is not destroyed, which neither receives into itself anything else from anywhere else, "nor itself enters into anything anywhere", is one thing," (52a, emphasis added).

According to Plato, Socrates postulated a world of ideal Forms, which he admitted were impossible to know. Nevertheless, he formulated a very specific description of that world, which did not match his metaphysical principles. Corresponding to the world of Forms is our world, that of the shadows, an imitation of the real one. Just as shadows exist only because of the light of a fire, our world exists as, "the offspring of the good". Our world is modeled after the patterns of the Forms. The function of humans in our world is therefore to imitate the ideal world as much as possible which, importantly, includes imitating the good, i.e. acting morally.

Plato lays out much of this theory in the "Republic" where, in an attempt to define Justice, he considers many topics including the constitution of the ideal state. While this state, and the Forms, do not exist on earth, because their imitations do, Plato says we are able to form certain well-founded opinions about them, through a theory called recollection.

The republic is a greater imitation of Justice:Our aim in founding the state was not the disproportional happiness of any one class, but the greatest happiness of the whole; we thought that in a state ordered with a view to the good of the whole we should be most likely to find justice.

The key to not know how such a state might come into existence is the word "founding" ("oikidzomen"), which is used of colonization. It was customary in such instances to receive a constitution from an elected or appointed lawgiver; however in Athens, lawgivers were appointed to reform the constitution from time to time (for example, Draco, Solon). In speaking of reform, Socrates uses the word "purge" ("diakathairountes") in the same sense that Forms exist purged of matter.

The purged society is a regulated one presided over by philosophers educated by the state, who maintain three non-hereditary classes as required: the tradesmen (including merchants and professionals), the guardians (militia and police) and the philosophers (legislators, administrators and the philosopher-king). Class is assigned at the end of education, when the state institutes individuals in their occupation. Socrates expects class to be hereditary but he allows for mobility according to natural ability. The criteria for selection by the academics is ability to perceive forms (the analog of English "intelligence") and martial spirit as well as predisposition or aptitude.

The views of Socrates on the proper order of society are certainly contrary to Athenian values of the time and must have produced a shock effect, intentional or not, accounting for the animosity against him. For example, reproduction is much too important to be left in the hands of untrained individuals: "... the possession of women and the procreation of children ... will ... follow the general principle that friends have all things in common, ..." The family is therefore to be abolished and the children – whatever their parentage – to be raised by the appointed mentors of the state.

Their genetic fitness is to be monitored by the physicians: "... he (Asclepius, a culture hero) did not want to lengthen out good-for-nothing lives, or have weak fathers begetting weaker sons – if a man was not able to live in the ordinary way he had no business to cure him ..." Physicians minister to the healthy rather than cure the sick: "... (Physicians) will minister to better natures, giving health both of soul and of body; but those who are diseased in their bodies they will leave to die, and the corrupt and incurable souls they will put an end to themselves." Nothing at all in Greek medicine so far as can be known supports the airy (in the Athenian view) propositions of Socrates. Yet it is hard to be sure of Socrates' real views considering that there are no works written by Socrates himself. There are two common ideas pertaining to the beliefs and character of Socrates: the first being the Mouthpiece Theory where writers use Socrates in dialogue as a mouthpiece to get their own views across. However, since most of what we know about Socrates comes from plays, most of the Platonic plays are accepted as the more accurate Socrates since Plato was a direct student of Socrates.

Perhaps the most important principle is that just as the Good must be supreme so must its image, the state, take precedence over individuals in everything. For example, guardians "... will have to be watched at every age in order that we may see whether they preserve their resolution and never, under the influence either of force or enchantment, forget or cast off their sense of duty to the state." This concept of requiring guardians of guardians perhaps suffers from the Third Man weakness (see below): guardians require guardians require guardians, ad infinitum. The ultimate trusty guardian is missing. Socrates does not hesitate to face governmental issues many later governors have found formidable: "Then if anyone at all is to have the privilege of lying, the rulers of the state should be the persons, and they ... may be allowed to lie for the public good."

Plato's conception of Forms actually differs from dialogue to dialogue, and in certain respects it is never fully explained, so many aspects of the theory are open to interpretation. Forms are first introduced in the Phaedo, but in that dialogue the concept is simply referred to as something the participants are already familiar with, and the theory itself is not developed. Similarly, in the Republic, Plato relies on the concept of Forms as the basis of many of his arguments but feels no need to argue for the validity of the theory itself or to explain precisely what Forms are. Commentators have been left with the task of explaining what Forms are and how visible objects participate in them, and there has been no shortage of disagreement. Some scholars advance the view that Forms are paradigms, perfect examples on which the imperfect world is modeled. Others interpret Forms as universals, so that the Form of Beauty, for example, is that quality that all beautiful things share. Yet others interpret Forms as "stuffs," the conglomeration of all instances of a quality in the visible world. Under this interpretation, we could say there is a little beauty in one person, a little beauty in another—all the beauty in the world put together is the Form of Beauty. Plato himself was aware of the ambiguities and inconsistencies in his Theory of Forms, as is evident from the incisive criticism he makes of his own theory in the Parmenides.

Plato's main evidence for the existence of Forms is intuitive only and is as follows.

We call both the sky and blue jeans by the same color, blue. However, clearly a pair of jeans and the sky are not the same color; moreover, the wavelengths of light reflected by the sky at every location and all the millions of blue jeans in every state of fading constantly change, and yet we somehow have a consensus of the basic form Blueness as it applies to them. Says Plato:But if the very nature of knowledge changes, at the time when the change occurs there will be no knowledge, and, according to this view, there will be no one to know and nothing to be known: but if that which knows and that which is known exist ever, and the beautiful and the good and every other thing also exist, then I do not think that they can resemble a process of flux, as we were just now supposing.

Plato believed that long before our bodies ever existed, our souls existed and inhabited heaven, where they became directly acquainted with the forms themselves. Real knowledge, to him, was knowledge of the forms. But knowledge of the forms cannot be gained through sensory experience because the forms are not in the physical world. Therefore, our real knowledge of the forms must be the memory of our initial acquaintance with the forms in heaven. Therefore, what we seem to learn is in fact just remembering.

No one has ever seen a perfect circle, nor a perfectly straight line, yet everyone knows what a circle and a straight line are. Plato utilizes the tool-maker's blueprint as evidence that Forms are real:... when a man has discovered the instrument which is naturally adapted to each work, he must express this natural form, and not others which he fancies, in the material ...

Perceived circles or lines are not exactly circular or straight, and true circles and lines could never be detected since by definition they are sets of infinitely small points. But if the perfect ones were not real, how could they direct the manufacturer?

Plato was well aware of the limitations of the theory, as he offered his own criticisms of it in his dialogue "Parmenides". There Socrates is portrayed as a young philosopher acting as junior counterfoil to aged Parmenides. To a certain extent it is tongue-in-cheek as the older Socrates will have solutions to some of the problems that are made to puzzle the younger.

The dialogue does present a very real difficulty with the Theory of Forms, which Plato most likely only viewed as problems for later thought. These criticisms were later emphasized by Aristotle in rejecting an independently existing world of Forms. It is worth noting that Aristotle was a pupil and then a junior colleague of Plato; it is entirely possible that the presentation of "Parmenides" "sets up" for Aristotle; that is, they agreed to disagree.

One difficulty lies in the conceptualization of the "participation" of an object in a form (or Form). The young Socrates conceives of his solution to the problem of the universals in another metaphor, which though wonderfully apt, remains to be elucidated:
Nay, but the idea may be like the day which is one and the same in many places at once, and yet continuous with itself; in this way each idea may be one and the same in all at the same time.

But exactly how is a Form like the day in being everywhere at once? The solution calls for a distinct form, in which the particular instances, which are not identical to the form, participate; i.e., the form is shared out somehow like the day to many places. The concept of "participate", represented in Greek by more than one word, is as obscure in Greek as it is in English. Plato hypothesized that distinctness meant existence as an independent being, thus opening himself to the famous third man argument of Parmenides, which proves that forms cannot independently exist and be participated.

If universal and particulars – say man or greatness – all exist and are the same then the Form is not one but is multiple. If they are only like each other then they contain a form that is the same and others that are different. Thus if we presume that the Form and a particular are alike then there must be another, or third Form, man or greatness by possession of which they are alike. An infinite regression would then result; that is, an endless series of third men. The ultimate participant, greatness, rendering the entire series great, is missing. Moreover, any Form is not unitary but is composed of infinite parts, none of which is the proper Form.

The young Socrates (some may say the young Plato) did not give up the Theory of Forms over the Third Man but took another tack, that the particulars do not exist as such. Whatever they are, they "mime" the Forms, appearing to be particulars. This is a clear dip into representationalism, that we cannot observe the objects as they are in themselves but only their representations. That view has the weakness that if only the mimes can be observed then the real Forms cannot be known at all and the observer can have no idea of what the representations are supposed to represent or that they are representations.

Socrates' later answer would be that men already know the Forms because they were in the world of Forms before birth. The mimes only recall these Forms to memory. The comedian Aristophanes wrote a play, "The Clouds", poking fun of Socrates with his head in the clouds.

The topic of Aristotle's criticism of Plato's Theory of Forms is a large one and continues to expand. Rather than quote Plato, Aristotle often summarized. Classical commentaries thus recommended Aristotle as an introduction to Plato. As a historian of prior thought, Aristotle was invaluable, however this was secondary to his own dialectic and in some cases he treats purported implications as if Plato had actually mentioned them, or even defended them. In examining Aristotle's criticism of The Forms, it is helpful to understand Aristotle's own hylomorphic forms, by which he intends to salvage much of Plato's theory.

In the summary passage quoted above Plato distinguishes between real and non-real "existing things", where the latter term is used of substance. The figures that the artificer places in the gold are not substance, but gold is. Aristotle stated that, for Plato, all things studied by the sciences have Form and asserted that Plato considered only substance to have Form. Uncharitably, this leads him to something like a contradiction: Forms existing as the objects of science, but not-existing as non-substance. Scottish philosopher W.D. Ross objects to this as a mischaracterization of Plato.

Plato did not claim to know where the line between Form and non-Form is to be drawn. As Cornford points out, those things about which the young Socrates (and Plato) asserted "I have often been puzzled about these things" (in reference to Man, Fire and Water), appear as Forms in later works. However, others do not, such as Hair, Mud, Dirt. Of these, Socrates is made to assert, "it would be too absurd to suppose that they have a Form."

Ross also objects to Aristotle's criticism that Form Otherness accounts for the differences between Forms and purportedly leads to contradictory forms: the Not-tall, the Not-beautiful, etc. That particulars participate in a Form is for Aristotle much too vague to permit analysis. By one way in which he unpacks the concept, the Forms would cease to be of one essence due to any multiple participation. As Ross indicates, Plato didn't make that leap from "A is not B" to "A is Not-B." Otherness would only apply to its own particulars and not to those of other Forms. For example, there is no Form Not-Greek, only "particulars" of Form Otherness that somehow "suppress" Form Greek.

Regardless of whether Socrates meant the particulars of Otherness yield Not-Greek, Not-tall, Not-beautiful, etc., the particulars would operate specifically rather than generally, each somehow yielding only one exclusion.

Plato had postulated that we know Forms through a remembrance of the soul's past lives and Aristotle's arguments against this treatment of epistemology are compelling. For Plato, particulars somehow do not exist, and, on the face of it, "that which is non-existent cannot be known". See "Metaphysics" III 3–4.

The theory is presented in the following dialogues:





</doc>
<doc id="277206" url="https://en.wikipedia.org/wiki?curid=277206" title="Freethought">
Freethought

Freethought (or "free thought") is a philosophical viewpoint which holds that positions regarding truth should be formed on the basis of logic, reason, and empiricism, rather than authority, tradition, revelation, or dogma. According to the "Oxford English Dictionary", a freethinker is "a person who forms their own ideas and opinions rather than accepting those of other people, especially in religious teaching."<ref>


</doc>
<doc id="47885111" url="https://en.wikipedia.org/wiki?curid=47885111" title="International Philosophical Bibliography">
International Philosophical Bibliography

The International Philosophical Bibliography (IPB), also known in French as "Répertoire bibliographique de la philosophie" (RBP), is a bibliographic database covering publications on the history of philosophy and continental philosophy.

The database comprises records of publications in over 30 languages. Annually, about 12,000 records are added. The indexes include, among other elements, over 84,000 names of authors, editors, translators, reviewers, and collaborators, as well as more than 3,000 commentaries on philosophical works.

Since 1934, the IPB has been developed by the Higher Institute of Philosophy at the University of Louvain (UCLouvain). The online version was launched by Peeters Publishers in 1997 and continues to be updated quarterly.


</doc>
<doc id="17582998" url="https://en.wikipedia.org/wiki?curid=17582998" title="The Sleep of Reason Produces Monsters">
The Sleep of Reason Produces Monsters

The Sleep of Reason Produces Monsters () is an etching by the Spanish painter and printmaker Francisco Goya. Created between 1797 and 1799 for the "Diario de Madrid", it is the 43rd of 80 etchings making up the suite of satires "Los Caprichos". 

Many suggest that the artist Goya depicts himself asleep amidst his drawing tools, his reason dulled by slumber and bedeviled by creatures that prowl in the dark. The work includes owls that may be symbols of folly and bats symbolizing ignorance. Implied in Goya's preparatory inscription, the artist's nightmare reflects his view of Spanish society, which he portrayed in the "Caprichos" as demented, corrupt, and ripe for ridicule. The work is held at the Metropolitan Museum of Art in New York and was the gift of M. Knoedler & Co. in 1918.

The full epigraph for capricho No. 43 reads; "Fantasy abandoned by reason produces impossible monsters: united with her (reason), she (fantasy) is the mother of the arts and the origin of their marvels."

The title of C. P. Snow's "The Sleep of Reason", tenth book in his "Strangers and Brothers" series, and the "Doctor Who" novel "The Sleep of Reason" are drawn from this print.

Occasionally the title phrase is rendered as "The dream of reason produces monsters", since the Spanish word "sueño" can mean either "sleep" or "dream". However, Goya's epigraph makes it clear that his intended interpretation is "the sleep of reason".



</doc>
<doc id="59691369" url="https://en.wikipedia.org/wiki?curid=59691369" title="Epistemic cultures">
Epistemic cultures

Epistemic cultures (most of the times in plural form) are a concept developed in the nineties by anthropologist Karin Knorr Cetina in her book "Epistemic Cultures, how the sciences make knowledge." Opposed to a monist vision of scientific activity (according to which, would exist a unique scientific method), Knorr Cetina defines the concept of epistemic cultures as a diversity of scientific activities according to different scientific fields, not only in methods and tools, but also in reasonings, establishing evidence, and relationships between theory and empiry. Knorr Cetina's work is seminal in questioning the so-called unity of science.

In practice, Knorr Cetina compares two contemporary important scientific fields: High energy physics and molecular biology. She worked as an anthropologist within two laboratories, along the line of the laboratory anthropology work by Latour and Woolgar. Her anthropological work is comparative and the two chosen scientific fields are highly mediaticized and easily distinguishable.

Epistemic cultures as a philosophical concept has been perused by numerous philosophical, anthropological or historical studies of science.

High energy physics and molecular biology are very different as scientific fields belonging to two different epistemic cultures. They also are very different in terms of academic authorship. Biagioli describes this difference in terms of publications culture regarding number of authors per paper, distribution of contributorship within authors, preprint policy and he precisely chooses to oppose the very same domains.


</doc>
