<doc id="1525262" url="https://en.wikipedia.org/wiki?curid=1525262" title="Middlebrow">
Middlebrow

The term middlebrow describes easily accessible art, usually literature, and the people who use the arts to acquire culture and "class" (social prestige). First used in the British satire magazine "Punch" in 1925, the term "middlebrow" is the intermediary "brow" descriptor between "highbrow" and "lowbrow", which are terms derived from the pseudo-science of phrenology.

The term middlebrow became a pejorative usage in the modernist cultural criticism, by Dwight Macdonald, Virginia Woolf, and Russell Lynes, which served the cause of the marginalization of the popular culture in favor of high culture. Culturally, the middlebrow is classed as a forced and ineffective attempt at cultural and intellectual achievement, and as characterizing literature that emphasizes emotional and sentimental connections, rather than intellectual quality and literary innovation; although postmodernism more readily perceives the advantages of the middlebrow cultural-position that is aware of high culture, but is able to balance aesthetic claims with the claims of the everyday world.

Virginia Woolf derided the middlebrow in an un-posted letter to the editor of the "New Statesman & Nation", concerning a radio broadcast that attacked the Highbrows. That letter was posthumously published in the essay collection "The Death of the Moth" (1942).

Woolf criticizes middlebrows as petty purveyors of highbrow cultures for their own shallow benefit. Rather than selecting books for their intrinsic cultural value, middlebrow people select and read what they are told is best. Middlebrows are concerned with "how" what they do makes them appear, unlike highbrows, the avant-garde men and women who act according to their indelible commitment to beauty, value, art, form, and integrity. Woolf said that, "We highbrows read what we like and do what we like and praise what we like". Likewise, a lowbrow is devoted to a singular interest, a person "of thoroughbred vitality who rides his body in pursuit of a living at a gallop across life"; and, therefore, the lowbrow are equally worthy of reverence, as they, too, are living for what they intrinsically know as valuable.

Instead of such freedom, the middlebrows are "betwixt and between", which Woolf classifies as "in pursuit of no single object, neither Art itself nor life itself, but both mixed indistinguishably, and rather nastily, with money, fame, power, or prestige." Their value system rewards quick gains through literature already designated as 'Classic' and 'Great', never of their own choosing, because "to buy living art requires living taste." The middlebrow are meretricious—which is much less demanding than authenticity.

"Harper's Magazine" editor Russell Lynes satirized Virginia Woolf's highbrow scorn in the article "Highbrow, Lowbrow, Middlebrow". Quoting her and other highbrow proponents, such as art critic Clement Greenberg, Lynes parodied the highbrow's pompous superiority by noting how the subtle distinctions Woolf found significant among the "brows" were just means of upholding cultural superiority. Specifically, he parodies the highbrow claim that the products a person uses distinguishes his or her level of cultural worth, by satirically identifying the products that would identify a middlebrow person.

Lynes continued distinguishing among "brows", dividing middlebrow into upper-middlebrow and lower-middlebrow. The upper-middlebrow's arts patronage makes highbrow activity possible. Museums, orchestras, operas, and publishing houses are run by upper-middlebrows. The lower middlebrows attempt using the arts for self-enhancement: "hell-bent on improving their minds as well as their fortunes". They also intend to live the simple, easy life outlined in advertisements; "lower middlebrow-ism" was "a world that smells of soap". Caricaturing Woolf, Lynes outlined the perfect world without middlebrows; lowbrows work and highbrows create pure art.

Months later, "Life" magazine asked Lynes to specifically distinguish among the right foods, furniture, clothes, and arts for each of the four 'brows'. That began a national preoccupation, as people tried to identify their proper social class, based upon their favorite things. Although "middlebrow" often has connoted contempt, Lynes lauded the zeal and aspirations of the middlebrows.

J. B. Priestley sought to create a positive cultural space around the concept of middlebrow – one characterised by earnestness, friendliness and ethical concerns. He couched his defense of the middlebrow in terms of radio stations, praising the BBC Home Service for its cosiness and plainness, midway between the Light Programme and the Third Programme: "Between the raucous lowbrows and the lisping highbrows is a fine gap, meant for the middle or broadbrows...our homely fashion".

In a struggle that involved competition for readers as well as for cultural capital, Virginia Woolf responded by renaming the BBC the "Betwixt and Between Company".

Dwight Macdonald's critique of middlebrow culture, "Masscult and Midcult" (1960), associated the modern industrial drive, away from specialization and the folk, with creating a mass-market arts, and, therefore, anonymous consumers of the arts. In the U.S., highbrow culture is associated with specialization for the connoisseurs, while lowbrow culture entails authentic folk products made for specific communities. Mass culture (masscult) copies and manipulates both traditions, with factory-created products, made without innovation or care, expressly for the market, "to please the crowd by any means", thereby creating an American society in which "a pluralistic culture cannot exist", wherein the rule is cultural homogeneity.

In contrast Midcult (middle culture), came about with middlebrow culture, and dangerously copies and adulterates high culture, by way of "a tepid ooze of Midcult", which threatens high culture, with dramaturgy, literature, and architecture, such as "Our Town" (1938), "The Old Man and the Sea" (1952), and American collegiate gothic architecture.

The Middlebrow "pretends to respect the standards of High Culture, while, in fact, it waters them down and vulgarizes them." Macdonald recommended a separation of the brows, so that "the few who care about good writing, painting, music, architecture, philosophy, etc. have their High Culture, and don't fuzz up the distinction with the Midcult."

The Book-of-the-Month Club and Oprah Winfrey's Book Club have been widely characterized as middlebrow, marketed to bring classics and 'highbrow' literature to the middle class. This was particularly highlighted when author Jonathan Franzen, after his book "The Corrections" was selected, remarked in several publications that some of Oprah's book club picks were middlebrow In her seminal account of the Book-of-the-Month Club (as it was from its inception in 1926 to the 1980s before it transformed to a purely commercial operation), "A Feeling for Books", Janice Radway argues that middlebrow culture is not simply a diluted impersonation of highbrow, but instead distinctly defined itself in defiance of avant-garde high culture. The club provided subscribers with literature selected by expert and 'generalist' judges, but held the personal, emotional experience of reading a good book as paramount, while simultaneously maintaining 'high standards' for literary quality. In this way, the club was in opposition to the general criticism of middlebrow culture in that it is forced high culture. Instead, Radway demonstrates that the middlebrow culture allows readers to simultaneously access the emotional and intellectual challenges that good reading provides. Radway also identifies the conflicting gender messages sent by the selections. While the club was marketed extensively to the female reader, including its emphasis on the emotional pleasure of books, the focus on intellectual, academic literature of the middlebrow trapped the reader into the constrictive masculine standards of value, classifying 'great books' as those that fell in line with male, technical classifications of excellence.

"Slate Magazine" suggests that the late 2000s and early 2010s could potentially be considered the "golden age of middlebrow art"—pointing to television shows "Breaking Bad", "Mad Men", "The Sopranos" and "The Wire" and novels "Freedom", "The Marriage Plot" and "A Visit from the Goon Squad". "Slate" also defines the films of Aaron Sorkin as middlebrow. Some argue that "Slate" itself is middlebrow journalism.

In a March 2012 article for "Jewish Ideas Daily", Peodair Leihy described the work of poet and songwriter Leonard Cohen as "a kind of pop—upper-middle-brow to lower-high-brow, to be sure, but pop nonetheless." This aesthetic was further theorized in an essay from November that year for "The American Scholar" that saw William Deresiewicz propose the addition of "upper middle brow," a culture falling between masscult and midcult. He defined it as, "infinitely subtler than Midcult. It is post- rather than pre-ironic, its sentimentality hidden by a veil of cool. It is edgy, clever, knowing, stylish, and formally inventive."

In "The New Yorker", Macy Halford characterizes "Harper's Magazine" and "The New Yorker" itself as "often [being] viewed as prime examples of the middlebrow: both magazines are devoted to the high but also to making it accessible to many; to bringing ideas that might remain trapped in ivory towers and academic books, or in high-art (or film or theatre) scenes, into the pages of a relatively inexpensive periodical that can be bought at bookstores and newsstands across the country (and now on the Internet)." She also notes the internet's effect on the middlebrow debate: "Internet is forcing us to rethink (again) what "middlebrow" means: in an era when the highest is as accessible as the lowest—accessible in the sense that both are only a click away ... —we actually have to think anew about how to walk that middle line." Halford describes Wikipedia: "...Wiki is itself a kind of middlebrow product" and links to this middlebrow entry "because it actually provides a smart summary."

Founded in 2008, Middlebrow Improvisational Theatre is a collective of students at Middlebury College who have smashed the norms of Middlebrow comedy. Making their mark with eccentric characters and solid improvisation, they critique and comment on the strangeness of the world with just a hint of nonsense. They have entirely lived up to the ethos of their namesake, providing accessible humor in an unexpected way. Notable alumni include Will "Pooley" Lupica and Kaitlyind Collins, creators of cartoon show "Ghoulstein & Ghoulstein."



</doc>
<doc id="1396834" url="https://en.wikipedia.org/wiki?curid=1396834" title="High culture">
High culture

High culture encompasses the cultural objects of aesthetic value, which a society collectively esteem as exemplary art. It may also include intellectual works considered to be of supreme philosophical, historical, or literary value, as well as the education which cultivates such aesthetic and intellectual pursuits. In popular usage, the term "high culture" identifies the culture of an upper class (an aristocracy) or of a status class (the intelligentsia); and also identifies a society’s common repository of broad-range knowledge and tradition (e.g. folk culture) that transcends the social-class system of the society. Sociologically, the term "high culture" is contrasted with the term "low culture", the forms of popular culture characteristic of the less-educated social classes, such as the barbarians, the Philistines, and "hoi polloi" (the masses).

In European history, high culture was understood as a cultural concept common to the humanities, until the mid-19th century, when Matthew Arnold introduced the term "high culture" in the book "Culture and Anarchy" (1869). The Preface defines culture as "the disinterested endeavour after man’s perfection" pursued, obtained, and achieved by effort to "know the best that has been said and thought in the world". Such a literary definition of high culture also includes philosophy. Moreover, the philosophy of aesthetics proposed in high culture is a force for moral and political good. Critically, the term "high culture" is contrasted with the terms "popular culture" and "mass culture".

In "Notes Towards the Definition of Culture" (1948), T. S. Eliot said that high culture and popular culture are necessary and complementary parts of the culture of a society. In "The Uses of Literacy" (1957), Richard Hoggart presents the sociologic experience of the working-class man and woman in acquiring the cultural literacy, at university, which facilitates social upward mobility. In the U.S., Harold Bloom and F. R. Leavis pursued the definition of high culture, by way of the Western canon of literature.
Media theorist Steven Johnson writes that, unlike popular culture, "the classics—and soon to be classics—are" in their own right descriptions and explanations of the cultural systems that produced them." He says that "a crucial way in which mass culture differs from high art" is that individual works of mass culture are less interesting than the broader cultural trends which produced them.

History of high culture in the West

The high culture of the West originated in the classical-world traditions of intellectual and aesthetic life in Ancient Greece (from c. 8th century BC – AD 147) and Ancient Rome (753 BC – AD 476). In the classical Greco-Roman tradition, the ideal mode of language was published and preserved in works of elevated style (correct grammar, syntax, and diction). Certain forms of language used by authors in valorized epochs were held up in antiquity and the Renaissance as eternal valid models and normative standards of excellence; e.g. the Attic dialect of ancient Greek spoken and written by the playwrights and philosophers of Periclean Athens (fifth century BC); and the form of classical Latin used in the "Golden Age" of Roman culture (c. 70 B.C. - AD 18) represented by such figures as Cicero and Virgil. This form of education was known to the Greeks as παιδεία, which was translated by the Romans into Latin as "humanitas" since it reflected a form of education aiming at the refinement of human nature, rather than the acquisition of technical or vocational skills. Indeed, the Greco-Roman world tended to see such manual, commercial, and technical labor as subordinate to purely intellectual activities. 

From the idea of the "free" man with sufficient leisure to pursue such intellectual and aesthetic refinement, arose the classical distinction between the "liberal" arts which are intellectual and done for their own sake, as against the "servile"or "mechanical" arts which were associated with manual labor and done to earn a living. This implied an association between high culture and the upper classes whose inherited wealth provided such time for intellectual cultivation. The leisured gentleman not weighed down by the necessity of earning a living, was free to devote himself to activities proper to such a "free man" – those deemed to involve true excellence and nobility as opposed to mere utility.
During the Renaissance, the classical intellectual values of the fully rediscovered Græco–Roman culture were the cultural capital of the upper classes(and the aspiring), and aimed at the complete development of human intellectual, aesthetic, and moral faculties. This ideal associated with humanism (a later term derived from the humanities or "studia humanitatis"), was communicated in Renaissance Italy through institutions such as the Renaissance court schools. Renaissance humanism soon spread through Europe becoming much of the basis of upper class education for centuries. For the socially ambitious man and woman who means to rise in society, "The Book of the Courtier" (1528), by Baldasare Castiglione, instructs the reader to acquire and possess knowledge of the Græco–Roman Classics, being education integral to the social-persona of the aristocrat. A key contribution of the Renaissance was the elevation of painting and sculpture to a status equal to the liberal arts (hence the visual arts lost for elites any lingering negative association with manual artisanship.) The early Renaissance treatises of Leon Battista Alberti were instrumental in this regard.

The evolution of the concept of high culture initially was defined in educational terms largely as critical study and knowledge of the Græco–Roman arts and humanities which furnished much of the foundation for European cultures and societies. However, aristocratic patronage through most of the modern era was also pivotal to the support and creation of new works of high culture across the range of arts, music, and literature. The subsequent prodigious development of the modern European languages and cultures meant that the modern definition of the term "high culture" embraces not only Greek and Latin texts, but a much broader canon of select literary, philosophical, historical, and scientific books in both ancient and modern languages. Of comparable importance are those works of art and music considered to be of the highest excellence and broadest influence (e.g. the Parthenon, the painting and sculpture of Michelangelo, the music of J. S. Bach, etc). Together these texts and art works constitute the exemplary artifacts representing the high culture of the Western world. 
In the Western and some East Asian traditions, art that demonstrates the imagination of the artist is accorded the status of high art. In the West this tradition began in Ancient Greece, was reinforced in the Renaissance, and by Romanticism, which eliminated the hierarchy of genres within the fine arts, which was established in the Renaissance. In China there was a distinction between the literati painting by the scholar-officials and the work produced by common artists, working in largely different styles, or the decorative arts such as Chinese porcelain which were produced by unknown craftsmen working in large factories. In both China and the West the distinction was especially clear in landscape painting, where for centuries imaginary views, produced from the imagination of the artist, were considered superior works.

In socially-stratified Europe and the Americas, a first-hand immersion to the high culture of the West, the Grand Tour of Europe, was a rite of passage that complemented and completed the book education of a gentleman, from the nobility, the aristocracy, and the bourgeoisie, with a worldly perspective of society and civilisation. The post-university tour of the cultural centres of Europe was a social-class benefit of the cultural capital transmitted through the high-status institutions (schools, academies, universities) meant to produce the ideal gentleman of that society. 

The European concept of high culture included cultivation of refined etiquette and manners; the education of taste in the fine arts such as sculpture and painting; an appreciation of classical music and opera in its diverse history and myriad forms; knowledge of the humane letters ("literae humaniores") represented by the best Greek and Latin authors, and more broadly of the liberal arts traditions (e.g. philosophy, history, drama, rhetoric, and poetry) of Western civilisation, as well as a general acquaintance with important concepts in theology, science, and political thought.

Much of high culture consists of the appreciation of what is sometimes called "high art". This term is rather broader than Arnold's definition and besides literature includes music, visual arts (especially painting), and traditional forms of the performing arts (including some cinema). The decorative arts would not generally be considered high art.

The cultural products most often regarded as forming part of high culture are most likely to have been produced during periods of high civilization, for which a large, sophisticated, and wealthy urban-based society provides a coherent and conscious aesthetic framework, and a large-scale milieu of training, and, for the visual arts, sourcing materials and financing work. Such an environment enables artists, as near as possible, to realize their creative potential with as few as possible practical and technical constraints. Although the Western concept of high culture naturally concentrates on the Greco-Roman tradition, and its resumption from the Renaissance onwards, such conditions existed in other places at other times.

Art music (or serious music or erudite music) is an umbrella term used to refer to musical traditions implying advanced structural and theoretical considerations and a written musical tradition. The notion of art music is a frequent and well-defined musicological distinction – musicologist Philip Tagg, for example, refers to art music as one of an "axiomatic triangle consisting of 'folk', 'art' and 'popular' musics". He explains that each of these three is distinguishable from the others according to certain criteria, with high cultural music often performed to an audience whilst folk music would traditionally be more participatory. In this regard, "art music" frequently occurs as a contrasting term to "popular music" and to "traditional" or "folk music".

Art film is the result of filmmaking which is typically a serious, independent film aimed at a niche market rather than a mass market audience. Film critics and film studies scholars typically define an "art film" using a "...canon of films and those formal qualities that mark them as different from mainstream Hollywood films", which includes, among other elements: a social realism style; an emphasis on the authorial expressivity of the director or writer; and a focus on the thoughts and dreams of characters, rather than presenting a clear, goal-driven story. According to the film scholar David Bordwell, "art cinema itself is a film genre, with its own distinct conventions."

The term has always been susceptible to attack for elitism, and, in response, many proponents of the concept devoted great efforts to promoting high culture among a wider public than the highly educated bourgeoisie whose natural territory it was supposed to be. There was a drive, beginning in the 19th century, to open museums and concert halls to give the general public access to high culture. Figures such as John Ruskin and Lord Reith of the BBC in Britain, Leon Trotsky and others in Communist Russia, and many others in America and throughout the western world have worked to widen the appeal of elements of high culture such as classical music, art by old masters and the literary classics.

With the widening of access to university education, the effort spread there, and all aspects of high culture became the objects of academic study, which with the exception of the classics had not often been the case until the late 19th century. University liberal arts courses still play an important role in the promotion of the concept of high culture, though often now avoiding the term itself.

Especially in Europe, governments have been prepared to subsidize high culture through the funding of museums, opera and ballet companies, orchestras, cinema, public broadcasting stations such as BBC Radio 3, ARTE, and in other ways. Organizations such as the Arts Council of Great Britain, and in most European countries, whole ministries administer these programs. This includes the subsidy of new works by composers, writers and artists. There are also many private philanthropic sources of funding, which are especially important in the US, where the federally funded Corporation for Public Broadcasting also funds broadcasting. These may be seen as part of the broader concept of official culture, although often a mass audience is not the intended market.

The relations between high culture and mass culture are concerns of cultural studies, media studies, and critical theory, sociology, Postmodernism and Marxist philosophy. In the essay "The Work of Art in the Age of Mechanical Reproduction" (1936), Walter Benjamin explored the relations of value of the arts (high and mass) when subjected to industrial reproduction. The critical theoreticians Theodor W. Adorno and Antonio Gramsci interpreted the high-art and mass-art cultural relations as an instrument of social control, with which the ruling class maintain their cultural hegemony upon society.

For the Orientalist Ernest Renan and for the rationalist philosopher Ernest Gellner, high culture was conceptually integral to the politics and ideology of nationalism, as a requisite part of a healthy national identity. Gellner expanded the conceptual scope of the phrase in "Nations and Nationalism" (1983) stating that high art is "a literate, codified culture, which permits context-free communication" among cultures.

In "Distinction: A Social Critique of the Judgement of Taste" (1979), the sociologist Pierre Bourdieu proposed that æsthetic taste (cultural judgement) is in large part derived from social class. Social class establishes the definitions of high art, e.g. in social etiquette, gastronomy, oenology, military service. In such activities of aesthetic judgement, the ruling-class person uses social codes unknown to middle-class and lower-class persons in the pursuit and practice of activities of taste.




</doc>
<doc id="8950930" url="https://en.wikipedia.org/wiki?curid=8950930" title="Cultural memory">
Cultural memory

Because memory is not just an individual, private experience but is also part of the collective domain, cultural memory has become a topic in both historiography (Pierre Nora, Richard Terdiman) and cultural studies (e.g., Susan Stewart). These emphasize cultural memory’s process (historiography) and its implications and objects (cultural studies), respectively. Two schools of thought have emerged, one articulates that the present shapes our understanding of the past. The other assumes that the past has an influence on our present behavior. It has, however, been pointed out (most notably by Guy Beiner) that these two approaches are not necessarily mutually exclusive.

Crucial in understanding cultural memory as a phenomenon is the distinction between memory and history. This distinction was put forward by Pierre Nora, who pinpointed a niche in-between history and memory.

Scholars disagree as to when to locate the moment representation 'took over'. Nora points to the formation of European nation states. For Richard Terdiman, the French revolution is the breaking point: the change of a political system, together with the emergence of industrialization and urbanization, made life more complex than ever before. This not only resulted in an increasing difficulty for people to understand the new society in which they were living, but also, as this break was so radical, people had trouble relating to the past "before" the revolution. In this situation, people no longer had an implicit understanding of their past. In order to understand the past, it had to be represented through history. As people realized that history was only one version of the past, they became more and more concerned with their own cultural heritage (in French called "patrimoine") which helped them shape a collective and national identity. In search for an identity to bind a country or people together, governments have constructed collective memories in the form of commemorations which should bring and keep together minority groups and individuals with conflicting agendas. What becomes clear is that the obsession with memory coincides with the fear of forgetting and the aim for authenticity.

However, more recently questions have arisen whether there ever was a time in which 'pure', non-representational memory existed – as Nora in particular put forward. Scholars like Tony Bennett rightly point out that representation is a crucial precondition for human perception in general: pure, organic and objective memories can never be witnessed as such.

It is because of a sometimes too contracted conception of memory as just a temporal phenomenon, that the concept of cultural memory has often been exposed to misunderstanding. Nora pioneered connecting memory to physical, tangible locations, nowadays globally known and incorporated as "lieux de mémoire". He certifies these in his work as "mises en abîme"; entities that symbolize a more complex piece of our history. Although he concentrates on a spatial approach to remembrance, Nora already points out in his early historiographical theories that memory goes beyond just tangible and visual aspects, thereby making it flexible and in flux. This rather problematic notion, also characterized by Terdiman as the 'omnipresence' of memory, implies that for instance on a sensory level, a smell or a sound can become of cultural value, due to its commemorative effect.

Either in visualized or abstracted form, one of the largest complications of memorializing our past is the inevitable fact that it is absent. Every memory we try to reproduce becomes – as Terdiman states – a 'present past'. It is this impractical desire for recalling what is gone forever that brings to surface a feeling of nostalgia, noticeable in many aspects of daily life but most specifically in cultural products.

Recently, interest has developed in the area of 'embodied memory'. According to Paul Connerton the body can also be seen as a container, or carrier of memory, of two different types of social practice; inscribing and incorporating. The former includes all activities which are helpful for storing and retrieving information: photographing, writing, taping, etc. The latter implies skilled performances which are sent by means of physical activity, like a spoken word or a handshake. These performances are accomplished by the individual in an unconscious manner, and one might suggest that this memory carried in gestures and habits, is more authentic than 'indirect' memory via inscribing.

The first conceptions of embodied memory, in which the past is 'situated' in the body of the individual, derive from late nineteenth century thoughts of evolutionists like Jean Baptiste Lamarck and Ernst Haeckel. Lamarck’s law of inheritance of acquired characteristics and Haeckel's theory of ontogeny recapitulating phylogeny, suggested that the individual is a summation of the whole history that had preceded him or her. (However, neither of these concepts is accepted by current science.)

Memory can, for instance, be contained in objects. Souvenirs and photographs inhabit an important place in the cultural memory discourse. Several authors stress the fact that the relationship between memory and objects has changed since the nineteenth century. Stewart, for example, claims that our culture has changed from a culture of production to a culture of consumption. Products, according to Terdiman, have lost 'the memory of their own process' now, in times of mass-production and commodification. At the same time, he claims, the connection between memories and objects has been institutionalized and exploited in the form of trade in souvenirs. These specific objects can refer to either a distant time (an antique) or a distant (exotic) place. Stewart explains how our souvenirs authenticate our experiences and how they are a survival sign of events that exist only through the invention of narrative.

This notion can easily be applied to another practice that has a specific relationship with memory: photography. Catherine Keenan explains how the act of taking a picture can underline the importance of remembering, both individually and collectively. Also she states that pictures cannot only stimulate or help memory, but can rather eclipse the actual memory – when we remember in terms of the photograph – or they can serve as a reminder of our propensity to forget. Others have argued that photographs can be incorporated in memory and therefore supplement it.

Edward Chaney has coined the term 'Cultural Memorials' to describe both generic types, such as obelisks or sphinxes, and specific objects, such as the Obelisk of Domitian, Abu Simbel or 'The Young Memnon', which have meanings attributed to them that evolve over time. Readings of ancient Egyptian artefacts by Herodotus, Pliny, the Collector Earl of Arundel, 18th-century travellers, Napoleon, Shelley, William Bankes, Harriet Martineau, Florence Nightingale or Sigmund and Lucian Freud, reveal a range of interpretations variously concerned with reconstructing the intentions of their makers.

Historian Guy Beiner argued that "studies of cultural memory tend to privilege literary and artistic representations of the past. As such, they often fail to engage with the social dynamics of memory. Monuments, artworks, novels, poems, plays and countless other productions of cultural memory do not in themselves remember. Their function as "aides-mémoire" is subject to popular reception. We need to be reminded that remembrance, like trauma, is formulated in human consciousness and that this is shared through social interaction".

As a contrast to the sometimes generative nature of previously mentioned studies on cultural memory, an alternative 'school' with its origins in gender and postcolonial studies underscored the importance of the individual and particular memories of those unheard in most collective accounts: women, minorities, homosexuals, etc.

Experience, whether it be lived or imagined, relates mutually to culture and memory. It is influenced by both factors, but determines these at the same time. Culture influences experience by offering mediated perceptions that affect it, as Frigga Haug states by opposing conventional theory on femininity to lived memory. In turn, as historians such as Neil Gregor have argued, experience affects culture, since individual experience becomes communicable and therefore collective. A memorial, for example, can represent a shared sense of loss.

The influence of memory is made obvious in the way the past is experienced in present conditions, for – according to Paul Connerton, for instance – it can never be eliminated from human practice. On the other hand, it is perception driven by a longing for authenticity that colors memory, which is made clear by a desire to experience the real (Susan Stewart). Experience, therefore, is substantial to the interpretation of culture as well as memory, and vice versa.

Traumatic transmissions are articulated over time not only through social sites or institutions but also through cultural, political, and familial generations, a key social mechanism of continuity and renewal across human groups, cohorts, and communities. The intergenerational transmission of collective trauma is a well-established phenomenon in the scholarly literature on psychological, familial, sociocultural, and biological modes of transmission. Ordinary processes of remembering and transmission can be understood as cultural practices by which people recognize a lineage, a debt to their past, and through which "they express moral continuity with that past." The intergenerational preservation, transformation, and transmutation of traumatic memory such as of genocide tragic historical legacy can be assimilated, redeemed, and transformed.

Recent research and theorizing in cultural memory has emphasized the importance of considering the content of cultural identities in understanding the study of social relations and predicting cultural attitudes.

The Institute of Germanic & Romance Studies, School of Advanced Study, University of London, has developed its MA degree around the above-mentioned topics.

The MA in Cultural Memory has now been running for 10 years. This unique degree explores the many different ways in which culture is based on the construction, manipulation and transmission of memories, and the role played by memory in collective and individual identity formation.

The degree programme is supplemented by a Cultural Memory Seminar and by the new Centre for the Study of Cultural Memory.

In 2008, the first issue of quarterly journal "Memory Studies" concerning subjects of and relating to cultural memory was published by SAGE.

Jan Assmann in his book "Das kulturelle Gedächtnis", drew further upon Maurice Halbwachs's theory on collective memory. Other scholars like Andreas Huyssen have identified a general interest in memory and mnemonics since the early 1980s, illustrated by phenomena as diverse as memorials and retro-culture. Some might see cultural memory as becoming more democratic, due to liberalization and the rise of new media. Others see cultural memory as remaining concentrated in the hands of corporations and states.

Cultural Memory has long been disregarded in terms of a native people's right to their culture and the memories contained therein. 

Lowry Burgess has also been spearheading the creation of the “The 31 Article, Declaration and Resolution for The United Nations Universal Declaration on Human Rights, The Right to Historic Memory”. These revolutionary documents create an ecosystem where The UN and the World Bank can provide protection for cultural historical memory and artifacts from destructive groups by using their existing credit system to provide humanitarian benefit to countries that protect and maintain historic sites and related cultural artifacts.

‘The Right to historic Cultural Memory’ derives from 50 years of the author’s public political experience, institutional administration, study and research, arts practice, world travel, teaching, seminars, public lectures, international conferences, books, publications, and bibliographies.




</doc>
<doc id="26642577" url="https://en.wikipedia.org/wiki?curid=26642577" title="Sophistication">
Sophistication

Sophistication has come to mean a few things, but its original definition was "to denature, or simplify". Today it is common as a measure of refinement—displaying good taste, wisdom and subtlety rather than crudeness, stupidity and vulgarity.
In the perception of social class, sophistication can be linked with concepts such as status, privilege and superiority.

In social terms, the connotations of sophistication depends on whether one is an insider or an outsider of the sophisticated class. Sophistication can be seen as "a form of snobbery," or as "among the most desirable of human qualities."

A study of style conveys an idea of the range of possible elements through which one can demonstrate sophistication in elegance and fashion, covering the art of "[...] the shoemaker, the hairdresser, the cosmetologist, the cookbook writers, the chef, the diamond merchant, the couturieres, and the fashion queens, the inventors of the folding umbrella ... and of champagne."

In Ancient Greece, "sophia" was the special insight of poets and prophets. This then became the wisdom of philosophers such as sophists. But their use of rhetoric to win arguments gave sophistication a derogatory quality. Sophistry was then the art of misleading.

The system of modern Western sophistication has its roots in France, arguably helped along its way by the policies of King Louis XIV (reigned 1643–1715).

The English regarded sophistication as decadent and deceptive until the aristocratic sensibilities and refined elegance of Regency dandies such as Beau Brummell (1778–1840) became fashionable and admired.

Recognised varieties of sophistication include:


In the analysis of humor, Victor Raskin distinguishes "two types of sophistication: limited access, or allusive knowledge, and complex processing".

Methods of acquiring the appearance of personal sophistication include:



On a societal level commentators can associate various forms of sophistication with civilization.

Alecia Watterson



</doc>
<doc id="25907070" url="https://en.wikipedia.org/wiki?curid=25907070" title="Ethnoscience">
Ethnoscience

Ethnoscience has been defined as an attempt "to reconstitute what serves as science for others, their practices of looking after themselves and their bodies, their botanical knowledge, but also their forms of classification, of making connections, etc." (Augé, 1999: 118).

Ethnoscience has not always focused on ideas distinct from those of "cognitive anthropology", "component analysis", or "the New Ethnography"; it is a specialization of indigenous knowledge-systems, such as ethno-botany, ethno-zoology, ethno-medicine, etc. (Atran, 1991: 595). According to Scott Atran, ethnoscience looks at culture with a scientific perspective (1991: 650), although most anthropologists abhor this definition. Ethnoscience helps to understand how people develop with different forms of knowledge and beliefs, and focuses on the ecological and historical contributions people have been given (Atran, 1991: 650). Tim Ingold describes ethnoscience as a cross-discipline (2000: 160). He writes that ethnoscience is based on increased collaboration between social sciences and the humanities (e.g., anthropology, sociology, psychology, and philosophy) with natural sciences such as biology, ecology, or medicine (Ingold, 2000: 406-7). At the same time, ethnoscience is increasingly transdisciplinary in its nature (Ingold, 2000: 407).

Of course, naturally over time, the ways in which data has been collected and studied has changed and the field has evolved, becoming more detailed and specific (Urry, 1972: 45). The ideas, mechanics, and methods of ethnoscience evolved from something else - a combination of several things. This pretext amalgamation of theories, processes, and –isms led to the evolution of today's ethnoscience.

Early on, Franz Boas established cultural relativism as an approach to understanding indigenous scientific practices (Uddin, 2005: 980). Cultural relativism identifies people's differences and shows how they are a result of the social, historical, and geographical conditions (Uddin, 2005: 980). Boas is known for his work in Northern Vancouver, British Columbia, Canada, working with the Kwakwaka'wakw Indians, which is where he established the importance of culture (Uddin, 2005: 980). Lévi-Strauss' structuralism was a strong contributor to the ideas of ethnoscience (Uddin, 2005: 980). It, itself, was the leading idea of providing structure to the research and a guide to organizing and relating different cultures. "Ethnoscience refers to a 'reduction of chaos' achieved by a particular culture, rather than to the 'highest possible and conscious degree' to which such chaos may be reduced;" basically, the ethnoscience of a society creates its culture (Sturtevant, 1964: 100). Much of the influence of anthropology, e.g., geographical determinism, was through the contributions of Jean Bodin (Harris, 1968: 42). In his text, he tried to explain why "northern people were faithful, loyal to the government, cruel, and sexually uninterested, compared to why southern people were malicious, craft, wise, expert in science but ill-adapted to political activity (Harris, 1968: 52)." The Greek historian, Polybius, asserted "we mortals have an irresistible tendency to yield to climatic influences; and to this cause, and no other, may be traced the great distinctions that prevail among us in character, physical formation, complexion, as well as in most of our habits…" (quoted in Harris, 1968: 41).

Another aspect of anthropology prior to ethnoscience is enculturation. Newton and Newton described enculturation as a process whereby the novice, or "outsider", learns what is important to the "insider" (1998). Marvin Harris writes, "One of [enculturation's] most important technical expressions is the doctrine of 'psychic unity,' the belief that in the study of sociocultural differences, hereditary (genetic) differences cancel each other out, leaving 'experience' as the most significant variable" (Harris, 1968: 15). This is one of the many starts of people opening up to the idea that just because people are different, doesn't mean they are wrong in their thinking. Harris describes how religious beliefs hinder and affect the progress of anthropology and ethnography. The moral beliefs and restrictions of religion fought against anthropological ideas, possibly due to (especially at the time) to the newly hyped idea of evolutionism and Darwinism (Harris, 1968).

Bronislaw Malinowski was one of many who contributed heavily to the precursor of ethnoscience. His earlier work brought attention to sociological studies; his earliest publication focused on a family in Australia, using a sociological study perspective (Harris, 1968: 547). After the First World War, anthropological work was at a stand still; nothing had evolved, if not regressed (Urry, 1972: 54). This allowed him to start from scratch, and rebuild his ideas and methods (Harris, 1968: 547).

Later, however, Malinowski branched out to political evolution during World War II. The period after World War II is what led to ethnoscience; anthropologists learned their skills could be applied to problems that were affecting modern societies (Mead, 1973: 1). Malinowski said "… with his tables of kinship terms, genealogies, maps, plans and diagrams, proves an extensive and big organization, shows the contribution of the tribe, of the clan, of the family, and he gives a picture of the natives subjected to a strict code of behavior and good manners, to which in comparison the life at the Court of Versailles or Escurial was free and easy" (1922: 10). After World War II, there was an extreme amount of growth in the anthropological field, not only with research opportunities but academically, as well (Mead, 1973: 2).

The anthropologist Robin Horton, who taught at several Nigerian universities, considered the traditional knowledge of indigenous peoples as incorporated within conceptual world views that bear certain similarities to, and differences from, the modern scientific worldview. Like modern science, traditional thought provides a theoretical structure that "places things in a causal order wider than that provided by common sense" (Horton, 1967, p. 53). In contrast to modern science, he saw traditional thought as having a limited awareness of theoretical alternatives and, consequently, displaying "an absolute acceptance of the established theoretical tenets" (Horton, 1967, pp. 155–6).

There are dozens, if not hundreds, of related methods and processes that preceded ethnoscience. Ethnoscience is just another way to study the human culture and the way people interact in society. Taking a look at the ideas and analyses prior to ethnoscience can help understand why it was developed in the first place. Although, it is not widely used and there is criticism on both ends, ethnoscience allows for a more comprehensive way to collect data and patterns of a people. This is not to say the process is its best or that there will be nothing better. That is the best part: everything evolves, even thought. Just as the ideas did in the past, they can improve over time and regress over time but change is inevitable.

Ethnoscience is a new term and study that came into anthropological theory in the 1960s. Often referred to as "indigenous knowledge", ethnoscience introduces a perspective based on native perceptions. It is based on a complete emic perspective, which excludes all observations, interpretations and or any personal notions belonging to the ethnographer. The taxonomy and classification of indigenous systems, to name a few, used to categorize plants, animals, religion and life is adapted from a linguistic analysis. The concept of "Native Science" is also related to the understanding the role of the environment intertwined with the meaning humans place upon their lives. Understanding the language and the native people's linguistic system is one method to understand a native people's system of knowledge of organization. Not only is there categorization for things pertaining to nature and culture thought language, but more importantly and complex is the relationship between environment and culture. Ethnoscience looks at the intricacies of the connection between culture and its surrounding environment. There are also potential limitations and shortcomings in interpreting these systems of knowledge as a dictation of culture and behavior.

Since an ethnographer is not able to physically enter inside an indigenous person's mind, it is essential to not only create a setting or question-answer format to understand perspective but to analyze semantics and word order of given answer to derive an emic understanding. The main focus on a particular component of the languages is placed on its lexicon. The terms "etic" and "emic" are derived from the linguistic terms of "phonetic" and "phonemic".

As introduced by Gregory Cajete, some limitations the concept of indigenous knowledge, is the potential to bypass non-indigenous knowledge as pertinent and valuable. The labels of "indigenous" are overly accepted by those who seek more support by outsiders to further their cause. There might also be an unequal distribution of knowledge amongst a tribe or peoples. There is also the idea that culture is bound by environment. Some theorists conclude that indigenous people's culture is not operated by mental concentrations but solely by the earth that surrounds them. Some theorists go the extent to state that biological processes are based upon the availability, of lack thereof, environmental resources. The methods for sustainability are founded through the workings of the land. These techniques are exercised from the basis of tradition. The importance of the combination of ecological process, social structures, environmental ethics and spiritual ecology are crucial to the expression of the true connection between the natural world and "ecological consciousness".

The origin of Ethnoscience began between the years 1960 to 1965; deriving from the concept of "ethno- + science". Ethno- a combining form meaning "race", "culture", "people", used in the formation of compound words: ethnography. The two concepts later emerged into "ethno-science". The origin of the word 'science' involves the empiric observation of measurable quantities and the testing of hypotheses to falsify or support them. 
"Ethnoscience refers to the system of knowledge and cognition typical of a given culture...to put it another way a culture itself amounts to the sum of a given society's folk classifications, all of that society's ethnoscience, its particular ways of classifying its material and social universe" (Sturtevant 1964: 99–100). The aim of ethnoscience is to gain a more complete description of cultural knowledge. Ethnoscience has been successfully used on several studies of given cultures relating to their linguistics, folk taxonomy, and how they classify their foods, animals and plants.

Ethnoscience is the examination of the perceptions, knowledge, and classifications of the world as reflected in their use of language, which can help anthropologists understand a given culture. By using an ethnographic approach to studying a culture and learning their lexicon and syntax they are able to gain more knowledge in understanding how a particular culture classifies its material and social universe. In addition, this approach "adopted provides simultaneously a point at which the discipline of linguistics, or at least some of its general attitudes, may sensibly be used in anthropology and as a means of gaining insight not only into the nature of man but also into the nature of culture" (Videbeck and Pia, 1966).

Researchers can use linguistics to study what a given culture considers important in a given situation or unforeseen event, and can rank those potential situations in terms of their likelihood to recur. In addition, "understanding the contingencies is helpful in the task of comprehending folk taxonomies on the one hand, and, on the other, an understanding of the taxonomy is required for a full scale appreciation of criteria considered relevant in a given culture (Videbeck and Pia, 1966).

Ethnoscience can be used to analyze the kinship terminology of a given culture, using their language and according to how they view members of their society. Taxonomies "are models of analysis whose purpose is the description of particular types of hierarchical relationships between members of a given set of elements" (Perchonock and Werner, 1969). For example, in our society we classify family groups by giving members the title of father, mother, sister, daughter, brother, son, grandfather, grandmother, etc.

Ethnoscience deals with how a given culture classifies certain principles in addition to how it is express through their language. By understanding a given culture through how they view the world, anthropologists attempt to eliminate any bias through translation as well as categorized their principles in their own ways. "The new methods, which focus on the discovery and description of folk systems, have come to be known as Ethnoscience. Ethnoscience analysis has thus far concentrated on systems of classification within such cultural and linguistic domains as colors, plants, and medicines" (Perchonock and Werner, 1969). An ethnoscientific approach can be used to better understand a given culture and their knowledge of their culture. Using an ethnographic approach can help anthropologists understand how that given culture views and categorizes their own foods, animal kingdom, medicines, as well as plants.

Ethnoscience can be effectively summed up as a classification system for a particular culture in the same way that a botanist would use a taxonomic system for the classification of plant species. Everything from class levels, food consumption, clothing, and material culture objects would be subjected to a taxonomic classification system. In essence, ethnoscience is a way of classifying cultural systems in a structured order to better understand the culture.
The roots of ethnoscience can be traced back to influential anthropologists such as Franz Boas, Bronislaw Malinowski, and Benjamin Whorf who attempted to understand other cultures from an insider's perspective. Ward Goodenough is accredited for bringing ethnoscience to the stage when he define cultural systems of knowledge by stating:

""A societies culture consists of whatever it is one has to know or believe in order to operate in a manner acceptable to its members. Culture is not a material phenomenon; it does not consist of things, behavior, or emotions. It is rather an organization of these things. It is the form of things that people have in mind, their models for perceiving, relating, and otherwise interpreting them."
" (Goodenough 1957:167)
In order to properly put ethnoscience in context we must first understand the definition of ethnoscience. it is defined as "an attempt at cultural description from a totally emic perspective (a perspective in ethnography that uses the concepts and categories that are relevant and meaningful to the culture that is insider analysis) standpoint, this eliminating all of the ethnographer's own categories" (Morey and Luthans 27). Ethnoscience is also a way of learning and understanding how an individual or group perceive their environment and how they fit in with their environment as reflected in their own words and actions.

Ethnoscience has many techniques when applied to an emic perspective. Ethnosemantics, ethnographic semantics, ethnographic ethnoscience, formal analysis, and componential analysis are the terms that apply to the practice of ethnoscience. Ethnosemantics looks at the meaning of words in order to place them in context of the culture being studied. It allows for taxonomy of a certain part of the culture being looked at so that there is a clear breakdown which in turn leads to a deeper understanding of the subject at hand. Ethnographic semantics are very similar to cognitive anthropology in that its primary focus is the intellectual and rational perspectives of the culture being studied. Ethnographic semantics specifically looks at how language is used throughout the culture. Lastly, ethnographic ethnoscience is related to ethnosemantics such that, it uses a taxonomic system to understand how cultural knowledge is accessible through language. Ethnographic ethnoscience uses similar classification systems for cultural domains like ethnobotany and ethnoanatomy. Again, ethnoscience is a way of understanding a how a culture sees itself through its own language. Understanding the cultural language allows the ethnographer to have a deeper and more intimate understanding of the culture.




</doc>
<doc id="2036118" url="https://en.wikipedia.org/wiki?curid=2036118" title="Cultural lag">
Cultural lag

The term "cultural lag" refers to the notion that culture takes time to catch up with technological innovations, and that social problems and conflicts are caused by this lag. Subsequently, cultural lag does not only apply to this idea only, but also relates to theory and explanation. It helps by identifying and explaining social problems to predict future problems.

As explained by James W. Woodward, when the material conditions change, changes are occasioned in the adaptive culture, but these changes in the adaptive culture do not synchronize exactly with the change in the material culture, this delay is the culture lag. The term was coined by sociologist William F. Ogburn in his 1922 work "Social change with respect to culture and original nature." His theory of cultural lag suggests that a period of maladjustment occurs when the non-material culture is struggling to adapt to new material conditions. This resonates with ideas of technological determinism. That is it can presuppose that technology has independent effects on society at large. However it does not necessarily assign causality to technology. Rather cultural lag focuses examination on the period of adjustment to new technologies. 

According to Ogburn, cultural lag is a common societal phenomenon due to the tendency of material culture to evolve and change rapidly and voluminously while non-material culture tends to resist change and remain fixed for a far longer period of time. Due to the opposing nature of these two aspects of culture, adaptation of new technology becomes rather difficult. This distinction between material and non-material culture is also a contribution of Ogburn's 1922 work on social change. 

Cultural lag creates problems for a society in a multitude of ways. The issue of cultural lag tends to permeate any discussion in which the implementation of some new technology is a topic. For example, the advent of stem cell research has given rise to many new, potentially beneficial medical technologies; however these new technologies have also raised serious ethical questions about the use of stem cells in medicine. Cultural lag is seen as a critical ethical issue because failure to develop broad social consensus on appropriate applications of modern technology may lead to breakdowns in social solidarity and the rise of social conflict.




</doc>
<doc id="12870646" url="https://en.wikipedia.org/wiki?curid=12870646" title="Legal culture">
Legal culture

Legal cultures are described as being temporary outcomes of interactions and occur pursuant to a challenge and response paradigm. Analyses of core legal paradigms shape the characteristics of individual and distinctive legal cultures.
“Comparative legal cultures are examined by a field of scholarship, which is situated at the line bordering comparative law and historical jurisprudence.”

Legal cultures can be examined by reference to fundamentally different legal systems. However, such cultures can also be differentiated between systems with a shared history and basis which are now otherwise influenced by factors that encourage cultural change. Students learn about legal culture in order to better understand how the law works in society. This can be seen as the study of Law and Society. These studies are available at schools such as Drake University in Des Moines, Iowa.

Western legal culture is unified in the systematic reliance on legal constructs. Such constructs include corporations, contracts, estates, rights and powers. These concepts are not only nonexistent in primitive or traditional legal systems but they can also be predominately incapable of expression in those language systems which form the basis of such legal cultures.

As a general proposition, the concept of legal culture depends on language and symbols and any attempt to analyze non-western legal systems in terms of categories of modern western law can result in distortion attributable to differences in language. So while legal constructs are unique to classical Roman, modern civil and common law cultures, legal concepts or primitive and archaic law get their meaning from sensed experience based on facts as opposed to theory or abstract. Legal culture therefore in the former group is influenced by academics, learned members of the profession and historically, philosophers. The latter group’s culture is harnessed by beliefs, values and religion at a foundational level.

Traditional law in Africa is based on natural justice and lacks abstract concepts. This is characteristic of cultures that have an absence of written language which is necessary to elaborate concepts into theory. The doctrines of traditional African law are based on social considerations whereby parties to disputes seek not declarations of right or wrong but rather they seek restitution of social relationships.

The trier of fact and law adjudicates between closely related people from communities as opposed to strangers in commerce. Judgments stress the importance of living together in generous, loving kindness, mutual helpfulness and reciprocity. Evidence suggests that ‘African law demonstrates that all men, because they live in society, have some theory of rules of justice which they believe arise from reason itself; [and Gluckman’s evidence] suggests that Africans may well have formulated, in embryonic form at least, a theory of natural justice coming from human kindness itself.’ 

The Islamic legal system exemplifies law as part of a larger culture where the concepts of knowledge, right and human nature play a central role. A case study by Lawrence Rosen explains the anthropological, procedural and judicial discretion aspects of bringing a case to court in Sefrou, Morocco. The case study makes explicit those fundamentals in Islamic society that shape Islamic legal culture and differentiate this from western legal cultures.

Rigid procedural rules and strict court room decorum or etiquette which is entrenched in western legal cultures clears the way for a more natural process of dispute resolution. In Morocco, close attention is paid to social origins, connections and identity where these concepts influence a qadi’s (judge) judicial interrogation and discretion.

While the systems of law found in the western world consist of conceptualisation and implementation that mimic the extrajudicial world only slightly, in the Islamic courts of Morocco, the culture of law being propounded reflects the overall culture of its people. This is attributable to the goals of law in Islamic society, which is not to hold state or religious power as supreme or to develop an exacting body of legal doctrine, but to restore relationships and then facilitate the resolution of disputes independently of rigid precedent.

The traditional focus between common law culture and civil law culture has been highlighted by court room procedure, whereby the former nurtures an adversarial environment and the latter an inquisitorial one. Indeed no system of court procedure can ever be purely adversarial or purely inquisitorial.

In fact France, which subscribes to a civil legal system, historically gave the judge a passive role and left the parties to engage in an accusatorial manner. Nonetheless the common law culture predominately consists of oral arguments where legal representors steer the case in search of justice and reinforcement of rights.

The use of a Jury in the common law as a judge of fact is unique when compared to civil law systems. The Jury are triers of fact in both civil and criminal cases and this reflects a particular culture of law; namely the direct involvement of society in the legal framework. In France a judge’s role as trier of law and fact is merely as an administrator without creating binding legal principle. Hence the civil law culture is more rational, orderly, authoritative and paternalistic.

Common law has a culture of judicial inventiveness and even flexibility. Enunciation of principle is not forever paramount but indeed a continuing flow of cases and statutes add to the ebb and flow of the law, whereby ‘case law represented the modern man’s realisation of his own limitations.’ Further differences include where a civilian lawyer speaks in terms of the law of nature while the common lawyer speaks to reason. It follows that the culture of these legal systems has been moulded by perceptions of justice and the means available to attain it.

Legal culture can differ between countries despite their conformity to a similar if not identical legal system. Both the United States and England possess common law systems of law and yet each country embodies a distinctive legal culture. This has been attributable by contrasting both the institutions within the legal system and characteristics of the profession (judges, barristers and solicitors).

According to Posner during 1996 there was about 15 times more American judges than English judges but only about 10 times more American lawyers than English lawyers. Posner suggests that English judges have more prestige than American judges and a related point is that the ratio of judges to lawyers is lower in England than the United States. The consequence of this is that the English common law system, as opposed to the American legal system, displays a legal culture of greater prestige and elitism not only in the judiciary but also those who are candidates for the judiciary.

In England, and other Commonwealth jurisdictions, barristers are apt candidates for judicial nomination. The reasons for this stem from the common law systems which have a culture to encourage, harness and capture high quality intellect and experience within a concentrated portion of non-judicial officers of the legal profession known as barristers (which includes and accounts for their subsequent appointments to higher ranking queens counsel and senior counsel).

Barristers are engaged upon a solicitor's brief instead of direct engagement with the client. This insulation avoids lay persons being taken advantage of by unscrupulous lawyers which is evidently "a big problem in the United States, where incompetent lawyers, and known to be such both by judges and by other lawyers, often wow naïve clients." 

The cost of pursuing litigation influences the culture of each legal system in terms of what society perceives as the net benefit gained from the court and the profession. To litigate similar cases in England and the United States would cost approximately the same; however English courts are not as generous as their American counterparts in awarding damages, especially punitive damages. Therefore the net expected benefit of litigation being greater in the United States encourages a legal culture that is more litigious in nature than England.

National character is inherent in the legal institutions of the courts and parliament, their formation and their output in terms of legislation or judgments. For example it has been said that many factors have contributed to the litigiousness of the United States, including: the rights afforded to the people, a written constitution, immigrant origins of its population, racial and ethnic heterogeneity and the wealth and spoils of its population. To this end national character and history influence current legal culture.

The legal culture of China, as well as its social and economic culture, continues to undergo dramatic change since the People’s Republic of China's reforms of 1978. Transformation has occurred by legal modernisation whereby a rule of law has been suggested to replace the rule of man. The latter is a characteristic of the traditional rural Chinese society where unwritten rules, personal relationships and trust govern citizens' legal relationships; analogous to gemeinschaft. In the modern society of China, institutional, customary and legal reform (a rule of law that embodies universal rules uniformly enforced by a centralised and bureaucratic state) is necessary to govern legal relations; analogous to gesellschaft.

Direct transplants of western legal systems or culture may not provide an adequate rule of law where the life of ordinary Chinese may be marginalised in favour of legal elite who use legal instruments for self-promotion. Furthermore, implanting western legal norms disregards the local culture and relations; thus potentially destroying significant cultural bonds and relationships in the rural community. The traditional rural Chinese legal culture which is premised on personal and informal relations faces erosion unless legal pluralism is promoted.

A top down approach in analysing the legal culture of China suggests that both under Deng Xiaoping and Jiang Zemin, China is "a country under rule by law, not rule of law." Evidence comes from post Mao-China, where law is seen as necessary for institutionalising and generalising ad hoc policies for economic reform and as maintaining party leadership.

Further problems with the Chinese legal culture include a piecemeal approach to law making with an imbalance between law and policy; denials of private law; neglect towards human rights and individual liberties; and poor enforcement of laws. According to Chen, the consensus in China among scholars is that the lack of democracy and rule of law are interdependent concepts whereby "the rule of law is legitimate only if it is the product of democratic government." 

What is evident with the China experience is that legal culture is susceptible to change in pursuance to socio-economic and political forces. While such a change could be beneficial for portions of the society and international relations, traditional and established cultural methods face extinction.




</doc>
<doc id="32839108" url="https://en.wikipedia.org/wiki?curid=32839108" title="Superficiality">
Superficiality

The discourses in philosophy regarding social relation. What social psychologists call "the principle of superficiality versus depth" has pervaded Western culture since at least the time of Plato.

Socrates sought to convince his debaters to turn from the superficiality of a worldview based on the acceptance of convention to the examined life of philosophy, founded (as Plato at least considered) upon the underlying Ideas. For more than two millennia, there was in the Platonic wake a general valorisation of critical thought over the superficial subjectivity that refused deep analysis. The salon style of the Précieuses might for a time affect superficiality, and play with the possibility of treating serious topics in a light-hearted fashion; but the prevailing western consensus firmly rejected elements such as everyday chatter or the changing vagaries of fashion as superficial distractions from a deeper reality.

By contrast, Nietzsche opened the modernist era with a self-conscious praise of superficiality: "What is required is to stop courageously at the surface, the fold, the skin, to adore appearance, to believe in forms, tones, words, in the whole Olympus of appearance! Those Greeks were superficial – "out of profundity"!".

His (still) preference for superficiality was however over-shadowed for most of the 20th century by modernism's full subscription to the depth/surface model, and to the privileging of the former over the latter. Frederic Jameson has highlighted four main modernist versions of the belief in a "deeper" reality - Marxist, psychoanalytic, existential, and semiotic - in each of which reality is understood to be concealed behind an inauthentic surface or façade. Jameson contrast these models sharply with the lack of depth, the ahistoricity, the surface-focus and flatness of the postmodern consciousness, with its new cult of the image and the simulacrum.

In the last third of the 20th century, Lyotard began challenging the Platonic view of a true meaning hidden behind surface as a "theatrical" world-view, insisting instead that sense manifestations had their own reality which necessarily impacted upon the purely verbal order of intelligibility. Similarly, deconstruction has increasingly sought to undo the depth/surface hierarchy, proposing in ironic style that superficiality is as deep as depth. The result has been the call to abandon the idea that behind appearances there is any ultimate truth to be found; and in consequence the growing postmodern replacement of depth by surface, or by multiple surfaces. 

That process of substitution was well under way by the 1990s, when notoriously "surface was depth", and in the new millennium has led to a state of what has been called hypervisibility: everything is on view. In this new era of exposure we are all submerged in what the psychoanalyst Michael Parsons has called "the totalist world where there is a horror of inwardness; everything must be revealed".

If postmodernism's proponents welcomed the way a new transcendence of the surface /depth dichotomy allowed a fuller appreciation of the possibilities of the superficial - the surface consciousness of the now, as opposed to the depths of historical time - critics like J. G. Ballard object that the end-product is a world of "laws without penalties, events without significance, a sun without shadows": of surface without depth. They see postmodern superficiality as a by-product of the false consciousness of global capitalism, where surface distractions, news, and entertainment supersaturate the zapping mind in such a way as to foreclose the possibility of envisioning any critical alternative.

Almost all depth psychologies defy the postmodern to value depth over surface - to aim, in David Cooper's words, for "change from the depths of oneself upwards into the "superficies" of one's social appearance". Debates may rage over whether to "begin" analysis at the surface or by way of deep interpretations, but this is essentially a question of timing. Thus for example Jungians would highlight at the start of therapy what they call the "persona-restoring" phase as an effort to preserve superficiality, but would later optimally see the client moving from the surface to deeper emotion and creativity.

Fritz Perls by contrast maintained that "the simplicity of the Gestalt approach is that we pay attention to the obvious, to the utmost surface. We don't delve into a region which we don't know anything about, into the so-called 'unconscious. A similar focus on the superficial has fuelled much of the Freud Wars of late modernity, in which, according to Jonathan Lear, "the real object of attack - for which Freud is only a stalking-horse - is the very idea that humans have unconscious motivation". Given a choice of surface or depth—"are we to see humans as having depth, layers of meaning which lie beneath the surface of their own understanding?"—he asks: "Or are we to take ourselves as transparent to ourselves...to ignore the complexity, depth and darkness of human life"; the postmodern bias remains towards superficiality.

Social psychology considers that in everyday life social processing veers between superficiality, where we rely on first impressions and immediate judgements, and a deeper form of processing in which we seek to understand the other person more fully. In the ordinary course of life, we necessarily take others at face-value, and use ideal types/stereotypes to guide our daily activities; while institutions too can rely on the superficial consensus of groupthink to preclude deeper investigation.

Some circumstances however necessitate a shift from superficial to extensive processing. When things become serious, we must put more and deeper thought into understanding, leaving superficial judgements to cases where the stakes are low, not high.




</doc>
<doc id="33301100" url="https://en.wikipedia.org/wiki?curid=33301100" title="Cultural radicalism">
Cultural radicalism

Cultural radicalism (Danish: "Kulturradikalisme") was a movement in first Danish, but later also Norwegian culture. It was particular strong in the Interwar Period, but its philosophy has its origin in the 1870s and a great deal of modern social commentary still refer to it.

At the time of the height of the cultural radical movement it was referred to as modern. The words cultural radical and cultural radicalism was first used in an essay by Elias Bredsdorff in the broadsheet newspaper, "Politiken", in 1956. Bredsdorff described cultural radicals as people who are socially responsible with an international outlook.

Cultural radicalism has usually been described as the heritage of Georg Brandes's Modern Breakthrough, the foundation and early editorials of the newspaper "Politiken", the foundation of the political party "Radikale Venstre", to the magazine "Kritisk Revy" by Poul Henningsen (PH). By opponents of cultural radicalism though, it often simply refers to the liberal intellectual elite.

The values most commonly associated with cultural radicalism are among others: criticism of religion, opposition to social norms, criticism of Victorian sexual morality, anti-militarism and an openness to new cultural input other than the classic western (e.g. jazz, modern architecture, art, literature and theater).

"Cultural radicalism" is also used outside of Denmark. In Scandinavia, it often refers to the Danish movement, but elsewhere, the concept may just share the etymology. In Sweden, cultural radicalism has been seen as opposition to the Swedish church and to the Neo-Victorian sexual moral. In Norway the movement has been associated with the magazine Mot Dag in 1930s and its authors such as Sigurd Hoel and Arnulf Øverland. In the US, "cultural radicalism" is sometimes used as the opposite of cultural conservatism, especially in the context of culture wars.





</doc>
<doc id="22810417" url="https://en.wikipedia.org/wiki?curid=22810417" title="Official culture">
Official culture

Official culture is the culture that receives social legitimation or institutional support in a given society. Official culture is usually identified with bourgeoisie culture. For revolutionary Guy Debord, official culture is a "rigged game", where conservative powers forbid subversive ideas to have direct access to the public discourse, and where such ideas are integrated only after being trivialized and sterilized.

A widespread observation is that a great talent has a free spirit. For instance Pushkin, which some scholar regard as Russia's first great writer, attracted the mad irritation of the Russian officialdom and particularly of the Tsar, since he 




</doc>
<doc id="34454406" url="https://en.wikipedia.org/wiki?curid=34454406" title="Philosophy of culture">
Philosophy of culture

Philosophy of culture is a branch of philosophy that examines the essence and meaning of culture.

The German philosopher Immanuel Kant (1724–1804) has formulated an individualist definition of "enlightenment" similar to the concept of "bildung": "Enlightenment is man's emergence from his self-incurred immaturity." He argued that this immaturity comes not from a lack of understanding, but from a lack of courage to think independently. Against this intellectual cowardice, Kant urged: "Sapere aude", "Dare to be wise!" In reaction to Kant, German scholars such as Johann Gottfried Herder (1744–1803) argued that human creativity, which necessarily takes unpredictable and highly diverse forms, is as important as human rationality. Moreover, Herder proposed a collective form of "bildung": "For Herder, Bildung was the totality of experiences that provide a coherent identity, and sense of common destiny, to a people."

In 1795, the great linguist and philosopher Wilhelm von Humboldt (1767–1835) called for an anthropology that would synthesize Kant's and Herder's interests. During the Romantic era, scholars in Germany, especially those concerned with nationalist movements—such as the nationalist struggle to create a "Germany" out of diverse principalities, and the nationalist struggles by ethnic minorities against the Austro-Hungarian Empire—developed a more inclusive notion of culture as "worldview"("Weltanschauung"). According to this school of thought, each ethnic group has a distinct worldview that is incommensurable with the worldviews of other groups. Although more inclusive than earlier views, this approach to culture still allowed for distinctions between "civilized" and "primitive" or "tribal" cultures.

In 1860, Adolf Bastian (1826–1905) argued for "the psychic unity of mankind". He proposed that a scientific comparison of all human societies would reveal that distinct worldviews consisted of the same basic elements. According to Bastian, all human societies share a set of "elementary ideas" ("Elementargedanken"); different cultures, or different "folk ideas" ("Völkergedanken"), are local modifications of the elementary ideas. This view paved the way for the modern understanding of culture. Franz Boas (1858–1942) was trained in this tradition, and he brought it with him when he left Germany for the United States.
In the 19th century, humanists such as English poet and essayist Matthew Arnold (1822–1888) used the word "culture" to refer to an ideal of individual human refinement, of "the best that has been thought and said in the world." This concept of culture is comparable to the German concept of "bildung": "...culture being a pursuit of our total perfection by means of getting to know, on all the matters which most concern us, the best which has been thought and said in the world."

In practice, "culture" referred to an élite ideal and was associated with such activities as art, classical music, and haute cuisine. As these forms were associated with urban life, "culture" was identified with "civilization" (from lat. "civitas", city). Another facet of the Romantic movement was an interest in folklore, which led to identifying a "culture" among non-elites. This distinction is often characterized as that between high culture, namely that of the ruling social group, and low culture. In other words, the idea of "culture" that developed in Europe during the 18th and early 19th centuries reflected inequalities within European societies.

Matthew Arnold contrasted "culture" with anarchy; other Europeans, following philosophers Thomas Hobbes and Jean-Jacques Rousseau, contrasted "culture" with "the state of nature". According to Hobbes and Rousseau, the Native Americans who were being conquered by Europeans from the 16th centuries on were living in a state of nature; this opposition was expressed through the contrast between "civilized" and "uncivilized." According to this way of thinking, one could classify some countries and nations as more civilized than others and some people as more cultured than others. This contrast led to Herbert Spencer's theory of Social Darwinism and Lewis Henry Morgan's theory of cultural evolution. Just as some critics have argued that the distinction between high and low cultures is really an expression of the conflict between European elites and non-elites, some critics have argued that the distinction between civilized and uncivilized people is really an expression of the conflict between European colonial powers and their colonial subjects.

Other 19th-century critics, following Rousseau have accepted this differentiation between higher and lower culture, but have seen the refinement and sophistication of high culture as corrupting and unnatural developments that obscure and distort people's essential nature. These critics considered folk music (as produced by "the folk", i.e., rural, illiterate, peasants) to honestly express a natural way of life, while classical music seemed superficial and decadent. Equally, this view often portrayed indigenous peoples as "noble savages" living authentic and unblemished lives, uncomplicated and uncorrupted by the highly stratified capitalist systems of the West.

In 1870 the anthropologist Edward Tylor (1832–1917) applied these ideas of higher versus lower culture to propose a theory of the evolution of religion. According to this theory, religion evolves from more polytheistic to more monotheistic forms. In the process, he redefined culture as a diverse set of activities characteristic of all human societies. This view paved the way for the modern understanding of culture.



</doc>
<doc id="1852708" url="https://en.wikipedia.org/wiki?curid=1852708" title="Occidentalism">
Occidentalism

Occidentalism refers to and identifies representations of the Western world (the Occident) in two ways: (i) as dehumanizing stereotypes of the Western world, Europe, the Americas, Australia, New Zealand, South Africa, and Israel; and (ii) as ideological representations of the West, as applied in "Occidentalism: A Theory of Counter-Discourse in Post-Mao China" (1995), by Chen Xiaomei; "Occidentalism: Images of the West" (1995), by James G. Carrier; and "Occidentalism: The West in the Eyes of its Enemies" (2004), Ian Buruma and Avishai Margalit. Occidentalism is often counterpart to the term orientalism as used by Edward Said in his book of that title, which refers to and identifies Western stereotypes of the Eastern world, the Orient.

In China "Traditions Regarding Western Countries" became a regular part of the "Twenty-Four Histories" from the 5th century CE, when commentary about The West concentrated upon on an area that did not extend farther than Syria. The extension of European imperialism in the 18th and 19th centuries established, represented, and defined the existence of an "Eastern world" and of a "Western world". Western stereotypes appear in works of Indian, Chinese and Japanese art of those times. At the same time, Western influence in politics, culture, economics and science came to be constructed through an imaginative geography of West and East.

In "Occidentalism: The West in the Eyes of its Enemies" (2004), Buruma and Margalit said that nationalist and nativist resistance to the West replicates Eastern-world responses against the socio-economic forces of modernization, which originated in Western culture, among utopian radicals and conservative nationalists who viewed capitalism, liberalism, and secularism as forces destructive of their societies and cultures. That the early responses to the West were a genuine encounter between alien cultures, many of the later manifestations of "Occidentalism" betray the influence of Western ideas upon Eastern intellectuals, such as the supremacy of the nation-state, the Romantic rejection of rationality, and the spiritual impoverishment of the citizenry of liberal democracies.

Buruma and Margalit trace that resistance to German Romanticism and to the debates, between the Westernisers and the Slavophiles in 19th-century Russia, and that like arguments appear in the ideologies of Zionism, Maoism, Islamism, and Imperial Japanese nationalism. Nonetheless, Alastair Bonnett rejects the analyses of Buruma and Margalit as Eurocentric, and said that the field of Occidentalism emerged from the interconnection of Eastern and Western intellectual traditions.




</doc>
<doc id="35291011" url="https://en.wikipedia.org/wiki?curid=35291011" title="Semiotics of culture">
Semiotics of culture

Semiotics of culture is a research field within semiotics that attempts to define culture from semiotic perspective and as a type of human symbolic activity, creation of signs and a way of giving meaning to everything around. Therefore, here culture is understood as a system of symbols or meaningful signs. Because the main sign system is the linguistic system, the field is usually referred to as semiotics of culture and language. Under this field of study symbols are analyzed and categorized in certain class within the hierarchal system. With postmodernity, metanarratives are no longer as pervasive and thus categorizing these symbols in this postmodern age is more difficult and rather critical.

The research field was of particular interest for the Tartu–Moscow Semiotic School (USSR). Linguists and semioticians by the Tartu School viewed culture as a hierarchical semiotic system consisting of a set of functions correlated to it, and linguistic codes that are used by social groups to maintain coherence. These codes are viewed as superstructures based on natural language, and here the ability of humans to symbolize is central.

The study received a research ground also in Japan where the idea that culture and nature should not be contrasted and contradicted but rather harmonized was developed.



</doc>
<doc id="36791036" url="https://en.wikipedia.org/wiki?curid=36791036" title="Genre-busting">
Genre-busting

"Genre-busting" is a term used occasionally in reviews of written work, music and visual art and refers to the author or artist's ability to cross over two or more established styles. For instance, in writing, to combine the horror genre with a western or hard-boiled detective story with science fiction. In music the term may refer to a song combining styles or defying classification.

The sound of the term calls to mind other uses of "buster" such as "crime buster", "Gangbusters", "Ghostbusters", "Dambusters", etc.

Creative people don't always feel comfortable working within an established category. So genre-busting within the publishing world has become a type of literary fiction. The publisher Atticus Books has gone so far as to declare, on their website: "We specialize in genre-busting literary fiction—i.e., titles that fall between the cracks of genre fiction and compelling narratives that feature memorable main characters."

The "Video Movie Guide 1998" stated in its foreword, "In past years, reviews in VMG have been broken down into genre categories. Now, by popular demand, we are listing all movies together in alphabetical order... So many movies today mix genres... and there are no clear-cut categories anymore."

Interviewed in "Mustard" comedy magazine in 2005, writer Alan Moore said: "I mean, this is probably a bad thing to say to someone from a comedy magazine, but I don't like genre. I think that genre was made up by some spotty clerk in WH Smiths in the 1920s to make his worthless fucking job a little easier for him: "it'd be easier if these books said what they were about on the spine."" going on to say: "In the novel I'm writing, Jerusalem, there's an awful lot of funny stuff, and there's supernatural stuff; there's stuff in the prologue that's as good as Stephen King and it's just a description of my brother walking through a block of flats. It's horror. And there's social history, there's political stuff. Why not mix it all together? Because that's what life is actually like. We laugh, we cry, you know, we buy the t-shirt." 



</doc>
<doc id="33596709" url="https://en.wikipedia.org/wiki?curid=33596709" title="Individualistic culture">
Individualistic culture

Individualistic culture is a society which is characterized by individualism, which is the prioritization or emphasis, of the individual over the entire group. Individualistic cultures are oriented around the self, being independent instead of identifying with a group mentality. They see each other as only loosely linked, and value personal goals over group interests. Individualistic cultures tend to have a more diverse population and are characterized with emphasis on personal achievements, and a rational assessment of both the beneficial and detrimental aspects of relationships with others. Individualistic cultures have such unique aspects of communication as being a low power-distance culture and having a low-context communication style. The United States, Australia, Great Britain, Canada, the Netherlands, and New Zealand have been identified as highly individualistic cultures.

Power distance is defined to be the degree to which unequal distribution of power is accepted in a culture. Low power distance cultures challenge authority, encourage a reduction of power differences between management and employees, and encourage the use of power legitimately. Low power distance is more likely to occur in an individualistic culture, because in a collectivist culture, people protect the well being of the group and established order so they would be less likely to challenge authority or people in power. Even though individualistic cultures are more likely to be low power distance, these cultures don't expect to completely eliminate power difference. People within this low power distance culture, however, are more likely to respond to such imbalances in power with more negative emotional responses than in the alternative, high power distance cultures. Low power distance cultures include Austria, Israel, Denmark, New Zealand, the Republic of Ireland, and Sweden. The U.S. ranks 38th on the scale.

Individualistic cultures are also more likely to have a low-context communication style. This means that communication is precise, direct, and specific. Unlike in high-context communication, reading between the lines is not necessary in low-context communication. This explicit communication is used in order to prevent any form of misunderstanding between cultures. The ability to articulate the thoughts and opinions one holds as well as to express them eloquently are encouraged, as is persuasive speaking. Low-context communication is all content and no relationship dimension.

Individualistic cultures tend to prioritize the individual person over the group, and this can be seen in how the display rules vary from a collectivist culture compared to an individualistic culture. Display rules are the rules that exist in different cultures that determine how emotion should be displayed publicly. In an individualistic culture, self-expression is highly valued, making the display rules less strict and allowing people to display intense emotion such as: happiness, anger, love, etc. While in a collectivist culture, moderation and self-control is highly valued for the well being of the group, and collectivist cultures therefore tend to restrain from showing emotion in public.

Conflict strategies are methods used to resolve different problems. There are different approaches to resolving conflict, and depending the culture a person is brought up in, the more likely it is for them to use a certain approach. Since individualistic culture sets greater value to personal achievement, contrary to collectivist cultures who value harmony, it is more likely for a person from an individualistic culture to use competition as their method of resolving conflict. When using competition as an approach to resolving conflict, a person is more confrontational and seeks to achieve his or her own goals with no regard of the goals of others. Using this approach a person seeks domination, which means to get others to do what the person wants instead of what they initially wanted. On the contrary, a collectivist culture would more likely use a less confrontational approach such as accommodation to end the conflict with compromise so that each party is benefited.



</doc>
<doc id="30049818" url="https://en.wikipedia.org/wiki?curid=30049818" title="Welfare culture">
Welfare culture

Welfare culture refers to the behavioral consequences of providing poverty relief (i.e., welfare) to low-income individuals. Welfare is considered a type of social protection, which may come in the form of remittances, such as 'welfare checks', or subsidized services, such as free/reduced healthcare, affordable housing, and more. Pierson (2006) has acknowledged that, like poverty, welfare creates behavioral ramifications, and that studies differ regarding whether welfare empowers individuals or breeds dependence on government aid. Pierson also acknowledges that the evidence of the behavioral effects of welfare varies across countries (such as Norway, France, Denmark, and Germany), because different countries implement different systems of welfare.

In the United States, the debate over the impact of welfare traces back as far as the New Deal, but it later became a more mainstream political controversy with the birth of modern welfare under President Lyndon B. Johnson's Great Society. The term "welfare culture," however, was not coined until 1986, by Lawrence Mead.

Welfare may be used to refer to any government-based aid used to promote the well-being of its citizens. In recent decades, however, welfare has been restricted to refer to the Temporary Assistance to Needy Families program (TANF), which provides monthly stipends for indigent families that meet a specific array of criteria.

The term "welfare culture" uses the more broad interpretation of welfare, all government social programs. However, scholars like David Ellwood and Lawrence Summers (1985) believe that the debate over welfare culture could be more accurate if each specific welfare program were examined individually. Specific programs include Medicare, Medicaid, unemployment benefits, and disability benefits.

Kent R. Weaver argues that most scholars cite the Social Security Act of 1935 as the origin of the American welfare state. That reform enacted a wide expanse of services for the poor and financially stressed, including unemployment benefits, Aid to Families with Dependent Children (later replaced in by the Temporary Assistance to Needy Families program under the Clinton administration), retirement income stipends, subsidized housing, and many others.

Scholars such as June Axinn and Mark J. Stern (2007) estimate that the Social Security Act of 1935 and the newly institutionalized programs accompanying the New Deal increased the capacity to find employment, avoid starvation, and secure some form of affordable housing. Furthermore, economist Robert Cohen (1973) estimated that the New Deal sparked a reduction in unemployment from 20% to 15% by the end of the 1940s.
Stanley Feldman and John Zaller (1992) cite a number of economists and political historians who opposed government-based aid, because such critics credit the economic stimulus during World War II as the true solution to the unemployment and poverty of the Great Depression. During the war, American industries began to produce military weapons, food, and other material needs for the troops. The new economic incentive, in addition to a net export and an influx in gold, reduced interest rates, increased investments, and sparked job growth. Christine Romber (1992) and various other economic historians began to criticize the New Deal as the cause for unnecessary and unjustified reliance on government programs.

However, Jerold Rusk (2008), a political scientist, recognizes a consensus among economic, history, and political scholars, which acknowledges that the effects of the New Deal are difficult to separate from the effects of World War II, which prevents any legitimate conclusion from being drawn on the debate.

In the early 1960s, President Johnson began his War on Poverty by introducing many new elements to welfare, including Medicare, Medicaid, increases in subsidized public housing, and more. David Frum (2002) believed such increases in government programs were counterproductive and found positive correlations between government aid and those who could not stay above the poverty line without such aid. Frum concluded that welfare bred dependence on the government.
During the Johnson administration, a sociologist, Senator Daniel Patrick Moynihan, published a study on the impacts of welfare on behavior during the 1960s. His report, "" (1965), is commonly referred to as the "Moynihan Report."

The Moynihan Report advocates for increased welfare for poor black families but that welfare does not empower the destitute to find solutions to their financial troubles. Moynihan stated, "The breakdown of the negro family has led to a startling increase in welfare dependency." Welfare, although helpful, was a reactive measure failing to address the true roots of poverty. Moynihan concluded that more proactive means to empower black families include the promotion of vocational training and a value in education.

Johnson's precedent for increasing welfare benefits hit its pinnacle in the late 1970s under President Jimmy Carter when Temporary Assistance to Needy Family (TANF) recipients were receiving $238 a month, adjusted for inflation. According to the Census Bureau, a strong correlation with poverty reduction is noted, suggesting a link between welfare and empowerment. Poverty dropped from 23% of the population to 12% during the Johnson years. Poverty did not see an increase again until 1982 with 15% of Americans facing poverty, two years after welfare programs experienced serious cuts under President Ronald Reagan.

However, the findings are not without their criticisms. According to the US Census Bureau, poverty had already begun to decrease before Johnson passed the Equal Opportunity Act. Additionally, unemployment reached some of its lowest rates in history under President Dwight Eisenhower near the end of the 1950s. Before Eisenhower left office, unemployment was estimated to be less than 5%.

In 1986, Lawrence Mead introduced a series of studies on welfare culture. Mead compared changes in income levels and welfare benefits across urban dwellers from the 1960s through the 1980s. Mead's studies suggest that over half of all welfare recipients will not need to stay on welfare for more than 10 years, but only 12% will be off welfare in less than 3 years. Mead concludes that welfare has demonstrated some proven effects for helping impoverished families meet their basic needs and find employment, thus acting as a tool for empowerment. However, Mead acknowledges that the welfare system can do better. Mead believes welfare culture could breed empowerment more effectively if mandatory participation in education/job training programs were required for welfare recipients.

Anthropologist Oscar Lewis studied the behavioral effects of poverty on indigent Mexicans. He introduced the concept of the "culture of poverty" and 70 personality traits that he saw in the mentality of the impoverished, including helplessness, disdain for the government, lack of confidence, hopelessness, and a sense of futility that accompanies the search for employment.




</doc>
<doc id="38566488" url="https://en.wikipedia.org/wiki?curid=38566488" title="Trademark look">
Trademark look

Trademark look or signature look is the characteristic clothes or other distinguishing signs used by a certain character or performer, making the person more recognizable by the audience. Politicians may also have trademark signs, such as the suit of American President Barack Obama or the Merkel-Raute of German Chancellor Angela Merkel. It can also refer to the clothes of a certain subculture.

Sometimes, when a celebrity stops using a trademark look, people might even find it hard to recognise them.

The term is not used in trademark law and a trademark look is not necessarily trademark protected in itself.



</doc>
<doc id="2490371" url="https://en.wikipedia.org/wiki?curid=2490371" title="Low culture">
Low culture

"Low culture" is a derogatory term for forms of popular culture that have mass appeal. Its contrast is "high culture", which can also be derogatory. It has been said by culture theorists that both high culture and low culture are subcultures.

The boundaries of low culture and high culture blur, through convergence. Many people are "omnivores", making cultural choices from different menus.

In his book "Popular Culture and High Culture", Herbert J. Gans gives a definition of how to identify and create low culture:
Herbert Gans states in his book "Popular Culture and High Culture" that the different classes of culture are linked correspondingly to socio-economic and educational classes. For any given socio-economic class, there is a culture for that class. Hence the terms high and low culture and the manifestation of those terms as they appeal to their respective constituents.

All cultural products (especially high culture) have a certain demographic to which they appeal most. Low culture appeals to very simple and basic human needs plus offers a perceived return to innocence, the escape from real world problems, or the experience of living vicariously through viewing someone else’s life on television.

Low culture can be formulaic, employing trope conventions, stock characters and character archetypes in a manner that can be perceived as more simplistic, crude, emotive, unbalanced, or blunt compared to high culture's implementations—which may be perceived as more subtle, balanced, or refined and open for interpretations.


</doc>
<doc id="143364" url="https://en.wikipedia.org/wiki?curid=143364" title="Culture hero">
Culture hero

A culture hero is a mythological hero specific to some group (cultural, ethnic, religious, etc.) who changes the world through invention or discovery. Although many culture heroes help with the creation of the world, the majority of culture heroes are important because of their effect on the world after creation. A typical culture hero might be credited as the discoverer of fire, agriculture, songs, tradition, law or religion, and is usually the most important legendary figure of a people, sometimes as the founder of its ruling dynasty.

In many Native American mythologies and beliefs, the coyote spirit stole fire from the gods (or stars or sun) and is more of a trickster than a culture hero. Natives from the Southeastern United States typically saw a rabbit trickster/culture hero, and Pacific Northwest native stories often feature a raven in this role: in some stories, Raven steals fire from his uncle Beaver and eventually gives it to humans. The Western African trickster spider Ananse is also widely disseminated. In Norse mythology, Odin (yet another trickster deity) is said to have stolen the mead of poetry from Jotunheim and is credited as the discoverer of the runes.

The term culture hero was first brought about by historian Kurt Breysig; however, he used the German word "heilbringer," which translates to savior. Over the years, culture hero has been interpreted in many ways. Older interpretations by Breysig, Paul Ehrenreich, and Wilhelm Schmidt thought that the journey of culture heroes was a way in which the humans could attempt to understand things in nature, such as the rising and setting of the sun, or the movement of the stars and constellations. Their interpretations eventually got rejected and replaced with newer interpretations by scholars such as Hermann Baumann, Adolf E. Jensen, Mircea Eliade, Otto Zerries, Raffaele Pettazzoni, and Harry Tegnaeus which evolved as a result of having more access to ethnological data, creating the present day and famously known version of the culture hero.

A culture hero is able to perform unbelievable tasks in life because he is different from the normal human. It is often believed that the culture hero is not from this world. All of a culture hero's power originates from their birth. Culture heroes are rarely born regularly. When their mothers get pregnant, it is not because of a man but instead is the result of the wind, or a drop of water. Once a culture hero is born, they are either very powerful babies or even come out of the womb as already full grown. The main point this makes is that the culture hero is not from this world.

A culture hero generally goes on an adventure (often called the hero's journey) that in turn does one of the following:


Culture Heroes often time have more than one form, such as having the ability to transform from human to some form of animal, such as a fish or bird. A culture hero has many good qualities about him/her but also has bad ones as well which is why they must go on their journeys. In some journeys the hero is known as a trickster. They act in their own selfish way and the benefits from what they have done ends up being shared with the humans as a side effect.

Once the Culture hero has finished their task, they usually end up disappearing. In many stories, the hero is transformed back to their origin. Other times the place they die will be marked with a stone, tree, or body of water. The end of a Culture Hero's life will lead to the creation of something else, such as a river, constellations, food, animals, and the moon and sun. Culture heroes are the etiological explanation for many humans about the things occurring in their daily lives.

Modern culture heroes look very different from mythological culture heroes because they have different standards they need to complete before they becoming a culture hero.

Some culture heroes are real live people. They are the ones you compare yourself to when looking at your own success because they are the very best at what they do. A good example of this would be Michael Jordan. Adults, teens and even children know who he is and when you look at other basketball players, or even yourself, he is the one that is looked at as the greatest. New players are constantly being compared to Jordan, but he has a special status as a culture hero that separates him from the rest.

Movies and books are the other source of modern culture heroes. These let you imagine a person who is seemingly a better version of humans. However, each of these characters also have an evil counterpart. Eventually the hero must defeat this evil to prevail. Overall people look towards these figures for hope. People see that they have defeated their inner evil and that it is possible for them to do so as well, thus creating a modern culture hero.



</doc>
<doc id="3039067" url="https://en.wikipedia.org/wiki?curid=3039067" title="High-context and low-context cultures">
High-context and low-context cultures

In anthropology, high-context culture and low-context culture is a measure of how explicit the messages exchanged in a culture are, and how important the context is in communication. High and low context cultures fall on a continuum that describes how a person communicates with others through their range of communication abilities: utilizing gestures, relations, body language, verbal messages, or non-verbal messages. These concepts were first introduced by the anthropologist Edward T. Hall in his 1976 book "Beyond Culture". According to Hall, in a low-context culture, the message will be interpreted through just the words (whether written or spoken) and their explicit meaning. In a high-context culture, messages are also interpreted using tone of voice, gesture, silence or implied meaning, as well as context or situation. There, the receiver is expected to use the situation, messages and cultural norms to understand the message.

High context cultures often stem from less direct verbal and nonverbal communication, utilizing small communication gestures and reading into these less direct messages with more meaning. Low context cultures are the opposite; direct verbal communication is needed to properly understand a message being said and doing so relies heavily on explicit verbal skills.

"High" and "low" context cultures are typically defined by language group, nationality, or regional community. However, they have also been applied to corporations, professions and other cultural groups, as well as settings such as online and offline communication. 

Cultural contexts are not absolutely "high" or "low". Instead, a comparison between cultures may find communication differences to a greater or lesser degree. Typically a high-context culture will be relational, collectivist, intuitive, and contemplative. They place a high value on interpersonal relationships and group members are a very close-knit community. Typically a low-context culture will be less close-knit, and so individuals communicating will have fewer relational cues when interpreting messages. Therefore, it is necessary for more explicit information to be included in the message so it is not misinterpreted. Not all individuals in a culture can be defined by cultural stereotypes, and there will be variations within a national culture in different settings. For example, Hall describes how Japanese culture has both low- and high- context situations. However, understanding the broad tendencies of predominant cultures can help inform and educate individuals on how to better facilitate communication between individuals of differing cultural backgrounds. 

Although the concept of high- and low-context cultures is usually applied in the field of analyzing national cultures, it can also be used to describe scientific or corporate cultures, or specific settings such as airports or law courts. A simplified example mentioned by Hall is that scientists working in "hard science" fields (like chemistry and physics) tend to have lower-context cultures: because their knowledge and models have fewer variables, they will typically include less context for each event they describe. In contrast, scientists working with living systems need to include more context because there can be significant variables which impact the research outcomes. 

Croucher’s study examines the assertion that culture influences communication style (high/low context) preference. Data was gathered in India, Ireland, Thailand, and the United States where the results confirm that "high-context nations (India and Thailand) prefer the avoiding and obliging conflict styles more than low-context nations (Ireland and the United States), whereas low-context nations prefer the uncompromising and dominating communication style more than high-context nations." 

In addition, Hall identified countries such as Japan, Arabic countries and some Latin American Countries to practice high-context culture; “High context communication carries most of its information within physical acts and features such as avoiding eye contact or even the shrug of a shoulder.” On the other hand, he identified countries such as Germany, the United States and Scandinavia as low context cultures. These countries are quite explicit and elaborate without having prior knowledge to each member’s history or background. 

Cultures and languages are defined as higher or lower context on a spectrum. For example, it could be argued that the Canadian French language is higher context than Canadian English, but lower context than Spanish or French French. An individual from Texas (a higher-context culture) may communicate with a few words or use of a prolonged silence characteristic of Texan English, where a New Yorker would be very explicit (as typical of New York City English), although both speak the same language (American English) and are part of a nation (the United States of America) which is lower-context relative to other nations. Hall notes a similar difference between Navajo-speakers and English-speakers in a United States school. 

Hall and Hall proposed a "spectrum" of national cultures from "High-Context cultures" to "Low-Context Cultures. This has been expanded to further countries by Copeland & Griggs (1985).

Cultural context can also shift and evolve. For instance, a study has argued that both Japan and Finland (high-context cultures) are becoming lower-context with the increased influence of Western European and United States culture.

The categories of context cultures are not totally separate. Both often take many aspects of the other's cultural communication abilities and strengths into account. The terms high- and low-context cultures are not classified with strict individual characteristics or boundaries. Instead, many cultures tend to have a mixture or at least some concepts that are shared between them, overlapping the two context cultures.

Ramos suggests that "in low context culture, communication members’ communication must be more explicit. As such, what is said is what is meant, and further analysis of the message is usually unnecessary." This implies that communication is quite direct and detailed because members of the culture are not expected to have knowledge of each other's histories, past experience or background. Because low-context communication concerns more direct messages, the meaning of these messages is more dependent on the words being spoken rather than on the interpretation of more subtle or unspoken cues.

The Encyclopedia of Diversity and Social Justice states that, "high context defines cultures that are relational and collectivist, and which most highlight interpersonal relationships. Cultures and communication in which context is of great importance to structuring actions is referred to as high context."In such cultures, people are highly perceptive of actions. Furthermore, cultural aspects such as tradition, ceremony, and history are also highly valued. Because of this, many features of cultural behavior in high-context cultures, such as individual roles and expectations, do not need much detailed or thought-out explanation.

According to Watson, "the influence of cultural variables interplays with other key factors – for example, social identities, those of age, gender, social class and ethnicity; this may include a stronger or weaker influence." A similarity that the two communication styles share is its influence on social characteristics such as age, gender, social class and ethnicity. For example, for someone who is older and more experienced within a society, the need for social cues may be higher or lower depending on the communication style. The same applies for the other characteristics in varied countries.

On the other hand, certain intercultural communication skills are unique for each culture and it is significant to note that these overlaps in communication techniques are represented subgroups within social interactions or family settings. Many singular cultures that are large have subcultures inside of them, making communication and defining them more complicated than the low context and high context culture scale. The diversity within a main culture shows how the high and low scale differs depending on social settings such as school, work, home, and in other countries; variation is what allows the scale to fluctuate even if a large culture is categorized as primarily one or the other.

Between each type of culture context, there will be forms of miscommunication because of the difference in gestures, social cues, and intercultural adjustments; however, it is important to recognize these differences and learn how to avoid miscommunication to benefit certain situations. Since all sets of cultures differ, especially from a global standpoint where language also creates a barrier for communication, social interactions specific to a culture normally require a range of appropriate communication abilities that an opposing culture may not understand or know about. This significance follows into many situations such as the workplace, which can be prone to diversified cultures and opportunities for collaboration and working together. Awareness of miscommunication between high and low context cultures within the workplace or intercultural communication settings advocates for collected unification within a group through the flexibility and ability to understand one another. 

Families, subcultures and in-groups typically favour higher-context communication. Groups that are able to rely on a common background may not need to use words as explicitly to understand each other. Settings and cultures where people come together from a wider diversity of backgrounds such as international airports, large cities, or multi-national firms, tend to use lower-context communication forms.

Hall links language to culture through the work of Sapir-Whorf on linguistic relativity. A trade language will typically need to explicitly explain more of the context than a dialect which can assume a high level of shared context. Because a low-context setting cannot rely on shared understanding of potentially ambiguous messages, low-context cultures tend to give more information, or to be precise in their language. In contrast, a high-context language like Japanese or Chinese can use a high number of homophones but still be understood by a listener who knows the context. 

The concept of elaborated and restricted codes is introduced by sociologist Basil Bernstein in his book "Class, Codes and Control". An elaborated code indicates that the speaker is expressing his/her idea by phrasing from an abundant selection of alternatives without assuming the listener shares significant amounts of common knowledge, which allows the speaker to explain their idea explicitly. In contrast, restricted codes are phrased from more limited alternatives, usually with collapsed and shortened sentences. Therefore, restricted codes require listeners to share a great deal of common perspective to understand the implicit meanings and nuances of a conversation.

Restricted codes are commonly used in high-context culture groups, where group members share the same cultural background and can easily understand the implicit meanings "between the lines" without further elaboration. Conversely, in cultural groups with low context, where people share less common knowledge or ‘value individuality above group identification’, detailed elaboration becomes more essential to avoid misunderstanding.

The concepts of collectivism and individualism have been applied to high- and low-context cultures by Dutch psychologist Geert Hofstede in his Cultural Dimensions Theory. Collectivist societies prioritize the group over the individual, and vice versa for individualist ones. In high-context cultures, language may be used to assist and maintain relationship-building and to focus on process. India and Japan are typically high-context, highly collectivistic cultures, where business is done by building relationships and maintaining respectful communication.

Individualistic cultures promote the development of individual values and independent social groups. Individualism may lead to communicating to all people in a group in the same way, rather than offering hierarchical respect to certain members. Because individualistic cultures may value cultural diversity, a more explicit way of communicating is often required to avoid misunderstanding. Language may be used to achieve goals or exchange information. The USA and Australia are typically low-context, highly individualistic cultures, where transparency and competition in business are prized.

High-context cultures tend to be more stable, as their communication is more economical, fast, efficient and satisfying; but these are gained at a price of devoting time into preprogramming cultural background, and their high stability might come with a price of a high barrier for development. By contrast, low-context cultures tend to change more rapidly and drastically, allowing extension to happen at faster rates. This also means that low-context communication may fail due to the overload of information, which makes culture lose its screening function.

Therefore, higher-context cultures tend to correlate with cultures that also have a strong sense of tradition and history, and change little over time. For example, Native Americans in the United States have higher-context cultures with a strong sense of tradition and history, compared to general American culture. Focusing on tradition creates opportunities for higher context messages between individuals of each new generation, and the high-context culture feeds back to the stability hence allows the tradition to be maintained. This is in contrast to lower-context cultures in which the shared experiences upon which communication is built can change drastically from one generation to the next, creating communication gaps between parents and children, as in the United States.

Culture also affects how individuals interpret other people's facial expressions. An experiment performed by the University of Glasgow shows that different cultures have different understanding of the facial expression signals of the six basic emotions, which are the so-called "universal language of emotion"—happiness, surprise, fear, disgust, anger and sadness. In high-context cultures, facial expressions and gestures take on greater importance in conveying and understanding a message, and the receiver may require more cultural context to understand "basic" displays of emotions.

Cultural differences in advertising and marketing may also be explained through high- and low-context cultures. One study on McDonald's online advertising compared Japan, China, Korea, Hong Kong, Pakistan, Germany, Denmark, Sweden, Norway, Finland, and the United States, and found that in high-context countries, the advertising used more colors, movements, and sounds to give context, while in low-context cultures the advertising focused more on verbal information and linear processes.




</doc>
<doc id="41748961" url="https://en.wikipedia.org/wiki?curid=41748961" title="Resistance through culture">
Resistance through culture

Resistance through culture (also called cultural resistance, resistance through the aesthetic, or intellectual resistance) is a form of nonconformism. It is not open dissent, but a discreet stance.

A revolt "so well hidden that it seem[s] inexistent", it is a quest "to extend the boundaries of official tolerance, either by adopting a line considered by authorities to be ideologically suspect, or by highlighting certain contemporary social problems, or both." Criticized for being "utopian, and thus inadequate to the realities of that age", during the time of the Communist regimes in Europe, it was also a surviving formula, a modality for writers and artists to cheat Communist censorship without going the whole way into open political opposition.

One of the most sharply criticized phrases in post-revolutionary Romania, considered to be not much more than "blowing in the wind" by Romanian-born German Nobel literature prize winner Herta Müller, and "not only resignation [...] but complicity with the terorist communism" by Romanian exiled writer Paul Goma, so-called "resistance through culture" has often been linked to Constantin Noica's so-called "Păltiniș School".

In the fine arts, Corneliu Baba, among others, is sometimes considered to be an example of a painter who was nonconformist in this way.


</doc>
<doc id="590768" url="https://en.wikipedia.org/wiki?curid=590768" title="Classic">
Classic

A classic is an outstanding example of a particular style; something of lasting worth or with a timeless quality; of the first or highest quality, class, or rank – something that exemplifies its class. The word can be an adjective (a "classic" car) or a noun (a "classic" of English literature). It denotes a particular quality in art, architecture, literature, design, technology, or other cultural artifacts. In commerce, products are named 'classic' to denote a long-standing popular version or model, to distinguish it from a newer variety. "Classic" is used to describe many major, long-standing sporting events. Colloquially, an everyday occurrence (e.g. a joke or mishap) may be described in some dialects of English as 'an absolute classic'.

"Classic" should not be confused with "classical", which refers specifically to certain cultural styles, especially in music and architecture: styles generally taking inspiration from the Classical tradition, hence classicism.

The classics are the literature of ancient Greece and Rome, known as classical antiquity, and once the principal subject studied in the humanities. Classics (without the definite article) can refer to the study of philosophy, literature, history and the arts of the ancient world, as in "reading classics at Cambridge". From that usage came the more general concept of 'classic'.

The Chinese classics occupy a similar position in Chinese culture, and various other cultures have their own classics.

Books, films and music particularly may become "a classic" but a painting would more likely be called a masterpiece. A classic is often something old that is still popular.

The first known use of "classic" in this sense — a work so excellent that it is on the level of the "classics" (Greek and Latin authors) — is by the 18th-century scholar Rev. John Bowle. He applied the term to "Don Quixote", of which Bowle prepared an innovative edition, such as he judged that a classic work needed.

Some other examples would be the book "The Adventures of Tom Sawyer" by Mark Twain, the 1941 film "Citizen Kane", and the song Heartbreak Hotel by Elvis Presley. Lists of classics are long and wide-ranging, and would vary depending on personal opinion. Classic rock is a popular radio format, playing a repertoire of old but familiar recordings.

A contemporary work may be hailed as an "instant classic", but the criteria for classic status tends to include the test of time. The term "classic" is in fact often generalized to refer to any work of a certain age, regardless of whether it is any good. A cult classic may be well known but is only favored by a minority.

A well known and reliable procedure, such as a demonstration of well-established scientific principle, may be described as classic: e.g. the cartesian diver experiment.

Manufacturers frequently describe their products as classic, to distinguish the original from a new variety, or to imply qualities in the product – although the Ford Consul Classic, a car manufactured 1961–1963, has the "classic" tag for no apparent reason. The iPod classic was simply called the iPod until the sixth generation, when "classic" was added to the name because other designs were also available – an example of a retronym. "Coca-Cola Classic" is the name used for the relaunch of Coca-Cola after the failure of the New Coke recipe change. Similarly, the Classic (transit bus), a transit bus manufactured from 1982–97, succeeded an unpopular futuristic design.

A classic can be something old that remains prized or valuable (but not an antique). Classic cars, for example, are recognised by various collectors' organisations such as the Classic Car Club of America, who regulate the qualifying attributes that constitute classic status.

Many sporting events take the name "classic":


In Spanish-speaking countries, the term "Clásico" refers to a match between two football teams known as traditional rivals, e.g. El Clásico in Spain.



</doc>
<doc id="42534554" url="https://en.wikipedia.org/wiki?curid=42534554" title="Theology of culture">
Theology of culture

Theology of culture is a branch of theology that studies culture and cultural phenomenas. It lies close to philosophy of culture, but has focus more on existentialism and spiritualism.

Paul Tillich was the first theologian who wrote about the theology of culture. He discussed about making difference between the sacred and the secular. Nowadays, the theology of culture also deals with cultural differences between religions and thus shares many features with the theology of religions.


</doc>
<doc id="37886950" url="https://en.wikipedia.org/wiki?curid=37886950" title="Culture and social cognition">
Culture and social cognition

Culture & Social Cognition is the relationship between human culture and human cognitive capabilities. Cultural cognitive evolution proposes that humans’ unique cognitive capacities are not solely due to biological inheritance, but are in fact due in large part to cultural transmission and evolution (Tomasello, 1999). Modern humans and great apes are separated evolutionarily by about six million years. Proponents of cultural evolution argue that this would not have been enough time for humans to develop the advanced cognitive capabilities required to create tools, language, and build societies through biological evolution. Biological evolution could not have individually produced each of these cognitive capabilities within that period of time. Instead, humans must have evolved the capacity to learn through cultural transmission (Tomasello, 1999). This provides a more plausible explanation that would fit within the given time frame. Instead of having to biologically account for each cognitive mechanism that distinguishes modern humans from previous relatives, one would only have to account for one significant biological adaptation for cultural learning. According to this view, the ability to learn through cultural transmission is what distinguishes humans from other primates (Tomasello, 1999). Cultural learning allows humans to build on existing knowledge and make collective advancements, also known as the “ratchet effect”. The ratchet effect simply refers to the way in which humans continuously add on to existing knowledge through modifications and improvements. This unique ability distinguishes humans from related primates, who do not seem to build collaborative knowledge over time. Instead, primates seem to build individual knowledge, in which the expertise of one animal is not built on by others, and does not progress across time.

Human cultural learning involves:
Cultural learning is made possible by a deep understanding of social cognition. Humans have the unique capacity to identify and relate to others and view them as intentional beings. Humans are able to understand that others have intentions, goals, desires, and beliefs. It is this deep understanding, this cognitive adaptation, that allows humans to learn from and with others through cultural transmission (Tomasello, 1999).

Primates show distinct characteristics of social cognition in comparison to mammals. Mammals are able to identify members of their species, understand basic kinships and basic social hierarchies, make predictions about others’ behavior based on emotion and movement, and engage in social learning (Tomasello, 1999). Primates, however, show a more extensive understanding of these concepts. Primates not only understand kinship and social hierarchies, but they also have an understanding of relational categories. That is, primates are able to understand social relations that extend beyond their individual interaction with others. Mammals are able to form direct relationships based on social hierarchies, but primates have an understanding of social hierarchies and relationships that extend beyond them personally. Researchers believe that this understanding of relational categories might have been the evolutionary precursor to humans’ deeper understanding of desires, beliefs, and goals underlying causal relationships, and thereby allowing humans to relate to and understand other individuals, making way for cultural evolution (Tomasello, 1999).

Although it is now believed that non-human primates such as chimpanzees have some limited understanding of others as intentional beings, it is clear that these understanding are not as deep as human understanding of others as intentional agents. Chimpanzees, for example, demonstrated an ability to think about what others see, and predict behavior based on these beliefs in several studies conducted by Tomasello and Hare (2003). For example, subordinate chimpanzees in one experiment avoided food that they knew the dominant chimpanzee could see, but sought food that the dominant chimpanzee could not see due to a physical barrier. In another experiment, subordinate chimpanzees made decisions about approaching food based on whether or not the dominant chimpanzee had seen the human researcher place the food behind the barrier. Chimpanzees were also found to react differently to humans who were unwilling versus unable to provide food (teasing the chimpanzee with food, or pretending to have an accident with it), thereby showing some ability to discriminate intentionality.

Dogs have also shown some interesting but limited abilities at social cognition in a series of studies by Hare and Tomasello (2005). Dogs have the ability to read human social cues, even to a greater extent than chimpanzees. Dogs are able to respond to human pointing, the human gaze, and subtle human nods without training. Researchers now believe that these abilities are the result of convergent evolution between humans and dogs through domestication. Research with domesticated foxes has shown that the likely mechanism for this convergent evolution was the selection of tame behavior in dogs. This finding suggests that perhaps humans had to evolve a propensity to cooperate before cultural evolution was able to take place (Hare & Tomasello, 2005).

Sociogenesis refers to collaborative inventiveness. It is the process by which two or more humans collectively interact and invent something new which could not have been developed by one individual alone, such as language and mathematics (Tomasello, 1999). Sociogenesis can occur across time, or simultaneously (Tomasello, 1999). Socigenesis across times occurs through the ratchet effect, when one individual modifies something they had previously learned through others. Over time, ideas, tools, and language advance. Simultaneous sociogenesis occurs when two or more individuals work together at the same time and develop something new.

In response to the nature versus nurture and learned versus innate debate, proponents of cultural evolution argue that cognitive psychology must take into account historical processes when studying and discussion cognition (Tomasello, 1999). For example, the similarities between languages have led many researchers to decry that language or aspects of language must be innate. The extreme variability in math and counting systems across cultures has prevented similar conclusions for math. However, Tomasello argues that if you look at these concepts with historical processes in mind, another plausible explanation could be that language, but not math, developed before people split into different populations. Math developed only after such split, and because the cultural needs of these people differed, differential counting and mathematical systems resulted. The critique is that categorizing concepts as innate or learned does not tell us anything about the process by which they originally developed.

 Hare, B., & Tomasello, M. (2005). Human-like social skills in dogs? Trends in Cognitive Sciences, Vol. 9 (9), 439-444.


</doc>
<doc id="12401182" url="https://en.wikipedia.org/wiki?curid=12401182" title="Design theory">
Design theory

Design theory is a subfield of design research concerned With 
various theoretical approaches towards understanding and delineating design principles, design knowledge, and design practice.

Design theory has been approached and interpreted in many ways, from personal statements of design principles, through constructs of the philosophy of design to a search for a design science.

The essay "Ornament and Crime" by Adolf Loos from 1908 is one of the early 'principles' design-theoretical texts. Others include Le Corbusier's "Vers une architecture", and Victor Papanek's "Design for the real world" (1972).

In a 'principles' approach to design theory, the De Stijl movement promoted a geometrical abstract, "ascetic" form of purism that was limited to functionality. This modernist attitude underpinned the Bauhaus movement. Principles were drawn up for design that were applicable to all areas of modern aesthetics.

For an introduction to the philosophy of design see the article by Per Galle at the Royal Danish Academy.

An example of early design science was Altshuller's "Theory of inventive problem solving", known as TRIZ, from Russia in the 1940s. Herbert Simon's 1969 "The sciences of the artificial" began a more scientific basis to the study of design. Since then the further development of fields such as design methods, design research, design science and design thinking has promoted a wider understanding of design theory.





</doc>
<doc id="32017750" url="https://en.wikipedia.org/wiki?curid=32017750" title="Languaculture">
Languaculture

Languaculture is a term meaning that a language includes not only elements such as grammar and vocabulary, but also past knowledge, local and cultural information, habits and behaviours. The term was created by the American anthropologist Michael Agar.

Agar used the term "languaculture" for the first time in his essay "Language Shock: Understanding the culture of conversation". Languaculture is an adjustment of the term "linguaculture", suggested by the American linguistic anthropologist Paul Friedrich. Agar explains the vowel change stating that language is a more commonly used word.

When Agar talks about languaculture, he defines it as the necessary tie between language and culture. He underlines that languages and cultures are always closely related and it is not possible to distinguish languages from cultures. Therefore, you cannot really know a language if you do not know also the culture expressed by that language.

The notion of culture and its understanding involve the link between two different languacultures that Agar define LC1 (source languaculture) and LC2 (target languaculture).

The learning of target languaculture is driven by "rich points". We realize that a culture is different from ours when we face some behaviours which we do not understand. Rich points are those surprises, those departures from an outsider’s expectations that signal a difference between source languaculture and target languaculture. They are the moments of incomprehension, when you suddenly do not know what is happening. In this situation different reactions are possible. You can ignore the rich point and hope that the next part makes sense. You can perceive it as evidence that the person who produced it has some lacks. Or you can wonder why you do not understand and if maybe some other languaculture comes into play. Therefore, rich points belong to daily life and not only to language. Agar highlights that the term "rich" has the positive connotations of thickness, wealth and abundance. The largest rich point is the total incomprehension due to huge differences between source languaculture and target languaculture. In this case we are facing a ‘culture shock’ that causes a deep bewilderment. The smallest rich point can occur among different groups of the same community.
The existence of rich points comes from the fact that every statement implicitly refers to various elements that are taken for granted in a certain culture and do not match the elements of another culture (cultural implicitness).

According to Agar, culture is a construction, a translation between source languaculture and target languaculture. Like a translation, it makes no sense to talk about the culture of X without saying the culture of X for Y, taking into account the standpoint from which it is observed. For this reason culture is relational.
Moreover, culture is always plural. No person or group can be described, explained or generalized completely with a single cultural label.



</doc>
<doc id="1525258" url="https://en.wikipedia.org/wiki?curid=1525258" title="Highbrow">
Highbrow

Used colloquially as a noun or adjective, "highbrow" is synonymous with intellectual; as an adjective, it also means elite, and generally carries a connotation of high culture. The word draws its metonymy from the pseudoscience of phrenology, and was originally simply a physical descriptor.

"Highbrow" can be applied to music, implying most of the classical music tradition; to literature—i.e., literary fiction and poetry; to films in the arthouse line; and to comedy that requires significant understanding of analogies or references to appreciate. The term "highbrow" is considered by some (with corresponding labels as 'middlebrow' 'lowbrow') as discriminatory or overly selective; and "highbrow" is currently distanced from the writer by quotation marks: "We thus focus on the consumption of two generally recognised 'highbrow' genres—opera and classical". The first usage in print of "highbrow" was recorded in 1884. The term was popularized in 1902 by Will Irvin, a reporter for "The Sun" who adhered to the phrenological notion of more intelligent people having high foreheads.

The opposite of "highbrow" is "lowbrow", and between them is "middlebrow", describing culture that is neither high nor low; as a usage, "middlebrow" is derogatory, as in Virginia Woolf's unsent letter to the "New Statesman", written in the 1930s and published in "The Death of the Moth and Other Essays" (1942). According to the "Oxford English Dictionary", the word "middlebrow" first appeared in print in 1925, in "Punch": "The BBC claims to have discovered a new type—'the middlebrow'. It consists of people who are hoping that some day they will get used to the stuff that they ought to like". The term had previously appeared in hyphenated form in 1912:
It was popularized by the American writer and poet Margaret Widdemer, whose essay "Message and Middlebrow" appeared in the "Review of Literature" in 1933. The three genres of fiction, as American readers approached them in the 1950s and as obscenity law differentially judged them, are the subject of Ruth Pirsig Wood, "Lolita in Peyton Place: Highbrow, Middlebrow, and Lowbrow Novels", 1995.

Prince Hamlet was considered by Virginia Woolf as a highbrow lacking orientation in the world once he had lost the lowbrow Ophelia with her grip on earthly realities: this, she thought, explained why in general highbrows "honour so wholeheartedly and depend so completely upon those who are called lowbrows".




</doc>
<doc id="47917953" url="https://en.wikipedia.org/wiki?curid=47917953" title="Ceremonial pole">
Ceremonial pole

A ceremonial pole symbolizes a variety of concepts in several different cultures. For example, in the Miao culture in Yunnan China. In "The Evolution of the Idea of God", Grant Allen notes that Samoyeds of Siberia, and Damara of South Africa plant stakes at the graves of ancestors. According to Zelia Nuttall in "The Fundamental Principles Of Old and New World Civilizations", tree and pole reverence to Anu in ancient Babylonia-Assyria may have evolved from the fire-drill and beam of the oil press, stating that it was extremely probable that the primitive employment of a fire-stick by the priesthood, for the production of "celestial fire," may have played an important role in causing the stick, and thence the pole and tree, to become the symbol of Anu.

"Kay Htoe Boe" is a Karenni ancient dance and prayer festival, held by the men in the Kayan community in Myanmar (Burma). In the Kayan creation story, the Eugenia tree is the first tree in the world. Kay Htoe Boe poles are usually made from the Eugenia tree.

"Kay Htoe Boe" poles have four levels, named for the stars, sun and moon, and the fourth level is a ladder made with a long white cotton cloth.

A "jangseung" or "village guardian" is a Korean ceremonial pole, usually made of wood. Jangseungs were traditionally placed at the edges of villages to mark for village boundaries and frighten away demons. They were also worshipped as village tutelary deities.

An Asherah pole is a sacred tree or pole that stood near Canaanite religious locations to honor the Ugaritic mother-goddess Asherah, consort of El. The relation of the literary references to an "asherah" and archaeological finds of Judaean pillar-figurines has engendered a literature of debate.

The "asherim" were also cult objects related to the worship of the fertility goddess Asherah, the consort of either Ba'al or, as inscriptions from Kuntillet ‘Ajrud and Khirbet el-Qom attest, Yahweh, and thus objects of contention among competing cults. The insertion of "pole" begs the question by setting up unwarranted expectations for such a wooden object: "we are never told exactly what it was", observes John Day. Though there was certainly a movement against goddess-worship at the Jerusalem Temple in the time of King Josiah, it did not long survive his reign, as the following four kings "did what was evil in the eyes of Yahweh" (2 Kings 23:32, 37; 24:9, 19). Further exhortations came from Jeremiah. The traditional interpretation of the Biblical text is that the Israelites imported pagan elements such as the Asherah poles from the surrounding Canaanites. In light of archeological finds, however, modern scholars now theorize that the Israelite folk religion was Canaanite in its inception and always polytheistic, and it was the prophets and priests who denounced the Asherah poles who were the innovators; such theories inspire ongoing debate.

In present times in Indian subcontinent several festivals and celebrations, as in Hinglajmata Sindh, Gudi Padwa, KathiKawadi, Jatarakathi, Nandidhwaja, Khambadev (Maharashtra), Nimad (Madhya Pradesh), Gogaji temple (Rajasthan) and Khambeshvari (Odisha) then in Tripura and in Manipur, central poles are features in temple and festival settings.

According to Adi Parva (critical edition) of Indian epic Mahabharata a Bamboo festival named "Shakrotsava" was Celebrated in Chedi Kingdom. Uparichara Vasu was a king of Chedi belonging to the Puru dynasty. He was known as the friend of Indra. During his reign, Chedi kingdom introduced "Shakrotsava" festival in his kingdom in the honor of Indra. The festival involved planting of a bamboo pole every year, in honor of Indra. The king will then pray for the expansion of his cities and kingdom. After erecting the pole, people decked it with golden cloth and scents and garlands and various ornaments. (1,63).

A maypole is a tall wooden pole erected as a part of various European folk festivals, around which a maypole dance often takes place.

The festivals may occur on May Day or Pentecost (Whitsun), although in some countries it is instead erected at Midsummer. In some cases the maypole is a permanent feature that is only utilised during the festival, although in other cases it is erected specifically for the purpose before being taken down again.

Primarily found within the nations of Germanic Europe and the neighbouring areas which they have influenced, its origins remain unknown, although it has been speculated that it originally had some importance in the Germanic paganism of Iron Age and early Medieval cultures, and that the tradition survived Christianisation, albeit losing any original meaning that it had. It has been a recorded practice in many parts of Europe throughout the Medieval and Early Modern periods, although became less popular in the 18th and 19th centuries. Today, the tradition is still observed in some parts of Europe and among European communities in North America.

The fact that they were found primarily in areas of Germanic Europe, where, prior to Christianisation, Germanic paganism was followed in various forms, has led to speculation that the maypoles were in some way a continuation of a Germanic pagan tradition. One theory holds that they were a remnant of the Germanic reverence for sacred trees, as there is evidence for various sacred trees and wooden pillars that were venerated by the pagans across much of Germanic Europe, including Thor's Oak and the Irminsul. It is also known that, in Norse paganism, cosmological views held that the universe was a world tree, known as Yggdrasil.

The floor of the Mære Church, Norway, was excavated in 1969 and found to contain the remains of a pagan cult structure. The nature of that structure was not clear. Lidén felt this represented the remains of a building, but a critique by Olsen (1969:26) in the same work suggested this may have been a site for pole-related rituals. A recent review of the evidence by Walaker (Norddide 2011: 107-113) concluded that this site was similar to the site in Hove (Åsen, also in Nord-Trøndelag) and was therefore likely the site of a ceremonial pole.

In Māori mythology, Rongo – the god of cultivated food, especially the kūmara, a vital food crop – is represented by a god stick called "whakapakoko atua".

In the Cook Islands Cult figures called staff-gods or "atua rakau" from Rarotonga, apparently combine images of gods with their human descendants. They range in length between 28 inches (71 cm) and 18 feet (5.5 m) and were carried and displayed horizontally.



</doc>
<doc id="203808" url="https://en.wikipedia.org/wiki?curid=203808" title="Meme pool">
Meme pool

A meme pool is the sum total of all memes (transmittable units of cultural ideas, practices, symbols) present in a given human population. The term is analogous to gene pool. The meme pool is in essence the matrix of the whole of the culture of a population. Because the memes of instruction of production of material culture are included, then the entire culture, including material culture and interactions between individuals is determined by information held within the meme pool. The state of a meme pool determines what sort of memes will be reproductive, and in this way it may be thought of as the meme-logical environment. 

Examples of meme pools may include large Internet communities such as imageboards, online forums, and wikis. More tangibly, large shopping malls, schools, and other social institutions may be included in the definition of a meme pool.

The term was coined by Richard Dawkins in The Selfish Gene. 


</doc>
<doc id="167703" url="https://en.wikipedia.org/wiki?curid=167703" title="Empowerment">
Empowerment

The term empowerment refers to measures designed to increase the degree of autonomy and self-determination in people and in communities in order to enable them to represent their interests in a responsible and self-determined way, acting on their own authority. It is the process of becoming stronger and more confident, especially in controlling one's life and claiming one's rights. Empowerment as action refers both to the process of self-empowerment and to professional support of people, which enables them to overcome their sense of powerlessness and lack of influence, and to recognize and use their resources. To do work with power.

The term empowerment originates from American community psychology and is associated with the social scientist Julian Rappaport (1981). However, the roots of empowerment theory extend further into history and are linked to Marxist sociological theory. These sociological ideas have continued to be developed and refined through Neo-Marxist Theory (also known as Critical Theory).

In social work, empowerment forms a practical approach of resource-oriented intervention. In the field of citizenship education and democratic education, empowerment is seen as a tool to increase the responsibility of the citizen. Empowerment is a key concept in the discourse on promoting civic engagement. Empowerment as a concept, which is characterized by a move away from a deficit-oriented towards a more strength-oriented perception, can increasingly be found in management concepts, as well as in the areas of continuing education and self-help.

Robert Adams points to the limitations of any single definition of 'empowerment', and the danger that academic or specialist definitions might take away the word and the connected practices from the very people they are supposed to belong to. Still, he offers a minimal definition of the term: 
'Empowerment: the capacity of individuals, groups and/or communities to take control of their circumstances, exercise power and achieve their own goals, and the process by which, individually and collectively, they are able to help themselves and others to maximize the quality of their lives.'

One definition for the term is "an intentional, ongoing process centered in the local community, involving mutual respect, critical reflection, caring, and group participation, through which people lacking an equal share of resources gain greater access to and control over those resources".

Rappaport's (1984) definition includes: "Empowerment is viewed as a process: the mechanism by which people, organizations, and communities gain mastery over their lives."

Sociological empowerment often addresses members of groups that social discrimination processes have excluded from decision-making processes through – for example – discrimination based on disability, race, ethnicity, religion, or gender. Empowerment as a methodology is also associated with feminism.

Empowerment is the process of obtaining basic opportunities for marginalized people, either directly by those people, or through the help of non-marginalized others who share their own access to these opportunities. It also includes actively thwarting attempts to deny those opportunities. Empowerment also includes encouraging, and developing the skills for, self-sufficiency, with a focus on eliminating the future need for charity or welfare in the individuals of the group. This process can be difficult to start and to implement effectively.

One empowerment strategy is to assist marginalized people to create their own nonprofit organization, using the rationale that only the marginalized people, themselves, can know what their own people need most, and that control of the organization by outsiders can actually help to further entrench marginalization. Charitable organizations lead from outside of the community, for example, can disempower the community by entrenching a dependence charity or welfare. A nonprofit organization can target strategies that cause structural changes, reducing the need for ongoing dependence. Red Cross, for example, can focus on improving the health of indigenous people, but does not have authority in its charter to install water-delivery and purification systems, even though the lack of such a system profoundly, directly and negatively impacts health. A nonprofit composed of the indigenous people, however, could ensure their own organization does have such authority and could set their own agendas, make their own plans, seek the needed resources, do as much of the work as they can, and take responsibility – and credit – for the success of their projects (or the consequences, should they fail).

The process of which enables individuals/groups to fully access personal or collective power, authority and influence, and to employ that strength when engaging with other people, institutions or society. In other words, "Empowerment is not giving people power, people already have plenty of power, in the wealth of their knowledge and motivation, to do their jobs magnificently. We define empowerment as letting this power out." It encourages people to gain the skills and knowledge that will allow them to overcome obstacles in life or work environment and ultimately, help them develop within themselves or in the society.

To empower a female "...sounds as though we are dismissing or ignoring males, but the truth is, both genders desperately need to be equally empowered." Empowerment occurs through improvement of conditions, standards, events, and a global perspective of life.

Before there can be the finding that a particular group requires empowerment and that therefore their self-esteem needs to be consolidated on the basis of awareness of their strengths, there needs to be a deficit diagnosis usually carried out by experts assessing the problems of this group. The fundamental asymmetry of the relationship between experts and clients is usually not questioned by empowerment processes. It also needs to be regarded critically, in how far the empowerment approach is really applicable to all patients/clients. It is particularly questionable whether mentally ill people in acute crisis situations are in a position to make their own decisions. According to Albert Lenz, people behave primarily regressive in acute crisis situations and tend to leave the responsibility to professionals. It must be assumed, therefore, that the implementation of the empowerment concept requires a minimum level of communication and reflectivity of the persons involved.

In social work, empowerment offers an approach that allows social workers to increase the capacity for self-help of their clients. For example, this allows clients not to be seen as passive, helpless 'victims' to be rescued but instead as a self-empowered person fighting abuse/ oppression; a fight, in which the social worker takes the position of a facilitator, instead of the position of a 'rescuer'.

Marginalized people who lack self-sufficiency become, at a minimum, dependent on charity, or welfare. They lose their self-confidence because they cannot be fully self-supporting. The opportunities denied them also deprive them of the pride of accomplishment which others, who have those opportunities, can develop for themselves. This in turn can lead to psychological, social and even mental health problems. "Marginalized" here refers to the overt or covert trends within societies whereby those perceived as lacking desirable traits or deviating from the group norms tend to be excluded by wider society and ostracized as undesirables.

As a concept, and model of practice, empowerment is also used in health promotion research and practice.
The key principle is for individuals to gain increased control over factors that influence their health status . 

To empower individuals and to obtain more equity in health, it is also important to address health-related behaviors . 

Studies suggest that health promotion interventions aiming at empowering adolescents should enable active learning activities, use visualizing tools to facilitate self-reflection, and allow the adolescents to influence intervention activities .

According to Robert Adams, there is a long tradition in the UK and the USA respectively to advance forms of self-help that have developed and contributed to more recent concepts of empowerment. For example, the free enterprise economic theories of Milton Friedman embraced self-help as a respectable contributor to the economy. Both the Republicans in the US and the Conservative government of Margaret Thatcher built on these theories. 'At the same time, the mutual aid aspects of the concept of self-help retained some currency with socialists and democrats.'

In economic development, the empowerment approach focuses on mobilizing the self-help efforts of the poor, rather than providing them with social welfare. Economic empowerment is also the empowering of previously disadvantaged sections of the population, for example, in many previously colonized African countries.

The World Pensions Council (WPC) has argued that large institutional investors such as pension funds and endowments are exercising a greater influence on the process of adding and replacing corporate directors – as they are themselves steered to do so by their own board members (pension trustees).

This could eventually put more pressure on the CEOs of publicly listed companies, as “more than ever before, many [North American], UK and European Union pension trustees speak enthusiastically about flexing their fiduciary muscles for the UN’s Sustainable Development Goals”, and other ESG-centric investment practices 

Legal empowerment happens when marginalised people or groups use the legal mobilisation i.e., law, legal systems and justice mechanisms to improve or transform their social, political or economic situations. Legal empowerment approaches are interested in understanding how they can use the law to advance interests and priorities of the marginalised.

According to 'Open society foundations' (an NGO) "Legal empowerment is about strengthening the capacity of all people to exercise their rights, either as individuals or as members of a community. Legal empowerment is about grass root justice, about ensuring that law is not confined to books or courtrooms, but rather is available and meaningful to ordinary people.

Lorenzo Cotula in his book ' "Legal Empowerment for Local Resource Control" ' outlines the fact that legal tools for securing local resource rights are enshrined in legal system, does not necessarily mean that local resource users are in position to use them and benefit from them. The state legal system is constrained by a range of different factors – from lack of resources to cultural issues. Among these factors economic, geographic, linguistic and other constraints on access to courts, "lack of legal awareness as well as legal assistance " tend to be recurrent problems.

In many context, marginalised groups do not trust the legal system owing to the widespread manipulation that it has historically been subjected to by the more powerful. 'To what extent one knows the law, and make it work for themselves with 'para legal tools', is legal empowerment; assisted utilizing innovative approaches like legal literacy and awareness training, broadcasting legal information, conducting participatory legal discourses, supporting local resource user in negotiating with other agencies and stake holders and to strategies combining use of legal processes with advocacy along with media engagement, and socio legal mobilisation.

Sometimes groups are marginalized by society at large, with governments participating in the process of marginalization. Equal opportunity laws which actively oppose such marginalization, are supposed to allow empowerment to occur. These laws made it illegal to restrict access to schools and public places based on race. They can also be seen as a symptom of minorities' and women's empowerment through lobbying.

Gender empowerment conventionally refers to the empowerment of women, which is a significant topic of discussion in regards to development and economics nowadays. It also points to approaches regarding other marginalized genders in a particular political or social context. This approach to empowerment is partly informed by feminism and employed legal empowerment by building on international human rights. Empowerment is one of the main procedural concerns when addressing human rights and development. The Human Development and Capabilities Approach, The Millennium Development Goals, and other credible approaches/goals point to empowerment and participation as a necessary step if a country is to overcome the obstacles associated with poverty and development. The UN Sustainable Development Goals targets gender equality and women's empowerment for the global development agenda.

According to Thomas A. Potterfield, many organizational theorists and practitioners regard employee empowerment as one of the most important and popular management concepts of our time.

Ciulla discusses an inverse case: that of bogus empowerment.

In the sphere of management and organizational theory, "empowerment" often refers loosely to processes for giving subordinates (or workers generally) greater discretion and resources: distributing control in order to better serve both customers and the interests of employing organizations.

One account of the history of workplace empowerment in the United States recalls the clash of management styles in railroad construction in the American West in the mid-19th century, where "traditional" hierarchical East-Coast models of control encountered individualistic pioneer workers, strongly supplemented by methods of efficiency-oriented "worker responsibility" brought to the scene by Chinese laborers. In this case, empowerment at the level of work teams or brigades achieved a notable (but short-lived) demonstrated superiority. See the views of Robert L. Webb.

Since the 1980s and 1990s, empowerment has become a point of interest in management concepts and business administration. In this context, empowerment involves approaches that promise greater participation and integration to the employee in order to cope with their tasks as independently as possible and responsibly can. A strength-based approach known as "empowerment circle" has become an instrument of organizational development. Multidisciplinary empowerment teams aim for the development of quality circles to improve the organizational culture, strengthening the motivation and the skills of employees. The target of subjective job satisfaction of employees is pursued through flat hierarchies, participation in decisions, opening of creative effort, a positive, appreciative team culture, self-evaluation, taking responsibility (for results), more self-determination and constant further learning. The optimal use of existing potential and abilities can supposedly be better reached by satisfied and active workers. Here, knowledge management contributes significantly to implement employee participation as a guiding principle, for example through the creation of communities of practice.

However, it is important to ensure that the individual employee has the skills to meet their allocated responsibilities and that the company's structure sets up the right incentives for employees to reward their taking responsibilities. Otherwise there is a danger of being overwhelmed or even becoming lethargic.

Empowerment of employees requires a culture of trust in the organization and an appropriate information and communication system. The aim of these activities is to save control costs, that become redundant when employees act independently and in a self-motivated fashion. 
In the book "Empowerment Takes More Than a Minute", the authors illustrate three keys that organizations can use to open the knowledge, experience, and motivation power that people already have. The three keys that managers must use to empower their employees are:

According to Stewart, in order to guarantee a successful work environment, managers need to exercise the "right kind of authority" (p. 6). To summarize, "empowerment is simply the effective use of a manager’s authority", and subsequently, it is a productive way to maximize all-around work efficiency.

These keys are hard to put into place and it is a journey to achieve empowerment in a workplace. It is important to train employees and make sure they have trust in what empowerment will bring to a company.

The implementation of the concept of empowerment in management has also been criticised for failing to live up to its claims.

Marshall McLuhan insisted that the development of electronic media would eventually weaken the hierarchical structures that underpin central governments, large corporation, academia and, more generally, rigid, “linear-Cartesian” forms of social organization. 
From that perspective, new, “electronic forms of awareness” driven by information technology would empower citizen, employees and students by disseminating in near-real-time vast amounts of information once reserved to a small number of experts and specialists. Citizens would be bound to ask for substantially more say in the management of government affairs, production, consumption, and education 

World Pensions Council (WPC) economist Nicolas Firzli has argued that rapidly rising cultural tides, notably new forms of online engagement and increased demands for ESG-driven public policies and managerial decisions are transforming the way governments and corporation interact with citizen-consumers in the “Age of Empowerment” 



</doc>
<doc id="49124863" url="https://en.wikipedia.org/wiki?curid=49124863" title="Ritualcide">
Ritualcide

Ritualcide is the systematic destruction or alteration of traditional ritual practices and their sequencing. Rituals have a prescribed form, source, and sequence that include sacred objects, places, times and seasons, music, dance, texts, songs and words, and mediators (such as monks, spirit mediums, religious leaders, and traditional healers). Ritualcide is not necessarily linked to genocide, but "genocidal priming" may gain a handhold when regimes tamper with collective tradition and leave inhabitants vulnerable and/or susceptible to spirit-based harm and angst. Herein ancestral pathways for intimate connection are often disrupted.

The term "ritualcide" was coined by Peg LeVine in "Love and Dread in Cambodia: Weddings, Births and Ritual Harm Under the Khmer Rouge," which emerged from an eight-year ethnographic study into "Khmer Rouge weddings" and Cambodian ritual history before, during and after Democratic Kampuchea. The definition was expanded in 2015 when LeVine continued research at the Shoah Foundation, Center for Advanced Genocide Research. In October, 2016, ritualcide was introduced at the Extraordinary Chambers in the Courts of Cambodia (ECCC) in conjunction with Khmer Rouge activity between 1975 and 1979; when LeVine gave expert witness, she suggested it was a "crime against culture". She has shown how ritual loss complicates the aftermath of trauma for the living and the dead, and ruptures the cosmological order that binds ancestors. Also, without access to reliable, traditional ritual sources, collective fear and vulnerability increase for survivors. In genocide and Holocaust studies, ritual restoration holds relevance for recovery by survivors and ancestors, and their collective sense of protection and cultural continuity.


</doc>
<doc id="50693529" url="https://en.wikipedia.org/wiki?curid=50693529" title="Critical consumerism">
Critical consumerism

Critical consumption is the conscious choice of buying or not buying a specific product according to ethical and political beliefs. The critical consumer recognizes the importance of considering some characteristics of the product and its realization, such as environmental sustainability and respect of workers’ rights. Indeed, critical consumers take full responsibility for the environmental, social and political effects of their choices. The critical consumer can sympathize with certain social movement goals and contributes towards them through modifying their consumption behavior.

Work on critical consumption has differed in the terms used to refer to boycotting and buycotting actions. The more prominent include ethical consumption and political consumerism, while sustainable consumption, more linked with policy, has also increased in usage.

Often consumer and citizen are considered as different because consumers only show self-interest, whereas citizens denote expanded self-interest. The general idea is that, consumers ‘buy what they want—or what they have been persuaded to want—within the limits of what they can get. Citizenship, on the other hand, carries duties or responsibilities along with various rights. Since consumers are seen also as citizens they have to behave in a community-oriented, moral and political way, rather than as a self-interested one.

A specificity of critical consumption is the political use of consumption, which is the consumers’ choice of “"producers and products with the aim of changing ethically or politically objectionable institutional or market practices"”. Their choices depend on different factors as non economic issues that concern personal and family well-being, issue of fairness, justice, ethical or political assessment. Main forms and tools of political use of consumption are boycotting, "buycotting" (anti-boycotting) and also culture jamming or adbusting.

Political consumerism can be considered as an alternative form of political engagement, especially for young generations. In addition, market-based political strategies of young citizens go beyond boycotting and “buycotting”; they also started to participate in internet campaigns becoming active consumers. Their individual choices become political movements able to challenge political and economic powers. Therefore, as a political actor, the consumer “is seen as directly responsible not only for him or herself but also for the world”. The phenomenon of political consumerism takes into account social transformations like globalization, the ever-increasing role of the market and individualization.

Studies from the UK (Harrison et al. 2005, Varul and Wilson-Kovacs 2008, Zaccai 2007), Germany (Baringhorst et al. 2007; Lamla and Neckel 2006), Italy (Forno 2006, Tosi 2006, Sassatelli 2010), France (Chessel and Cochoy 2004, Dubuisson-Queller 2009), North America (Johnston et al. 2011, Johnston and Bauman 2009, Johnston 2008) and Scandinavia (Micheletti et al. 2004) argued that consumes are becoming increasingly politicized according to the boycott and buycott principles. In particular, Scandinavian people seems to be more committed in political consumerism, for example Sweden increased his average of boycotting episodes from 15 percent in 1987 to 29 percent in 1997.

Nevertheless, it is important to consider that even if a growing number of citizens are turning to the market to express their political and moral concerns, it is difficult to assess whether political consumerism can also be considered as a meaningful or effective form of political participation.

The chase for a fair consumption has deep roots in consumption history, starting for example with the American Revolution. Sympathizers of the American cause, in those years, refused to buy English goods, to support colons rebellion. This act of conscious choice can be seen as the beginning of both critical and political consumption. Traces of these two concepts can be found at the turn of the nineteenth century, in the United States, where the National Consumer League promoted the so-called “Whitelists”, in which all the companies that treated fairly their employees were listed.

At the end of the century, also the first forms of political activism in consumption took place in the United States and Europe, like the “Dont Buy Jewish” boycotts. Several organizations were born in those times and in the following centuries, asking the consumers to join the mobilizations as active subjects.

A variety of discourses about the “duty” and the “responsibilities” of social actors arose after the 1999 World Trade Organization protests in Seattle. People were explicitly asked to think that to shop is to vote.

Boycotting and "buycotting" (Anti-boycott), as a particularly self-conscious form of consumption, are expressions of an individual’s political, ethical or environmental stance. Both boycotting and "buycotting" are discrete acts of critical consumption and they are mutually contingent. In fact, if the use-value or utility of a product is important, then it is difficult to view them as separate actions.

Boycotting refers to abstaining from buying, avoiding specific products or brands to punish companies for undesirable policies or business practices. "Buycotting" is a term coined by Friedman (1996); it refers to “positive buying” that aims to foster corporations that represent values – fair trade, environmentalism, sustainable development – that consumers choose to support.

When one boycotts a product or service, it does not mean that he abstains from consuming at all, but that he may select an alternative product or service. Equally, a choice to "buycott" could be understood as including a rejection or boycott of the non-ethical alternative. This interdependence is useful to explain the traditional pairing of boycotting and "buycotting" in much analysis of consumer politics.

One of the rising types of boycotting is the ad hoc one, which underlines the importance of consumers as political subjects. These initiatives show that critical consumption is really impacting in special occasions, gaining much more visibility than everyday boycotts. An example of this type of events is the Buy Nothing Day (BND).

The notion of sustainability has both a temporal dimension demonstrated by the trade-off between present and future generations, and a justice dimension which considers the different distribution of harm and benefit. Under the term sustainability, notions of sustainable resource consumption by recycling, environmental protection, animal welfare, social justice, and climate responsibilities are gathered.

Although the "good" purposes of critical consumerism there are some critics and pitfalls connected to this practice of consumption: 


There are many examples of critical consumerism:





</doc>
<doc id="50951733" url="https://en.wikipedia.org/wiki?curid=50951733" title="Human interactions with microbes">
Human interactions with microbes

Human interactions with microbes include both practical and symbolic uses of microbes, and negative interactions in the form of human, domestic animal, and crop diseases.

Practical use of microbes began in ancient times with fermentation in food processing; bread, beer and wine have been produced by yeasts from the dawn of civilisation, such as in ancient Egypt. More recently, microbes have been used in activities from biological warfare to the production of chemicals by fermentation, as industrial chemists discover how to manufacture a widening variety of organic chemicals including enzymes and bioactive molecules such as hormones and competitive inhibitors for use as medicines. Fermentation is used, too, to produce substitutes for fossil fuels in forms such as ethanol and methane; fuels may also be produced by algae. Anaerobic microorganisms are important in sewage treatment. In scientific research, yeasts and the bacterium "Escherichia coli" serve as model organisms especially in genetics and related fields.

On the symbolic side, an early poem about brewing is the Sumerian "Hymn to Ninkasi", from 1800 BC. In the Middle Ages, Giovanni Boccaccio's "The Decameron" and Geoffrey Chaucer's "The Canterbury Tales": addressed people's fear of deadly contagion and the moral decline that could result. Novelists have exploited the apocalyptic possibilities of pandemics from Mary Shelley's 1826 "The Last Man" and Jack London's 1912 "The Scarlet Plague" onwards. Hilaire Belloc wrote a humorous poem to "The Microbe" in 1912. Dramatic plagues and mass infection have formed the story lines of many Hollywood films, starting with "Nosferatu" in 1922. In 1971, "The Andromeda Strain" told the tale of an extraterrestrial microbe threatening life on Earth. Microbiologists since Alexander Fleming have used coloured or fluorescing colonies of bacteria to create miniature artworks.

Microorganisms such as bacteria and viruses are important as pathogens, causing disease to humans, crop plants, and domestic animals. 

Culture consists of the social behaviour and norms found in human societies and transmitted through social learning. Cultural universals in all human societies include expressive forms like art, music, dance, ritual, religion, and technologies like tool usage, cooking, shelter, and clothing. The concept of material culture covers physical expressions such as technology, architecture and art, whereas immaterial culture includes principles of social organization, mythology, philosophy, literature, and science. This article describes the roles played by microorganisms in human culture.

Since microbes were not known until the Early Modern period, they appear in earlier literature indirectly, through descriptions of baking and brewing. Only with the invention of the microscope, as used by Robert Hooke in his 1665 book "Micrographia", and by Antonie Van Leeuwenhoek in the 1670s, the germ theory of disease, and progress in microbiology in the 19th century were microbes observed directly, identified as living organisms, and put to use on a scientific basis. The same knowledge also allowed microbes to appear explicitly in literature and the arts.

Controlled fermentation with microbes in brewing, wine making, baking, pickling and cultured dairy products such as yogurt and cheese, is used to modify ingredients to make foods with desirable properties. The principal microbes involved are yeasts, in the case of beer, wine, and ordinary bread; and bacteria, in the case of anaerobically fermented vegetables, dairy products, and sourdough bread. The cultures variously provide flavour and aroma, inhibit pathogens, increase digestibility and palatability, make bread rise, reduce cooking time, and create useful products including alcohol, organic acids, vitamins, amino acids, and carbon dioxide. Safety is maintained with the help of food microbiology.

Oxidative sewage treatment processes rely on microorganisms to oxidise organic constituents. Anaerobic microorganisms reduce sludge solids producing methane gas and a sterile mineralised residue. In potable water treatment, one method, the slow sand filter, employs a complex gelatinous layer composed of a wide range of microorganisms to remove both dissolved and particulate material from raw water.

Microorganisms are used in fermentation to produce ethanol, and in biogas reactors to produce methane. Scientists are researching the use of algae to produce liquid fuels, and bacteria to convert various forms of agricultural and urban waste into usable fuels.

Microorganisms are used for many commercial and industrial purposes, including the production of chemicals, enzymes and other bioactive molecules, often through protein engineering. For example, acetic acid is produced by the bacterium "Acetobacter aceti", while citric acid is produced by the fungus "Aspergillus niger". Microorganisms are used to prepare a widening range of bioactive molecules and enzymes. For example, Streptokinase produced by the bacterium "Streptococcus" and modified by genetic engineering is used to remove clots from the blood vessels of patients who have suffered a heart attack. Cyclosporin A is an immunosuppressive agent in organ transplantation, while statins produced by the yeast "Monascus purpureus" serve as blood cholesterol lowering agents, competitively inhibiting the enzyme that synthesizes cholesterol.

Microorganisms are essential tools in biotechnology, biochemistry, genetics, and molecular biology. The yeasts brewer's yeast ("Saccharomyces cerevisiae") and fission yeast ("Schizosaccharomyces pombe") are important model organisms in science, since they are simple eukaryotes that can be grown rapidly in large numbers and are easily manipulated. They are particularly valuable in genetics, genomics and proteomics, for example in protein production. The easily cultured gut bacterium "Escherichia coli", a prokaryote, is similarly widely used as a model organism.

Microbes can form an endosymbiotic relationship with larger organisms. For example, the bacteria that live within the human digestive system contribute to human health through gut immunity, the synthesis of vitamins such as folic acid and biotin, and the fermentation of complex indigestible carbohydrates. Future drugs and food chemicals may need to be tested on the gut microbiota; it is already clear that probiotic supplements can promote health, and that gut microbes are affected by both diet and medicines.

Pathogenic microbes, and toxins that they produce, have been developed as possible agents of warfare. Crude forms of biological warfare have been practiced since antiquity. In the 6th century BC, the Assyrians poisoned enemy wells with a fungus said to render the enemy delirious. In 1346, the bodies of Mongol warriors of the Golden Horde who had died of plague were thrown over the walls of the besieged Crimean city of Kaffa, possibly assisting the spread of the Black Death into Europe.
Advances in bacteriology in the 20th century increased the sophistication of possible bio-agents in war. Biological sabotage—in the form of anthrax and glanders—was undertaken on behalf of the Imperial German government during World War I, with indifferent results. In World War II, Britain weaponised tularemia, anthrax, brucellosis, and botulism toxins, but never used them.
The USA similarly explored biological warfare agents, developing anthrax spores, brucellosis, and botulism toxins for possible military use. Japan developed biological warfare agents, with the use of experiments on human prisoners, and was about to use them when the war ended.

Being very small, and unknown until the invention of the microscope, microbes do not feature directly in art or literature before Early Modern times (though they appear indirectly in works about brewing and baking), when Antonie van Leeuwenhoek observed microbes in water in 1676; his results were soon confirmed by Robert Hooke. A few major diseases such as tuberculosis appear in literature, art, film, opera and music.

The literary possibilities of post-apocalyptic stories about pandemics (worldwide outbreaks of disease) have been explored in novels and films from Mary Shelley's 1826 "The Last Man" and Jack London's 1912 "The Scarlet Plague" onwards. Medieval writings that deal with plague include Giovanni Boccaccio's "The Decameron" and Geoffrey Chaucer's "The Canterbury Tales": both treat the people's fear of contagion and the resulting moral decline, as well as bodily death.

The making of beer has been celebrated in verse since the time of Ancient Sumeria, c. 1800 BC, when the "Hymn to Ninkasi" was inscribed on a clay tablet. Ninkasi, tutelary goddess of beer, and daughter of the creator Enki and the "queen of the sacred lake" Ninki, "handles the dough and with a big shovel, mixing in a pit, the bappir with [date] honey, ... waters the malt set on the ground, ... soaks the malt in a jar, ... spreads the cooked mash on large reed mats, coolness overcomes, ... holds with both hands the great sweet wort, brewing it with honey".

Wine is a frequent topic in English literature, from the spiced French and Italian "ypocras", "claree", and "vernage" in Chaucer's "The Merchant's Tale" onwards. William Shakespeare's Falstaff drank Spanish "sherris sack", in contrast to Sir Toby Belch's preference for "canary". Wine references in later centuries branch out to more winegrowing regions.

"The Microbe" is a humorous 1912 poem by Hilaire Belloc, starting with the lines "The microbe is so very small / You cannot make him out at all,/ But many sanguine people hope / To see him through a microscope. "Microbes and Man" is an admired "classic" book, first published in 1969, by the "father figure of British microbiology" John Postgate on the whole subject of microorganisms and their relationships with humans.

Microbes feature in many highly dramatized films. Hollywood was quick to exploit the possibilities of deadly disease, mass infection and drastic government reaction, starting as early as 1922 with "Nosferatu", in which a Dracula-like figure, Count Orlok, sleeps in unhallowed ground contaminated with the Black Death, which he brings with him wherever he goes. Another classic film, Ingmar Bergman's 1957 "The Seventh Seal", deals with the plague theme very differently, with the grim reaper directly represented by an actor in a hood. More recently, the 1971 "The Andromeda Strain", based on a novel by Michael Crichton, portrayed an extraterrestrial microbe contaminating the Earth.

"A Very Cellular Song," a song from the British psychedelic folk band The Incredible String Band's 1968 album "The Hangman's Beautiful Daughter," is told partially from the point of view of an amoeba, a protistan.

Microbial art is the creation of artworks by culturing bacteria, typically on agar plates, to form desired patterns. These may be chosen to fluoresce under ultraviolet light in different colours. Alexander Fleming, the discoverer of penicillin, created "germ paintings" using different species of bacteria that were naturally pigmented in different colours.

An instance of a protist in an artwork is the artist Louise Bourgeois's bronze sculpture "Amoeba". It has a white patina resembling plaster, and was designed in 1963–5, based on drawings of a pregnant woman's belly that she made as early as the 1940s. According to the Tate Gallery, the work "is a roughly modelled organic form, its bulges and single opening suggesting a moving, living creature in the stages of evolution."

Microorganisms are the causative agents (pathogens) in many infectious diseases of humans and domestic animals. Pathogenic bacteria cause diseases such as plague, tuberculosis and anthrax. Protozoa cause diseases including malaria, sleeping sickness, dysentery and toxoplasmosis. Microscopic fungi cause diseases such as ringworm, candidiasis and histoplasmosis. Pathogenic viruses cause diseases such as influenza, yellow fever and AIDS.

The practice of hygiene was created to prevent infection or food spoiling by eliminating microbes, especially bacteria, from the surroundings.

Microorganisms including bacteria, fungi, and viruses are important as plant pathogens, causing disease to crop plants. Fungi cause serious crop diseases such as maize leaf rust, wheat stem rust, and powdery mildew. Bacteria cause plant diseases including leaf spot and crown galls. Viruses cause plant diseases such as leaf mosaic. The oomycete "Phytophthora infestans" causes potato blight, contributing to the Great Irish Famine of the 1840s.

The tulip breaking virus played a role in the tulip mania of the Dutch Golden Age. The famous Semper Augustus tulip, in particular, owed its striking pattern to infection with the plant disease, a kind of mosaic virus, making it the most expensive of all the tulip bulbs sold.


</doc>
<doc id="40142750" url="https://en.wikipedia.org/wiki?curid=40142750" title="Peng's Coefficient">
Peng's Coefficient

Peng’s Coefficient is an economic term which refers to the proportion of an individual’s spending on culture- and spirit-related products or services, such as books, movie, opera, concert, travelling, training and so forth, to her/his total expenditure. Peng’s Coefficient is inversely proportional to Engel’s Coefficient, because the more proportion people spend on food, the less proportion on culture and spirit.
The concept was named after its creator Peng Bing from China.
Equation: P=S/T


</doc>
<doc id="5903" url="https://en.wikipedia.org/wiki?curid=5903" title="Cultural movement">
Cultural movement

A cultural movement is a change in the way a number of different disciplines approach their work. This embodies all art forms, the sciences, and philosophies. Historically, different nations or regions of the world have gone through their own independent sequence of movements in culture, but as world communications have accelerated this geographical distinction has become less distinct. When cultural movements go through revolutions from one to the next, genres tend to get attacked and mixed up, and often new genres are generated and old ones fade. These changes are often reactions against the prior cultural form, which typically has grown stale and repetitive. An obsession emerges among the mainstream with the new movement, and the old one falls into neglect – sometimes it dies out entirely, but often it chugs along favored in a few disciplines and occasionally making reappearances (sometimes prefixed with "neo-").

There is continual argument over the precise definition of each of these periods, and one historian might group them differently, or choose different names or descriptions. As well, even though in many cases the popular change from one to the next can be swift and sudden, the beginning and end of movements are somewhat subjective, as the movements did not spring fresh into existence out of the blue and did not come to an abrupt end and lose total support, as would be suggested by a date range. Thus use of the term "period" is somewhat deceptive. "Period" also suggests a linearity of development, whereas it has not been uncommon for two or more distinctive cultural approaches to be active at the same time. Historians will be able to find distinctive traces of a cultural movement before its accepted beginning, and there will always be new creations in old forms. So it can be more useful to think in terms of broad "movements" that have rough beginnings and endings. Yet for historical perspective, some rough date ranges will be provided for each to indicate the "height" or accepted time span of the movement.

This current article covers western, notably European and American cultural movements. They have, however, been paralleled by cultural movements in the Orient and elsewhere. In the late 20th and early 21st century in Thailand, for example, there has been a cultural shift away from western social and political values more toward Japanese and Chinese. As well, That culture has reinvigorated monarchical concepts to accommodate state shifts away from western ideology regarding democracy and monarchies. 






</doc>
<doc id="12918880" url="https://en.wikipedia.org/wiki?curid=12918880" title="Cultural district">
Cultural district

A cultural district is traditionally conceived as a well-recognized, labeled, mixed-use area of a settlement in which a high concentration of cultural facilities serves as the anchor of attraction.

A debate has emerged on the concept of the cultural district, promoting potentially ground-breaking initiatives, even if most of the literature has concentrated on urban clusters, cities of art and cities of culture.

Facilities include: performance spaces, museums, galleries, artist studios, arts-related retail shops, music or media production studios, dance studios, high schools or colleges for the arts, libraries, arboretums and gardens.
Because they are mixed-use developments, cultural districts incorporate other facilities such as office complexes, retail spaces and, occasionally, residential areas.

The creation of a cultural district implies collaboration between the arts and the local community. Cultural districts may be seen by local authorities as a way to revitalize the “brownfields” of the urban core: areas of abandoned buildings that encourage businesses and residents to leave the cities.

The developing theory of cultural districts increasingly conceives them as development models for local systems, where the term ‘district’ refers to supra-urban area. At supra-urban or regional level the complexity of a cultural district is even more marked than at urban level, due to potential interdependencies among a greater multitude of actors. A useful approach towards a deeper understanding can be to conceive cultural districts as complex adaptive systems. Indeed, complexity is definitely not a management fad and fashion, a mere metaphor or methodology, but a deeper perception of reality. Organizations are classically seen as purpose-driven entities with a structural form, exhibiting a certain degree of order and determinism. Such a linear top-down approach to analysis and design, however, exhibits many limitations when used for organizational settings characterized by a complex web of interdependencies. The view of a cultural district as a complex adaptive system suggests new ideas and approaches for policy-makers, designers and managers. It also opens up debate on issues of organizational design and change.

More than 90 cities in the United States have planned or implemented cultural districts, positioning the arts at the center of their urban revitalization efforts.
All cultural districts are unique, reflecting their cities’ unique environment, including history of land use, urban growth and cultural development. There is no standard model.
Most cultural districts are built to take advantage of other city attractions such as historic features, convention spaces and parks and other natural amenities.

Structural considerations within or near the district, community leadership and social forces all influence the development of a cultural district and the type of district that results. Factors influencing the siting of cultural districts include: perceived need for urban revitalization, existing investment, property value and preexisting cultural facilities.

Unlike a cultural center or a shopping mall, a cultural district comprises a large number of property owners, both public and private, who control the various properties involved, hence a structural complexity. The effectiveness of the coordinating agency in guiding the direction of the cultural district varies according to its size, budget, mandated functions and degree of authority, resulting in widespread variation in the coordinated cultural programming and administration services offered by cultural districts. The coordinated agency appointed for the district must work carefully to ensure inclusiveness of concerns and to balance potentially conflicting interests.

Cultural districts offer two major types of services: one targets the arts community, providing marketing /promotion, box office services and property management; the other targets the district’s business and property owners, offering urban design and development services or administrative support.

The excitement and attraction of a cultural district is a high mixture of interesting things to do, places to see, and places to visit (both cultural and noncultural), across the day and evening.

Some artist-activists are promoting the concept of a "Naturally Occurring Cultural District," or NOCD, patterned after the demographic concept of a naturally occurring retirement community. A NOCD "supports existing neighborhood cultural assets rather than imposing arts institutions somewhere new," according to Tamara Greenfield, co-director of NOCD-New York. Co-director Caron Atlas explained: "If a cultural district has emerged 'naturally,' then it grows from, builds on and validates existing community assets rather than importing assets from outside a community." Indeed, different conceptions of cultural districts include self-organization and emergence in different degrees (e.g. Lazzeretti, 2003; Le Blanc, 2010; Sacco et al., 2013; Stern & Seifert, 2007). Many authors argue that districtualization is essentially spontaneous and that the conditions for formation can be recognized and sustained, not created from the top. If the conception of a cultual district as a complex adaptive system were accepted, the design process would be conceived as something more flexible, dynamic and in evolution. Complexity theory and complex adaptive systems should move understanding of supra-urban cultural districts towards a more holistic and bottom-up approach rather than a linear top-down approach to analysis and design. This does not suggest inhibiting any attempt at prediction or planning. The use of qualitative analysis and rough estimations or agent-based modelling can represent a fertile ground for both future research, policy-making and managerial implications.



</doc>
<doc id="43569192" url="https://en.wikipedia.org/wiki?curid=43569192" title="Aversion to happiness">
Aversion to happiness

Aversion to happiness, also called cherophobia or fear of happiness, is an attitude towards happiness in which individuals may deliberately avoid experiences that invoke positive emotions or happiness.

One of several reasons why cherophobia may develop is the belief that when one becomes happy, a negative event will soon occur that will taint that happiness, as if punishing that individual for satisfaction. This belief is thought to be more prevalent in Eastern cultures. In Western cultures, such as American culture, "it is almost taken for granted that happiness is one of the most important values guiding people's lives". Western cultures are more driven by an urge to maximize happiness and to minimize sadness. Failing to appear happy often gives cause for concern. The value placed on happiness echoes through Western positive psychology and through research on subjective well-being. Fear of happiness is associated with fragility of happiness beliefs, suggesting that one of the causes of aversion to happiness may be the belief that happiness is unstable and fragile. Research shows that fear of happiness is associated with avoidant and anxious attachment styles.

Joshanloo and Weijers identify four reasons for an aversion to happiness: (1)a belief that happiness will cause bad things to happen; (2) that happiness will cause you to become a bad person; (3) that expressing happiness is somehow bad for you and others; and (4) that pursuing happiness is bad for you and others. For example, "some people—in Western and Eastern cultures—are wary of happiness because they believe that bad things, such as unhappiness, suffering, and death, tend to happen to happy people."

These findings "call into question the notion that happiness is the ultimate goal, a belief echoed in any number of articles and self-help publications about whether certain choices are likely to make you happy". Also, "in cultures that believe worldly happiness to be associated with sin, shallowness, and moral decline will actually feel less satisfied when their lives are (by other standards) going well", so measures of personal happiness cannot simply be considered a yardstick for satisfaction with one's life, and attitudes such as aversion to happiness have important implications for measuring happiness across cultures and ranking nations on happiness scores.


</doc>
<doc id="53628878" url="https://en.wikipedia.org/wiki?curid=53628878" title="Cognitive adequacy">
Cognitive adequacy

Cognitive adequacy is a term proposed by Rein Raud as a standard of judging cultural phenomena. According to this method, a cultural phenomenon is cognitively adequate if it provides the means of solving certain problems in a certain socio-cultural context. This is true even when that solution is, according to other criteria, wrong. For example, before the Great Depression in the US many people thought that it is cognitively adequate to think of getting rich quickly through land speculation. All cultural phenomena are replaced by others when they are no longer cognitively adequate. For example, when a community has embraced a new religion, or when science has displaced religion as the primary explanatory discourse for their world.


</doc>
<doc id="54004404" url="https://en.wikipedia.org/wiki?curid=54004404" title="Criminal tradition">
Criminal tradition

Criminal tradition - of the cultural transmission of criminal values. Criminal traditions are transmitted from the older generation to the younger generation, such as social customs are in other forms of society.

Studies of the criminal tradition involved Clifford R. Shaw and Henry D. McKay. They put forward a theory of “cultural transmission”, focuses on the development in some urban neighborhoods of a criminal tradition that persists from one generation to another despite constant changes in population. This theory stresses the value systems of different areas

Also worth noting theory of “differential association,” in which Edwin H. Sutherland described the processes by which criminal values are taken over by the individual. Edwin H. Sutherland asserted that criminal behavior is learned and that it is learned in interaction with others who have already incorporated criminal values.

Research by Shaw and McKay on the concept of cultural transmission indicates that a criminal tradition or subculture does exist in areas of larger cities. According to their studies Criminal tradition arises and is maintained in areas of instability, and the values, norms, and behaviors of the participants in the criminal tradition are viewed as normal by these people.

Traditions are not personified, so adolescents and boys are easier to obey than direct instructions from specific individuals. This is the power of tradition. The norms of the life of groups in which the will of their members manifest themselves take the form of tradition most often. In the tradition that there is no personification, adolescents find it easier to obey them than to a particular person. Against this background, the criminal traditions that are prevalent in youth criminal groups, especially in closed educational and correctional institutions are especially dangerous. In a criminal environment, there are two kinds of traditions:


At the same time, there is a transformation of existing criminal traditions and the emergence of new ones. The reason for this is the changes in the social, economic, legal and other spheres.

On the criminal tradition in different countries of the world, there is a huge amount of work. There is an impressive number of works on the Russian criminal tradition, written in different languages. 
We can also highlight works by Jonny Steinberg on the numbers gangs of South Africa

There is also the view that it is impossible to consider all the traditions of the criminal environment as antisocial and harmful, including, for the reason that some of the traditions in the cells of the remand center, contribute to hygiene and the maintenance of sanitary norms.

In Russian criminal tradition adherents of the criminal (criminal) tradition are characterized by active participation in the life of the "thieves' community"; Living on tangible assets obtained by criminal means; Propaganda of "thieves' customs and traditions, as well as criminal way of life; Compulsion to keep a word not only before the "brother", but also the criminal-criminal world; Organization of collection of "obschekovyh" funds and control over their use; Guardianship and assistance to detainees and convicts, the so-called "vagabonds" and "honest prisoners"; Compliance with the decisions of "gatherings"; Demanding of "brotherhood" and control over their compliance; Organization of counteraction to state bodies.



</doc>
<doc id="9020225" url="https://en.wikipedia.org/wiki?curid=9020225" title="Cultural policy">
Cultural policy

Cultural policy is the government actions, laws and programs that regulate, protect, encourage and financially (or otherwise) support activities related to the arts and creative sectors, such as painting, sculpture, music, dance, literature, and filmmaking, among others and culture, which may involve activities related to language, heritage and diversity. The idea of cultural policy was developed at UNESCO in the 1960s. Generally, this involves governments setting in place processes, legal classifications, regulations, legislation and institutions (e.g., galleries, museums, libraries, opera houses, etc.) which promote and facilitate cultural diversity and creative expressions in a range of art forms and creative activities. Cultural policies vary from one country to another, but generally they aim to improve the accessibility of arts and creative activities to citizens and promote the artistic, musical, ethnic, sociolinguistic, literary and other expressions of all people in a country. In some countries, especially since the 1970s, there is an emphasis on supporting the culture of Indigenous peoples and marginalized communities and ensuring that cultural industries (e.g., filmmaking or TV production) are representative of a country's diverse cultural heritage and ethnic and linguistic demographics. 

Cultural policy can be done at a nation-state level, at a sub-national level (e.g., U.S. states or Canadian provinces), at a regional level or at a municipal level (e.g., a city government creating a museum or arts centre). Examples of cultural policy-making at the nation-state level could include anything from funding music education or theatre programs at little to no cost, to hosting corporate-sponsored art exhibitions in a government museum, to establishing legal codes (such as the U.S. Internal Revenue Service’s 501(c)(3) tax designation for not-for-profit enterprises) and creating political institutions (such as the various ministries of culture and departments of culture and the National Endowment for the Humanities and the National Endowment for the Arts in the United States), arts granting councils, and cultural institutions such as galleries and museums. Similar significant organisations in the United Kingdom include the Department for Culture, Media and Sport (DCMS), and Arts Council England.

Throughout much of the twentieth century, many of the activities that compose cultural policy in the 2010s were governed under the title of "arts policy". Arts policy includes direct funding to artists, creators and art institutions and indirect funding to artists and arts institutions through the tax system (e.g., by making donations to arts charities tax-deductible). However, as Kevin Mulcahy has observed, "cultural policy encompasses a much broader array of activities than were addressed under arts policy. Whereas arts policy was effectively limited to addressing aesthetic concerns (e.g., funding art galleries and opera houses), the significance of the transformation to cultural policy can be observed in its demonstrable emphases on cultural identity, valorization of indigineity [Indigenous people's culture] and analyses of historical dynamics (such as hegemony and colonialism)." A general trend in Western industrialized nations is a shift, since the 1970s and 1980s, away from solely supporting a small number of relatively elite, professionalized art forms and institutions (e.g., Classical music, painting, sculpture, art galleries) to also supporting amateur and community cultural and creative activities (e.g., community theatre) and cultural forms which were not considered part of the Western canon by previous generations (e.g., traditional music such as blues, World music, and so on).

Prior to the twentieth century, the arts were typically supported by the patronage of the church, aristocrats such as kings and queens, and wealthy merchants. During the nineteenth century, artists increased their use of the private marketplace to earn revenue. For example, the composer Beethoven put on public concerts for which admission was charged. During the twentieth century, governments began to take over some of the arts patronage roles. Governments' first efforts to support culture were typically the establishment of archives, museums and libraries. Over the twentieth century, governments established a range of other institutions, such as arts councils and departments of culture. The first departments of culture typically supported the major arts that are part of the Western canon, such as painting and sculpture, and the major performing arts (Classical music and theatre).

In the twentieth century, Western governments in the U.K., Canada, Australia, New Zealand and many European nations developed arts policy measures to promote, support and protect the arts, artists and arts institutions. These governments' arts policy initiatives generally had two aims: supporting excellence in the arts and broadening access to the arts by citizens. An example of an arts policy initiative that supports excellence would be a government grant program which provides funding to the highest-achieving artists in the country. A concrete example would be a literary prize of $100,000 for the best fiction authors from the country, as selected by a panel of top experts. An example of an arts policy initiative that aims at increasing access to the arts would be a music in the schools program funded by the government. A concrete example would be a program which funded an orchestra or jazz quartet and paid them to play free concerts in elementary schools. This would enable children from lower- and middle-income families to hear live music. 

The two goals, supporting excellence and broadening access, are often trade-offs, as any increase in emphasis on one policy objective typically has an adverse effect on the other goal. To give an example, if a hypothetical country has a $12 million per year grant program for orchestras in the country, if the government focuses on the goal of supporting musical excellence, it may decide to provide $4 million per year to the three top orchestras in the country, as determined by a panel of independent professional music critics, conductors and music professors. This decision would strongly support the goal of enhancing excellence, as funding would only go to the top musical groups. However, this approach would only enable citizens in three cities to have access to professional orchestras.

On the other hand, if the government was focusing on broadening access to symphony concerts, it might direct the independent panel to pick 12 orchestras in the country, with the stipulation that only one orchestra per city be selected. By proving $1 million per year to 12 orchestras in 12 cities, this would enable citizens from 12 cities in the country to see live orchestra shows. However, by funding 12 orchestras, this would mean that funding would go to ensembles that do not meet the highest standards of excellence. Thus, excellence and broadening access are often trade-offs.

Cultural policy, while a small part of the budgets of even the most generous of governments, governs a sector of immense complexity. It entails “a large, heterogeneous set of individuals and organizations engaged in the creation, production, presentation, distribution, and preservation of and education about aesthetic heritage, and entertainment activities, products and artifacts”. A cultural policy necessarily encompasses a broad array of activities and typically involves public support for:

Some governments may place policy areas from this list in other ministries or departments. For example, national parks may be assigned to an environment department, or public humanities may be delegated to an education department. 

Since culture is a public good (i.e., contributes a public value to society for which it is hard to exclude non-payers, as all of society benefits from arts and culture) and something that is generally viewed as a merit good, governments have pursued programs to promote greater accessibility. In this way of thinking, significant aesthetic works such as paintings and sculptures should be made broadly available to the public. In other words, “high culture” should not be the exclusive preserve of a particular social class or of a metropolitan location. Rather, the benefits of the highest reaches of cultural excellence should be made in an egalitarian manner; national cultural treasures should be accessible without regard to the impediments of class circumstances, educational attainment or place of habitation. A democratic state cannot be seen as simply indulging the aesthetic preferences of a few, however enlightened, or of overtly infusing art with political values. Consequently, a democratic cultural policy must articulate its purposes in ways that demonstrate how the public interest is being served. These purposes have often been expressed as involving either the creation of cultural democracy or the democratization of culture.

The objective of cultural democratization is the aesthetic enlightenment, enhanced dignity, and educational development of the general citizenry. “Dissemination was the key concept with the aim of establishing equal opportunity for all citizens to participate in publicly organized and financed cultural activities”. To further this goal, performances and exhibitions are low cost; public art education promotes equality of aesthetic opportunity; national institutions tour and perform in work places, retirement homes and housing complexes.

As indicated earlier, the “democratization of culture” is a top-down approach that promulgates certain forms of cultural programming that are deemed to be a public good. Clearly, such an objective is open to criticism for what is termed cultural elitism; that is, the assumption that some aesthetic expressions are inherently superior - at least as determined by a cognoscenti concerned with the acquisition of cultural capital. “The problem with this policy [is] that, fundamentally, it intend[s] to create larger audiences for performances whose content [is] based on the experience of society’s privileged groups. In sum, it has… taken for granted that the cultural needs of all society’s members [are] alike”. The objective of cultural democracy, on the other hand, is to provide for a more participatory (or populist) approach in the definition and provision of cultural opportunities.

The coupling of the concept of democratization of culture to cultural democracy has a pragmatic as well as a philosophical component. Cultural patronage in democratic governments is markedly different from patronage by wealthy individuals or corporations. Private or politically paramount patrons are responsible only to themselves and are free to indulge in their tastes and preferences. Democratic governments, on the other hand, are responsible to the electorate and are held accountable for their policy decisions.

The two objectives just discussed - dissemination of high culture and participation in a broader range of cultural activities - evoke a related debate about the content of public culture: “elitist” or “populist.” 
Proponents of the elitist position argue that cultural policy should emphasize aesthetic quality as the determining criterion for public subvention. This view is typically supported by the major cultural organizations, creative artists in the traditionally defined field of the fine arts, cultural critics, and the well-educated, well-to-do audiences for these art forms. Ronald Dworkin terms this the “lofty approach,” which “insists that art and culture must reach a certain degree of sophistication, richness, and excellence in order for human nature to flourish, and that the state must provide this excellence if the people will not or cannot provide it for themselves”. Advocates of the elitist position generally focus on supporting the creation, preservation and performance of works of the Western canon, a group of artworks that are viewed as the best artistic and cultural products of Western society.

By contrast, the populist position advocates defining culture broadly and inclusively and making this culture broadly available. The populist approach emphasizes a less traditional and more pluralist notion of artistic merit and consciously seeks to create a policy of cultural diversity. With a focus on personal enhancement, the populist’s position posits very limited boundaries between amateur and professional arts activities. Indeed, the goal is to provide opportunities for those outside the professional mainstream. To give an example, whereas an elite approach advocates support for professional musicians, particularly those from Classical music, a populist approach would advocate support for amateur, community singers and musicians.

“Proponents of populism are frequently advocates of minority arts, folk arts, ethnic arts, or counter-cultural activities” as Kevin V. Mulcahy said. Cultural “elitists,” on the other hand, argue in support of excellence over amateurism and favor an emphasis on aesthetic discipline over “culture as everything.” There are “two key tensions for national cultural policy between the goals of excellence versus access, and between government roles as facilitator versus architect”.
Kevin V. Mulcahy argued that in effect, elitism is cultural democracy as populism is to the democratization of culture. Unfortunately, there has been a tendency to see these positions as mutually exclusive, rather than complementary. “Elitists” are denounced as “high brow snobs” advocating an esoteric culture which focuses on art music and the types of art seen in museums and galleries; populists are dismissed as “pandering philistines” promoting a trivialized and commercialized culture, as they endorse the value of popular music and folk art. However, these mutual stereotypes belie complementariness between two bookends of an artistically autonomous and politically accountable cultural policy. There is a synthesis that can be termed a “latitudinarian approach” to public culture; that is, one that is aesthetically inclusive and broadly accessible.

Musicologists David Hebert and Mikolaj Rykowski write that when “music is recognized as invaluable cultural heritage, entailing unique artefacts of intellectual property, new developments in this field then become acknowledged as important forms of social "innovation";” However, they caution policy-makers that with glocalization, the rise of “‘big data’ offers unprecedentedly powerful tools but also inevitably entails many risks for all kinds of artists (both musicians and their collaborators in other arts) as well as the sustainability of traditional cultural practices.”

Such a public-cultural policy would remain faithful to the highest standards of excellence from a broad range of aesthetic expressions while providing the widest possible access to people from different geographic locales, socio-economic strata, and educational background, as Dr. Mulcahy said. In conceiving of public policy as an opportunity to provide alternatives not readily available in the marketplace, public cultural agencies would be better positioned to complement the efforts of the private sector rather than duplicate their activities. Similarly, cultural agencies can promote community development by supporting artistic heritages that are at a competitive disadvantage in a cultural world that is increasingly profit-driven. In sum, excellence should be viewed as the achievements of greatness from a horizontal, rather than a vertical, perspective and a cultural policy as supporting the totality of these varieties of excellence.

These attitudes about a public cultural responsibility stand in marked contrast to much of the rest of the world, where culture is a question of historic patrimony, or the national identities of peoples, whether in independent states or regions within more powerful states. Inevitably, sensitive issues are involved in any discussion of culture as a public policy. However, given the demands in a democratic system that public policies show a return to the taxpayer, cultural policy has frequently argued for support on the basis of utility. It can be argued that there is a parity between the state’s responsibility for its citi’ social-economic-physical needs and their access to culture and opportunities for artistic self-expression. However, the aesthetic dimension of public policy has never been widely perceived as intuitively obvious or politically imperative. Accordingly, the cultural sector has often argued its case from the secondary, ancillary benefits that result from public support for programs that are seemingly only aesthetic in nature. Cultural policy is not typically justified solely on the grounds that it is a good-in-itself, but rather that it yields other good results.

The future of cultural policy would seem to predict an increasingly inexorable demand that the arts “carry their own weight” rather than rely on a public subsidy to pursue “art for art’s sake”. Kevin V. Mulcahy dubbed this “cultural Darwinism” is most pronounced in the United States where public subsidy is limited and publicly supported aesthetic activities are expected to demonstrate a direct public benefit. Non-American cultural institutions are less constrained by the need to maintain diversified revenue streams that demand high levels of earned income and individual and corporate donations to compensate for limited government appropriations.

On the other hand, cultural institutions everywhere are increasingly market-driven in their need for supplementary funds and as a justification for continued public support. The American model of an essentially privatized culture is increasingly attractive to governments seeking to curtail their cultural subsidies. In a system of mixed funding, public culture can nurture the arts groups and cultural activities that contribute to individual self-worth and community definition even if counting for less in the economic bottom-line. At root, a cultural policy is about creating public spheres that are not dependent upon profit motives nor validated by commercial values. As political democracy is dependent upon the existence of civil society and socio-economic pluralism, cultural policy stands as an essential public commitment in realizing these fundamental preconditions.

One of the available and yet underappreciated tools in cultural policy at the national level is the reduction of VAT rates for cultural goods and services. Economic theory can be used to explain how reduced fiscal rates are expected to decrease prices and increase quantities of consumed cultural goods and services. Fiscal policy can be an important part of cultural policy, in particular the VAT rate discounts on cultural consumption, yet it receives less attention than deserved.

At the international level UNESCO is in charge of cultural policy. Contact information for ministries of culture and national arts councils in 160 countries is available from the website of the International Federation of Arts Councils and Culture Agencies (IFACCA). On a local scale, subnational (e.g., state or provincial governments), city and local governments offer citizens and local authorities the opportunity to develop arts and culture with the Agenda 21 for Culture.

Cultural policy research is a field of academic inquiry that grew out of cultural studies in the 1990s. It grew out of the idea that cultural studies should not only be critical, but also try to be useful. Since the 2010s, there are many departments of Cultural Policy Studies around the world. A document that gives an overview over cultural policies worldwide is the Global Report (2018) of the 2005 Convention on the Protection and Promotion of the Diversity of Cultural Expressions. 

Read more about the Global Report: Re|Shaping Cultural Policies





</doc>
<doc id="144633" url="https://en.wikipedia.org/wiki?curid=144633" title="Counterculture">
Counterculture

A counterculture (also written counter-culture) is a subculture whose values and norms of behavior differ substantially from those of mainstream society, often in opposition to mainstream cultural mores. A countercultural movement expresses the ethos and aspirations of a specific population during a well-defined era. When oppositional forces reach critical mass, countercultures can trigger dramatic cultural changes. Prominent examples of countercultures in Europe and North America include Romanticism (1790–1840), Bohemianism (1850–1910), the more fragmentary counterculture of the Beat Generation (1944–1964), followed by the globalized counterculture of the 1960s (1964–1974), usually associated with the hippie subculture and the diversified punk subculture of the 1970s and 1980s.

John Milton Yinger originated the term "contraculture" in his 1960 article in "American Sociological Review". Yinger suggested the use of the term contraculture "wherever the normative system of a group contains, as a primary element, a theme of conflict with the values of the total society, where personality variables are directly involved in the development and maintenance of the group's values, and wherever its norms can be understood only by reference to the relationships of the group to a surrounding dominant culture." 

Some scholars have attributed the "counterculture" to Theodore Roszak, author of "The Making of a Counter Culture". It became prominent in the news media amid the social revolution that swept the Americas, Western Europe, Japan, Australia, and New Zealand during the 1960s.

Scholars differ in the characteristics and specificity they attribute to "counterculture". "Mainstream" culture is of course also difficult to define, and in some ways becomes identified and understood through contrast with counterculture. Counterculture might oppose mass culture (or "media culture"), or middle-class culture and values. Counterculture is sometimes conceptualized in terms of generational conflict and rejection of older or adult values.

Counterculture may or may not be explicitly political. It typically involves criticism or rejection of currently powerful institutions, with accompanying hope for a better life or a new society. It does not look favorably on party politics or authoritarianism.

Cultural development can also be affected by way of counterculture. Scholars such as Joanne Martin and Caren Siehl, deem counterculture and cultural development as "a balancing act, [that] some core values of a counterculture should present a direct challenge to the core values of a dominant culture". Therefore, a prevalent culture and a counterculture should coexist in an uneasy symbiosis, holding opposite positions on valuable issues that are essentially important to each of them. According to this theory, a counterculture can contribute a plethora of useful functions for the prevalent culture, such as "articulating the foundations between appropriate and inappropriate behavior and providing a safe haven for the development of innovative ideas".

Typically, a "fringe culture" expands and grows into a counterculture by defining its own values in opposition to mainstream norms. Countercultures tend to peak, then go into decline, leaving a lasting impact on mainstream cultural values. Their life cycles include phases of rejection, growth, partial acceptance and absorption into the mainstream. During the late 1960s, hippies became the largest and most visible countercultural group in the United States. The "cultural shadows" left by the Romantics, Bohemians, Beats and Hippies remain visible in contemporary Western culture.

According to Sheila Whiteley, "recent developments in sociological theory complicate and problematize theories developed in the 1960s, with digital technology, for example, providing an impetus for new understandings of counterculture". Andy Bennett writes that "despite the theoretical arguments that can be raised against the sociological value of counterculture as a meaningful term for categorising social action, like subculture, the term lives on as a concept in social and cultural theory… [to] become part of a received, mediated memory". However, "this involved not simply the utopian but also the dystopian and that while festivals such as those held at Monterey and Woodstock might appear to embrace the former, the deaths of such iconic figures as Brian Jones, Jimi Hendrix, Jim Morrison and Janis Joplin, the nihilistic mayhem at Altamont, and the shadowy figure of Charles Manson cast a darker light on its underlying agenda, one that reminds us that ‘pathological issues [are] still very much at large in today's world".

The counterculture of the 1960s and early 1970s generated its own unique brand of notable literature, including comics and cartoons, and sometimes referred to as the underground press. In the United States, this includes the work of Robert Crumb and Gilbert Shelton, and includes Mr. Natural; Keep on Truckin'; "Fritz the Cat"; Fat Freddy's Cat; Fabulous Furry Freak Brothers; the album cover art for "Cheap Thrills"; and in several countries contributions to "International Times", "The Village Voice", and "Oz" magazine. During the late 1960s and early 1970s, these comics and magazines were available for purchase in head shops along with items like beads, incense, cigarette papers, tie-dye clothing, Day-Glo posters, books, etc.

During the late 1960s and early 1970s, some of these shops selling hippie items also became cafés where hippies could hang out, chat, smoke marijuana, read books, etc., e.g. Gandalf's Garden in the King's Road, London, which also published a magazine of the same name. Another such hippie/anarchist bookshop was Mushroom Books, tucked away in the Lace Market area of Nottingham.

Some genres tend to challenge societies with their content that is meant to outright question the norms within cultures and even create change usually towards a more modern way of thought. More often than not, sources of these controversies can be found in art such as Marcel Duchamp whose piece "Fountain" was meant to be "a calculated attack on the most basic conventions of art" in 1917. Contentious artists like Banksy base most of their works off of mainstream media and culture to bring pieces that usually shock viewers into thinking about their piece in more detail and the themes behind them. A great example can be found in Dismaland, the biggest project of "anarchism" to be organised and exhibited which showcases multiple works such as an "iconic Disney princess's horse-drawn pumpkin carriage, [appearing] to re-enact the death of Princess Diana".

Counterculture is very much evident in music particularly on the basis of the separation of genres into those considered acceptable and within the status quo and those not. Since many minorities groups are already considered counterculture, the music they create and produce may reflect their sociopolitical realities and their musical culture may be adopted as a social expression of their counterculture. This is reflected in dancehall with the concept of base frequencies and base culture in Henriques's "Sonic diaspora", where he expounds that "base denotes crude, debased, unrefined, vulgar, and even animal" for the Jamaican middle class and is associated with the "bottom-end, low frequencies…basic lower frequencies and embodied resonances distinctly inferior to the higher notes" that appear in dancehall.
According to Henriques, "base culture is bottom-up popular, street culture, generated by an urban underclass surviving almost entirely outside the formal economy". That the music is low frequency sonically and regarded as reflective of a lower culture shows the influential connection between counterculture and the music produced. It should also be noted that while music may be considered base and counter culture, it may actually enjoy a lot of popularity which can be seen by the labelling of hip hop as a counter culture genre, despite it being one of the most commercially successful and high charting genres.

Many of these artists though once being taboo, have been assimilated into culture and are no longer a source of moral panic since they don't cross overtly controversial topics or challenge staples of current culture. Instead of being a topic to fear, they have initiated subtle trends that other artists and sources of media may follow.

Gay liberation (considered a precursor of various modern LGBT social movements) was known for its links to the counterculture of the time (e.g. groups like the Radical Faeries), and for the gay liberationists' intent to transform or abolish fundamental institutions of society such as gender and the nuclear family; in general, the politics were radical, anti-racist, and anti-capitalist in nature. In order to achieve such liberation, consciousness raising and direct action were employed.

At the outset of the 20th century, homosexual acts were punishable offenses in these countries. The prevailing public attitude was that homosexuality was a moral failing that should be punished, as exemplified by Oscar Wilde's 1895 trial and imprisonment for "gross indecency". But even then, there were dissenting views. Sigmund Freud publicly expressed his opinion that homosexuality was "assuredly no advantage, but it is nothing to be ashamed of, no vice, no degradation; it cannot be classified as an illness; we consider it to be a variation of the sexual function, produced by a certain arrest of sexual development". According to Charles Kaiser's "The Gay Metropolis", there were already semi-public gay-themed gatherings by the mid-1930s in the United States (such as the annual drag balls held during the Harlem Renaissance). There were also bars and bathhouses that catered to gay clientele and adopted warning procedures (similar to those used by Prohibition-era speakeasies) to warn customers of police raids. But homosexuality was typically subsumed into bohemian culture, and was not a significant movement in itself.

Eventually, a genuine gay culture began to take root, albeit very discreetly, with its own styles, attitudes and behaviors and industries began catering to this growing demographic group. For example, publishing houses cranked out pulp novels like "The Velvet Underground" that were targeted directly at gay people. By the early 1960s, openly gay political organizations such as the Mattachine Society were formally protesting abusive treatment toward gay people, challenging the entrenched idea that homosexuality was an aberrant condition, and calling for the decriminalization of homosexuality. Despite very limited sympathy, American society began at least to acknowledge the existence of a sizable population of gays. The film "The Boys in the Band", for example, featured negative portrayals of gay men, but at least recognized that they did in fact fraternize with each other (as opposed to being isolated, solitary predators who "victimized" straight men).

Disco music in large part rose out of the New York gay club scene of the early 1970s as a reaction to the stigmatization of gays and other outside groups such as blacks by the counterculture of that era. By later in the decade Disco was dominating the pop charts. The popular Village People and the critically acclaimed Sylvester had gay-themed lyrics and presentation.

Another element of LGBT counter-culture that began in the 1970s—and continues today—is the lesbian land, landdyke movement, or womyn's land movement. Radical feminists inspired by the back-to-the-land initiative and migrated to rural areas to create communities that were often female-only and/or lesbian communes. "Free Spaces" are defined by Sociologist Francesca Polletta as "small-scale settings within a community or movement that are removed from the direct control of dominant groups, are voluntarily participated in, and generate the cultural challenge that precedes or accompanies political mobilization. Women came together in Free Spaces like music festivals, activist groups and collectives to share ideas with like-minded people and to explore the idea of the lesbian land movement. The movement is closely tied to eco-feminism.

The four tenets of the Landdyke Movement are relationship with the land, liberation and transformation, living the politics, and bodily Freedoms. Most importantly, members of these communities seek to live outside of a patriarchal society that puts emphasis on "beauty ideals that discipline the female body, compulsive heterosexuality, competitiveness with other women, and dependence". Instead of adhering typical female gender roles, the women of Landdyke communities value "self-sufficiency, bodily strength, autonomy from men and patriarchal systems, and the development of lesbian-centered community". Members of the Landdyke movement enjoy bodily freedoms that have been deemed unacceptable in the modern Western world—such as the freedom to expose their breasts, or to go without any clothing at all. An awareness of their impact on the Earth, and connection to nature is essential members of the Landdyke Movement's way of life.

The watershed event in the American gay rights movement was the 1969 Stonewall riots in New York City. Following this event, gays and lesbians began to adopt the militant protest tactics used by anti-war and black power radicals to confront anti-gay ideology. Another major turning point was the 1973 decision by the American Psychiatric Association to remove homosexuality from the official list of mental disorders. Although gay radicals used pressure to force the decision, Kaiser notes that this had been an issue of some debate for many years in the psychiatric community, and that one of the chief obstacles to normalizing homosexuality was that therapists were profiting from offering dubious, unproven "cures".

The AIDS epidemic was initially an unexpected blow to the movement, especially in North America. There was speculation that the disease would permanently drive gay life underground. Ironically, the tables were turned. Many of the early victims of the disease had been openly gay only within the confines of insular "gay ghettos" such as New York City's Greenwich Village and San Francisco's Castro; they remained closeted in their professional lives and to their families. Many heterosexuals who thought they didn't know any gay people were confronted by friends and loved ones dying of "the gay plague" (which soon began to infect heterosexual people also). LGBT communities were increasingly seen not only as victims of a disease, but as victims of ostracism and hatred. Most importantly, the disease became a rallying point for a previously complacent gay community. AIDS invigorated the community politically to fight not only for a medical response to the disease, but also for wider acceptance of homosexuality in mainstream America. Ultimately, coming out became an important step for many LGBT people.

During the early 1980s what was dubbed "New Music", New wave, "New pop" popularized by MTV and associated with gender bending Second British Music Invasion stars such as Boy George and Annie Lennox became what was described by Newsweek at the time as an alternate mainstream to the traditional masculine/heterosexual rock music in the United States.

In 2003, the United States Supreme Court officially declared all sodomy laws unconstitutional.

Bill Osgerby argues that:
the counterculture's various strands developed from earlier artistic and political movements. On both sides of the Atlantic the 1950s "Beat Generation" had fused existentialist philosophy with jazz, poetry, literature, Eastern mysticism and drugs – themes that were all sustained in the 1960s counterculture.

In the United States, the counterculture of the 1960s became identified with the rejection of conventional social norms of the 1950s. Counterculture youth rejected the cultural standards of their parents, especially with respect to racial segregation and initial widespread support for the Vietnam War, and, less directly, the Cold War—with many young people fearing that America's nuclear arms race with the Soviet Union, coupled with its involvement in Vietnam, would lead to a nuclear holocaust.

In the United States, widespread tensions developed in the 1960s in American society that tended to flow along generational lines regarding the war in Vietnam, race relations, sexual mores, women's rights, traditional modes of authority, and a materialist interpretation of the American Dream. White, middle class youth—who made up the bulk of the counterculture in western countries—had sufficient leisure time, thanks to widespread economic prosperity, to turn their attention to social issues. These social issues included support for civil rights, women's rights, and gay rights movements, and a rejection of the Vietnam War. The counterculture also had access to a media which was eager to present their concerns to a wider public. Demonstrations for social justice created far-reaching changes affecting many aspects of society. Hippies became the largest countercultural group in the United States.

Rejection of mainstream culture was best embodied in the new genres of psychedelic rock music, pop-art and new explorations in spirituality. Musicians who exemplified this era in the United Kingdom and United States included The Beatles, John Lennon,  Neil Young, Bob Dylan, The Grateful Dead, Jefferson Airplane, Jimi Hendrix, The Doors, Frank Zappa, The Rolling Stones, Velvet Underground, Janis Joplin, The Who, Joni Mitchell, The Kinks, Sly and the Family Stone and, in their early years, Chicago. New forms of musical presentation also played a key role in spreading the counterculture, with large outdoor rock festivals being the most noteworthy. The climactic live statement on this occurred from August 15–18, 1969, with the "Woodstock Music Festival" held in Bethel, New York—with 32 of rock's and psychedelic rock's most popular acts performing live outdoors during the sometimes rainy weekend to an audience of half a million people. (Michael Lang stated 400,000 attended, half of which did not have a ticket.) It is widely regarded as a pivotal moment in popular music history—with "Rolling Stone" calling it one of the "50 Moments That Changed the History of Rock and Roll". According to Bill Mankin, "It seems fitting… that one of the most enduring labels for the entire generation of that era was derived from a rock festival: the ‘Woodstock Generation’."

Sentiments were expressed in song lyrics and popular sayings of the period, such as "do your own thing", "turn on, tune in, drop out", "whatever turns you on", "Eight miles high", "sex, drugs, and rock 'n' roll", and "light my fire". Spiritually, the counterculture included interest in astrology, the term "Age of Aquarius" and knowing people's astrological signs of the Zodiac. This led Theodore Roszak to state "A eclectic taste for mystic, occult, and magical phenomena has been a marked characteristic of our postwar youth culture since the days of the beatniks." In the United States, even actor Charlton Heston contributed to the movement, with the statement "Don't trust anyone over thirty" (a saying coined in 1965 by activist Jack Weinberg) in the 1968 film "Planet of the Apes"; the same year, actress and social activist Jane Fonda starred in the sexually-themed "Barbarella". Both actors opposed the Vietnam War during its duration, and Fonda would eventually become controversially active in the peace movement.

The counterculture in the United States has been interpreted as lasting roughly from 1964 to 1972—coincident with America's involvement in Vietnam—and reached its peak in August 1969 at the Woodstock Festival, New York, characterized in part by the film "Easy Rider" (1969). Unconventional or psychedelic dress; political activism; public protests; campus uprisings; pacifist then loud, defiant music; drugs; communitarian experiments, and sexual liberation were hallmarks of the sixties counterculture—most of whose members were young, white and middle-class.

In the United States, the movement divided the population. To some Americans, these attributes reflected American ideals of free speech, equality, world peace, and the pursuit of happiness; to others, they reflected a self-indulgent, pointlessly rebellious, unpatriotic, and destructive assault on the country's traditional moral order. Authorities banned the psychedelic drug LSD, restricted political gatherings, and tried to enforce bans on what they considered obscenity in books, music, theater, and other media.

The counterculture has been argued to have diminished in the early 1970s, and some have attributed two reasons for this. First, it has been suggested that the most popular of its political goals—civil rights, civil liberties, gender equality, environmentalism, and the end of the Vietnam War—were "accomplished" (to at least some degree); and also that its most popular social attributes—particularly a "live and let live" mentality in personal lifestyles (the "sexual revolution")—were co-opted by mainstream society. Second, a decline of idealism and hedonism occurred as many notable counterculture figures died, the rest settled into mainstream society and started their own families, and the "magic economy" of the 1960s gave way to the stagflation of the 1970s—the latter costing many in the middle-classes the luxury of being able to live outside conventional social institutions. The counterculture, however, continues to influence social movements, art, music, and society in general, and the post-1973 mainstream society has been in many ways a hybrid of the 1960s establishment and counterculture.

The counterculture movement has been said to be rejuvenated in a way that maintains some similarities from the Counterculture of the 1960s, but it is different as well. Photographer Steve Schapiro investigated and documented these contemporary hippie communities from 2012 to 2014. He traveled the country with his son, attending festival after festival. These findings were compiled in Schapiro’s book "Bliss: Transformational Festivals & the Neo Hippie." One of his most valued findings was that these “Neo Hippies” experience and encourage such a spiritual commitment to the community.

Australia's countercultural trend followed the one burgeoning in the US, and to a lesser extend the one in Great Britain. Political scandals in the country, such as the disappearance of Harold Holt, and the 1975 constitutional crisis, as well as Australia's involvement in Vietnam War, led to a disillusionment or disengagement with political figures and the government. Large protests were held in the countries most populated cities such as Sydney and Melbourne, one prominent march was held in Sydney in 1971 on George Street. The photographer Roger Scott, who captured the protest in front of the Queen Victoria Building, remarked: "I knew I could make a point with my camera. It was exciting. The old conservative world was ending and a new Australia was beginning. The demonstration was almost silent. The atmosphere was electric. The protesters were committed to making their presence felt … It was clear they wanted to show the government that they were mighty unhappy".

Political upheaval made its way into art in the country: film, music and literature were shaped by the ongoing changes both within the country, the Southern Hemisphere and the rest of the world. Bands such as The Master’s Apprentices, The Pink Finks and Normie Rowe & The Playboys, along with Sydney’s The Easybeats, Billy Thorpe & The Aztecs and The Missing Links began to emerge in the 1960s.

One of Australia's most noted literary voices of the counter-culture movement was Frank Moorhouse, whose collection of short stories, "Futility and Other Animals", was first published in Sydney 1969. Its "discontinuous narrative" was said to reflect the "ambience of the counter-culture". Helen Garner's "Monkey Grip" (1977), released eight years later, is considered a classic example of the contemporary Australian novel, and captured the thriving countercultural movement in Melbourne's inner-city in the mid 1970s, specifically open relationships and recreational drug use. Years later, Garner revealed it was strongly autobiographical and based on her own diaries. Additionally, from the 1960s, surf culture took rise in Australia given the abundance of beaches in the country, and this was reflected in art, from bands such as The Atlantics and novels like "Puberty Blues" as well as the film of the same name.

Starting in the late 1960s the counterculture movement spread from the US like a wildfire. Britain did not experience the intense social turmoil produced in America by the Vietnam War and racial tensions. Nevertheless, British youth readily identified with their American counterparts' desire to cast off the older generation's social mores. The new music was a powerful weapon. In this case, it took the form of a wholesale revolt against the class system, which was now being questioned for the first time in the nation's history. Rock music, which had first been introduced from the US in the 1950s, became a key instrument in the social uprisings of the young generation and Britain soon became a groundswell of musical talent thanks to groups like the Beatles, Rolling Stones, the Who, Pink Floyd, and more in coming years.

The antiwar movement in Britain closely collaborated with their American counterparts, supporting peasant insurgents in the Asian jungles. The "Ban the Bomb" protests centered around opposition to nuclear weaponry; the campaign gave birth to what was to become the peace symbol of the 1960s.

Although not exactly equivalent to the English definition, the term "Контркультура" ("Kontrkul'tura") became common in Russian to define a 1990s cultural movement that promoted acting outside of cultural conventions: the use of explicit language; graphical descriptions of sex, violence and illicit activities; and uncopyrighted use of "safe" characters involved in such activities.

During the early 1970s, the Soviet government rigidly promoted optimism in Russian culture. Divorce and alcohol abuse were viewed as taboo by the media. However, Russian society grew weary of the gap between real life and the creative world, and underground culture became "forbidden fruit". General satisfaction with the quality of existing works led to parody, such as how the Russian anecdotal joke tradition turned the setting of "War and Peace" by Leo Tolstoy into a grotesque world of sexual excess. Another well-known example is black humor (mostly in the form of short poems) that dealt exclusively with funny deaths and/or other mishaps of small, innocent children.

In the mid-1980s, the Glasnost policy permitted the production of less optimistic works. As a consequence, Russian cinema during the late 1980s and the early 1990s was action movies with explicit (but not necessarily graphic) scenes of ruthless violence and social dramas about drug abuse, prostitution and failing relationships. Although Russian movies of the time would be rated "R" in the United States due to violence, the use of explicit language was much milder than in American cinema.

In the late 1990s, Russian counterculture became increasingly popular on the Internet. Several websites appeared that posted user-created short stories dealing with sex, drugs and violence. The following features are considered the most popular topics in such works:


A notable aspect of counterculture at the time was the influence of contra-cultural developments on Russian pop culture. In addition to traditional Russian styles of music, such as songs with jail-related lyrics, new music styles with explicit language were developed.

In the recent past, Dr. Sebastian Kappen, an Indian theologian, has tried to redefine counterculture in the Asian context. In March 1990, at a seminar in Bangalore, he presented his countercultural perspectives (Chapter 4 in S. Kappen, "Tradition, modernity, counterculture: an Asian perspective", Visthar, Bangalore, 1994). Dr. Kappen envisages counterculture as a new culture that has to negate the two opposing cultural phenomena in Asian countries:

Kappen writes, "Were we to succumb to the first, we should be losing our identity; if to the second, ours would be a false, obsolete identity in a mental universe of dead symbols and delayed myths".

The most important countercultural movement in India had taken place in the state of West Bengal during the 1960s by a group of poets and artists who called themselves Hungryalists.




</doc>
<doc id="861492" url="https://en.wikipedia.org/wiki?curid=861492" title="Intercultural communication">
Intercultural communication

Intercultural communication (or cross-cultural communication) is a discipline that studies communication across different cultures and social groups, or how culture affects communication. It describes the wide range of communication processes and problems that naturally appear within an organization or social context made up of individuals from different religious, social, ethnic, and educational backgrounds. In this sense it seeks to understand how people from different countries and cultures act, communicate and perceive the world around them. Many people in intercultural business communication argue that culture determines how individuals encode messages, what medium they choose for transmitting them, and the way messages are interpreted. 
With regard to intercultural communication proper, it studies situations where people from different cultural backgrounds "interact". Aside from language, intercultural communication focuses on social attributes, thought patterns, and the cultures of different groups of people. It also involves understanding the different cultures, languages and customs of people from other countries. Intercultural communication plays a role in social sciences such as anthropology, cultural studies, linguistics, psychology and communication studies. Intercultural communication is also referred to as the base for international businesses. Several cross-cultural service providers assist with the development of intercultural communication skills. Research is a major part of the development of intercultural communication skills.

Identity and culture are also studied within the discipline of communication to analyze how globalization influences ways of thinking, beliefs, values, and identity, within and between cultural environments. Intercultural communication scholars approach theory with a dynamic outlook and do not believe culture can be measured nor that cultures share universal attributes. Scholars acknowledge that culture and communication shift along with societal changes and theories should consider the constant shifting and nuances of society.

The study of intercultural communication requires intercultural understanding, which is an ability to understand and value cultural differences. Language is an example of an important cultural component that is linked to intercultural understanding. "Intercultural communication" is in a way the 'interaction with speakers of other languages on equal terms and respecting their identities'.

Cross-cultural business communication is very helpful in building cultural intelligence through coaching and training in cross-cultural communication management and facilitation, cross-cultural negotiation, multicultural conflict resolution, customer service, business and organizational communication. Cross-cultural understanding is not just for incoming expats. Cross-cultural understanding begins with those responsible for the project and reaches those delivering the service or content. The ability to communicate, negotiate and effectively work with people from other cultures is vital to international business.

Important points to consider:


There is a connection between a person's personality traits and the ability to adapt to the host-country's environment—including the ability to communicate within that environment.

Two key personality traits are openness and resilience. Openness includes traits such as tolerance for ambiguity, extroversion and introversion, and open-mindedness. Resilience, on the other hand, includes having an internal locus of control, persistence, tolerance for ambiguity, and resourcefulness.

These factors, combined with the person's cultural and racial identity and level of liberalism, comprise that person's potential for adaptation.

There are common conceptualizations of attributes that define collectivistic and individualistic cultures. Operationalizing the perceptions of cultural identities works under the guise that cultures are static and homogeneous, when in fact cultures within nations are multi-ethnic and individuals show high variation in how cultural differences are internalized and expressed.

Globalization plays a central role in theorizing for mass communication, media, and cultural communication studies. Intercultural communication scholars emphasize that globalization emerged from the increasing diversity of cultures throughout the world and thrives with the removal of cultural barriers. The notion of nationality, or the construction of national space, is understood to emerge dialectically through communication and globalization.

The Intercultural Praxis Model by Kathryn Sorrells, PH.D shows us how to navigate through the complexities of cultural differences along with power differences. This model will help you understand who you are as an individual, and how you can better communicate with others that may be different from you. In order to continue living in a globalized society one can use this Praxis model to understand cultural differences (based on race, ethnicity, gender, class, sexual orientation, religion, nationality, etc.) within the institutional and historical systems of power. Intercultural Communication Praxis Model requires us to respond to someone who comes from a different culture than us, in the most open way we can. The media are influential in what we think of other cultures and also what we think about our own selves. However it is important, we educate ourselves, and learn how to communicate with others through Sorrells Praxis Model.

Sorrells’ process is made up of six points of entry in navigating intercultural spaces, including inquiry, framing, positioning, dialogue, reflection, and action. Inquiry, as the first step of the Intercultural Praxis Model, is an overall interest in learning about and understanding individuals with different cultural backgrounds and world-views, while challenging one’s own perceptions. Framing, then, is the awareness of “local and global contexts that shape intercultural interactions;” thus, the ability to shift between the micro, meso, and macro frames. Positioning is the consideration of one’s place in the world compared to others, and how this position might influence both world-views and certain privileges. Dialogue is the turning point of the process during which further understanding of differences and possible tensions develops through experience and engagement with cultures outside of one’s own. Next, reflection allows for one to learn through introspection the values of those differences, as well as enables action within the world “in meaningful, effective, and responsible ways." This finally leads to action, which aims to create a more conscious world by working toward social justice and peace among different cultures. As Sorrells argues, “In the context of globalization, [intercultural praxis] … offers us a process of critical, reflective thinking and acting that enables us to navigate … intercultural spaces we inhabit interpersonally, communally, and globally."

The problems in intercultural communication usually come from problems in message transmission and in reception. In communication between people of the same culture, the person who receives the message interprets it based on values, beliefs, and expectations for behavior similar to those of the person who sent the message. When this happens, the way the message is interpreted by the receiver is likely to be fairly similar to what the speaker intended. However, when the receiver of the message is a person from a different culture, the receiver uses information from his or her culture to interpret the message. The message that the receiver interprets may be very different from what the speaker intended.

Nonverbal communication has been shown to account for between 65% and 93% of interpreted communication. Minor variations in body language, speech rhythms, and punctuality often cause mistrust and misperception of the situation among cross-cultural parties. This is where nonverbal communication can cause problems with intercultural communication. Misunderstandings with nonverbal communication can lead to miscommunication and insults with cultural differences. For example, a handshake in one culture may be recognized as appropriate, whereas another culture may recognize it as rude or inappropriate.

Effective communication depends on the informal understandings among the parties involved that are based on the trust developed between them. When trust exists, there is implicit understanding within communication, cultural differences may be overlooked, and problems can be dealt with more easily. The meaning of trust and how it is developed and communicated vary across societies. Similarly, some cultures have a greater propensity to be trusting than others.

The following types of theories can be distinguished in different strands: focus on effective outcomes, on accommodation or adaption, on identity negotiation and management, on communication networks,on acculturation and adjustment.






Voluntary assimilation has also been a part of history dating back to the Spanish Inquisition of the late 14th and 15th centuries, when many Muslims and Jews voluntarily converted to Roman Catholicism as a response to religious prosecution while secretly continuing their original practices. Another example is when the Europeans moved to the United States.

Intercultural communication is competent when it accomplishes the objectives in a manner that is appropriate to the context and relationship. Intercultural communication thus needs to bridge the dichotomy between appropriateness and effectiveness: Proper means of intercultural communication leads to a 15% decrease in miscommunication.


Competent communication is an interaction that is seen as effective in achieving certain rewarding objectives in a way that is also related to the context in which the situation occurs. In other words, it is a conversation with an achievable goal that is used at an appropriate time/location.

Intercultural communication can be linked with identity, which means the competent communicator is the person who can affirm others' avowed identities. As well as goal attainment is also a focus within intercultural competence and it involves the communicator to convey a sense of communication appropriateness and effectiveness in diverse cultural contexts.

Ethnocentrism plays a role in intercultural communication. The capacity to avoid ethnocentrism is the foundation of intercultural communication competence. Ethnocentrism is the inclination to view one's own group as natural and correct, and all others as aberrant.

People must be aware that to engage and fix intercultural communication there is no easy solution and there is not only one way to do so. Listed below are some of the components of intercultural competence.


The following are ways to improve communication competence:



Verbal communication consist of messages being sent and received continuously with the speaker and the listener, it is focused on the way messages are portrayed. Verbal communication is based on language and use of expression, the tone in which the sender of the message relays the communication can determine how the message is received and in what context.

Factors that affect verbal communication:


The way a message is received is dependent on these factors as they give a greater interpretation for the receiver as to what is meant by the message. By emphasizing a certain phrase with the tone of voice, this indicates that it is important and should be focused more on.

Along with these attributes, verbal communication is also accompanied with non-verbal cues. These cues make the message clearer and give the listener an indication of what way the information should be received.

Example of non-verbal cues


In terms of intercultural communication there are language barriers which are effected by verbal forms of communication. In this instance there is opportunity for miscommunication between two or more parties. Other barriers that contribute to miscommunication would be the type of words chosen in conversation. Due to different cultures there are different meaning in vocabulary chosen, this allows for a message between the sender and receiver to be misconstrued.

Nonverbal communication is behavior that communicates without words—though it often may be accompanied by words. Minor variations in body language, speech rhythms, and punctuality often cause differing interpretations of the situation among cross-cultural parties.

Kinesic behavior is communication through body movement—e.g., posture, gestures, facial expressions and eye contact. The meaning of such behavior varies across countries.

Occulesics are a form of kinesics that includes eye contact and the use of the eyes to convey messages.

Proxemics concern the influence of proximity and space on communication (e.g., in terms of personal space and in terms of office layout). For example, space communicates power in the US and Germany.

Paralanguage refers to how something is said, rather than the content of what is said—e.g., rate of speech, tone and inflection of voice, other noises, laughing, yawning, and silence.

Object language or material culture refers to how people communicate through material artifacts—e.g., architecture, office design and furniture, clothing, cars, cosmetics, and time. In monochronic cultures, time is experienced linearly and as something to be spent, saved, made up, or wasted. Time orders life, and people tend to concentrate on one thing at a time. In polychronic cultures, people tolerate many things happening simultaneously and emphasize involvement with people. In these cultures, people may be highly distractible, focus on several things at once, and change plans often.

Clothing and the way people dress is used as a form of nonverbal communication.

Cross-cultural communication endeavours to bring together such relatively unrelated areas as cultural anthropology and established areas of communication. Its core is to establish and understand how people from different cultures communicate with each other. Its charge is to also produce some guidelines with which people from different cultures can better communicate with each other.

Cross-cultural communication, as with many scholarly fields, is a combination of many other fields. These fields include anthropology, cultural studies, psychology and communication. The field has also moved both toward the treatment of interethnic relations, and toward the study of communication strategies used by co-cultural populations, i.e., communication strategies used to deal with majority or mainstream populations.

The study of languages other than one's own can serve not only to help one understand what we as humans have in common, but also to assist in the understanding of the diversity which underlines our languages' methods of constructing and organizing knowledge. Such understanding has profound implications with respect to developing a critical awareness of social relationships. Understanding social relationships and the way other cultures work is the groundwork of successful globalization business affairs.

Language socialization can be broadly defined as “an investigation of how language both presupposes and creates anew, social relations in cultural context”. It is imperative that the speaker understands the grammar of a language, as well as how elements of language are socially situated in order to reach communicative competence. Human experience is culturally relevant, so elements of language are also culturally relevant. One must carefully consider semiotics and the evaluation of sign systems to compare cross-cultural norms of communication. There are several potential problems that come with language socialization, however. Sometimes people can over-generalize or label cultures with stereotypical and subjective characterizations. Another primary concern with documenting alternative cultural norms revolves around the fact that no social actor uses language in ways that perfectly match normative characterizations. A methodology for investigating how an individual uses language and other semiotic activity to create and use new models of conduct and how this varies from the cultural norm should be incorporated into the study of language socialization.



</doc>
<doc id="394976" url="https://en.wikipedia.org/wiki?curid=394976" title="Culture shock">
Culture shock

Culture shock is an experience a person may have when one moves to a cultural environment which is different from one's own; it is also the personal disorientation a person may feel when experiencing an unfamiliar way of life due to immigration or a visit to a new country, a move between social environments, or simply transition to another type of life. One of the most common causes of culture shock involves individuals in a foreign environment. Culture shock can be described as consisting of at least one of four distinct phases: honeymoon, negotiation, adjustment, and adaptation. 

Common problems include: information overload, language barrier, generation gap, technology gap, skill interdependence, formulation dependency, homesickness (cultural), boredom (job dependency), response ability (cultural skill set). There is no true way to entirely prevent culture shock, as individuals in any society are personally affected by cultural contrasts differently.

During this period, the differences between the old and new culture are seen in a romantic light. For example, in moving to a new country, an individual might love the new food, the pace of life, and the locals' habits. During the first few weeks, most people are fascinated by the new culture. They associate with nationals who speak their language, and who are polite to the foreigners. Like most honeymoon periods, this stage eventually ends.

After some time (usually around three months, depending on the individual), differences between the old and new culture become apparent and may create anxiety. Excitement may eventually give way to unpleasant feelings of frustration and anger as one continues to experience unfavorable events that may be perceived as strange and offensive to one's cultural attitude. Language barriers, stark differences in public hygiene, traffic safety, food accessibility and quality may heighten the sense of disconnection from the surroundings.

While being transferred into a different environment puts special pressure on communication skills, there are practical difficulties to overcome, such as circadian rhythm disruption that often leads to insomnia and daylight drowsiness; adaptation of gut flora to different bacteria levels and concentrations in food and water; difficulty in seeking treatment for illness, as medicines may have different names from the native country's and the same active ingredients might be hard to recognize.

Still, the most important change in the period is communication: People adjusting to a new culture often feel lonely and homesick because they are not yet used to the new environment and meet people with whom they are not familiar every day. The language barrier may become a major obstacle in creating new relationships: special attention must be paid to one's and others' culture-specific body language signs, linguistic faux pas, conversation tone, linguistic nuances and customs, and false friends. 

In the case of students studying abroad, some develop additional symptoms of loneliness that ultimately affect their lifestyles as a whole. Due to the strain of living in a different country without parental support, international students often feel anxious and feel more pressure while adjusting to new cultures—even more so when the cultural distances are wide, as patterns of logic and speech are different and a special emphasis is put on rhetoric.

Again, after some time (usually 6 to 12 months), one grows accustomed to the new culture and develops routines. One knows what to expect in most situations and the host country no longer feels all that new. One becomes concerned with basic living again, and things become more "normal". One starts to develop problem-solving skills for dealing with the culture and begins to accept the culture's ways with a positive attitude. The culture begins to make sense, and negative reactions and responses to the culture are reduced.

In the mastery stage individuals are able to participate fully and comfortably in the host culture. Mastery does not mean total conversion; people often keep many traits from their earlier culture, such as accents and languages. It is often referred to as the bicultural stage.

Reverse culture shock (also known as "re-entry shock" or "own culture shock") may take place—returning to one's home culture after growing accustomed to a new one can produce the same effects as described above. These are results from the psychosomatic and psychological consequences of the readjustment process to the primary culture. The affected person often finds this more surprising and difficult to deal with than the original culture shock. This phenomenon, the reactions that members of the re-entered culture exhibit toward the re-entrant, and the inevitability of the two are encapsulated in the following saying, which is also the title of a book by Thomas Wolfe, "You Can't Go Home Again".

Reverse culture shock is generally made up of two parts: idealization and expectations. When an extended period of time is spent abroad we focus on the good from our past, cut out the bad, and create an idealized version of the past. Secondly, once removed from our familiar setting and placed in a foreign one we incorrectly assume that our previous world has not changed. We expect things to remain exactly the same as when we left them. The realization that life back home is now different, that the world has continued without us, and the process of readjusting to these new conditions as well as actualizing our new perceptions about the world with our old way of living causes discomfort and psychological anguish. 

There are three basic outcomes of the Adjustment Phase:

Culture shock has many different effects, time spans, and degrees of severity. Many people are handicapped by its presence and do not recognize what is bothering them.

Culture shock is a subcategory of a more universal construct called transition shock. Transition shock is a state of loss and disorientation predicated by a change in one's familiar environment that requires adjustment. There are many symptoms of transition shock, including:



</doc>
<doc id="4543340" url="https://en.wikipedia.org/wiki?curid=4543340" title="Cultural intelligence">
Cultural intelligence

Cultural intelligence or cultural quotient (CQ) is a term used in business, education, government and academic research. Cultural intelligence can be understood as the capability to relate and work effectively across cultures. Originally, the term cultural intelligence and the abbreviation "CQ" was developed by the research done by Soon Ang and Linn Van Dyne as a researched-based way of measuring and predicting intercultural performance.

The term is relatively recent: early definitions and studies of the concepts were given by P. Christopher Earley and Soon Ang in the book "Cultural Intelligence: Individual Interactions Across Cultures" (2003) and more fully developed later by David Livermore in the book, "Leading with Cultural Intelligence". The concept is related to that of cross-cultural competence. but goes beyond that to actually look at intercultural capabilities as a form of intelligence that can be measured and developed. According to Earley, Ang, and Van Dyne, cultural intelligence can be defined as "a person's capability to adapt as s/he interacts with others from different cultural
regions", and has behavioral, motivational, and metacognitive aspects. Without cultural intelligence, both business and military actors seeking to engage foreigners are susceptible to mirror imaging.

Cultural intelligence or CQ is measured on a scale, similar to that used to measure an individual's intelligence quotient. People with higher CQs are regarded as better able to successfully blend into any environment, using more effective business practices, than those with a lower CQ. CQ is assessed using the academically validated assessment created by Linn Van Dyne and Soon Ang. Both self-assessments and multi-rater assessments are available through the Cultural Intelligence Center in East Lansing, Michigan and the Center makes the CQ Scale available to other academic researchers at no charge. Research demonstrates that CQ is a consistent predictor of performance in multicultural settings. Cultural intelligence research has been cited and peer-reviewed in more than seventy academic journals. The research and application of cultural intelligence is being driven by the Cultural Intelligence Center in the U.S. and Nanyang Business School in Singapore. Additional research and application of cultural intelligence has been conducted by Liliana Gil Valletta, who holds the trademark for the term since 2013. Defined as the ability to be aware of, understand and apply cultural competence into everyday business decisions, Gil Valletta has expanded the definition of cultural intelligence into a capability that yields a commercial advantage by turning cultural trends into profits and P&L impact. Since 2010, the firm CIEN+ and data science platform Culturintel is the first using artificial intelligence and big data tools to report measures of cultural intelligence and enable corporations to embed inclusion for business growth.

Ang, Van Dyne, & Livermore describe four CQ capabilities: motivation (CQ Drive), cognition (CQ Knowledge), meta-cognition (CQ Strategy) and behavior (CQ Action). CQ Assessments report scores on all four capabilities as well as several sub-dimensions for each capability. The four capabilities stem from the intelligence-based approach to intercultural adjustment and performance.

CQ-Drive is a person's interest and confidence in functioning effectively in culturally diverse settings. It includes:

CQ-Knowledge is a person's knowledge about how cultures are similar and how cultures are different. It includes:

CQ-Strategy is how a person makes sense of culturally diverse experiences. It occurs when people make judgments about their own thought processes and those of others. It includes:

CQ-Action is a person's capability to adapt verbal and nonverbal behavior to make it appropriate to diverse cultures. It involves having a flexible repertoire of behavioral responses that suit a variety of situations. It includes:

Additional research on cultural intelligence is being conducted by academics around the globe, including research on culturally intelligent organizations, the correlation between neuroscience and the development of cultural intelligence, and situational judgment making and CQ Assessment.

Cultural intelligence, also known within business as "cultural quotient" or "CQ", is a theory within management and organisational psychology, positing that understanding the impact of an individual's cultural background on their behaviour is essential for effective business, and measuring an individual's ability to engage successfully in any environment or social setting.

Elaine Mosakowski and her husband Christopher Earley in the October 2004 issue of "Harvard Business Review" described cultural intelligence. CQ has been gaining acceptance throughout the business community. CQ teaches strategies to improve cultural perception in order to distinguish behaviours driven by culture from those specific to an individual, suggesting that allowing knowledge and appreciation of the difference to guide responses results in better business practice.

Since 2010 and as presented in academia, national television and other industry forums, Liliana Gil Valletta and the firm CIEN+ have expanded the definition and application of cultural intelligence from the individual to the organizational construct and architecture. Their model allows corporations and business teams to assess their level of cultural intelligence excellence index (Cix) based on how well they integrate cross-cultural analytics, insights, metrics, rewards, senior support, R&D and profit plans to make inclusion the default. As defined by Gil Valletta, traditional CQ focuses on achieving individual competence while Cix focuses on achieving commercial growth.

CQ is developed through:

Ilan Alon, Michele Boulange, Judith Meyer, and Vasyl Taras have developed a new survey they call the BCIQ (Business Cultural Intelligence Quotient). While not rooted in the academic literature of multiple loci of intelligence, the survey provides practitioners with a tool to reflect on their understanding for use in an international management context 

The only peer reviewed measurement of CQ is the multi-rater assessment developed by Soon Ang and Linn Van Dyne.

Cultural intelligence refers to the cognitive, motivational, and behavioral capacities to understand and effectively respond to the beliefs, values, attitudes, and behaviors of individuals and groups under complex and changing circumstances in order to effect a desired change. The application and integration of cultural intelligence into the workings and practices of local government is advanced by community planner, Anindita Mitra in 2016 as a way to improve the effectiveness of local governments to respond to and serve a growing and diverse population.

Cultural knowledge and warfare are bound together as cultural intelligence is central to ensuring successful military operations. Culture is composed of factors including language, society, economy, customs, history, and religion. For military operations, cultural intelligence concerns the ability to make decisions based an understanding of these factors.

In the military sense, cultural intelligence is a complicated pursuit of anthropology, psychology, communications, sociology, history, and above all, military doctrine.

Diplomacy is the conduct by governmental officials of negotiations and other relations between nations. The use of cultural intelligence and other methods of soft power have been endorsed and encouraged as a primary tool of statecraft as opposed to more coercive forms of national power; its further development is being stressed as a primary exercise of power as opposed to the expensive (politically and financial) coercive options such as military action or economic sanctions. For example, in 2007, US Secretary of Defense Robert Gates called for "strengthening our capacity to use 'soft' power and for better integrating it with 'hard' power," stating that using these other instruments "could make it less likely that military force will have to be used in the first place, as local problems might be dealt with before they become crises." In a speech in 2006, Secretary of State Condoleezza Rice urged similar actions in support of her doctrine of "transformational diplomacy;" she made a similar speech, again, in 2008.

Governmental negotiation and other diplomatic efforts can be made much more effective if knowledge of a peoples is understood and practiced with skill. Joseph Nye, a leading political scientist, asserts in his book "Soft Power" that "a country may obtain the outcomes it wants in world politics because other countries – admiring its values, emulating its example, aspiring to its level of prosperity and openness – want to follow it. In this sense, it is also important to set the agenda and attract others in world politics, and not only to force them to change by threatening military force or economic sanctions. This soft power – getting others to want the outcomes that you want – co-opts people rather than coerces them."

The sorts of effects Nye describes are much more effective if there is a willingness on the part of the influencing agent to respect and understand the other agent's cultural background. An example of diplomacy was a provision within the USA PATRIOT Act "condemning discrimination against Arab and Muslim Americans" response to the events of 9/11. This provision ensures the protection of U.S. Muslims and Arabs, ensures a distinction between them and those that committed those terrorist acts, and lives up to the ideals of the U.S. constitution of non-discrimination. This precedent sets up an attitude of an awareness of and respect for peaceful, law-abiding Muslims.

However, cultural intelligence can be used to the opposite effect. In 2006 and 2007, Russian president Vladimir Putin used his knowledge of German chancellor Angela Merkel and her fear of dogs to intimidate her during negotiations by bringing his Labrador Retriever, Koni.

Cultural Intelligence as a U.S. military term did not gain prominence until the late 20th century with the rise of low-intensity and counterinsurgency warfare. However, the importance of cultural intelligence has only recently become commonly accepted with the counterinsurgency campaigns the U.S. has conducted in Afghanistan and Iraq.

Since the Iraq War and the War in Afghanistan, cultural intelligence is being seen as playing a more important role in the success of military operations in counterinsurgency. The U.S. Army and Marine Corps Counterinsurgency Field manual is explicit on this point:

"Cultural knowledge is essential to waging a successful counterinsurgency," and goes further, urging "counterinsurgents… should strive to avoid imposing their ideals of normalcy on a foreign cultural problem."

The manual's logic is that the "primary goal of any COIN operation is to foster development of effective governance by legitimate government." And the manual points out that different cultures have different ideas of what legitimacy entails, and that operations at building legitimacy need to meet the host nation's peoples' criteria. Failure to recognize and respect a host nation's culture has resulted in the deaths of some NATO troops, and attempts have been made to make Afghans aware of Western culture and vice versa to mitigate some of these unintentional effects. But the cultural attitudes of the host nation's peoples aren't the only consideration. The culture of the insurgents is crucial as well – for that information helps to develop "effective programs that attack the insurgency's root causes." In this way, this information helps to shape counterinsurgent military operations.

To this effect, the U.S. Army developed the Human Terrain System in February 2007 to provide cultural information of host nations. The HTS program was the primary unified effort to provide this information to supplement military operations in areas where armed services were deployed. The program was also controversial, with the American Anthropological Association arguing that such efforts represented a conflict of interest and a possible violation of the ethical standards of anthropologists; but it was defended by others as ethical. The U.S. Army Human Terrain System ended operations in September 2014.





</doc>
<doc id="53169305" url="https://en.wikipedia.org/wiki?curid=53169305" title="Assessment culture">
Assessment culture

Assessment culture is a subset of organizational culture defined by the values, beliefs, and assumptions held by its members. In higher education, a positive assessment culture is characterized by trusting relationships, data-informed decision-making, a respect for the profession of teaching, and an internally-driven thirst for discovery about student learning. Positive assessment culture generally connotes the existence of conditions for collaboration among practitioners, reward structures, professional development opportunities for faculty and staff, student involvement, and a shared commitment among leaders to making institutional improvements that are sustainable.

Assessment culture may be revealed behaviorally through factors such as: celebration of successes, comprehensive program review, shared use of common terminology and language, provision of technical support, and use of affirmative messaging to effectively convey meaning. The culture of assessment has been measured by scholars of perceptions among faculty to determine motivations, sense of support, and levels of fear related to assessment.


</doc>
<doc id="13144407" url="https://en.wikipedia.org/wiki?curid=13144407" title="Cultural practice">
Cultural practice

Cultural practice generally refers to the manifestation of a culture or sub-culture, especially in regard to the traditional and customary practices of a particular ethnic or other cultural group. In the broadest sense, this term can apply to any person manifesting any aspect of any culture at any time. However, in practical usage it often refers to the traditional practices developed within specific ethnic cultures, especially those aspects of culture that have been practiced since ancient times.

The term is gaining in importance due to the increased controversy over "rights of cultural practice", which are protected in many jurisdictions for indigenous peoples and sometimes ethnic minorities. It is also a major component of the field of cultural studies, and is a primary focus of international works such as the United Nations declaration of the rights of indigenous Peoples.

Cultural practice is also a subject of discussion in questions of cultural survival. If an ethnic group retains its formal ethnic identity but loses its core cultural practices or the knowledge, resources, or ability to continue them, questions arise as to whether the culture is able to actually survive at all. International bodies such as the United Nations Permanent Forum on Indigenous Issues continually work on these issues, which are increasingly at the forefront of globalization questions.


The real question of what qualifies as a legitimate cultural practice is the subject of much legal and ethnic community debate. The question arises in controversial subject areas such as genital mutilation, indigenous hunting and gathering practices, and the question of licensing of traditional medical practitioners.

Many traditional cultures acknowledge members outside of their ethnicity as cultural practitioners, but only under special circumstances. Generally, the knowledge or title must be passed in a traditional way, such as family knowledge shared through adoption, or through a master of that practice choosing a particular student who shows qualities desired for that practice, and teaching that student in a hands-on manner, in which they are able to absorb the core values and belief systems of the culture. The degree to which these non-ethnic practitioners are able to exercise "customary and traditional" rights, and the degree to which their practice is acknowledged as valid, is often a subject of considerable debate among indigenous and other ethnic communities, and sometimes with the legal systems under which these communities function. The difference between bona fide non-native cultural practitioners and cultural piracy, or cultural appropriation, is a major issue within the study of globalization and modernization.

The evolution of traditional cultures is a subject of much discussion in legal, scholarly, and community forums. It is generally accepted that all cultures are to some degree in a continual state of sociocultural evolution. However, major questions surround the legitimacy of newly evolved cultural expressions, especially when these are influenced by modernization or by the influence of other cultures. Also, there is significant debate surrounding the source of evolution: for example, an indigenous community may accept the use of store-bought materials in the creation of traditional arts, but may reject requirements to apply for a permit for certain gathering purposes; the central difference being that one is an "internal" cultural evolution, while the other is "externally" driven by the society or legal body that surrounds the culture.


</doc>
<doc id="19159508" url="https://en.wikipedia.org/wiki?curid=19159508" title="Culture">
Culture

Culture () is the social behavior and norms found in human societies. Culture is considered a central concept in anthropology, encompassing the range of phenomena that are transmitted through social learning in human societies. Cultural universals are found in all human societies; these include expressive forms like art, music, dance, ritual, religion, and technologies like tool usage, cooking, shelter, and clothing. The concept of material culture covers the physical expressions of culture, such as technology, architecture and art, whereas the immaterial aspects of culture such as principles of social organization (including practices of political organization and social institutions), mythology, philosophy, literature (both written and oral), and science comprise the intangible cultural heritage of a society.

In the humanities, one sense of culture as an attribute of the individual has been the degree to which they have cultivated a particular level of sophistication in the arts, sciences, education, or manners. The level of cultural sophistication has also sometimes been used to distinguish civilizations from less complex societies. Such hierarchical perspectives on culture are also found in class-based distinctions between a high culture of the social elite and a low culture, popular culture, or folk culture of the lower classes, distinguished by the stratified access to cultural capital. In common parlance, culture is often used to refer specifically to the symbolic markers used by ethnic groups to distinguish themselves visibly from each other such as body modification, clothing or jewelry. Mass culture refers to the mass-produced and mass mediated forms of consumer culture that emerged in the 20th century. Some schools of philosophy, such as Marxism and critical theory, have argued that culture is often used politically as a tool of the elites to manipulate the lower classes and create a false consciousness, and such perspectives are common in the discipline of cultural studies. In the wider social sciences, the theoretical perspective of cultural materialism holds that human symbolic culture arises from the material conditions of human life, as humans create the conditions for physical survival, and that the basis of culture is found in evolved biological dispositions.

When used as a count noun, a "culture" is the set of customs, traditions, and values of a society or community, such as an ethnic group or nation. Culture is the set of knowledge acquired over time. In this sense, multiculturalism values the peaceful coexistence and mutual respect between different cultures inhabiting the same planet. Sometimes "culture" is also used to describe specific practices within a subgroup of a society, a subculture (e.g. "bro culture"), or a counterculture. Within cultural anthropology, the ideology and analytical stance of cultural relativism holds that cultures cannot easily be objectively ranked or evaluated because any evaluation is necessarily situated within the value system of a given culture.

The modern term "culture" is based on a term used by the Ancient Roman orator Cicero in his "Tusculanae Disputationes", where he wrote of a cultivation of the soul or "cultura animi," using an agricultural metaphor for the development of a philosophical soul, understood teleologically as the highest possible ideal for human development. Samuel Pufendorf took over this metaphor in a modern context, meaning something similar, but no longer assuming that philosophy was man's natural perfection. His use, and that of many writers after him, "refers to all the ways in which human beings overcome their original barbarism, and through artifice, become fully human."

In 1986, philosopher Edward S. Casey wrote, "The very word "culture" meant 'place tilled' in Middle English, and the same word goes back to Latin "colere", 'to inhabit, care for, till, worship' and "cultus", 'A cult, especially a religious one.' To be cultural, to have a culture, is to inhabit a place sufficiently intensive to cultivate it—to be responsible for it, to respond to it, to attend to it caringly."

Culture described by Richard Velkley: ... originally meant the cultivation of the soul or mind, acquires most of its later modern meaning in the writings of the 18th-century German thinkers, who were on various levels developing Rousseau's criticism of "modern liberalism and Enlightenment". Thus a contrast between "culture" and "civilization" is usually implied in these authors, even when not expressed as such.

In the words of anthropologist E.B. Tylor, it is "that complex whole which includes knowledge, belief, art, morals, law, custom and any other capabilities and habits acquired by man as a member of society." Alternatively, in a contemporary variant, "Culture is defined as a social domain that emphasizes the practices, discourses and material expressions, which, over time, express the continuities and discontinuities of social meaning of a life held in common.

The "Cambridge English Dictionary" states that culture is "the way of life, especially the general customs and beliefs, of a particular group of people at a particular time." Terror management theory posits that culture is a series of activities and worldviews that provide humans with the basis for perceiving themselves as "person[s] of worth within the world of meaning"—raising themselves above the merely physical aspects of existence, in order to deny the animal insignificance and death that "Homo sapiens" became aware of when they acquired a larger brain.

The word is used in a general sense as the evolved ability to categorize and represent experiences with symbols and to act imaginatively and creatively. This ability arose with the evolution of behavioral modernity in humans around 50,000 years ago, and is often thought to be unique to humans, although some other species have demonstrated similar, though much less complex, abilities for social learning. It is also used to denote the complex networks of practices and accumulated knowledge and ideas that is transmitted through social interaction and exist in specific human groups, or cultures, using the plural form.

It has been estimated from archaeological data that the human capacity for cumulative culture emerged somewhere between 500,000–170,000 years ago.

Raimon Panikkar identified 29 ways in which cultural change can be brought about, including growth, development, evolution, involution, renovation, reconception, reform, innovation, revivalism, revolution, mutation, progress, diffusion, osmosis, borrowing, eclecticism, syncretism, modernization, indigenization, and transformation. In this context, modernization could be viewed as adoption of Enlightenment era beliefs and practices, such as science, rationalism, industry, commerce, democracy, and the notion of progress. Rein Raud, building on the work of Umberto Eco, Pierre Bourdieu and Jeffrey C. Alexander, has proposed a model of cultural change based on claims and bids, which are judged by their cognitive adequacy and endorsed or not endorsed by the symbolic authority of the cultural community in question.

Cultural invention has come to mean any innovation that is new and found to be useful to a group of people and expressed in their behavior but which does not exist as a physical object. Humanity is in a global "accelerating culture change period," driven by the expansion of international commerce, the mass media, and above all, the human population explosion, among other factors. Culture repositioning means the reconstruction of the cultural concept of a society.
Cultures are internally affected by both forces encouraging change and forces resisting change. These forces are related to both social structures and natural events, and are involved in the perpetuation of cultural ideas and practices within current structures, which themselves are subject to change. (See structuration.)

Social conflict and the development of technologies can produce changes within a society by altering social dynamics and promoting new cultural models, and spurring or enabling generative action. These social shifts may accompany ideological shifts and other types of cultural change. For example, the U.S. feminist movement involved new practices that produced a shift in gender relations, altering both gender and economic structures. Environmental conditions may also enter as factors. For example, after tropical forests returned at the end of the last ice age, plants suitable for domestication were available, leading to the invention of agriculture, which in turn brought about many cultural innovations and shifts in social dynamics.

Cultures are externally affected via contact between societies, which may also produce—or inhibit—social shifts and changes in cultural practices. War or competition over resources may impact technological development or social dynamics. Additionally, cultural ideas may transfer from one society to another, through diffusion or acculturation. In diffusion, the form of something (though not necessarily its meaning) moves from one culture to another. For example, hamburgers, fast food in the United States, seemed exotic when introduced into China. "Stimulus diffusion" (the sharing of ideas) refers to an element of one culture leading to an invention or propagation in another. "Direct borrowing," on the other hand, tends to refer to technological or tangible diffusion from one culture to another. Diffusion of innovations theory presents a research-based model of why and when individuals and cultures adopt new ideas, practices, and products.

Acculturation has different meanings, but in this context it refers to replacement of the traits of one culture with those of another, such as what happened to certain Native American tribes and to many indigenous peoples across the globe during the process of colonization. Related processes on an individual level include assimilation (adoption of a different culture by an individual) and transculturation. The transnational flow of culture has played a major role in merging different culture and sharing thoughts, ideas, and beliefs.

Immanuel Kant (1724–1804) formulated an individualist definition of "enlightenment" similar to the concept of "bildung": "Enlightenment is man's emergence from his self-incurred immaturity." He argued that this immaturity comes not from a lack of understanding, but from a lack of courage to think independently. Against this intellectual cowardice, Kant urged: "Sapere aude", "Dare to be wise!" In reaction to Kant, German scholars such as Johann Gottfried Herder (1744–1803) argued that human creativity, which necessarily takes unpredictable and highly diverse forms, is as important as human rationality. Moreover, Herder proposed a collective form of "bildung": "For Herder, Bildung was the totality of experiences that provide a coherent identity, and sense of common destiny, to a people."
In 1795, the Prussian linguist and philosopher Wilhelm von Humboldt (1767–1835) called for an anthropology that would synthesize Kant's and Herder's interests. During the Romantic era, scholars in Germany, especially those concerned with nationalist movements—such as the nationalist struggle to create a "Germany" out of diverse principalities, and the nationalist struggles by ethnic minorities against the Austro-Hungarian Empire—developed a more inclusive notion of culture as "worldview" ("Weltanschauung"). According to this school of thought, each ethnic group has a distinct worldview that is incommensurable with the worldviews of other groups. Although more inclusive than earlier views, this approach to culture still allowed for distinctions between "civilized" and "primitive" or "tribal" cultures.

In 1860, Adolf Bastian (1826–1905) argued for "the psychic unity of mankind." He proposed that a scientific comparison of all human societies would reveal that distinct worldviews consisted of the same basic elements. According to Bastian, all human societies share a set of "elementary ideas" ("Elementargedanken"); different cultures, or different "folk ideas" ("Völkergedanken"), are local modifications of the elementary ideas. This view paved the way for the modern understanding of culture. Franz Boas (1858–1942) was trained in this tradition, and he brought it with him when he left Germany for the United States.

In the 19th century, humanists such as English poet and essayist Matthew Arnold (1822–1888) used the word "culture" to refer to an ideal of individual human refinement, of "the best that has been thought and said in the world." This concept of culture is also comparable to the German concept of "bildung": "...culture being a pursuit of our total perfection by means of getting to know, on all the matters which most concern us, the best which has been thought and said in the world."

In practice, "culture" referred to an elite ideal and was associated with such activities as art, classical music, and haute cuisine. As these forms were associated with urban life, "culture" was identified with "civilization" (from lat. "civitas", city). Another facet of the Romantic movement was an interest in folklore, which led to identifying a "culture" among non-elites. This distinction is often characterized as that between high culture, namely that of the ruling social group, and low culture. In other words, the idea of "culture" that developed in Europe during the 18th and early 19th centuries reflected inequalities within European societies.

Matthew Arnold contrasted "culture" with anarchy; other Europeans, following philosophers Thomas Hobbes and Jean-Jacques Rousseau, contrasted "culture" with "the state of nature." According to Hobbes and Rousseau, the Native Americans who were being conquered by Europeans from the 16th centuries on were living in a state of nature; this opposition was expressed through the contrast between "civilized" and "uncivilized." According to this way of thinking, one could classify some countries and nations as more civilized than others and some people as more cultured than others. This contrast led to Herbert Spencer's theory of Social Darwinism and Lewis Henry Morgan's theory of cultural evolution. Just as some critics have argued that the distinction between high and low cultures is really an expression of the conflict between European elites and non-elites, other critics have argued that the distinction between civilized and uncivilized people is really an expression of the conflict between European colonial powers and their colonial subjects.

Other 19th-century critics, following Rousseau, have accepted this differentiation between higher and lower culture, but have seen the refinement and sophistication of high culture as corrupting and unnatural developments that obscure and distort people's essential nature. These critics considered folk music (as produced by "the folk," i.e., rural, illiterate, peasants) to honestly express a natural way of life, while classical music seemed superficial and decadent. Equally, this view often portrayed indigenous peoples as "noble savages" living authentic and unblemished lives, uncomplicated and uncorrupted by the highly stratified capitalist systems of the West.

In 1870 the anthropologist Edward Tylor (1832–1917) applied these ideas of higher versus lower culture to propose a theory of the evolution of religion. According to this theory, religion evolves from more polytheistic to more monotheistic forms. In the process, he redefined culture as a diverse set of activities characteristic of all human societies. This view paved the way for the modern understanding of culture.

Although anthropologists worldwide refer to Tylor's definition of culture, in the 20th century "culture" emerged as the central and unifying concept of American anthropology, where it most commonly refers to the universal human capacity to classify and encode human experiences symbolically, and to communicate symbolically encoded experiences socially. American anthropology is organized into four fields, each of which plays an important role in research on culture: biological anthropology, linguistic anthropology, cultural anthropology, and in the United States, archaeology. The term "Kulturbrille", or "culture glasses," coined by German American anthropologist Franz Boas, refers to the "lenses" through which we see our own countries. Martin Lindstrom asserts that "Kulturbrille", which allow us to make sense of the culture we inhabit, also "can blind us to things outsiders pick up immediately."

The sociology of culture concerns culture as manifested in society. For sociologist Georg Simmel (1858–1918), culture referred to "the cultivation of individuals through the agency of external forms which have been objectified in the course of history." As such, culture in the sociological field can be defined as the ways of thinking, the ways of acting, and the material objects that together shape a people's way of life. Culture can be any of two types, non-material culture or material culture. Non-material culture refers to the non-physical ideas that individuals have about their culture, including values, belief systems, rules, norms, morals, language, organizations, and institutions, while material culture is the physical evidence of a culture in the objects and architecture they make or have made. The term tends to be relevant only in archeological and anthropological studies, but it specifically means all material evidence which can be attributed to culture, past or present.

Cultural sociology first emerged in Weimar Germany (1918–1933), where sociologists such as Alfred Weber used the term "Kultursoziologie" (cultural sociology). Cultural sociology was then "reinvented" in the English-speaking world as a product of the "cultural turn" of the 1960s, which ushered in structuralist and postmodern approaches to social science. This type of cultural sociology may be loosely regarded as an approach incorporating cultural analysis and critical theory. Cultural sociologists tend to reject scientific methods, instead hermeneutically focusing on words, artifacts and symbols. "Culture" has since become an important concept across many branches of sociology, including resolutely scientific fields like social stratification and social network analysis. As a result, there has been a recent influx of quantitative sociologists to the field. Thus, there is now a growing group of sociologists of culture who are, confusingly, not cultural sociologists. These scholars reject the abstracted postmodern aspects of cultural sociology, and instead look for a theoretical backing in the more scientific vein of social psychology and cognitive science. 

The sociology of culture grew from the intersection between sociology (as shaped by early theorists like Marx, Durkheim, and Weber) with the growing discipline of anthropology, wherein researchers pioneered ethnographic strategies for describing and analyzing a variety of cultures around the world. Part of the legacy of the early development of the field lingers in the methods (much of cultural sociological research is qualitative), in the theories (a variety of critical approaches to sociology are central to current research communities), and in the substantive focus of the field. For instance, relationships between popular culture, political control, and social class were early and lasting concerns in the field.

In the United Kingdom, sociologists and other scholars influenced by Marxism such as Stuart Hall (1932–2014) and Raymond Williams (1921–1988) developed cultural studies. Following nineteenth-century Romantics, they identified "culture" with consumption goods and leisure activities (such as art, music, film, food, sports, and clothing). They saw patterns of consumption and leisure as determined by relations of production, which led them to focus on class relations and the organization of production.

In the United States, cultural studies focuses largely on the study of popular culture; that is, on the social meanings of mass-produced consumer and leisure goods. Richard Hoggart coined the term in 1964 when he founded the Birmingham Centre for Contemporary Cultural Studies or CCCS. It has since become strongly associated with Stuart Hall, who succeeded Hoggart as Director. Cultural studies in this sense, then, can be viewed as a limited concentration scoped on the intricacies of consumerism, which belongs to a wider culture sometimes referred to as "Western civilization" or "globalism."

From the 1970s onward, Stuart Hall's pioneering work, along with that of his colleagues Paul Willis, Dick Hebdige, Tony Jefferson, and Angela McRobbie, created an international intellectual movement. As the field developed, it began to combine political economy, communication, sociology, social theory, literary theory, media theory, film/video studies, cultural anthropology, philosophy, museum studies, and art history to study cultural phenomena or cultural texts. In this field researchers often concentrate on how particular phenomena relate to matters of ideology, nationality, ethnicity, social class, and/or gender. Cultural studies is concerned with the meaning and practices of everyday life. These practices comprise the ways people do particular things (such as watching television, or eating out) in a given culture. It also studies the meanings and uses people attribute to various objects and practices. Specifically, culture involves those meanings and practices held independently of reason. Watching television in order to view a public perspective on a historical event should not be thought of as culture, unless referring to the medium of television itself, which may have been selected culturally; however, schoolchildren watching television after school with their friends in order to "fit in" certainly qualifies, since there is no grounded reason for one's participation in this practice.

In the context of cultural studies, the idea of a "text" includes not only written language, but also films, photographs, fashion or hairstyles: the texts of cultural studies comprise all the meaningful artifacts of culture. Similarly, the discipline widens the concept of "culture." "Culture" for a cultural-studies researcher not only includes traditional high culture (the culture of ruling social groups) and popular culture, but also everyday meanings and practices. The last two, in fact, have become the main focus of cultural studies. A further and recent approach is comparative cultural studies, based on the disciplines of comparative literature and cultural studies.

Scholars in the United Kingdom and the United States developed somewhat different versions of cultural studies after the late 1970s. The British version of cultural studies had originated in the 1950s and 1960s, mainly under the influence of Richard Hoggart, E.P. Thompson, and Raymond Williams, and later that of Stuart Hall and others at the Centre for Contemporary Cultural Studies at the University of Birmingham. This included overtly political, left-wing views, and criticisms of popular culture as "capitalist" mass culture; it absorbed some of the ideas of the Frankfurt School critique of the "culture industry" (i.e. mass culture). This emerges in the writings of early British cultural-studies scholars and their influences: see the work of (for example) Raymond Williams, Stuart Hall, Paul Willis, and Paul Gilroy.

In the United States, Lindlof and Taylor write, "Cultural studies [were] grounded in a pragmatic, liberal-pluralist tradition." The American version of cultural studies initially concerned itself more with understanding the subjective and appropriative side of audience reactions to, and uses of, mass culture; for example, American cultural-studies advocates wrote about the liberatory aspects of fandom. The distinction between American and British strands, however, has faded. Some researchers, especially in early British cultural studies, apply a Marxist model to the field. This strain of thinking has some influence from the Frankfurt School, but especially from the structuralist Marxism of Louis Althusser and others. The main focus of an orthodox Marxist approach concentrates on the "production" of meaning. This model assumes a mass production of culture and identifies power as residing with those producing cultural artifacts. In a Marxist view, those who control the means of production (the economic "base") essentially control a culture. Other approaches to cultural studies, such as feminist cultural studies and later American developments of the field, distance themselves from this view. They criticize the Marxist assumption of a single, dominant meaning, shared by all, for any cultural product. The non-Marxist approaches suggest that different ways of consuming cultural artifacts affect the meaning of the product. This view comes through in the book "Doing Cultural Studies: The Story of the Sony Walkman" (by Paul du Gay "et al."), which seeks to challenge the notion that those who produce commodities control the meanings that people attribute to them. Feminist cultural analyst, theorist, and art historian Griselda Pollock contributed to cultural studies from viewpoints of art history and psychoanalysis. The writer Julia Kristeva is among influential voices at the turn of the century, contributing to cultural studies from the field of art and psychoanalytical French feminism.

Petrakis and Kostis (2013) divide cultural background variables into two main groups:

In 2016, a new approach to culture was suggested by Rein Raud, who defines culture as the sum of resources available to human beings for making sense of their world and proposes a two-tiered approach, combining the study of texts (all reified meanings in circulation) and cultural practices (all repeatable actions that involve the production, dissemination or transmission of meanings), thus making it possible to re-link anthropological and sociological study of culture with the tradition of textual theory.

Starting from the 1990s, psychological research on culture influence is growing and challenges the universality assumed in general psychology. Culture psychologists try to answer whether the human mind is independent from culture. Some study explores the relationship between emotions and culture. For example, people from collectivistic culture, like Japanese, suppress their positive emotions more than their American counterpart. Culture may affect people emotional experience and expression. On the other hand, some researcher try to look for differences of people's personality across culture. As different culture dictate distinctive norms, culture shock is also studied to understand how people react when they are confronted with another culture. Besides, cognitive tools may not accessible or function differently cross culture. Raised from a culture without abacus trained people with distinctive reasoning style. Or, cultural lens may make people view the same outcome of events differently. Western are motivated for their success experience. In contrast, failures motivate East Asian to work even harder than success. Culture is important for psychologists to consider when understanding the human mental operation.






</doc>
<doc id="505730" url="https://en.wikipedia.org/wiki?curid=505730" title="Cultural assimilation">
Cultural assimilation

Cultural assimilation is the process in which a minority group or culture comes to resemble a dominant group or assume the values, behaviors, and beliefs of another group. A conceptualization describes cultural assimilation as similar to acculturation while another merely considers the former as one of the latter's phases. Assimilation could also involve the so-called additive acculturation wherein, instead of replacing the ancestral culture, an individual expands their existing cultural repertoire.

Cultural assimilation may involve either a quick or a gradual change depending on circumstances of the group. Full assimilation occurs when members of a society become indistinguishable from those of the dominant group.

Whether it is desirable for a given group to assimilate is often disputed by both members of the group and those of the dominant society. Cultural assimilation does not guarantee social alikeness. Geographical and other natural barriers between cultures, even if created by the dominant culture, may be culturally different.Cultural assimilation can happen either spontaneously or forcibly ("see forced assimilation"). A culture can spontaneously adopt a different culture. Also, older, richer, or otherwise more dominant cultures can forcibly absorb subordinate cultures.

The term “assimilation” is often used with regard to not only indigenous groups but also immigrants settled in a new land. A new culture and new attitudes toward the origin culture are obtained through contact and communication. Assimilation assumes that a relatively-tenuous culture gets to be united to one unified culture. That process happens by contact and accommodation between each culture. The current definition of assimilation is usually used to refer to immigrants, but in multiculturalism, cultural assimilation can happen all over the world and within varying social contexts and is not limited to specific areas. For example, a shared language gives people the chance to study and work internationally, without being limited to the same cultural group. People from different countries contribute to diversity and form the "global culture" which means the culture combined by the elements from different countries. That "global culture" can be seen as a part of assimilation, which causes cultures from different areas to affect one another.

During the 19th and 20th centuries, the Canadian government began a campaign to forcibly assimilate Aboriginals. The government consolidated power over Aboriginal land through treaties and the use of force, eventually isolating indigenous people to reserves. Marriage practices and spiritual ceremonies were banned, and spiritual leaders were imprisoned. Additionally, the Canadian government instituted an extensive residential school system to assimilate children. The Truth and Reconciliation Commission of Canada concluded that this effort was violent enough to amount to cultural genocide. The schools actively worked to alienate children from their cultural roots. Students were prohibited from speaking their native languages, were regularly abused, and were arranged marriages by the government after their graduation. The explicit goal of the Canadian government was to completely assimilate the Aboriginals into European culture and destroy all traces of their native history.

In January 2019, newly elected Brazil's president Jair Bolsonaro has stripped the indigenous affairs agency FUNAI of the responsibility to identify and demarcate indigenous lands. He argued that those territories have very tiny isolated populations and proposed to integrate them into the larger Brazilian society. According to the Survival International, "Taking responsibility for indigenous land demarcation away from FUNAI, the Indian affairs department, and giving it to the Agriculture Ministry is virtually a declaration of open warfare against Brazil’s tribal peoples."

Immigrant assimilation is a complex process in which immigrants not only fully integrate themselves into a new country but also lose aspects, perhaps even all of their heritage. Social scientists rely on four primary benchmarks to assess immigrant assimilation: socioeconomic status, geographic distribution, second language attainment, and intermarriage. William A.V. Clark defines immigrant assimilation as "a way of understanding the social dynamics of American society and that it is the process that occurs spontaneously and often unintended in the course of interaction between majority and minority groups."

There has been little to no existing research or evidence that demonstrates whether and how immigrant’s mobility gains—assimilating to a dominant country such as language ability, socioeconomic status etc.— causes changes in the perception of those who were born in the dominant country. This essential type of research provides information on how immigrants are accepted into dominant countries. In the article by Ariela Schachter titled “From “different” to “similar”: an experimental approach to understanding assimilation” a was given to white American citizens to view their perception of immigrants who now resided in the United States. The survey indicated the white’s tolerated immigrants in their home country. White natives are open to having “structural” relation with the immigrants-origin individuals, for instance, friends and neighbors; however, this was with the exception of black immigrants and natives and undocumented immigrants. However, at the same time, white Americans viewed all non-white Americans, regardless of legal status, as dissimilar.

A similar journal by Jens Hainmueller and Daniel J. Hopkins titled “The Hidden American Immigration Consensus: A Conjoint Analysis of Attitudes toward Immigrants” confirmed similar attitudes towards immigrants. The researchers used an experiment to reach their goal which was to test nine theoretical relevant attributes of hypothetical immigrants. Asking a population-based sample of U.S citizens to decide between pairs of immigrants applying for admission to the United States, the U.S citizen would see an application with information for two immigrants including notes about their education status, country, origin, and other attributes. The results showed American’s viewed educated immigrants in high-status jobs favorably, whereas they view the following groups unfavorably: those who lack plans to work, those who entered without authorization, those who do not speak fluent English and those of Iraqi descent.

As the number of international students entering the US has increased, so has the number of international students in US colleges and universities. The adaption of these newcomers is important in cross-cultural research. In the journal "Cross-Cultural Adaptation of International College Student in the United States" by Yikang Wang, the goal was to examine how the psychological and socio-cultural adaption of international college students varied over time. The survey contained a sample of 169 international students attending a coeducational public university. The two subtypes of adaption: psychological and socio-cultural were examined. Psychological adaption refers to "feelings of well-being or satisfaction during cross-cultural transitions;" while socio-cultural refers to the ability to fit into the new culture. The results show both graduate and undergraduate students showed both the satisfactory and socio-cultural skilled changed over time. Psychological adaption had the most significant change for a student who has resided in the US for at least 24 months while socio-cultural adaption steadily increased over time. It can be concluded that eventually over time, the minority group will shed some of their culture's characteristic when in a new country and incorporate new culture qualities. Also, it was confirmed that the more time spent in a new country would result in becoming more accustomed to the dominate countries aspects of characteristics.

Figure 2 demonstrates as the length of time resided in the United States increase—the dominant country, the life satisfaction and socio-cultural skill increase as well—positive correlation.

Similar to Wang's journal, "Cross-Cultural Adaptation of International College Student in the United States", in Viola Angelini's journal, "Life Satisfaction of Immigrant: Does cultural assimilation matter?", the theory of assimilation as being beneficial is confirmed. The goal of this study was to assess the difference between cultural assimilation and the subjective well-being of immigrants. The journal included a study that examined a "direct measure of assimilation with a host culture and immigrants' subjective well-being." Using data from the German Socio-Economic Panel, it was concluded that there was a positive correlation between cultural assimilation and an immigrant's life's satisfaction/wellbeing even after discarding factors such as employment status, wages, etc. "Life Satisfaction of Immigrant: Does cultural assimilation matter?" also confirms "association with life satisfaction is stronger for established immigrants than for recent ones." It was found that the more immigrants that identified with the German culture and who spoke the fluent national language—dominant country language, the more they reported to be satisfied with their lives. Life satisfaction rates were higher for those who had assimilated to the dominant country than those who had not assimilated since those who did incorporate the dominant language, religion, psychological aspects, etc.

One's willingness to assimilate is, surprisingly, not only based solely on their decision to adapt but other factors as well, such as how they’re introduced to the dominant country. In the study “Examination of cultural shock, inter-cultural sensitivity and willingness to adopt” by Clare D’Souza, the study uses a diary method to analyze the data collected. The study involved students undergoing a study abroad tour. The results show negative intercultural sensitivity is much greater in participants who experience "culture shock". Those who experience culture shock have emotional expression and responses of hostility, anger, negativity, anxiety frustration, isolation, and regression. Also, for one who has traveled to the country before(pre-travel) before permanently moving, they would have predetermined beliefs about the culture and their status within the country. The emotional expression for this individual includes excitement, happiness, eagerness, and euphoria. This article addresses each theme, pre-travel, culture shock, negative cultural sensitivity and positive cultural sensitivity, their perception, emotional expression and responses, their gender and the interpretation for the responses.

Similar to Clare D’Souza’s journal “Examination of cultural shock, inter-cultural sensitivity and willingness to adapt,” another journal titled “International Students from Melbourne Describing Their Cross-Cultural Transitions Experiences: Culture Shock, Social Interaction, and Friendship Development” by Nish Belford focuses on cultural shock. Belford interviewed international students to explore their experience after living and studying in Melbourne, Australia. The data collected were narratives from the students that focused on variables such as “cultural similarity, intercultural communication competence, intercultural friendship, and relational identity to influence their experiences.” The names of the students have been changed for privacy purposes. Jules, one of the students, stated “It's just the small things that bother me a lot. For example, if people are just walking on the floor with their shoes and then just lying on the bed with their shoes. It bothers me a lot because that's not part of my culture.” Man and Jeremy commented “Like yeah . . . I found few things as a culture shock. Like one of my housemates, once like she said I have a step-mother, so in India I was like in India we don’t have step-mothers - yes she was Aussie. And I mean this was one of those things. The way people speak was different.” Last, Jeremy described his experience as “Yeah, like in Chinese background we normally do not stare at people - when talking to people - so eye contact is quite different and when I walk down the street - like random people say hi, how are you? To me - so which I found it was quite interesting because we Chinese we don't do that, like when you stop someone and if you talk to strangers to China it can be considered that you want something from me - yeah. Yes, it is a completely different experience.” It is common that international students who come into a new country to study abroad are confronted with “strangeness.” This exert focuses only on culture shock and does not include the responses from the students about social interaction and friendship development.

Between 1880 and 1920, the United States took in roughly 24 million immigrants. This increase in immigration can be attributed to many historical changes. The beginning of the 21st century has also marked a massive era of immigration, and sociologists are once again trying to make sense of the impacts that immigration has on society and on the immigrants themselves.

Assimilation had various meanings in American sociology. Henry Pratt Fairchild associates American assimilation with Americanization or the "melting pot" theory. Some scholars also believed that assimilation and acculturation were synonymous. According to a common point of view, assimilation is a "process of interpretation and fusion" from another group or person. That may include memories, behaviors and sentiments. By sharing their experiences and histories, they blend into the common cultural life. A related theory is structural pluralism proposed by American sociologist Milton Gordon. It describes the American situation wherein despite the cultural assimilation of ethnic groups to mainstream American society, they maintained structural separation. Gordon maintained that there is limited integration of the immigrants into American social institutions such as educational, occupational, political, and social cliques.

The long history of immigration in the established gateways means that the place of immigrants in terms of class, racial, and ethnic hierarchies in the traditional gateways is more structured or established, but on the other hand, the new gateways do not have much immigration history and so the place of immigrants in terms of class, racial, and ethnic hierarchies is less defined, and immigrants may have more influence to define their position. Secondly, the size of new gateways may influence immigrant assimilation. Having a smaller gateway may influence the level of racial segregation among immigrants and native-born people. Thirdly, the difference in institutional arrangements may influence immigrant assimilation. Traditional gateways, unlike new gateways, have many institutions set up to help immigrants such as legal aid, bureaus, social organizations. Finally, Waters and Jimenez have only speculated that those differences may influence immigrant assimilation and the way researchers that should assess immigrant assimilation.

Canada's multicultural history dates back to its European colonization in the 16th century, when French settlers, British settlers, and indigenous peoples vied for control of the region.

Canada retains one of the largest immigrant populations in the world. The 2016 census recorded 7.5 million documented immigrants, representing a fifth of the country's total population. Focus has shifted from a rhetoric of cultural assimilation to cultural integration. In contrast to assimilation, integration aims to preserve the roots of a minority society while still allowing for smooth coexistence with the dominant

Culture-specific:



</doc>
<doc id="18964621" url="https://en.wikipedia.org/wiki?curid=18964621" title="Cultural competency training">
Cultural competency training

Cultural Competency Training is an instruction to achieve cultural competence and the ability to appreciate and interpret accurately other cultures.

Cultural competence refers to an ability to interact effectively with people of different cultures. Cultural competence comprises four components: (a) awareness of one's own cultural worldview, (b) attitude towards cultural differences, (c) knowledge of different cultural practices and worldviews, and (d) cross-cultural skills. Developing cultural competence results in an ability to understand, communicate with, and effectively interact with people across cultures and leads to a 15% decrease in miscommunication. Cultural Competency has a fundamental importance in every aspect of a work field and that includes school and government setting. With the amalgamation of different cultures in American society, it has become imperative for teachers and government employees to have some form of cultural competency training.

To cater to an increasingly globalized society, many hospitals, organizations, and employers may choose to implement forms of cultural competency training methods to enhance transparency between language, values, beliefs, and cultural differences. Training in cultural competence often includes careful consideration of how best to approach people's various forms of diversity. This new found awareness oftentimes allows military members, educators, medical practitioners, workers, and common citizens to establish equity in their environments and enhances interrelationships between one another for increased productivity levels. There have been numerous developed theories as to how best to conduct cultural competency training, which oftentimes is dependent on the specific environment and type of work.

When defining the ideas that surround cultural competence training, defining what culture is can help to understand the ideas that shape the concept. Culture is defined as the set of shared attitudes, values, goals, and practices that characterizes an institution or organization. When looking at culture in terms of cultural competence training, certain groups of individuals should be focused on because of their relevance to society. There are many groups that are marginalized and underrepresented; however, four specific areas to look at are:

LGBTQIA community, race, and religion. These areas, along with others, represent concepts that make up one’s identity. The approach to identity helps to shape the ideas and themes that go into cultural competence training.
The acronym LGBTQIAP stands for Lesbian, Gay, Bisexual, Transsexual, Transgender, Queer, Questioning, Intersex, and Asexual. This particular group of individuals has faced numerous obstacles and has historical events to highlight the inequalities they face such as the Stonewall riots. The Stonewall riots became a symbol for the gay liberation movement when police attempted a raid at the Stonewall Inn bar to arrest the gay and lesbian patrons and the gay community fought back. Numerous systemic oppressions historically and currently target LGBT individuals. Cultural competence training helps professionals develop knowledge and skills on how to address issues and be more aware on the type of language that is politically correct.

Race is a sensitive aspect of cultural competency training that requires professionals to be able to identify, acknowledge and value cultural differences. Training on this aspect of cultural competence teaches professionals that to ignore racial differences, is a form of microaggression that can help exacerbate racial inequalities. In order to begin to understand intercultural communications one must understand the historical and social context under which different cultural groups operate. For example, the history related to the cultural genocide of indigenous peoples in North America, understanding the said group’s value system, their ways of learning, and logic is essential in being able to understand how certain aspects of their culture may be similar or different from our own. Such distinction must be approached with respect and without ascribing superiority or inferiority to the difference.

Religious differences can play a role in how professionals interact and communicate with others. Religiosity refers to the nature and extent of public and private religious activity, including belief in God, prayer, and place of worship attendance. Religiosity is usually linked to formal religious traditions (such as Christianity), institutions (such as mosques), sacred texts (such as The Book of Mormon), and a definitive moral code (such as the Decalogue). Spirituality can be an important part of religion but can also exist independent of extant faith traditions, involving a variety of more individual subjective beliefs and activities related to the sacred. In this aspect of cultural competence training professionals should learn how to have religious competence. Religious competence refers to skills, practices, and orientations that recognize, explore, and harness patient religiosity to facilitate diagnosis, recovery, and healing. Religious competence involves the learning and deployment of generic competencies, including active listening and a nonjudgmental stance. It is also an overarching orientation, providing a safe place for discussion of religious issues and identities received in a humble, respectful, and empathetic manner.

in terms of nationality, particularly for people who are immigrants, the recent increase in global migration make them an increasingly common demographic everywhere. Though they will have varying cultures as well. In this aspect, it is important for those who are trained to understand both similarities and differences between them, and the individual they are helping. With this knowledge, it makes the process of aiding the individual more efficient, and successful. Both the past Nation the individual has come from, and their journey of immigration as an experience, can shape their mentality. To have specialists with specific nationalities help explain some differences is a helpful strategy. 

School is considered to be the second learning home for kids. Every year a large number of people come to the United States. These groups of people are often families, including small children. In today’s world, cultural competency plays a very vital role in shaping the kids future. In the United States, there is an underlying difference among parents as to how a kid should be raised, but it is clear that cultural competency should be taught at a young age. The United States is not the front runner in cultural competency training amongst children, as Canada and Australia are seemingly far more progressive in this sector. Cultural competency training can be a huge help for the families who are thinking of adopting a foster child, specifically, if that child was born outside of United States. A school is a mixture of different races and cultures and as an educator, one must be sensitive to everyone’s needs. Different cultures act uniquely to the different situations, and as an educator, one has to not only value diversity, but also have a strategy for everyone to feel welcomed.

Over the years, there have been new developed ways of practicing cultural competency in the workforce. There are many different methods that would allow assistance in cultural competency such as: Global leadership programs, international team building exercises and specific cross-cultural skills training for special executive positions. Having a good grasp on the many different cultures that exist is increasingly becoming a major principle in the workforce. The techniques for cultural competency training must be practiced more than just in class room lecture. Trainers must be extremely educated in this matter to be able to sufficiently train people. They must take notice of their own biases perspective and about the different types cultures that receive discrimination.

In the medical setting, effective communication between clinicians, patients, families and other health care providers is fundamental.

Health disparities refer to gaps in the quality of health and health care across racial, ethnic, and socioeconomic groups. Studies have demonstrated the multiple factors that contribute to health disparities.

Cultural Competence Online for Medical Practice (CCOMP) is an attempt in the United States to address one of the factors - the patient-doctor interaction. The CCOMP project is funded by a grant from the National Institutes of Health (NIH) through the National Heart Lung and Blood Institute (NHLBI). CCOMP offers a clinician's guide to reduce cardiovascular disparities, intended to create effective cross-cultural approaches to care for African-American patients with cardiovascular disease, especially hypertension. Videos with real patient scenarios and case-based modules are aimed at developing this increased awareness.




</doc>
<doc id="30963584" url="https://en.wikipedia.org/wiki?curid=30963584" title="Cultural consensus theory">
Cultural consensus theory

Cultural consensus theory is an approach to information pooling (aggregation, data fusion) which supports a framework for the measurement and evaluation of beliefs as cultural; shared to some extent by a group of individuals. Cultural consensus models guide the aggregation of responses from individuals to estimate (1) the culturally appropriate answers to a series of related questions (when the answers are unknown) and (2) individual competence (cultural competence) in answering those questions. The theory is applicable when there is sufficient agreement across people to assume that a single set of answers exists. The agreement between pairs of individuals is used to estimate individual cultural competence. Answers are estimated by weighting responses of individuals by their competence and then combining responses.

Cultural consensus theory assumes that cultural beliefs are learned and shared across people and that there is a common understanding of what the world and society are all about. Since the amount of information in a culture is too large for any one individual to master, individuals know different subsets of the cultural knowledge and vary in their cultural competence. Cultural beliefs are beliefs held by a majority of culture members. Given a set of questions, on the same topic, shared cultural beliefs or norms regarding the answers can be estimated by aggregating the responses across a sample of culture members. When agreement is close to absolute, estimating answers is straightforward. The problem addressed by cultural consensus theory is how to estimate beliefs when there is some degree of heterogeneity present in responses. In general, cultural consensus theory provides a framework for determining whether responses are sufficiently homogeneous to estimate a single set of shared answers, and then estimating the answers and individual cultural competence in answering the questions.

Cultural consensus models do not create consensus or explain why consensus exists; they simply facilitate the discovery and description of possible consensus. A high degree of agreement among raters must be present in responses in order to use consensus theory – only with high agreement does it make sense to aggregate responses to estimate beliefs of the group. Although there are statistical methods to evaluate whether agreement among raters is greater than chance (Binomial test, Friedman test, or Kendall’s coefficient of concordance), these methods do not provide a best estimate of the “true” answers nor do they estimate competence of the raters. Cultural consensus theory is able to estimate competence from the agreement between subjects and then, answers are estimated by “weighting” individual responses by competence prior to aggregation.

A very important feature in the aggregation of responses is that the combined responses of individuals will be more accurate than the responses of each individual included in the aggregation. Reliability theory in psychology (specifically, the reliability coefficient and the Spearman–Brown prediction formula) provides a mathematical estimate of the accuracy or validity of aggregated responses from the number of units being combined and the level of agreement among the units. In this case, accuracy of aggregated responses can be calculated from the number of subjects and the average Pearson correlation coefficient between all pairs of subjects (across questions).

To use cultural consensus theory, at least three assumptions must be met:

Cultural consensus theory encompasses formal and informal models. Practically speaking, these models are often used to estimate cultural beliefs, including the degree to which individuals report such beliefs. The formal cultural consensus model models the decision-making process for answering questions. This version is limited to categorical-type responses: multiple-choice type questions (including those with dichotomous true/false or yes/no responses) and responses to open-ended questions (with a single word or short phrase response for each question). This version of the model has a series of additional assumptions that must be met, i.e., no response bias. The formal model has direct parallels in signal detection theory and latent class analysis. An informal version of the model is available as a set of analytic procedures and obtains similar information with fewer assumptions. The informal model parallels a factor analysis on people (without rotation) and thus has similarities to Q factor analysis (as in Q Methodology). The informal version of the model can accommodate interval estimates and ranked response data. Both approaches provide estimates of the culturally correct answers and estimates of individual differences in the accuracy of reported information. 

One specific method of the formal version used in the analysis of data is the mathematical model, which is a set of logical axioms as well as derived propositions and assumptions that explain how empirical variables fit in the model's parameters. The informal model, on the other hand, uses reliability analysis.

Cultural competence is estimated from the similarity in responses between pairs of subjects since the agreement between a pair of respondents is a function of their individual competencies. In the formal model, similarity is the probability that matched responses occur (match method. or the probability of particular response combinations occur (covariance method). Simple match or covariance measures are then corrected for guessing and the proportion of positive responses, respectively. In the informal model, similarity is calculated with a Pearson correlation coefficient.

A matrix of agreement coefficients between all pairs of subjects is then factored with a minimum residual factoring method (principal axis factoring without rotation) to solve for the unknown competence values on the main diagonal. (For the informal model, the maximum likelihood factor analysis algorithm is preferred, but principal axis factoring can be used as well.) To determine whether the solution meets cultural consensus criteria, that only a single factor is present, a goodness of fit rule is used. If the ratio of the first to second eigenvalues is large with subsequently small values and all first factor loadings are positive, then it is assumed that the data contain only a single factor or a single response pattern.

Individual competence values are used to weight the responses and estimate the culturally correct answers. In the formal model, a confidence level (Bayesian adjusted probabilities) is obtained for each answer from the pattern of responses and the individual competence scores. In the informal model, responses are also weighted, using a linear model. When factoring a correlation matrix, the estimated answers appear as the first set of factor scores. Also, note that factor scores are usually provided as standardized variables (mean of zero), but may be transformed back to your original data collection units.

When used as a method for analysis, the cultural consensus theory allows the following: the determination whether the observed variability in knowledge is cultural; the measurement of cultural competence that each individual possesses; and, the determination of culturally correct knowledge.

Cultural Consensus analyses may be performed with software applications. The formal consensus model is currently only available in the software packages ANTHROPAC or UCINET. Analysis procedures for the informal model are available in most statistical packages. The informal model can be run within a factor analysis procedure, requesting the minimum-residual (principal axis factoring) algorithm method that solves for the missing diagonal without rotation. However, when factor analysis is used for consensus applications, ~~the data must be transposed, so that questions are the unit of analysis (the rows in a data matrix) and people are the variables~~ (the columns in the data matrix).

An advantage of cultural consensus is the availability of necessary sample size information and that necessary sample sizes do not need to be very large. Sample size determination in a consensus analysis is similar to other types of analyses; namely, that when variability is low, power is high and small samples will suffice. Here, variability is the agreement (competence) among subjects. For the formal model, sample size can be estimated from the level of agreement (e.g., assuming a low average competence level of .50), the proportion of items to be correctly classified (assuming a high level, .95), and high confidence (.999) a minimum sample size of 29 (per subgroup) is necessary.[1,5] For higher levels of competence and lower levels of accuracy and confidence, smaller samples sizes are necessary. Similarly, sample size can be estimated with reliability theory and the Spearman–Brown prophecy formula (applied to people instead of items). For a relatively low level of agreement (an average correlation of .25 between people, comparable to an average competence of .50) and a high degree of desired validity (.95 correlation between the estimated answers and the true answers), a study would require a minimum sample size of 30 subjects.

In summary, cultural consensus theory offers a framework for estimating cultural beliefs. A formal model is based on the decision-making process model of how questions are answered (with parameters for competence, response bias and guessing). The model proceeds from axioms and uses mathematical proofs to arrive at estimates of competence and answers to a series of questions. The informal model is a set of statistical procedures that provides similar information. Given a series of related questions, the agreement between people’s reported answers is used to estimate their cultural competence. Cultural competence is how much an individual knows or shares group beliefs. Since the extraction of individual competencies depends upon having a single factor solution, the ratio of the first and second eigenvalues (> 3:1) serves as a goodness-of-fit indicator that a single factor is present in the pattern of responses. Culturally correct answers are estimated by weighting and combining individuals’ responses.



</doc>
<doc id="32962014" url="https://en.wikipedia.org/wiki?curid=32962014" title="Cultural deprivation">
Cultural deprivation

Cultural deprivation is a theory in sociology where a person has inferior norms, values, skills and knowledge. The theory states that people of the working class experience cultural deprivation and this disadvantages them, as a result of which the gap between classes increases. 

For example, in education, lower-class students suffer from cultural deprivation as their parents do not know the best school for their child but middle-class parents know the system and so send their children to the best school for them. This puts the lower-class students at a disadvantage, thus increasing inequality and the gap between middle-class and lower-class students. 

Proponents of this theory argue that working class culture (regardless of race, gender, ethnicity or other factors) inherently differs from that of people in the middle class. This difference in culture means that while middle-class children can easily acquire cultural capital by observing their parents, working-class children cannot, and this deprivation is self-perpetuating.

The theory claims that the middle class gains cultural capital as the result of primary socialization, while the working class does not. Cultural capital helps the middle class succeed in society because their norms and values facilitate educational achievement and subsequent employability. Working class members of society that lack cultural capital do not pass it on to their children, perpetuating the class system. Middle-class children's cultural capital allows them to communicate with their middle-class teachers more effectively than working-class children and this contributes to social inequality.

Bourdieu claimed that state schools are set up to make everybody middle class, although only the middle class and some high achieving working class have the cultural capital to achieve this. From a Marxist perspective cultural deprivation observes that the resources available to the working class are limited and that working-class children enter school less-well prepared than others.




</doc>
<doc id="164660" url="https://en.wikipedia.org/wiki?curid=164660" title="Cultural diversity">
Cultural diversity

Cultural diversity is the quality of diverse or different cultures, as opposed to monoculture, the global monoculture, or a homogenization of cultures, akin to cultural decay. The phrase cultural diversity can also refer to having different cultures respect each other's differences. The phrase "cultural diversity" is also sometimes used to mean the variety of human societies or cultures in a specific region, or in the world as a whole. Globalization is often said to have a negative effect on the world's cultural diversity.

Diversity refers to the attributes that people use to confirm themselves with respect to others, “that person is different from me.” These attributes include demographic factors (such as race, gender, and age) as well as values and cultural norms. The many separate societies that emerged around the globe differs markedly from each other, and many of these differences persist to this day. The more obvious cultural differences that exist between people are language, dress and traditions, there are also significant variations in the way societies organize themselves, such as in their shared conception of morality, religious belief, and in the ways they interact with their environment. Cultural diversity can be seen as analogous to biodiversity.
By analogy with biodiversity, which is thought to be essential to the long-term survival of life on earth, it can be argued that cultural diversity may be vital for the long-term survival of humanity; and that the conservation of indigenous cultures may be as important to humankind as the conservation of species and ecosystems is to life in general. The General Conference of UNESCO took this position in 2001, asserting in Article 1 of the Universal Declaration on Cultural Diversity that "...cultural diversity is as necessary for humankind as biodiversity is for nature."

This position is rejected by some people, on several grounds. Firstly, like most evolutionary accounts of human nature, the importance of cultural diversity for survival may be an un-testable hypothesis, which can neither be proved nor disproved. Secondly, it can be argued that it is unethical deliberately to conserve "less developed" societies, because this will deny people within those societies the benefits of technological and medical advances enjoyed by those in the "developed" world.

In the same manner that the promotion of poverty in underdeveloped nations as "cultural diversity" is unethical. It is unethical to promote all religious practices simply because they are seen to contribute to cultural diversity. Particular religious practices are recognized by the WHO and UN as unethical, including female genital mutilation, polygamy, child brides, and human sacrifice.

With the onset of globalization, traditional nation-states have been placed under enormous pressures. Today, with the development of technology, information and capital are transcending geographical boundaries and reshaping the relationships between the marketplace, states and citizens. In particular, the growth of the mass media industry has largely impacted on individuals and societies across the globe. Although beneficial in some ways, this increased accessibility has the capacity to negatively affect a society's individuality. With information being so easily distributed throughout the world, cultural meanings, values and tastes run the risk of becoming homogenized. As a result, the strength of identity of individuals and societies may begin to weaken.

Some individuals, particularly those with strong religious beliefs, maintain that it is in the best interests of individuals and of humanity as a whole that all people adhere to a specific model for society or specific aspects of such a model.
Nowadays, communication between different countries becomes more and more frequent. And more and more students choose to study overseas for experiencing culture diversity. Their goal is to broaden their horizons and develop themselves from learning overseas. For example, according to Fengling, Chen, Du Yanjun, and Yu Ma's paper "Academic Freedom in the People's Republic of China and the United States Of America.", they pointed out that Chinese education more focus on "traditionally, teaching has consisted of spoon feeding, and learning has been largely by rote. China's traditional system of education has sought to make students accept fixed and ossified content." And "In the classroom, Chinese professors are the laws and authorities; Students in China show great respect to their teachers in general." On another hand, in United States of America education "American students treat college professors as equals." Also "American students' are encouraged to debate topics. The free open discussion on various topics is due to the academic freedom which most American colleges and universities enjoy." Discussion above gives us an overall idea about the differences between China and the United States on education. But we cannot simply judge which one is better, because each culture has its own advantages and features. Thanks to those difference forms the culture diversity and those make our world more colorful. For students who go abroad for education, if they can combine positive culture elements from two different cultures to their self-development, it would be a competitive advantage in their whole career. Especially, with current process of global economics, people who owned different perspectives on cultures stand at a more competitive position in current world.

Cultural diversity is difficult to quantify, but a good indication is thought to be a count of the number of languages spoken in a region or in the world as a whole. By this measure we may be going through a period of precipitous decline in the world's cultural diversity. Research carried out in the 1990s by David Crystal (Honorary Professor of Linguistics at the University of Wales, Bangor) suggested that at that time, on average, one language was falling into disuse every two weeks. He calculated that if that rate of the language death were to continue, then by the year 2100 more than 90% of the languages currently spoken in the world will have gone extinct.

Overpopulation, immigration and imperialism (of both the militaristic and cultural kind) are reasons that have been suggested to explain any such decline. However, it could also be argued that with the advent of globalism, a decline in cultural diversity is inevitable because information sharing often promotes homogeneity.

The Universal Declaration on Cultural Diversity adopted by UNESCO in 2001 is a legal instrument that recognizes cultural diversity as the "common heritage of humanity" and considers its safeguarding to be a concrete and ethical imperative inseparable from respect for human dignity.

Beyond the Declaration of Principles adopted in 2003 at the Geneva Phase of the World Summit on the information Society (WSIS), the UNESCO Convention on the Protection and Promotion of the Diversity of Cultural Expressions, adopted in October 2005, is a legally binding instrument to all States Parties to the Convention that recognizes

It was adopted in response to "growing pressure exerted on countries to waive their right to enforce cultural policies and to put all aspects of the cultural sector on the table when negotiating international trade agreements". To date, 116 member states as well as the European Union have ratified the Convention, except the US, Australia and Israel. States Parties recognize the specificity of cultural goods and services, as well as state sovereignty and public services in this area. Thought for world trade, this soft law instrument (meaning non-binding) clearly became a crucial reference to the definition of the European policy choice. In 2009, the European Court of Justice favoured a broad view of culture—beyond cultural values through the protection of film or the objective of promoting linguistic diversity yet previously recognized. On top of it, under this Convention, the EU and China have committed to fostering more balanced cultural exchanges, strengthening international cooperation and solidarity with business and trade opportunities in cultural and creative industries. The most motivating factor behind Beijing's willingness to work in partnership at business level might certainly be the access to creative talents and skills from foreign markets.

There is also the Convention for the Safeguarding of the Intangible Cultural Heritage ratified on June 20, 2007 by 78 states which said: 

Cultural diversity was also promoted by the Montreal Declaration of 2007, and by the European Union. The idea of a global multicultural heritage covers several ideas, which are not exclusive (see multiculturalism). In addition to language, diversity can also include religious or traditional practice.

On a local scale, Agenda 21 for culture, the first document of world scope that establishes the foundations for a commitment by cities and local governments to cultural development, supports local authorities committed to cultural diversity.

The defense of cultural diversity can take several meanings:

In a specific occasion of social life, or custom, cultural uniformity can be observed and displayed in behaviors of a community.

Cultural diversity is presented as the antithesis of cultural uniformity.

Some (including UNESCO) fear this hypothesis of a trend towards cultural uniformity. To support this argument they emphasize different aspects:

There are several international organizations that work towards protecting threatened societies and cultures, including Survival International and UNESCO. The UNESCO Universal Declaration on Cultural Diversity, adopted by 185 Member States in 2001, represents the first international standard-setting instrument aimed at preserving and promoting cultural diversity and intercultural dialogue.

Indeed, the notion of "cultural diversity" has been echoed by more neutral organizations, particularly within the UNESCO. Beyond the Declaration of Principles adopted in 2003 at the Geneva Phase of the World Summit on the information Society (WSIS), the UNESCO Convention on the Protection and Promotion of the Diversity of Cultural Expressions was adopted on 20 October 2005, but neither ratified by the US, Australia nor by Israel. It is instead a clear recognition of the specificity of cultural goods and services, as well as state sovereignty and public services in this area. Thought for world trade, this soft law instrument (strength in not binding) clearly became a crucial reference to the definition of the European policy choice. In 2009, the European Court of Justice favoured a broad view of culture—beyond cultural values—through the protection of film or the objective of promoting linguistic diversity yet previously recognized. On top of it, under this Convention, the EU and China have committed to fostering more balanced cultural exchanges, strengthening international cooperation and solidarity with business and trade opportunities in cultural and creative industries.

The European Commission-funded "Network of Excellence on "Sustainable Development in a Diverse World"" (known as "SUS.DIV") builds upon the UNESCO Declaration to investigate the relationship between cultural diversity and sustainable development.





</doc>
<doc id="323912" url="https://en.wikipedia.org/wiki?curid=323912" title="Cultural ecology">
Cultural ecology

Cultural ecology is the study of human adaptations to social and physical environments. Human adaptation refers to both biological and cultural processes that enable a population to survive and reproduce within a given or changing environment. This may be carried out diachronically (examining entities that existed in different epochs), or synchronically (examining a present system and its components). The central argument is that the natural environment, in small scale or subsistence societies dependent in part upon it, is a major contributor to social organization and other human institutions. In the academic realm, when combined with study of political economy, the study of economies as polities, it becomes political ecology, another academic subfield. It also helps interrogate historical events like the Easter Island Syndrome.

Anthropologist Julian Steward (1902-1972) coined the term, envisioning cultural ecology as a methodology for understanding how humans adapt to such a wide variety of environments. In his "Theory of Culture Change: The Methodology of Multilinear Evolution" (1955), cultural ecology represents the "ways in which culture change is induced by adaptation to the environment." A key point is that any particular human adaptation is in part historically inherited and involves the technologies, practices, and knowledge that allow people to live in an environment. This means that while the environment influences the character of human adaptation, it does not determine it. In this way, Steward wisely separated the vagaries of the environment from the inner workings of a culture that occupied a given environment. Viewed over the long term, this means that environment and culture are on more or less separate evolutionary tracks and that the ability of one to influence the other is dependent on how each is structured. It is this assertion - that the physical and biological environment affects culture - that has proved controversial, because it implies an element of environmental determinism over human actions, which some social scientists find problematic, particularly those writing from a Marxist perspective. Cultural ecology recognizes that ecological locale plays a significant role in shaping the cultures of a region.

Steward's method was to:


Steward's concept of cultural ecology became widespread among anthropologists and archaeologists of the mid-20th century, though they would later be critiqued for their environmental determinism. Cultural ecology was one of the central tenets and driving factors in the development of processual archaeology in the 1960s, as archaeologists understood cultural change through the framework of technology and its effects on environmental adaptation.

Cultural ecology as developed by Steward is a major subdiscipline of anthropology. It derives from the work of Franz Boas and has branched out to cover a number of aspects of human society, in particular the distribution of wealth and power in a society, and how that affects such behaviour as hoarding or gifting (e.g. the tradition of the potlatch on the Northwest North American coast).

One 2000s-era conception of cultural ecology is as a general theory that regards ecology as a paradigm not only for the natural and human sciences, but for cultural studies as well. In his "Die Ökologie des Wissens" (The Ecology of Knowledge), Peter Finke explains that this theory brings together the various cultures of knowledge that have evolved in history, and that have been separated into more and more specialized disciplines and subdisciplines in the evolution of modern science (Finke 2005). In this view, cultural ecology considers the sphere of human culture not as separate from but as interdependent with and transfused by ecological processes and natural energy cycles. At the same time, it recognizes the relative independence and self-reflexive dynamics of cultural processes. As the dependency of culture on nature, and the ineradicable presence of nature in culture, are gaining interdisciplinary attention, the difference between cultural evolution and natural evolution is increasingly acknowledged by cultural ecologists. Rather than genetic laws, information and communication have become major driving forces of cultural evolution (see Finke 2005, 2006). Thus, causal deterministic laws do not apply to culture in a strict sense, but there are nevertheless productive analogies that can be drawn between ecological and cultural processes.

Gregory Bateson was the first to draw such analogies in his project of an Ecology of Mind (Bateson 1973), which was based on general principles of complex dynamic life processes, e.g. the concept of feedback loops, which he saw as operating both between the mind and the world and within the mind itself. Bateson thinks of the mind neither as an autonomous metaphysical force nor as a mere neurological function of the brain, but as a "dehierarchized concept of a mutual dependency between the (human) organism and its (natural) environment, subject and object, culture and nature", and thus as "a synonym for a cybernetic system of information circuits that are relevant for the survival of the species." (Gersdorf/ Mayer 2005: 9).

Finke fuses these ideas with concepts from systems theory. He describes the various sections and subsystems of society as 'cultural ecosystems' with their own processes of production, consumption, and reduction of energy (physical as well as psychic energy). This also applies to the cultural ecosystems of art and of literature, which follow their own internal forces of selection and self-renewal, but also have an important function within the cultural system as a whole (see next section).

The interrelatedness between culture and nature has been a special focus of literary culture from its archaic beginnings in myth, ritual, and oral story-telling, in legends and fairy tales, in the genres of pastoral literature, nature poetry. Important texts in this tradition include the stories of mutual transformations between human and nonhuman life, most famously collected in Ovid’s Metamorphoses, which became a highly influential text throughout literary history and across different cultures. This attention to culture-nature interaction became especially prominent in the era of romanticism, but continues to be characteristic of literary stagings of human experience up to the present. 

The mutual opening and symbolic reconnection of culture and nature, mind and body, human and nonhuman life in a holistic and yet radically pluralistic way seems to be one significant mode in which literature functions and in which literary knowledge is produced. From this perspective, literature can itself be described as the symbolic medium of a particularly powerful form of "cultural ecology" (Zapf 2002). Literary texts have staged and explored, in ever new scenarios, the complex feedback relationship of prevailing cultural systems with the needs and manifestations of human and nonhuman "nature." From this paradoxical act of creative regression they have derived their specific power of innovation and cultural self-renewal.

German ecocritic Hubert Zapf argues that literature draws its cognitive and creative potential from a threefold dynamics in its relationship to the larger cultural system: as a "cultural-critical metadiscourse," an "imaginative counterdiscourse," and a "reintegrative interdiscourse" (Zapf 2001, 2002). It is a textual form which breaks up ossified social structures and ideologies, symbolically empowers the marginalized, and reconnects what is culturally separated. In that way, literature counteracts economic, political or pragmatic forms of interpreting and instrumentalizing human life, and breaks up one-dimensional views of the world and the self, opening them up towards their repressed or excluded other. Literature is thus, on the one hand, a sensorium for what goes wrong in a society, for the biophobic, life-paralyzing implications of one-sided forms of consciousness and civilizational uniformity, and it is, on the other hand, a medium of constant cultural self-renewal, in which the neglected biophilic energies can find a symbolic space of expression and of (re-)integration into the larger ecology of cultural discourses. This approach has been applied and widened in volumes of essays by scholars from over the world (ed. Zapf 2008, 2016), as well as in a recent monograph (Zapf 2016).

In geography, cultural ecology developed in response to the "landscape morphology" approach of Carl O. Sauer. Sauer's school was criticized for being unscientific and later for holding a "reified" or "superorganic" conception of culture. Cultural ecology applied ideas from ecology and systems theory to understand the adaptation of humans to their environment. These cultural ecologists focused on flows of energy and materials, examining how beliefs and institutions in a culture regulated its interchanges with the natural ecology that surrounded it. In this perspective humans were as much a part of the ecology as any other organism. Important practitioners of this form of cultural ecology include Karl Butzer and David Stoddart.

The second form of cultural ecology introduced decision theory from agricultural economics, particularly inspired by the works of Alexander Chayanov and Ester Boserup. These cultural ecologists were concerned with how human groups made decisions about how they use their natural environment. They were particularly concerned with the question of agricultural intensification, refining the competing models of Thomas Malthus and Boserup. Notable cultural ecologists in this second tradition include Harold Brookfield and Billie Lee Turner II. Starting in the 1980s, cultural ecology came under criticism from political ecology. Political ecologists charged that cultural ecology ignored the connections between the local-scale systems they studied and the global political economy. Today few geographers self-identify as cultural ecologists, but ideas from cultural ecology have been adopted and built on by political ecology, land change science, and sustainability science.

Books about culture and ecology began to emerge in the 1950s and 1960s. One of the first to be published in the United Kingdom was "The Human Species" by a zoologist, Anthony Barnett. It came out in 1950-subtitled "The biology of man" but was about a much narrower subset of topics. It dealt with the cultural bearing of some outstanding areas of environmental knowledge about health and disease, food, the sizes and quality of human populations, and the diversity of human types and their abilities. Barnett's view was that his selected areas of information "...are all topics on which knowledge is not only desirable, but for a twentieth-century adult, necessary". He went on to point out some of the concepts underpinning human ecology towards the social problems facing his readers in the 1950s as well as the assertion that human nature cannot change, what this statement could mean, and whether it is true. The third chapter deals in more detail with some aspects of human genetics.

Then come five chapters on the evolution of man, and the differences between groups of men (or races) and between individual men and women today in relation to population growth (the topic of 'human diversity'). Finally, there is a series of chapters on various aspects of human populations (the topic of "life and death"). Like other animals man must, in order to survive, overcome the dangers of starvation and infection; at the same time he must be fertile. Four chapters therefore deal with food, disease and the growth and decline of human populations.

Barnett anticipated that his personal scheme might be criticised on the grounds that it omits an account of those human characteristics, which distinguish humankind most clearly, and sharply from other animals. That is to say, the point might be expressed by saying that human behaviour is ignored; or some might say that human psychology is left out, or that no account is taken of the human mind. He justified his limited view, not because little importance was attached to what was left out, but because the omitted topics were so important that each needed a book of similar size even for a summary account. In other words, the author was embedded in a world of academic specialists and therefore somewhat worried about taking a partial conceptual, and idiosyncratic view of the zoology of "Homo sapiens".

Moves to produce prescriptions for adjusting human culture to ecological realities were also afoot in North America. Paul Sears, in his 1957 Condon Lecture at the University of Oregon, titled "The Ecology of Man," he mandated "serious attention to the ecology of man" and demanded "its skillful application to human affairs." Sears was one of the few prominent ecologists to successfully write for popular audiences. Sears documents the mistakes American farmers made in creating conditions that led to the disastrous Dust Bowl. This book gave momentum to the soil conservation movement in the United States.

During this same time was J.A. Lauwery's "Man's Impact on Nature", which was part of a series on 'Interdependence in Nature' published in 1969. Both Russel's and Lauwerys' books were about cultural ecology, although not titled as such. People still had difficulty in escaping from their labels. Even "Beginnings and Blunders", produced in 1970 by the polymath zoologist Lancelot Hogben, with the subtitle "Before Science Began", clung to anthropology as a traditional reference point. However, its slant makes it clear that 'cultural ecology' would be a more apt title to cover his wide-ranging description of how early societies adapted to environment with tools, technologies and social groupings. In 1973 the physicist Jacob Bronowski produced "The Ascent of Man", which summarised a magnificent thirteen part BBC television series about all the ways in which humans have moulded the Earth and its future.

By the 1980s the human ecological-functional view had prevailed. It had become a conventional way to present scientific concepts in the ecological perspective of human animals dominating an overpopulated world, with the practical aim of producing a greener culture. This is exemplified by I. G. Simmons' book "Changing the Face of the Earth", with its telling subtitle "Culture, Environment History" which was published in 1989. Simmons was a geographer, and his book was a tribute to the influence of W.L Thomas' edited collection, "Man's role in 'Changing the Face of the Earth" that came out in 1956.

Simmons' book was one of many interdisciplinary culture/environment publications of the 1970s and 1980s, which triggered a crisis in geography with regards its subject matter, academic sub-divisions, and boundaries. This was resolved by officially adopting conceptual frameworks as an approach to facilitate the organisation of research and teaching that cuts cross old subject divisions. Cultural ecology is in fact a conceptual arena that has, over the past six decades allowed sociologists, physicists, zoologists and geographers to enter common intellectual ground from the sidelines of their specialist subjects.

In the first decade of the 21st century, there are publications dealing with the ways in which humans can develop a more acceptable cultural relationship with the environment. An example is sacred ecology, a sub-topic of cultural ecology, produced by Fikret Berkes in 1999. It seeks lessons from traditional ways of life in Northern Canada to shape a new environmental perception for urban dwellers. This particular conceptualisation of people and environment comes from various cultural levels of local knowledge about species and place, resource management systems using local experience, social institutions with their rules and codes of behaviour, and a world view through religion, ethics and broadly defined belief systems.

Despite the differences in information concepts, all of the publications carry the message that culture is a balancing act between the mindset devoted to the exploitation of natural resources and that, which conserves them. Perhaps the best model of cultural ecology in this context is, paradoxically, the mismatch of culture and ecology that have occurred when Europeans suppressed the age-old native methods of land use and have tried to settle European farming cultures on soils manifestly incapable of supporting them. There is a sacred ecology associated with environmental awareness, and the task of cultural ecology is to inspire urban dwellers to develop a more acceptable sustainable cultural relationship with the environment that supports them.




</doc>
<doc id="13775689" url="https://en.wikipedia.org/wiki?curid=13775689" title="Cultural emphasis">
Cultural emphasis

Cultural emphasis is an important aspect of a culture which is often reflected though language and, more specifically, vocabulary (Ottenheimer, 2006, p. 266). This means that the vocabulary people use in a culture indicates what is important to that group of people. If there are a lot of words to describe a certain topic in a specific culture, then there is a good chance that that topic is considered important to that culture.

The idea of cultural emphasis is rooted form the work of Franz Boas, who is considered to be one of the founders of American Anthropology (Ottenheimer, 2006, p. 15). Franz Boas developed and taught concepts such as cultural relativism and the "cultural unconscious", which allowed anthropologists who studied under him, like Edward Sapir and Ruth Benedict, to further study and develop ideas on language and culture (Hart, 2005, p. 179).

One way in which cultural emphasis is exemplified is a populace talks about the weather. For example, in a place where it is cold and it snows a lot, a large collection of words to describe the snow would be expected.

In a place where it is hot, a cornucopia of associated terms would be expected.

A concentration of related terms for similar phenomena suggests the importance in distinguishing between them. Furthermore, if you are not from the area, or that culture, you might not have experienced or know the difference between, for example, a dry heat or a humid heat, when the difference may have huge implications for the outcome of a particular action.




</doc>
<doc id="8135793" url="https://en.wikipedia.org/wiki?curid=8135793" title="Cultural framework">
Cultural framework

Cultural framework is a term used in social science to explain traditions, value systems, myths and symbols that are common in a given society. A given society may have multiple cultural frameworks (for example, United States society has different cultural frameworks for its white and African American populations). Usually cultural frameworks are mixed; as certain individuals or entire groups can be familiar with many cultural frameworks.

There is an important relation between cultural frameworks and ideologies, as most successful ideologies are closely connected to cultural frameworks of societies they spread in. Cultural framework should not, however, be confused with ideology, as those concepts are separate. For example, in Nazi Germany, Nazism was an ideology, while religious beliefs, patriotism and traditions dating back to Germanic and Frankish tribes were part of the German cultural framework.



</doc>
<doc id="477975" url="https://en.wikipedia.org/wiki?curid=477975" title="Cultural identity">
Cultural identity

Cultural identity is the identity or feeling of belonging to a group. It is part of a person's self-conception and self-perception and is related to nationality, ethnicity, religion, social class, generation, locality or any kind of social group that has its own distinct culture. In this way, cultural identity is both characteristic of the individual but also of the culturally identical group of members sharing the same cultural identity or upbringing.

Cultural (and Ethnic) Identity is a subset of the communication theory of identity that establishes four "frames of identity" that allow us to view how we build identity. These frames include the personal frame, enactment of communication frame, relationship frame, and communal frame. The communal frame refers to the cultural constraints or the sense of "right" that people live by (which varies by cultural group). Therefore, Cultural (and Ethnic) Identity become central to a persons identity, how they see themselves and how they relate to the world. 

Various modern cultural studies and social theories have investigated cultural identity and understanding . In recent decades, a new form of identification has emerged which breaks down the understanding of the individual as a coherent whole subject into a collection of various cultural identifiers. These cultural identifiers may be the result of various conditions including: location, gender, race, history, nationality, language, sexuality, religious beliefs, ethnicity, aesthetics, and even food. As one author writes, recognizing both coherence and fragmentation:

The divisions between cultures can be very fine in some parts of the world, especially in rapidly changing cities where the population is ethnically diverse and social unity is based primarily on locational contiguity.

As a "historical reservoir," culture is an important factor in shaping identity. Since one of the main characteristics of a culture is its "historical reservoir," many if not all groups entertain revisions, either consciously or unconsciously, in their historical record in order to either bolster the strength of their cultural identity or to forge one which gives them precedent for actual reform or change. 
Some critics of cultural identity argue that the preservation of cultural identity, being based upon difference, is a divisive force in society, and that cosmopolitanism gives individuals a greater sense of shared citizenship. When considering practical association in international society, states may share an inherent part of their 'make up' that gives common ground and an alternative means of identifying with each other. Nations provide the framework for culture identities called external cultural reality, which influences the unique internal cultural realities of the individuals within the nation.

Also of interest is the interplay between cultural identity and new media.

Rather than necessarily representing an individual's interaction within a certain group, cultural identity may be defined by the social network of people imitating and following the social norms as presented by the media. Accordingly, instead of learning behaviour and knowledge from cultural/religious groups, individuals may be learning these social norms from the media to build on their cultural identity.

A range of cultural complexities structure the way individuals operate with the cultural realities in their lives. Nation is a large factor of the cultural complexity, as it constructs the foundation for individual's identity but it may contrast with ones cultural reality. Cultural identities are influenced by several different factors such as ones religion, ancestry, skin colour, language, class, education, profession, skill, family and political attitudes. These factors contribute to the development of one's identity.

Cultural identity is essentially how we as individuals cater to all positions of our lives. We may be teachers, students, friends, bosses, employees, etc. How we act and how our schemas contribute to our positions are the building blocks of your overall cultural identity.

It is also noted that an individual's "cultural arena", or place where one lives, impacts the culture that person chooses to abide by. The surroundings, the environment, the people in these places play a factor in how one feels about the culture they wish to adopt. Many immigrants find the need to change their culture in order to fit into the culture of most citizens in the country. This can conflict with an immigrant's current belief in their culture and might pose a problem, as the immigrant feels compelled to choose between the two presenting cultures.

Some might be able to adjust to the various cultures in the world by committing to two or more cultures. It is not required to stick to one culture. Many people socialize and interact with people in one culture in addition to another group of people in another culture. Thus cultural identity is able to take many forms and can change depending on the cultural area. The nature of the impact of cultural arena has changed with the advent of the Internet, bringing together groups of people with shared cultural interests who before would have been more likely to integrate into their real world cultural arena. This plasticity is what allows people to feel like part of society wherever they go.

Language develops from the wants of the people who tend to disperse themselves in a common given location over a particular period of time. This tends to allow people to share a way of life that generally links individuals in a certain culture that is identified by the people of that group. The affluence of communication that comes along with sharing a language promotes connections and roots to ancestors and cultural histories. Language can function as a fluid and ever changing identifier, and can be developed in response or rebellion of another cultural code, such as creole languages in the US . 

Language also includes the way people speak with peers, family members, authority figures, and strangers, including the tone and familiarity that is included in the language.

Language learning process can also be affected by cultural identity via the understanding of specific words, and the preference for specific words when learning and using a second language.

Since many aspects of a person's cultural identity can be changed, such as citizenship or influence from outside cultures can change cultural traditions, language is a main component of cultural identity.

Kevin McDonough pointed out, in his article, several factors concerning support or rejection of the government for different cultural identity education systems. Other authors have also shown concern for the state support regarding equity for children, school transitions and multicultural education. During March 1998, the two authors, Linda D. Labbo and Sherry L. Field collected several useful books and resources to promote multicultural education in South Africa.

Identity development among immigrant groups has been studied across a multi-dimensional view of acculturation. Dina Birman and Edison Trickett (2001) conducted a qualitative study through informal interviews with first-generation Soviet Jewish Refugee adolescents looking at the process of acculturation through three different dimensions: language competence, behavioral acculturation, and cultural identity. The results indicated that, “…acculturation appears to occur in a linear pattern over time for most dimensions of acculturation, with acculturation to the American culture increasing and acculturation to the Russian culture decreasing. However, Russian language competence for the parents did not diminish with length of residence in the country” (Birman & Trickett, 2001).

In a similar study, Phinney, Horencyzk, Liebkind, and Vedder (2001) focused on a model, which concentrates on the interaction between immigrant characteristics and the responses of the majority society in order to understand the psychological effects of immigration. The researchers concluded that most studies find that being bicultural, having a combination of having a strong ethnic and national identity, yields the best adaptation in the new country of residence. An article by LaFromboise, L. K. Colemna, and Gerton, reviews the literature on the impact of being bicultural. It is shown that it is possible to have the ability to obtain competence within two cultures without losing one’s sense of identity or having to identity with one culture over the other. (LaFromboise Et Al. 1993) The importance of ethnic and national identity in the educational adaptation of immigrants indicates that a bicultural orientation is advantageous for school performance (Portes & Rumbaut, 1990). Educators can assume their positions of power in beneficially impactful ways for immigrant students, by providing them with access to their native cultural support groups, classes, after–school activities, and clubs in order to help them feel more connected to both native and national cultures. It is clear that the new country of residence can impact immigrants’ identity development across multiple dimensions. Biculturalism can allow for a healthy adaptation to life and school. With many new immigrant youth, a school district in Alberta, Canada has gone as far as to partner with various agencies and professionals in an effort to aid the cultural adjustment of new Filipino immigrant youths . In the study cited, a combination of family workshops and teacher professional development aimed to improve the language learning and emotional development of these youths and families .

How great is "Achievement Loss Associated with the Transition to Middle School and High School"? John W. Alspaugh's research is in the September/October 1998 "Journal of Educational Research" (vol. 92, no. 1), 2026. Comparing three groups of 16 school districts, the loss was greater where the transition was from sixth grade than from a K-8 system. It was also greater when students from multiple elementary schools merged into a single middle school. Students from both K-8 and middle schools lost achievement in transition to high school, though this was greater for middle school students, and high school dropout rates were higher for districts with grades 6-8 middle schools than for those with K-8 elementary schools.

The Jean S. Phinney Three-Stage Model of Ethnic Identity Development is a widely accepted view of the formation of cultural identity. In this model cultural Identity is often developed through a three-stage process: unexamined cultural identity, cultural identity search, and cultural identity achievement.

Unexamined cultural identity: "a stage where one's cultural characteristics are taken for granted, and consequently there is little interest in exploring cultural issues." This for example is the stage one is in throughout their childhood when one doesn't distinguish between cultural characteristics of their household and others. Usually a person in this stage accepts the ideas they find on culture from their parents, the media, community, and others.

An example of thought in this stage: "I don't have a culture I'm just an American." "My parents tell me about where they lived, but what do I care? I've never lived there."

Cultural identity search: "is the process of exploration and questioning about one's culture in order to learn more about it and to understand the implications of membership in that culture." During this stage a person will begin to question why they hold their beliefs and compare it to the beliefs of other cultures. For some this stage may arise from a turning point in their life or from a growing awareness of other cultures. This stage is characterized by growing awareness in social and political forums and a desire to learn more about culture. This can be expressed by asking family members questions about heritage, visiting museums, reading of relevant cultural sources, enrolling in school courses, or attendance at cultural events. This stage might have an emotional component as well.

An example of thought in this stage: "I want to know what we do and how our culture is different from others." "There are a lot of non-Japanese people around me, and it gets pretty confusing to try and decide who I am."

Cultural identity achievement: "is characterized by a clear, confident acceptance of oneself and an internalization of one's cultural identity." In this stage people often allow the acceptance of their cultural identity play a role in their future choices such as how to raise children, how to deal with stereotypes and any discrimination, and approach negative perceptions. This usually leads to an increase in self-confidence and positive psychological adjustment

There is a set of phenomena that occur in conjunction between virtual culture – understood as the modes and norms of behaviour associated with the internet and the online world – and youth culture. While we can speak of a duality between the virtual (online) and real sphere (face-to-face relations), for youth, this frontier is implicit and permeable. On occasions – to the annoyance of parents and teachers – these spheres are even superposed, meaning that young people may be in the real world without ceasing to be connected.

In the present techno-cultural context, the relationship between the real world and the virtual world cannot be understood as a link between two independent and separate worlds, possibly coinciding at a pointghghg, but as a Moebius strip where there exists no inside and outside and where it is impossible to identify limits between both. For new generations, to an ever-greater extent, digital life merges with their home life as yet another element of nature. In this naturalizing of digital life, the learning processes from that environment are frequently mentioned not just since they are explicitly asked but because the subject of the internet comes up spontaneously among those polled. The ideas of active learning, of googling 'when you don’t know', of recourse to tutorials for 'learning' a programme or a game, or the expression 'I learnt English better and in a more entertaining way by playing' are examples often cited as to why the internet is the place most frequented by the young people polled.

The internet is becoming an extension of the expressive dimension of the youth condition. There, youth talk about their lives and concerns, design the content that they make available to others and assess others reactions to it in the form of optimized and electronically mediated social approval. Many of today's youth go through processes of affirmation procedures and is often the case for how youth today grow dependency for peer approval. When connected, youth speak of their daily routines and lives. With each post, image or video they upload, they have the possibility of asking themselves who they are and to try out profiles differing from those they assume in the ‘real’ world. The connections they feel in more recent times have become much less interactive through personal means compared to past generations. The influx of new technology and access has created new fields of research on effects on teens and young adults. They thus negotiate their identity and create senses of belonging, putting the acceptance and censure of others to the test, an essential mark of the process of identity construction.

Youth ask themselves about what they think of themselves, how they see themselves personally and, especially, how others see them. On the basis of these questions, youth make decisions which, through a long process of trial and error, shape their identity. This experimentation is also a form through which they can think about their insertion, membership and sociability in the ‘real’ world.

From other perspectives, the question arises on what impact the internet has had on youth through accessing this sort of ‘identity laboratory’ and what role it plays in the shaping of youth identity. On the one hand, the internet enables young people to explore and perform various roles and personifications while on the other, the virtual forums – some of them highly attractive, vivid and absorbing (e.g. video games or virtual games of personification) – could present a risk to the construction of a stable and viable personal identity.



</doc>
<doc id="6267" url="https://en.wikipedia.org/wiki?curid=6267" title="Cultural imperialism">
Cultural imperialism

Cultural imperialism comprises the cultural aspects of imperialism. “Imperialism” here refers to the creation and maintenance of unequal relationships between civilizations, favoring a more powerful civilization. Thus, cultural imperialism is the practice of promoting and imposing a culture, usually that of a politically powerful nation, over a less powerful society; in other words, the cultural hegemony of industrialized or economically influential countries which determine general cultural values and standardize civilizations throughout the world. The term is employed especially in the fields of history, cultural studies, and postcolonial theory. It is usually used in a pejorative sense, often in conjunction with calls to reject such influence. Cultural imperialism can take various forms, such as an attitude, a formal policy, or military action, insofar as it reinforces cultural hegemony.

Although the "Oxford English Dictionary" has a 1921 reference to the "cultural imperialism of the Russians", John Tomlinson, in his book on the subject, writes that the term emerged in the 1960s and has been a focus of research since at least the 1970s. Terms such as "media imperialism", "structural imperialism", "cultural dependency and domination", "cultural synchronization", "electronic colonialism", "ideological imperialism", and "economic imperialism" have all been used to describe the same basic notion of cultural imperialism.

Various academics give various definitions of the term. American media critic Herbert Schiller wrote: "The concept of cultural imperialism today [1975] best describes the sum of the processes by which a society is brought into the modern world system and how its dominating stratum is attracted, pressured, forced, and sometimes bribed into shaping social institutions to correspond to, or even promote, the values and structures of the dominating centre of the system. The public media are the foremost example of operating enterprises that are used in the penetrative process. For penetration on a significant scale the media themselves must be captured by the dominating/penetrating power. This occurs largely through the commercialization of broadcasting."

Tom McPhail defined "Electronic colonialism as the dependency relationship established by the importation of communication hardware, foreign-produced software, along with engineers, technicians, and related information protocols, that vicariously establish a set of foreign norms, values, and expectations which, in varying degrees, may alter the domestic cultures and socialization processes." Sui-Nam Lee observed that "communication imperialism can be defined as the process in which the ownership and control over the hardware and software of mass media as well as other major forms of communication in one country are singly or together subjugated to the domination of another country with deleterious effects on the indigenous values, norms and culture." Ogan saw "media imperialism often described as a process whereby the United States and Western Europe produce most of the media products, make the first profits from domestic sales, and then market the products in Third World countries at costs considerably lower than those the countries would have to bear to produce similar products at home."

Downing and Sreberny-Mohammadi state: "Imperialism is the conquest and control of one country by a more powerful one. Cultural imperialism signifies the dimensions of the process that go beyond economic exploitation or military force. In the history of colonialism, (i.e., the form of imperialism in which the government of the colony is run directly by foreigners), the educational and media systems of many Third World countries have been set up as replicas of those in Britain, France, or the United States and carry their values. Western advertising has made further inroads, as have architectural and fashion styles. Subtly but powerfully, the message has often been insinuated that Western cultures are superior to the cultures of the Third World."
Needless to say, all these authors agree that cultural imperialism promotes the interests of certain circles within the imperial powers, often to the detriment of the target societies.

The issue of cultural imperialism emerged largely from communication studies. However, cultural imperialism has been used as a framework by scholars to explain phenomena in the areas of international relations, anthropology, education, science, history, literature, and sports.

Many of today's academics that employ the term, "cultural imperialism," are heavily informed by the work of Foucault, Derrida, Said, and other poststructuralist and postcolonialist theorists. Within the realm of postcolonial discourse, "cultural imperialism" can be seen as the cultural legacy of colonialism, or forms of social action contributing to the continuation of Western hegemony. To some outside of the realm of this discourse, the term is critiqued as being unclear, unfocused, and/or contradictory in nature.

The work of French philosopher and social theorist Michel Foucault has heavily influenced use of the term "cultural imperialism," particularly his philosophical interpretation of power and his concept of governmentality.

Following an interpretation of power similar to that of Machiavelli, Foucault defines power as immaterial, as a "certain type of relation between individuals" that has to do with complex strategic social positions that relate to the subject's ability to control its environment and influence those around itself. According to Foucault, power is intimately tied with his conception of truth. "Truth", as he defines it, is a "system of ordered procedures for the production, regulation, distribution, circulation, and operation of statements" which has a "circular relation" with systems of power. Therefore, inherent in systems of power, is always "truth", which is culturally specific, inseparable from ideology which often coincides with various forms of hegemony. "Cultural imperialism" may be an example of this.

Foucault's interpretation of governance is also very important in constructing theories of transnational power structure. In his lectures at the Collège de France, Foucault often defines governmentality as the broad art of "governing", which goes beyond the traditional conception of governance in terms of state mandates, and into other realms such as governing "a household, souls, children, a province, a convent, a religious order, a family". This relates directly back to Machiavelli's The Prince, and Foucault's aforementioned conceptions of truth and power. (i.e. various subjectivities are created through power relations that are culturally specific, which lead to various forms of culturally specific governmentality such as neoliberal governmentality.)

Informed by the works of Noam Chomsky, Foucault, and Antonio Gramsci, Edward Saïd is a founding figure of postcolonialism, established with the book "Orientalism" (1978), a humanist critique of The Enlightenment, which criticizes Western knowledge of "The East"—specifically the English and the French constructions of what is and what is not "Oriental". Whereby said "knowledge" then led to cultural tendencies towards a binary opposition of the Orient vs. the Occident, wherein one concept is defined in opposition to the other concept, and from which they emerge as of unequal value. In "Culture and Imperialism" (1993), the sequel to "Orientalism", Saïd proposes that, despite the formal end of the “age of empire” after the Second World War (1939–45), colonial imperialism left a cultural legacy to the (previously) colonized peoples, which remains in their contemporary civilizations; and that said "cultural imperialism" is very influential in the international systems of power.

A self-described "practical Marxist-feminist-deconstructionist" Gayatri Chakravorty Spivak has published a number of works challenging the "legacy of colonialism" including "A Critique of Postcolonial Reason: Towards a History of the Vanishing Present" (1999), "Other Asias" (2005), and "Can the Subaltern Speak?" (1988).

In "Can the Subaltern Speak?" Spivak critiques common representations in the West of the Sati, as being controlled by authors other than the participants (specifically English colonizers and Hindu leaders). Because of this, Spivak argues that the subaltern, referring to the communities that participate in the Sati, are not able to represent themselves through their own voice. Spivak says that cultural imperialism has the power to disqualify or erase the knowledge and mode of education of certain populations that are low on the social hierarchy.

Throughout "Can the Subaltern Speak?", Spivak cites the works of Karl Marx, Michel Foucault, Walter Benjamin, Louis Althusser, Jacques Derrida, and Edward Said, among others.

In "A critique of Postcolonial Reason", Spivak argues that Western philosophy has a history of not only exclusion of the subaltern from discourse, but also does not allow them to occupy the space of a fully human subject.

"Cultural imperialism" can refer to either the forced acculturation of a subject population, or to the voluntary embracing of a foreign culture by individuals who do so of their own free will. Since these are two very different referents, the validity of the term has been called into question.

Cultural influence can be seen by the "receiving" culture as either a threat to or an enrichment of its cultural identity. It seems therefore useful to distinguish between cultural imperialism as an (active or passive) attitude of superiority, and the position of a culture or group that seeks to complement its own cultural production, considered partly deficient, with imported products.

The imported products or services can themselves represent, or be associated with, certain values (such as consumerism). According to one argument, the "receiving" culture does not necessarily perceive this link, but instead absorbs the foreign culture passively through the use of the foreign goods and services. Due to its somewhat concealed, but very potent nature, this hypothetical idea is described by some experts as ""banal imperialism"." For example, it is argued that while "American companies are accused of wanting to control 95 percent of the world's consumers", "cultural imperialism involves much more than simple consumer goods; it involved the dissemination of American principles such as freedom and democracy", a process which "may sound appealing" but which "masks a frightening truth: many cultures around the world are disappearing due to the overwhelming influence of corporate and cultural America".

Some believe that the newly globalised economy of the late 20th and early 21st century has facilitated this process through the use of new information technology. This kind of cultural imperialism is derived from what is called "soft power". The theory of electronic colonialism extends the issue to global cultural issues and the impact of major multi-media conglomerates, ranging from Viacom, Time-Warner, Disney, News Corp, to Google and Microsoft with the focus on the hegemonic power of these mainly United States-based communication giants.

One of the reasons often given for opposing any form of cultural imperialism, voluntary or otherwise, is the preservation of cultural diversity, a goal seen by some as analogous to the preservation of ecological diversity. Proponents of this idea argue either that such diversity is valuable in itself, to preserve human historical heritage and knowledge, or instrumentally valuable because it makes available more ways of solving problems and responding to catastrophes, natural or otherwise.

Of all the areas of the world that scholars have claimed to be adversely affected by imperialism, Africa is probably the most notable. In the expansive "age of imperialism" of the nineteenth century, scholars have argued that European colonization in Africa has led to the elimination of many various cultures, worldviews, and epistemologies, particularly through neocolonization of public education. This, arguably has led to uneven development, and further informal forms of social control having to do with culture and imperialism. A variety of factors, scholars argue, lead to the elimination of cultures, worldviews, and epistemologies, such as "de-linguicization" (replacing native African languages with European ones), devaluing ontologies that are not explicitly individualistic, and at times going as far as to not only define Western culture itself as science, but that non-Western approaches to science, the Arts, indigenous culture, etc. are not even knowledge. One scholar, Ali A. Abdi, claims that imperialism inherently "involve[s] extensively interactive regimes and heavy contexts of identity deformation, misrecognition, loss of self-esteem, and individual and social doubt in self-efficacy."(2000: 12) Therefore, all imperialism would always, already be cultural.

Neoliberalism is often critiqued by sociologists, anthropologists, and cultural studies scholars as being culturally imperialistic. Critics of neoliberalism, at times, claim that it is the newly predominant form of imperialism. Other Scholars, such as Elizabeth Dunn and Julia Elyachar have claimed that neoliberalism requires and creates its own form of governmentality.

In Dunn's work, "Privatizing Poland", she argues that the expansion of the multinational corporation, Gerber, into Poland in the 1990s imposed Western, neoliberal governmentality, ideologies, and epistemologies upon the post-soviet persons hired. Cultural conflicts occurred most notably the company's inherent individualistic policies, such as promoting competition among workers rather than cooperation, and in its strong opposition to what the company owners claimed was bribery.

In Elyachar's work, "Markets of Dispossession", she focuses on ways in which, in Cairo, NGOs along with INGOs and the state promoted neoliberal governmentality through schemas of economic development that relied upon "youth microentrepreneurs." Youth microentrepreneurs would receive small loans to build their own businesses, similar to the way that microfinance supposedly operates. Elyachar argues though, that these programs not only were a failure, but that they shifted cultural opinions of value (personal and cultural) in a way that favored Western ways of thinking and being.

Often, methods of promoting development and social justice to are critiqued as being imperialistic, in a cultural sense. For example, Chandra Mohanty has critiqued Western feminism, claiming that it has created a misrepresentation of the "third world woman" as being completely powerless, unable to resist male dominance. Thus, this leads to the often critiqued narrative of the "white man" saving the "brown woman" from the "brown man." Other, more radical critiques of development studies, have to do with the field of study itself. Some scholars even question the intentions of those developing the field of study, claiming that efforts to "develop" the Global South were never about the South itself. Instead, these efforts, it is argued, were made in order to advance Western development and reinforce Western hegemony.

The core of cultural imperialism thesis is integrated with the political-economy traditional approach in media effects research. Critics of cultural imperialism commonly claim that non-Western cultures, particularly from the Third World, will forsake their traditional values and lose their cultural identities when they are solely exposed to Western media. Nonetheless, Michael B. Salwen, in his book "Critical Studies in Mass Communication" (1991), claims that cross-consideration and integration of empirical findings on cultural imperialist influences is very critical in terms of understanding mass media in the international sphere. He recognizes both of contradictory contexts on cultural imperialist impacts. 
The first context is where cultural imperialism imposes socio-political disruptions on developing nations. Western media can distort images of foreign cultures and provoke personal and social conflicts to developing nations in some cases. 
Another context is that peoples in developing nations resist to foreign media and preserve their cultural attitudes. Although he admits that outward manifestations of Western culture may be adopted, but the fundamental values and behaviors remain still. Furthermore, positive effects might occur when male-dominated cultures adopt the “liberation” of women with exposure to Western media and it stimulates ample exchange of cultural exchange.

Critics of scholars who discuss cultural imperialism have a number of critiques. "Cultural imperialism" is a term that is only used in discussions where cultural relativism and constructivism are generally taken as true. (One cannot critique promoting Western values if one believes that said values are absolutely correct. Similarly, one cannot argue that Western epistemology is unjustly promoted in non-Western societies if one believes that those epistemologies are absolutely correct.) Therefore, those who disagree with cultural relativism and/or constructivism may critique the employment of the term, "cultural imperialism" on those terms.

John Tomlinson provides a critique of cultural imperialism theory and reveals major problems in the way in which the idea of cultural, as opposed to economic or political, imperialism is formulated. In his book "Cultural Imperialism: A Critical Introduction", he delves into the much debated “media imperialism” theory. Summarizing research on the Third World’s reception of American television shows, he challenges the cultural imperialism argument, conveying his doubts about the degree to which US shows in developing nations actually carry US values and improve the profits of US companies. Tomlinson suggests that cultural imperialism is growing in some respects, but local transformation and interpretations of imported media products propose that cultural diversification is not at an end in global society. He explains that one of the fundamental conceptual mistakes of cultural imperialism is to take for granted that the distribution of cultural goods can be considered as cultural dominance. He thus supports his argument highly criticizing the concept that Americanization is occurring through global overflow of American television products. He points to a myriad of examples of television networks who have managed to dominate their domestic markets and that domestic programs generally top the ratings. He also doubts the concept that cultural agents are passive receivers of information. He states that movement between cultural/geographical areas always involves translation, mutation, adaptation, and the creation of hybridity.

Other major critiques are that the term is not defined well, and employs further terms that are not defined well, and therefore lacks explanatory power, that "cultural imperialism" is hard to measure, and that the theory of a legacy of colonialism is not always true.

David Rothkopf, managing director of Kissinger Associates and an adjunct professor of international affairs at Columbia University (who also served as a senior US Commerce Department official in the Clinton Administration), wrote about cultural imperialism in his provocatively titled "In Praise of Cultural Imperialism?" in the summer 1997 issue of "Foreign Policy" magazine. Rothkopf says that the United States should embrace "cultural imperialism" as in its self-interest. But his definition of cultural imperialism stresses spreading the values of tolerance and openness to cultural change in order to avoid war and conflict between cultures as well as expanding accepted technological and legal standards to provide free traders with enough security to do business with more countries. Rothkopf's definition almost exclusively involves allowing individuals in other nations to accept or reject foreign cultural influences. He also mentions, but only in passing, the use of the English language and consumption of news and popular music and film as cultural dominance that he supports. Rothkopf additionally makes the point that globalization and the Internet are accelerating the process of cultural influence.

Culture is sometimes used by the organizers of society—politicians, theologians, academics, and families—to impose and ensure order, the rudiments of which change over time as need dictates. One need only look at the 20th century's genocides. In each one, leaders used culture as a political front to fuel the passions of their armies and other minions and to justify their actions among their people.

Rothkopf then cites genocide and s in Armenia, Russia, the Holocaust, Cambodia, Bosnia and Herzegovina, Rwanda and East Timor as examples of culture (in some cases expressed in the ideology of "political culture" or religion) being misused to justify violence. He also acknowledges that cultural imperialism in the past has been guilty of forcefully eliminating the cultures of natives in the Americas and in Africa, or through use of the Inquisition, "and during the expansion of virtually every empire.".The most important way to deal with cultural influence in any nation, according to Rothkopf, is to promote tolerance and allow, or even promote, cultural diversities that are compatible with tolerance and to eliminate those cultural differences that cause violent conflict:

Cultural dominance can also be seen in the 1930s in Australia where the Aboriginal Assimilation Policy acted as an attempt to wipe out the Native Australian people. The British settlers tried to biologically alter the skin colour of the Australian Aboriginal people through mixed breeding with white people. The policy also made attempts to forcefully conform the Aborigines to western ideas of dress and education.

Although the term was popularized in the 1960s, and was used by its original proponents to refer to cultural hegemonies in a post-colonial world, cultural imperialism has also been used to refer to times further in the past.

The Roman Empire has been seen as an early example of cultural imperialism.

Early Rome, in its conquest of Italy, assimilated the people of Etruria by replacing the Etruscan language with Latin, which led to the demise of that language and many aspects of Etruscan civilization.

Cultural Romanization was imposed on many parts of Rome's empire by "many regions receiving Roman culture unwillingly, as a form of cultural imperialism." For example, when Greece was conquered by the Roman armies, Rome set about altering the culture of Greece to conform with Roman ideals. For instance, the Greek habit of stripping naked, in public, for exercise, was looked on askance by Roman writers, who considered the practice to be a cause of the Greeks' effeminacy and enslavement. The Roman example has been linked to modern instances of European imperialism in African countries, bridging the two instances with Slavoj Zizek's discussions of 'empty signifiers'

The Pax Romana was secured in the empire, in part, by the "forced acculturation of the culturally diverse populations that Rome had conquered."

British worldwide expansion in the 18th and 19th centuries was an economic and political phenomenon. However, "there was also a strong social and cultural dimension to it, which Rudyard Kipling termed the 'white man's burden'." One of the ways this was carried out was by religious proselytising, by, amongst others, the London Missionary Society, which was "an agent of British cultural imperialism." Another way, was by the imposition of educational material on the colonies for an "imperial curriculum". Morag Bell writes, "The promotion of empire through books, illustrative materials, and educational syllabuses was widespread, part of an education policy geared to cultural imperialism". This was also true of science and technology in the empire. Douglas M. Peers and Nandini Gooptu note that "Most scholars of colonial science in India now prefer to stress the ways in which science and technology worked in the service of colonialism, as both a 'tool of empire' in the practical sense and as a vehicle for cultural imperialism. In other words, science developed in India in ways that reflected colonial priorities, tending to benefit Europeans at the expense of Indians, while remaining dependent on and subservient to scientific authorities in the colonial metropolis."

The analysis of cultural imperialism carried out by Edward Said drew principally from a study of the British Empire. According to Danilo Raponi, the cultural imperialism of the British in the 19th century had a much wider effect than only in the British Empire. He writes, "To paraphrase Said, I see cultural imperialism as a complex cultural hegemony of a country, Great Britain, that in the 19th century had no rivals in terms of its ability to project its power across the world and to influence the cultural, political and commercial affairs of most countries. It is the 'cultural hegemony' of a country whose power to export the most fundamental ideas and concepts at the basis of its understanding of 'civilisation' knew practically no bounds." In this, for example, Raponi includes Italy.

The New Cambridge Modern History writes about the cultural imperialism of Napoleonic France. Napoleon used the Institut de France "as an instrument for transmuting French universalism into cultural imperialism." Members of the Institute (who included Napoleon), descended upon Egypt in 1798. "Upon arrival they organised themselves into an Institute of Cairo. The Rosetta Stone is their most famous find. The science of Egyptology is their legacy."

After the First World War, Germans were worried about the extent of French influence in the annexed Rhineland, with the French occupation of the Ruhr Valley in 1923. An early use of the term appeared in an essay by Paul Ruhlmann (as "Peter Hartmann") at that date, entitled "French Cultural Imperialism on the Rhine".

"Cultural imperialism" has also been used in connection with the expansion of German influence under the Nazis in the middle of the twentieth century. Alan Steinweis and Daniel Rogers note that even before the Nazis came to power, "Already in the Weimar Republic, German academic specialists on eastern Europe had contributed through their publications and teaching to the legitimization of German territorial revanchism and cultural imperialism. These scholars operated primarily in the disciplines Of history, economics, geography, and literature."

In the area of music, Michael Kater writes that during the WWII German occupation of France, Hans Rosbaud, a German conductor based by the Nazi regime in Strasbourg, became "at least nominally, a servant of Nazi cultural imperialism directed against the French."

In Italy during the war, Germany pursued "a European cultural front that gravitates around German culture". The Nazi propaganda minister Joseph Goebbels set up the European Union of Writers, "one of Goebbels's most ambitious projects for Nazi cultural hegemony. Presumably a means of gathering authors from Germany, Italy, and the occupied countries to plan the literary life of the new Europe, the union soon emerged as a vehicle of German cultural imperialism."

For other parts of Europe, Robert Gerwarth, writing about cultural imperialism and Reinhard Heydrich, states that the "Nazis' Germanization project was based on a historically unprecedented programme of racial stock-taking, theft, expulsion and murder." Also, "The full integration of the [Czech] Protectorate into this New Order required the complete Germanization of the Protectorate's cultural life and the eradication of indigenous Czech and Jewish culture."

The actions by Nazi Germany reflect on the notion of race and culture playing a significant role in imperialism. The idea that there is a distinction between the Germans and the Jews has created the illusion of Germans believing they were superior to the Jewish inferiors, the notion of us/them and self/others.

The terms "McDonaldization" and "Cocacolonization" have been coined to describe the spread of Western cultural influence.





</doc>
<doc id="4442271" url="https://en.wikipedia.org/wiki?curid=4442271" title="Cultural institution">
Cultural institution

A cultural institution or cultural organization is an organization within a culture/subculture that works for the preservation or promotion of culture. The term is especially used of public and charitable organizations, but its range of meaning can be very broad. Examples of cultural institutions in modern society are museums, libraries and archives, churches, art galleries.



</doc>
<doc id="43732489" url="https://en.wikipedia.org/wiki?curid=43732489" title="Purple economy">
Purple economy

The purple economy is that part of the economy which contributes to sustainable development by promoting the cultural potential of goods and services.

“The purple economy refers to taking account of cultural aspects in economics. It designates an economy that adapts to the human diversity in globalization and that relies on the cultural dimension to give value to goods and services.” These two trends, one vertical and one horizontal, feed one another. In fact the growth in the cultural component attached to products is linked to each territory’s cultural vitality.

The context of the purple economy is that of the growing importance of culture in contemporary society. The factors involved in this include in particular: a global economic and political readjustment in favour of emerging countries, a return to local environments (once again perceived as centres for stability), new forms of claims (following on from the collapse of the great ideologies), growing social demand for quality based on cultural consumption patterns (which go hand in hand with the logic of popularization, individualization and longer life expectancies), innovative approaches (that presuppose a cultural state of mind and interdisciplinarity conducive to serendipity), and so on.

The purple economy is multidisciplinary, in that it enriches all goods and services by capitalizing on the cultural dimension inherent to every sector. The sensory, experiential economy is one application of this.

It differs from the cultural economy, which is sector-based.

In June 2013, the conclusions of a first inter-institutional working group on the purple economy, formed of experts from UNESCO, the OECD, the International Organisation of the Francophonie, French ministries, various companies and civil society. That document underscored the impact of the phenomenon of culturalization, which now affects the entire economy, with follow-on effects on employment and training. The report differentiates between "purple jobs" and "purplifying professions": the former are directly linked to the cultural environment by their very purpose (like town planners and developers), while the latter are merely caused to transform under the effect of culturalization (such as positions in human resources or in marketing and communications).

Another reference document published in June 2017 mentioned various aspects of the human environment in which economics are likely to produce cultural benefits: architecture, art, colours, enjoyment, ethics, heritage, imagination, learning, social skills, singularity, etc.

The term first appeared in 2011, in France, in a manifest published on Le Monde.fr. The signatories included the board members of the association Diversum, which organized the first International Purple Economy Forum under the patronage of UNESCO, the European Parliament and the European Commission.

The purple economy emphasizes the presence of externalities: the cultural environment from which agents draw and on which, in return, they leave their own footprints is a common good. As a result, the purple economy sees culture as an axis for sustainable development.

In fact, culture has been a whole sub-section of sustainability since the beginning. Corporate social responsibility can even be said to have originated in the International Covenant on Economic, Social and Cultural Rights adopted by the United Nations in 1966.

This issue is just one of the different components of sustainable development, alongside concerns relating to the natural environment (green economy) and to the social environment (social economy). The complementary nature of these aspects of the sustainable economy was reaffirmed in a call published by "Le Monde Économie" in 2015, leading up to the 21st United Nations Conference on Climate Change.


</doc>
<doc id="1713306" url="https://en.wikipedia.org/wiki?curid=1713306" title="Primitive culture">
Primitive culture

Primitive Culture is an 1871 book by Edward Burnett Tylor. According to Tylor a defining characteristic of primitive cultures is a greater amount of leisure time than in more complex societies. 

In 1953, John Carothers, a colonial psychiatrist who had previously worked at Mathari Mental Hospital in Nairobi, Kenya, published a report for the World Health Organization claiming and quoting several authors that compared African psychology to that of children, to immaturity compared the African mind to a European brain that had undergone a lobotomy. They were caricatures of primitive people at peace with nature, dwelling in a fascinating world of hallucinations and witch doctors.

However, African researchers have dismissed this concept, Thomas Adeoye Lambo, a leading psychiatrist and member of the Yoruba people wrote about the subject that they were "glorified pseudo-scientific novels or anecdotes with a subtle racial bias, having so many gaps and inconsistencies, that they can no longer be seriously presented as valuable observations of scientific merit". Even so, views like Carothers's had been echoed over decades of colonialism, becoming so commonplace that they were considered to be somewhat of a truism.

Further research published in JAMA has found very high rates of clinical depression in impoverished nations, such as Zimbabwe, and that depression wasn't a Western disease but a human one, and in fact glossing over primitive culture as being leisure filled and stress-free was entirely opposite of scientific findings.

Cultural primitivism has also been applied to interpretations of unfamiliar cuisines. The eating practices of Native American cultures have been likened to the ways of the noble savage, whose eating practices are characterized as equitable and inclusive. These qualifications are made from an etic perspective. Barbecue in particular has been studied by the scholar Andrew Warnes.




</doc>
<doc id="24723521" url="https://en.wikipedia.org/wiki?curid=24723521" title="Outline of culture">
Outline of culture

The following outline is provided as an overview of and topical guide to culture:

Culture – set of patterns of human activity within a community or social group and the symbolic structures that give significance to such activity. Customs, laws, dress, architectural style, social standards, religious beliefs, and traditions are all examples of cultural elements. Since 2010, Culture is considered the Fourth Pillar of Sustainable Development by UNESCO. More: Agenda 21 for Culture or in short Culture 21.






Subculture




Area studies



Culture of Africa


Culture of Asia


</doc>
<doc id="18290472" url="https://en.wikipedia.org/wiki?curid=18290472" title="Artificiality">
Artificiality

Artificiality (also called factitiousness, or the state of being artificial or man-made) is the state of being the product of intentional human manufacture, rather than occurring naturally through processes not involving or requiring human activity.

Artificiality often carries with it the implication of being false, counterfeit, or deceptive. The philosopher Aristotle wrote in his "Rhetoric":

However, artificiality does not necessarily have a negative connotation, as it may also reflect the ability of humans to replicate forms or functions arising in nature, as with an artificial heart or artificial intelligence. Political scientist and artificial intelligence expert Herbert A. Simon observes that "some artificial things are imitations of things in nature, and the imitation may use either the same basic materials as those in the natural object or quite different materials. Simon distinguishes between the artificial and the synthetic, the former being an imitation of something found in nature (for example, an artificial sweetener which generates sweetness using a formula not found in nature), and the latter being a replication of something found in nature (for example, a sugar created in a laboratory that is chemically indistinguishable from a naturally occurring sugar). Some philosophers have gone further and asserted that, in a deterministic world, "everything is natural and nothing is artificial", because everything in the world (including everything made by humans) is a product of the physical laws of the world.

It is generally possible for humans, and in some instances, for computers, to distinguish natural from artificial environments. The artificial environment tends to have more physical regularity both spatially and over time, with natural environments tending to have both irregular structures and structures that change over time. However, on close observation it is possible to discern some mathematical structures and patterns in natural environments, which can then be replicated to create an artificial environment with a more natural appearance.

For example, by identifying and imitating natural means of pattern formation, some types of automata have been used to generate organic-looking textures for more realistic shading of 3D objects.



</doc>
<doc id="677443" url="https://en.wikipedia.org/wiki?curid=677443" title="Homo faber">
Homo faber

Homo faber (Latin for "Man the Maker") is the concept that human beings are able to control their fate and their environment as a result of the use of tools.

In Latin literature, Appius Claudius Caecus uses this term in his "Sententiæ", referring to the ability of man to control his destiny and what surrounds him: "Homo faber suae quisque fortunae" ("Every man is the artifex of his destiny").

In older anthropological discussions, "Homo faber", as the "working man", is confronted with "Homo ludens", the "playing man", who is concerned with amusements, humor, and leisure. It is also used in George Kubler's book, The Shape of Time as a reference to individuals who create works of art.

The classic "homo faber suae quisque fortunae" was "rediscovered" by humanists in 14th century and was central in the Italian Renaissance.

In the 20th century, Max Scheler and Hannah Arendt made the philosophical concept central again.

Henri Bergson also referred to the concept in "Creative Evolution" (1907), defining intelligence, in its original sense, as the "faculty to create artificial objects, in particular tools to make tools, and to indefinitely variate its makings."

"Homo Faber" is the title of an influential novel by the Swiss author Max Frisch, published in 1957.

"Homo faber" can be also used in opposition or juxtaposition to "deus faber" ("God the Creator"), an archetype of which are the various gods of the forge.

"Homo faber" is used by Pierre Schaeffer in the Traité des objects Musicaux as the man creator of music, which uses its brute experience, an instinctive practice in music creation; Concluding that the "homo faber" aways precedes the Homo sapiens in the process of creation.

Frisch' book was made into the film "Voyager", starring Sam Shepard and Julie Delpy.

"Homo Faber" was one of the five International Baccalaureate Middle Years Programme areas of interaction, before it was replaced with "Human Ingenuity".

The concept of "homo faber" is referenced in Umberto Eco's "Open Work": he refutes its negative connotation and instead argues that "homo faber" is a manifestation of man's innate being in nature. Use of "homo faber" in this negative light is argued by Eco to represent the alienation from and objectification of nature.

"Homo Faber" is also the title of a short poem by Frank Bidart that is included in his collection "Desire" (1997).

"Homo faber" is often placed in juxtaposition to "homo adorans", the worshiping man. In other words, under traditional Judeo-Christian philosophy, the ultimate purpose of humankind is to worship God, whereas, under (for example) Marxist or Capitalist ideology, the purpose of humankind was embedded in what he or she can make or produce.





</doc>
<doc id="57165694" url="https://en.wikipedia.org/wiki?curid=57165694" title="Cultural manager">
Cultural manager

A cultural manager () is a person who is motivated by the improvement of art, works independently and professionally with knowledge of the subject, and develops work as a mediator between governmental and/or private cultural institutions with artists from different areas to articulate their work in the market with promotion and national and international dissemination.

The cultural manager works by looking for specific measures of success, always intending to improve the level of culture, seeking active cohesion between society, the governmental sector, the private sector, and the artists. The work of culture management poses learning challenges in diverse areas such as the administration of economic resources, training, and artistic communication.

Cultural management is a new profession. A person who is dedicated to this work is characterized by having abilities to visualize and interpret talent, knowing how to establish a dialogue with artists to link them to cultural projects to develop.

Universities that offer degree programs in cultural management include the University of Antioquia, the Latin American Social Sciences Institute, the University of Chile, the University of Córdoba (Spain), the National University of Colombia, the University of Barcelona, and the University of Piura.


</doc>
<doc id="6258" url="https://en.wikipedia.org/wiki?curid=6258" title="Civilization">
Civilization

A civilization or civilisation (see English spelling differences) is any complex society characterized by urban development, social stratification imposed by a cultural elite, symbolic systems of communication (for example, writing systems), and a perceived separation from and domination over the natural environment.

Civilizations are intimately associated with and often further defined by other socio-politico-economic characteristics, including centralization, the domestication of both humans and other organisms, specialization of labour, culturally ingrained ideologies of progress and supremacism, monumental architecture, taxation, societal dependence upon farming and expansionism. Historically, civilization has often been understood as a larger and "more advanced" culture, in contrast to smaller, supposedly primitive cultures. Similarly, some scholars have described civilization as being necessarily multicultural. In this broad sense, a civilization contrasts with non-centralized tribal societies, including the cultures of nomadic pastoralists, Neolithic societies or hunter-gatherers, but it also contrasts with the cultures found within civilizations themselves. As an uncountable noun, "civilization" also refers to the process of a society developing into a centralized, urbanized, stratified structure. Civilizations are organized in densely populated settlements divided into hierarchical social classes with a ruling elite and subordinate urban and rural populations, which engage in intensive agriculture, mining, small-scale manufacture and trade. Civilization concentrates power, extending human control over the rest of nature, including over other human beings.

Civilization, as its etymology (below) suggests, is a concept originally linked to towns and cities. The earliest emergence of civilizations is generally associated with the final stages of the Neolithic Revolution, culminating in the relatively rapid process of urban revolution and state formation, a political development associated with the appearance of a governing elite.

The English word "civilization" comes from the 16th-century French "civilisé" ("civilized"), from Latin "civilis" ("civil"), related to "civis" ("citizen") and "civitas" ("city"). The fundamental treatise is Norbert Elias's "The Civilizing Process" (1939), which traces social mores from medieval courtly society to the Early Modern period. In "The Philosophy of Civilization" (1923), Albert Schweitzer outlines two opinions: one purely material and the other material and ethical. He said that the world crisis was from humanity losing the ethical idea of civilization, "the sum total of all progress made by man in every sphere of action and from every point of view in so far as the progress helps towards the spiritual perfecting of individuals as the progress of all progress".

Adjectives like "civility" developed in the mid-16th century. The abstract noun "civilization", meaning "civilized condition", came in the 1760s, again from French. The first known use in French is in 1757, by Victor de Riqueti, marquis de Mirabeau, and the first use in English is attributed to Adam Ferguson, who in his 1767 "Essay on the History of Civil Society" wrote, "Not only the individual advances from infancy to manhood, but the species itself from rudeness to civilisation". The word was therefore opposed to barbarism or rudeness, in the active pursuit of progress characteristic of the Age of Enlightenment.

In the late 1700s and early 1800s, during the French Revolution, "civilization" was used in the singular, never in the plural, and meant the progress of humanity as a whole. This is still the case in French. The use of "civilizations" as a countable noun was in occasional use in the 19th century, but has become much more common in the later 20th century, sometimes just meaning culture (itself in origin an uncountable noun, made countable in the context of ethnography). Only in this generalized sense does it become possible to speak of a "medieval civilization", which in Elias's sense would have been an oxymoron.

Already in the 18th century, civilization was not always seen as an improvement. One historically important distinction between culture and civilization is from the writings of Rousseau, particularly his work about education, "". Here, civilization, being more rational and socially driven, is not fully in accord with human nature, and "human wholeness is achievable only through the recovery of or approximation to an original prediscursive or prerational natural unity" (see noble savage). From this, a new approach was developed, especially in Germany, first by Johann Gottfried Herder, and later by philosophers such as Kierkegaard and Nietzsche. This sees cultures as natural organisms, not defined by "conscious, rational, deliberative acts", but a kind of pre-rational "folk spirit". Civilization, in contrast, though more rational and more successful in material progress, is unnatural and leads to "vices of social life" such as guile, hypocrisy, envy and avarice. In World War II, Leo Strauss, having fled Germany, argued in New York that this opinion of civilization was behind Nazism and German militarism and nihilism.

Social scientists such as V. Gordon Childe have named a number of traits that distinguish a civilization from other kinds of society. Civilizations have been distinguished by their means of subsistence, types of livelihood, settlement patterns, forms of government, social stratification, economic systems, literacy and other cultural traits. Andrew Nikiforuk argues that "civilizations relied on shackled human muscle. It took the energy of slaves to plant crops, clothe emperors, and build cities" and considers slavery to be a common feature of pre-modern civilizations.

All civilizations have depended on agriculture for subsistence, with the possible exception of some early civilizations in Peru which may have depended upon maritime resources. Grain farms can result in accumulated storage and a surplus of food, particularly when people use intensive agricultural techniques such as artificial fertilization, irrigation and crop rotation. It is possible but more difficult to accumulate horticultural production, and so civilizations based on horticultural gardening have been very rare. Grain surpluses have been especially important because grain can be stored for a long time. A surplus of food permits some people to do things besides produce food for a living: early civilizations included soldiers, artisans, priests and priestesses, and other people with specialized careers. A surplus of food results in a division of labour and a more diverse range of human activity, a defining trait of civilizations. However, in some places hunter-gatherers have had access to food surpluses, such as among some of the indigenous peoples of the Pacific Northwest and perhaps during the Mesolithic Natufian culture. It is possible that food surpluses and relatively large scale social organization and division of labour predates plant and animal domestication.

Civilizations have distinctly different settlement patterns from other societies. The word "civilization" is sometimes simply defined as ""'living in cities"'". Non-farmers tend to gather in cities to work and to trade.

Compared with other societies, civilizations have a more complex political structure, namely the state. State societies are more stratified than other societies; there is a greater difference among the social classes. The ruling class, normally concentrated in the cities, has control over much of the surplus and exercises its will through the actions of a government or bureaucracy. Morton Fried, a conflict theorist and Elman Service, an integration theorist, have classified human cultures based on political systems and social inequality. This system of classification contains four categories

Economically, civilizations display more complex patterns of ownership and exchange than less organized societies. Living in one place allows people to accumulate more personal possessions than nomadic people. Some people also acquire landed property, or private ownership of the land. Because a percentage of people in civilizations do not grow their own food, they must trade their goods and services for food in a market system, or receive food through the levy of tribute, redistributive taxation, tariffs or tithes from the food producing segment of the population. Early human cultures functioned through a gift economy supplemented by limited barter systems. By the early Iron Age, contemporary civilizations developed money as a medium of exchange for increasingly complex transactions. In a village, the potter makes a pot for the brewer and the brewer compensates the potter by giving him a certain amount of beer. In a city, the potter may need a new roof, the roofer may need new shoes, the cobbler may need new horseshoes, the blacksmith may need a new coat and the tanner may need a new pot. These people may not be personally acquainted with one another and their needs may not occur all at the same time. A monetary system is a way of organizing these obligations to ensure that they are fulfilled. From the days of the earliest monetarized civilizations, monopolistic controls of monetary systems have benefited the social and political elites.

Writing, developed first by people in Sumer, is considered a hallmark of civilization and "appears to accompany the rise of complex administrative bureaucracies or the conquest state". Traders and bureaucrats relied on writing to keep accurate records. Like money, writing was necessitated by the size of the population of a city and the complexity of its commerce among people who are not all personally acquainted with each other. However, writing is not always necessary for civilization, as shown the Inca civilization of the Andes, which did not use writing at all except from a complex recording system consisting of cords and nodes instead: the "Quipus", whose still functioned as a civilized society.
Aided by their division of labour and central government planning, civilizations have developed many other diverse cultural traits. These include organized religion, development in the arts, and countless new advances in science and technology.

Through history, successful civilizations have spread, taking over more and more territory, and assimilating more and more previously-uncivilized people. Nevertheless, some tribes or people remain uncivilized even to this day. These cultures are called by some "primitive", a term that is regarded by others as pejorative. "Primitive" implies in some way that a culture is "first" (Latin = "primus"), that it has not changed since the dawn of humanity, though this has been demonstrated not to be true. Specifically, as all of today's cultures are contemporaries, today's so-called primitive cultures are in no way antecedent to those we consider civilized. Anthropologists today use the term "non-literate" to describe these peoples.

Civilization has been spread by colonization, invasion, religious conversion, the extension of bureaucratic control and trade, and by introducing agriculture and writing to non-literate peoples. Some non-civilized people may willingly adapt to civilized behaviour. But civilization is also spread by the technical, material and social dominance that civilization engenders.

Assessments of what level of civilization a polity has reached are based on comparisons of the relative importance of agricultural as opposed to trade or manufacturing capacities, the territorial extensions of its power, the complexity of its division of labour, and the carrying capacity of its urban centres. Secondary elements include a developed transportation system, writing, standardized measurement, currency, contractual and tort-based legal systems, art, architecture, mathematics, scientific understanding, metallurgy, political structures and organized religion.

Traditionally, polities that managed to achieve notable military, ideological and economic power defined themselves as "civilized" as opposed to other societies or human groupings outside their sphere of influence – calling the latter barbarians, savages, and primitives. In a modern-day context, "civilized people" have been contrasted with indigenous people or tribal societies.

"Civilization" can also refer to the culture of a complex society, not just the society itself. Every society, civilization or not, has a specific set of ideas and customs, and a certain set of manufactures and arts that make it unique. Civilizations tend to develop intricate cultures, including a state-based decision making apparatus, a literature, professional art, architecture, organized religion and complex customs of education, coercion and control associated with maintaining the elite.

The intricate culture associated with civilization has a tendency to spread to and influence other cultures, sometimes assimilating them into the civilization (a classic example being Chinese civilization and its influence on nearby civilizations such as Korea, Japan and Vietnam). Many civilizations are actually large cultural spheres containing many nations and regions. The civilization in which someone lives is that person's broadest cultural identity.

Many historians have focused on these broad cultural spheres and have treated civilizations as discrete units. Early twentieth-century philosopher Oswald Spengler, uses the German word "Kultur", "culture", for what many call a "civilization". Spengler believed a civilization's coherence is based on a single primary cultural symbol. Cultures experience cycles of birth, life, decline and death, often supplanted by a potent new culture, formed around a compelling new cultural symbol. Spengler states civilization is the beginning of the decline of a culture as "the most external and artificial states of which a species of developed humanity is capable".

This "unified culture" concept of civilization also influenced the theories of historian Arnold J. Toynbee in the mid-twentieth century. Toynbee explored civilization processes in his multi-volume "A Study of History," which traced the rise and, in most cases, the decline of 21 civilizations and five "arrested civilizations". Civilizations generally declined and fell, according to Toynbee, because of the failure of a "creative minority", through moral or religious decline, to meet some important challenge, rather than mere economic or environmental causes.

Samuel P. Huntington defines civilization as "the highest cultural grouping of people and the broadest level of cultural identity people have short of that which distinguishes humans from other species". Huntington's theories about civilizations are discussed below.

Another group of theorists, making use of systems theory, looks at a civilization as a complex system, i.e., a framework by which a group of objects can be analysed that work in concert to produce some result. Civilizations can be seen as networks of cities that emerge from pre-urban cultures and are defined by the economic, political, military, diplomatic, social and cultural interactions among them. Any organization is a complex social system and a civilization is a large organization. Systems theory helps guard against superficial but misleading analogies in the study and description of civilizations.

Systems theorists look at many types of relations between cities, including economic relations, cultural exchanges and political/diplomatic/military relations. These spheres often occur on different scales. For example, trade networks were, until the nineteenth century, much larger than either cultural spheres or political spheres. Extensive trade routes, including the Silk Road through Central Asia and Indian Ocean sea routes linking the Roman Empire, Persian Empire, India and China, were well established 2000 years ago, when these civilizations scarcely shared any political, diplomatic, military, or cultural relations. The first evidence of such long distance trade is in the ancient world. During the Uruk period, Guillermo Algaze has argued that trade relations connected Egypt, Mesopotamia, Iran and Afghanistan. Resin found later in the Royal Cemetery at Ur is suggested was traded northwards from Mozambique.

Many theorists argue that the entire world has already become integrated into a single "world system", a process known as globalization. Different civilizations and societies all over the globe are economically, politically, and even culturally interdependent in many ways. There is debate over when this integration began, and what sort of integration – cultural, technological, economic, political, or military-diplomatic – is the key indicator in determining the extent of a civilization. David Wilkinson has proposed that economic and military-diplomatic integration of the Mesopotamian and Egyptian civilizations resulted in the creation of what he calls the "Central Civilization" around 1500 BCE. Central Civilization later expanded to include the entire Middle East and Europe, and then expanded to a global scale with European colonization, integrating the Americas, Australia, China and Japan by the nineteenth century. According to Wilkinson, civilizations can be culturally heterogeneous, like the Central Civilization, or homogeneous, like the Japanese civilization. What Huntington calls the "clash of civilizations" might be characterized by Wilkinson as a clash of cultural spheres within a single global civilization. Others point to the Crusades as the first step in globalization. The more conventional viewpoint is that networks of societies have expanded and shrunk since ancient times, and that the current globalized economy and culture is a product of recent European colonialism. 

The notion of world history as a succession of "civilizations" is an entirely modern one.
In the European Age of Discovery, emerging Modernity was put into stark contrast with the
Neolithic and Mesolithic stage of the cultures of the New World, suggesting
that the complex states had emerged at some time in prehistory.
The term "civilization" as it is now most commonly understood, a complex state with centralisation, social stratification and specialization of labour, corresponds to early empires that arise in the Fertile Crescent in the Early Bronze Age, around roughly 3000 BC.
Gordon Childe defined the emergence of civilization as the result of two successive revolutions: the Neolithic Revolution, triggering the development of settled communities, and the Urban Revolution.

At first, the Neolithic was associated with shifting subsistence cultivation, where continuous farming led to the depletion of soil fertility resulting in the requirement to cultivate fields further and further removed from the settlement, eventually compelling the settlement itself to move. In major semi-arid river valleys, annual flooding renewed soil fertility every year, with the result that population densities could rise significantly.
This encouraged a secondary products revolution in which people used domesticated animals not just for meat, but also for milk, wool, manure and pulling ploughs and carts – a development that spread through the Eurasian Oecumene.

The earlier neolithic technology and lifestyle was established first in Western Asia (for example at Göbekli Tepe, from about 9,130 BCE), and later in the Yellow River and Yangtze basins in China (for example the Pengtoushan culture from 7,500 BCE), and later spread.
Mesopotamia is the site of the earliest developments of the Neolithic Revolution from around 10,000 BCE, with civilizations developing from 6,500 years ago. This area has been identified as having "inspired some of the most important developments in human history including the invention of the wheel, the development of cuneiform script, mathematics, astronomy and agriculture."
Similar pre-civilized "neolithic revolutions" also began independently from 7,000 BCE in northwestern South America (the Norte Chico civilization) and Mesoamerica.

The 8.2 Kiloyear Arid Event and the 5.9 Kiloyear Interpluvial saw the drying out of semiarid regions and a major spread of deserts. This climate change shifted the cost-benefit ratio of endemic violence between communities, which saw the abandonment of unwalled village communities and the appearance of walled cities, associated with the first civilizations.
This "urban revolution" marked the beginning of the accumulation of transferrable surpluses, which helped economies and cities develop. It was associated with the state monopoly of violence, the appearance of a soldier class and endemic warfare, the rapid development of hierarchies, and the appearance of human sacrifice.

The civilized urban revolution in turn was dependent upon the development of sedentism, the domestication of grains and animals and development of lifestyles that facilitated economies of scale and accumulation of surplus production by certain social sectors. The transition from "complex cultures" to "civilizations", while still disputed, seems to be associated with the development of state structures, in which power was further monopolized by an elite ruling class who practised human sacrifice.

Towards the end of the Neolithic period, various elitist Chalcolithic civilizations began to rise in various "cradles" from around 3300 BCE, expanding into large-scale empires in the course of the Bronze Age (Minoan Civilization, Old Kingdom of Egypt, Akkadian Empire, Assyrian Empire, Old Assyrian Empire, Phoenicia, Canaan, Indus Valley, Maya, Neo-Sumerian Empire, Babylonian Empire, Hittite Empire, Gojoseon, Shang Dynasty).

A parallel development took place independently in the Pre-Columbian Americas, where the Mayans began to be urbanised around 500 BCE, and the fully fledged Aztec and Inca emerged by the 15th century, briefly before European contact.

The Bronze Age collapse was followed by the Iron Age around 1200 BCE, during which a number of new civilizations emerged, culminating in a period from the 8th to the 3rd century BCE which Karl Jaspers termed the Axial Age, presented as a critical transitional phase leading to classical civilization.
William Hardy McNeill proposed that this period of history was one in which culture contact between previously separate civilizations saw the "closure of the oecumene" and led to accelerated social change from China to the Mediterranean, associated with the spread of coinage, larger empires and new religions. This view has recently been championed by Christopher Chase-Dunn and other world systems theorists.

A major technological and cultural transition to modernity began approximately 1500 CE in Western Europe, and from this beginning new approaches to science and law spread rapidly around the world, incorporating earlier cultures into the industrial and technological civilization of the present.

Civilizations have generally ended in one of two ways; either through being incorporated into another expanding civilization (e.g. As Ancient Egypt was incorporated into Hellenistic Greek, and subsequently Roman civilizations), or by collapse and reversion to a simpler form, as happens in what are called Dark Ages.

There have been many explanations put forward for the collapse of civilization. Some focus on historical examples, and others on general theory.

Political scientist Samuel Huntington, has argued that the defining characteristic of the 21st century will be a clash of civilizations. According to Huntington, conflicts between civilizations will supplant the conflicts between nation-states and ideologies that characterized the 19th and 20th centuries. These views have been strongly challenged by others like Edward Said, Muhammed Asadi and Amartya Sen. Ronald Inglehart and Pippa Norris have argued that the "true clash of civilizations" between the Muslim world and the West is caused by the Muslim rejection of the West's more liberal sexual values, rather than a difference in political ideology, although they note that this lack of tolerance is likely to lead to an eventual rejection of (true) democracy. In "Identity and Violence" Sen questions if people should be divided along the lines of a supposed "civilization", defined by religion and culture only. He argues that this ignores the many others identities that make up people and leads to a focus on differences.

Cultural Historian Morris Berman suggests in "Dark Ages America: the End of Empire" that in the corporate consumerist United States, the very factors that once propelled it to greatness―extreme individualism, territorial and economic expansion, and the pursuit of material wealth―have pushed the United States across a critical threshold where collapse is inevitable. Politically associated with over-reach, and as a result of the environmental exhaustion and polarization of wealth between rich and poor, he concludes the current system is fast arriving at a situation where continuation of the existing system saddled with huge deficits and a hollowed-out economy is physically, socially, economically and politically impossible. Although developed in much more depth, Berman's thesis is similar in some ways to that of Urban Planner, Jane Jacobs who argues that the five pillars of United States culture are in serious decay: community and family; higher education; the effective practice of science; taxation and government; and the self-regulation of the learned professions. The corrosion of these pillars, Jacobs argues, is linked to societal ills such as environmental crisis, racism and the growing gulf between rich and poor.

Cultural critic and author Derrick Jensen argues that modern civilization is directed towards the domination of the environment and humanity itself in an intrinsically harmful, unsustainable, and self-destructive fashion. Defending his definition both linguistically and historically, he defines civilization as "a culture... that both leads to and emerges from the growth of cities", with "cities" defined as "people living more or less permanently in one place in densities high enough to require the routine importation of food and other necessities of life". This need for civilizations to import ever more resources, he argues, stems from their over-exploitation and diminution of their own local resources. Therefore, civilizations inherently adopt imperialist and expansionist policies and, to maintain these, highly militarized, hierarchically structured, and coercion-based cultures and lifestyles.

The Kardashev scale classifies civilizations based on their level of technological advancement, specifically measured by the amount of energy a civilization is able to harness. The Kardashev scale makes provisions for civilizations far more technologically advanced than any currently known to exist (see also: Civilizations and the Future and Space civilization).

The current scientific consensus is that human beings are the only animal species with the cognitive ability to create civilizations. A recent thought experiment, however, has considered whether it would "be possible to detect an industrial civilization in the geological record" given the paucity of geological information about eras before the quaternary.




</doc>
<doc id="782895" url="https://en.wikipedia.org/wiki?curid=782895" title="Interculturalism">
Interculturalism

Interculturalism refers to support for cross-cultural dialogue and challenging self-segregation tendencies within cultures. Interculturalism involves moving beyond mere passive acceptance of a multicultural fact of multiple cultures effectively existing in a society and instead promotes dialogue and interaction between cultures.

Interculturalism has arisen in response to criticisms of existing policies of multiculturalism, such as criticisms that such policies had failed to create inclusion of different cultures within society, but instead have divided society by legitimizing segregated separate communities that have isolated themselves and accentuated their specificity. It is based on the recognition of both differences and similarities between cultures. It has addressed the risk of the creation of absolute relativism within postmodernity and in multiculturalism.

Philosopher Martha Nussbaum in her work "Cultivating Humanity", describes interculturalism as involving "the recognition of common human needs across cultures and of dissonance and critical dialogue within cultures" and that interculturalists "reject the claim of identity politics that only members of a particular group have the ability to understand the perspective of that group". Ali Rattansi, in his book "Multiculturalism: A Very Short Introduction" (2011) argues that Interculturalism offers a more fruitful way than conventional multiculturalism for different ethnic groups to co-exist in an atmosphere that encourages both better inter-ethnic understanding and civility; he provides useful examples of how interculturalist projects in the UK have shown in practice a constructive way forward for promoting multi-ethnic civility. Based on a considerable body of research, he also sets out the outlines of a new interpretation of global history which shows that concepts of tolerance are not restricted to the West, and that what is usually regarded as a unique Western cultural achievement should more appropriately be regarded as a Eurasian achievement. He thus offers a more interculturalist view of global history which undermines notions of 'a clash of civilisations'.

Interculturalism has both supporters and opponents amongst people who endorse multiculturalism. Gerald Delanty views interculturalism as capable of incorporating multiculturalism within it. In contrast, Nussbaum views interculturalism as distinct from multiculturalism and notes that several humanities professors have preferred interculturalism over multiculturalism because they view multiculturalism as being "associated with relativism and identity politics".

The United Nations' agency UNESCO adopted the Convention on the Protection and Promotion of the Diversity of Cultural Expressions in 2005 that declares support for interculturality. In Germany, all universities are required to have a section on intercultural competence in their social work programs, that involves students being able to be open to listen and communicate with people of different cultural backgrounds, have knowledge of the backgrounds of cultural groups, knowledge of existing stereotypes and prejudices involving cultural groups, and other criteria. Salman Cheema, the Head of Marketing and Communications of the British Council, in an article titled "From Multiculturalism to Interculturalism – A British perspective", spoke of an event co-hosted by the British Council and Canada's Institute for Research on Public Policy (IRPP) in Montreal, Quebec, Canada on April 11, 2013, interculturalist advocate Phil Wood declared that multiculturalism has faced serious problems that need to be resolved through interculturalism, and rejected those opponents of multiculturalism who seek to restore a pre-multiculturalist monoculturalist society. Several days later in Montreal, the New Democratic Party of Canada (NDP) declared support for interculturalism in the preamble of its constitution adopted its federal convention held in Montreal on April 14, 2013.




</doc>
<doc id="1982394" url="https://en.wikipedia.org/wiki?curid=1982394" title="Cultural appropriation">
Cultural appropriation

Cultural appropriation, at times also phrased cultural misappropriation, is the adoption of elements of one culture by members of another culture. This can be controversial when members of a dominant culture appropriate from disadvantaged minority cultures.

Cultural appropriation is considered harmful by many, and to be a violation of the collective intellectual property rights of the originating, minority cultures, notably indigenous cultures and those living under colonial rule. Often unavoidable when multiple cultures come together, cultural appropriation can include using other cultures' cultural and religious traditions, fashion, symbols, language, and music.

According to critics of the practice, cultural appropriation differs from acculturation, assimilation, or cultural exchange in that this appropriation is a form of colonialism: cultural elements are copied from a minority culture by members of a dominant culture, and these elements are used outside of their original cultural context—sometimes even against the expressly stated wishes of members of the originating culture.

Often, the original meaning of these cultural elements is lost or distorted, and such displays are often viewed as disrespectful, or even as a form of desecration, by members of the originating culture. Cultural elements which may have deep meaning to the original culture may be reduced to "exotic" fashion or toys by those from the dominant culture. Kjerstin Johnson has written that, when this is done, the imitator, "who does not experience that oppression is able to 'play', temporarily, an 'exotic' other, without experiencing any of the daily discriminations faced by other cultures." The African-American academic, musician and journalist Greg Tate argues that appropriation and the "fetishising" of cultures, in fact, alienates those whose culture is being appropriated.

The concept of cultural appropriation has also been widely criticized. Some writers on the topic note that the concept is often misunderstood or misapplied by the general public, and that charges of "cultural appropriation" are at times misapplied to situations such as eating food from a variety of cultures, or learning about different cultures. Commentators who criticize the concept believe that the act of cultural appropriation does not meaningfully constitute a social harm, or that the term lacks conceptual coherence. Others argue that the term sets arbitrary limits on intellectual freedom and artists' self-expression, reinforces group divisions, or itself promotes a feeling of enmity or grievance, rather than liberation.

Cultural appropriation can involve the use of ideas, symbols, artifacts, or other aspects of human-made visual or non-visual culture. As a concept that is controversial in its applications, the propriety of cultural appropriation has been the subject of much debate. Opponents of cultural appropriation view many instances as wrongful appropriation when the subject culture is a minority culture or is subordinated in social, political, economic, or military status to the dominant culture or when there are other issues involved, such as a history of ethnic or racial conflict. Linda Martín Alcoff writes that this is often seen in cultural outsiders' use of an oppressed culture's symbols or other cultural elements, such as music, dance, spiritual ceremonies, modes of dress, speech, and social behaviour when these elements are trivialized and used for fashion, rather than respected within their original cultural context. Opponents view the issues of colonialism, context, and the difference between appropriation and mutual exchange as central to analyzing cultural appropriation. They argue that mutual exchange happens on an "even playing field", whereas appropriation involves pieces of an oppressed culture being taken out of context by a people who have historically oppressed those they are taking from, and who lack the cultural context to properly understand, respect, or utilize these elements.

A different view of cultural appropriation states the practice is "a deeply conservative project", despite progressive roots. The goal is "to preserve in formaldehyde the content of an established culture and second tries prevent others from interacting with that culture." Proponents view it as often benign or mutually beneficial, citing mutation, product diversity, technological diffusion, and cultural empathy as among its benefits. For example, the film "Star Wars" used elements from Akira Kurosawa's "The Hidden Fortress", which itself used elements from Shakespeare; culture in the aggregate is arguably better off for each instance of appropriation. Fusion between cultures has produced such foods as American Chinese cuisine, modern Japanese sushi, and bánh mì, each of which is sometimes argued to reflect part of its respective culture's identity.

Cultural appropriation is a relatively recent subject of academic study. 
The term emerged in the 1980s, in discussions of post-colonial critiques of Western expansionism, though the concept had been explored earlier, such as in "Some General Observations on the Problems of Cultural Colonialism" by Kenneth Coutts‐Smith in 1976.

Cultural and racial theorist George Lipsitz has used the term "strategic anti-essentialism" to refer to the calculated use of a cultural form, outside of one's own, to define oneself or one's group. Strategic anti-essentialism can be seen in both minority cultures and majority cultures, and is not confined only to the use of the other. However, Lipsitz argues, when the majority culture attempts to strategically anti-essentialize itself by appropriating a minority culture, it must take great care to recognize the specific socio-historical circumstances and significance of these cultural forms so as not to perpetuate the already existing majority vs. minority unequal power relations.

A common example of cultural appropriation is the adoption of the iconography of another culture, and using it for purposes that are unintended by the original culture or even offensive to that culture's mores. Examples include sports teams using Native American tribal names or images as mascots; wearing jewelry or fashion with religious symbols such as the war bonnet, medicine wheel, or cross without any belief in those religions; and copying iconography from another culture's history such as Polynesian tribal tattoos, Chinese characters, or Celtic art worn without regard to their original cultural significance. Critics of the practice of cultural appropriation contend that divorcing this iconography from its cultural context or treating it as kitsch risks offending people who venerate and wish to preserve their cultural traditions.

In Australia, Aboriginal artists have discussed an "authenticity brand" to ensure consumers are aware of artworks claiming false Aboriginal significance. The movement for such a measure gained momentum after the 1999 conviction of John O'Loughlin for the fraudulent sale of works described as Aboriginal but painted by non-indigenous artists.

In Europe and North America a common example of cultural appropriation is the misrepresentation of East Indian symbols, mythology and religious ideas as typified in Rudyard Kipling's stories and Talbot Mundy's Jimgrim book series including the highly discussed Nine Unknown and King of the Khyber Rifles. Movements to undo the biases, misrepresentations, and cultural inaccuracies made popular by authors like Kipling and Mundy have gained significant momentum since Kipling's poem "If—" was scrubbed off Manchester University walls by student leaders. AAJA, a watchdog organization for fair and respectful cultural representation, works to point out and prevent these cultural inaccuracies in the media.

Historically, some of the most hotly debated cases of cultural appropriation have occurred in places where cultural exchange is the highest, such as along the trade routes in southwestern Asia and southeastern Europe. Some scholars of the Ottoman Empire and ancient Egypt argue that Ottoman and Egyptian architectural traditions have long been falsely claimed and praised as Persian or Arab.

Many Native Americans have criticized what they deem to be cultural appropriation of their sweat lodge and vision quest ceremonies by non-Natives, and even by tribes who have not traditionally had these ceremonies. They contend that there are serious safety risks whenever these events are conducted by those who lack the many years of training and cultural immersion required to lead them safely, pointing to the deaths or injuries in 1996, 2002, 2004, and several high-profile deaths in 2009.

Cultural appropriation is controversial in the fashion industry due to the belief that some trends commercialise and cheapen the ancient heritage of indigenous cultures. There is debate about whether designers and fashion houses understand the history behind the clothing they are taking from different cultures, besides the ethical issues of using these cultures' shared intellectual property without consent, acknowledgement, or compensation. In response to this criticism, many fashion experts claim that this occurrence is in fact "culture appreciation", rather than cultural appropriation. Companies and designers claim the use of unique cultural symbols is an effort to recognize and pay homage to that specific culture.

During the 17th century, the forerunner to the three piece suit was appropriated from the traditional dress of diverse Eastern European and Islamic countries. The Justacorps frock coat was copied from the long zupans worn in Poland and Ukraine, the necktie or cravat was derived from a scarf worn by Croatian mercenaries fighting for Louis XIII, and the brightly colored silk waistcoats popularised by Charles II of England were inspired by exotic Turkish, Indian and Persian attire acquired by wealthy English travellers.

During the Highland Clearances, the British aristocracy appropriated traditional Scottish clothing. Tartan was given spurious association with specific Highland clans after publications such as James Logan's romanticised work "The Scottish Gael" (1831) led the Scottish tartan industry to invent clan tartans and tartan became a desirable material for dresses, waistcoats and cravats. In America, plaid flannel had become workwear by the time of Westward expansion, and was widely worn by Old West pioneers and cowboys who were not of Scottish descent. In the 21st century, tartan remains ubiquitous in mainstream fashion.

By the 19th century the fascination had shifted to Asian culture. English Regency era dandies adapted the Indian churidars into slim fitting pantaloons, and frequently wore turbans within their own houses. Later, Victorian gentlemen wore smoking caps based on the Islamic fez, and fashionable turn of the century ladies wore Orientalist Japanese inspired kimono dresses. During the tiki culture fad of the 1950s, white women frequently donned the qipao to give the impression that they had visited Hong Kong, although the dresses were frequently made by seamstresses in America using rayon rather than genuine silk. At the same time, teenage British Teddy Girls wore Chinese coolie hats due to their exotic connotations.

In Mexico, the sombrero associated with the mestizo peasant class was appropriated from an earlier hat introduced by the Spanish colonials during the 18th century. This, in turn, was adapted into the cowboy hat worn by American cowboys after the US Civil War. In 2016, the University of East Anglia prohibited the wearing of sombreros to parties on campus, in the belief that these could offend Mexican students.

American Western wear was copied from the work attire of 19th century Mexican Vaqueros, especially the pointed cowboy boots and the guayabera which was adapted into the embroidered Western shirt. The China poblana dress associated with Mexican women was appropriated from the choli and lehenga worn by Indian maidservants like Catarina de San Juan who arrived from Asia from the 17th century onwards.

In Britain, the rough tweed cloth clothing of the Irish, English and Scottish peasantry, including the flat cap and Irish hat were appropriated by the upper classes as the British country clothing worn for sports such as hunting or fishing, in imitation of the then Prince of Wales. The country clothing, in turn, was appropriated by the wealthy American soc and later preppy subcultures during the 1950s and 1980s due to both its practicality and its association with the English elite. During the same period the British comedian Tommy Cooper was known for wearing a Fez throughout his performances.

When keffiyehs became popular in the late 2000s, experts made a clear distinction between the wearing of a genuine scarf, and a fake made in China. Palestinian independence activists and socialists denounced the wearing of scarves not made in Palestine as a form of cultural appropriation, but encouraged young white people and fellow Muslims to buy shemaghs made in the Herbawi factory to demonstrate solidarity with the Palestinian people and improve the economy of the West Bank. In 2017, Topshop caused controversy by selling Chinese-made playsuits that imitated the pattern of the keffiyeh.

Several fashion designers and models have featured imitations of Native American warbonnets in their fashion shows, such as Victoria's Secret in 2012, when model Karlie Kloss wore one during her walk on the runway; a Navajo Nation spokesman called it a "mockery". Cherokee academic Adrienne Keene wrote in "The New York Times":

For the [Native American] communities that wear these headdresses, they represent respect, power and responsibility. The headdress has to be earned, gifted to a leader in whom the community has placed their trust. When it becomes a cheap commodity anyone can buy and wear to a party, that meaning is erased and disrespected, and Native peoples are reminded that our cultures are still seen as something of the past, as unimportant in contemporary society, and unworthy of respect.

Both Victoria's Secret and Kloss issued apologies stating that they had no intentions of offending anyone.

Archbishop Justin Welby of the Anglican Church has claimed that the crucifix is "now just a fashion statement and has lost its religious meaning.". Crucifixes have been incorporated into Japanese lolita fashion by non-Christians in a cultural context that is distinct from its original meaning as a Christian religious symbol.


While the history of colonization and marginalization is not unique to the Americas, the practice of non-Native sports teams deriving team names, imagery, and mascots from indigenous peoples is still common in the United States and Canada, and has persisted to some extent despite protests from Indigenous groups. Cornel Pewewardy, Professor and Director of Indigenous Nations Studies at Portland State University, cites indigenous mascots as an example of dysconscious racism which, by placing images of Native American or First Nations people into an invented media context, continues to maintain the superiority of the dominant culture. It is argued that such practices maintain the power relationship between the dominant culture and the indigenous culture, and can be seen as a form of cultural imperialism.

Such practices may be seen as particularly harmful in schools and universities which have a stated purpose of promoting ethnic diversity and inclusion. In recognition of the responsibility of higher education to eliminate behaviors that create a hostile environment for education, in 2005 the NCAA initiated a policy against "hostile and abusive" names and mascots that led to the change of many derived from Native American culture, with the exception of those that established an agreement with particular tribes for the use of their specific names. Other schools retain their names because they were founded for the education of Native Americans, and continue to have a significant number of indigenous students. The trend towards the elimination of indigenous names and mascots in local schools has been steady, with two thirds having been eliminated over the past 50 years according to the National Congress of American Indians (NCAI).

While the leadership of nearly all Native American tribes object to their depictions as sports mascots, only one tribe explicitly approves of such representations. The Florida State Seminoles use the iconography of the Seminole tribe. Their mascots are Osceola and Renegade, depictions of the Seminole chief Osceola and his Appaloosa horse. After the NCAA attempted to ban the use of Native American names and iconography in college sports in 2005, the Seminole Tribe of Florida passed a resolution offering explicit support for FSU's use of Seminole culture and Osceola as a mascot; the university was granted a waiver, citing the close relationship with and consultation between the team and the tribe. In 2013, the tribe's chairman objected to outsiders meddling in tribal approval, stating that the FSU mascot and use of Seminole iconography "represents the courage of the people who were here and are still here, known as the Unconquered Seminoles." Conversely, in 2013, the Seminole Nation of Oklahoma expressed disapproval of "the use of all American Indian sports-team mascots in the public school system, by college and university level and by professional sports teams", and not all members of the tribe's Florida branch are supportive of its stance.

In other former colonies in Asia, Africa, and South America, the adoption of indigenous names for majority indigenous teams is also found. There are also ethnicity-related team names derived from prominent immigrant populations in the area, such as the Boston Celtics, the Notre Dame Fighting Irish, and the Minnesota Vikings.

The 2018 Commonwealth Games to be held on the Gold Coast in Australia from 4 April 2018 has named its mascot Borobi, the local Yugambeh word for "koala," and has sought to trademark the word through IP Australia. The application is being opposed by a Yugambeh cultural heritage organisation, which argues that the Games organising committee used the word without proper consultation with the Yugambeh people.

The term wigger (common spelling "wigga") is a slang term for a white person who adopts the mannerisms, language, and fashions associated with African-American culture, particularly hip hop, and, in Britain, the grime scene, often implying the imitation is being done badly, although usually with sincerity rather than mocking intent. Wigger is a portmanteau of "white" and "nigger" or "nigga," and the related term wangsta is a mashup of "wannabe" or "white", and "gangsta". Among black hip-hop fans, the word "nigga" can sometimes be considered a friendly greeting, but when used by whites, it is usually viewed as offensive. "Wigger" may be derogatory, reflecting stereotypes of African-American, black British, and white culture (when used as synonym of white trash). The term is sometimes used in a racist manner, by other white people to belittle the person perceived as "acting black", but it is also widely used by African Americans like 50 Cent offended by the wigga or wanksta's demeaning of black people and culture.

The phenomenon of white people adopting elements of black culture has been prevalent at least since slavery was abolished in the Western world. The concept has been documented in the United States, Canada, the United Kingdom, Australia, and other white-majority countries. An early form of this was the "white negro" in the jazz and swing music scenes of the 1920s and 1930s, as examined in the 1957 Norman Mailer essay "The White Negro". It was later seen in the zoot suiter of the 1930s and 1940s, the hipster of the 1940s, the beatnik of the 1950s–1960s, the blue-eyed soul of the 1970s, and the hip hop of the 1980s and 1990s. In 1993, an article in the UK newspaper "The Independent" described the phenomenon of white, middle-class kids who were "wannabe Blacks". 2005 saw the publication of "Why White Kids Love Hip Hop: Wangstas, Wiggers, Wannabes, and the New Reality of Race in America" by Bakari Kitwana, "a culture critic who's been tracking American hip hop for years""."

Robert A. Clift's documentary "Blacking Up: Hip-Hop's Remix of Race and Identity" questions white enthusiasts of black hip-hop culture. Clift's documentary examines "racial and cultural ownership and authenticity -- a path that begins with the stolen blackness seen in the success of Stephen Foster, Al Jolson, Benny Goodman, Elvis Presley, the Rolling Stones -- all the way up to Vanilla Ice (popular music's ur-wigger...) and Eminem." A review of the documentary refers to the wiggers as "white poseurs", and states that the term "wigger" "is used both proudly and derisively to describe white enthusiasts of black hip-hop culture".
The term "blackfishing" was popularised in 2018 by writer Wanna Thompson, describing female white social media influencers who adopt a look perceived to be black or mixed race - including braided hair, dark skin from tanning or make-up, full lips, and large thighs. Critics argue they take attention and opportunities from black influencers by appropriating their aesthetic and have likened the trend to blackface.

Among critics, the misuse and misrepresentation of indigenous culture is seen as an exploitative form of colonialism, and one step in the destruction of indigenous cultures.

The results of this use of indigenous knowledge have led some tribes, and the United Nations General Assembly, to issue several declarations on the subject. The "Declaration of War Against Exploiters of Lakota Spirituality" includes the passage:
Article 31 1 of the United Nations "Declaration on the Rights of Indigenous Peoples" states:

In 2015, a group of Native American academics and writers issued a statement against the Rainbow Family members whose acts of "cultural exploitation... dehumanize us as an indigenous Nation because they imply our culture and humanity, like our land, is anyone's for the taking."

In writing about Indigenous intellectual property for the Native American Rights Fund (NARF), board member Professor Rebecca Tsosie stresses the importance of these property rights being held collectively, not by individuals: 

The long-term goal is to actually have a legal system, and certainly a treaty could do that, that acknowledges two things. Number one, it acknowledges that indigenous peoples are peoples with a right to self-determination that includes governance rights over all property belonging to the indigenous people. And, number two, it acknowledges that indigenous cultural expressions are a form of intellectual property and that traditional knowledge is a form of intellectual property, but they are collective resources – so not any one individual can give away the rights to those resources. The tribal nations actually own them collectively.

Use of minority languages is also cited as cultural appropriation when non-speakers of Scottish Gaelic or Irish get tattoos in those languages. Likewise, the use of incorrect Scottish Gaelic in a tokenistic fashion aimed at non-Gaelic speakers on signage and announcements has been criticized as disrespectful to fluent speakers of the language.

Since the early 2000s, it has become increasingly popular for people not of Asian descent, to get tattoos of Indian devanagari, Korean letters or Han characters (traditional, simplified or Japanese), often without knowing the actual meaning of the symbols being used.

According to last US Census (2010), Asian-Americans make up 4.8 percent of the population. According to a study by the University of Southern California Annenberg School for Communication and Journalism in 2016, only one out of 20 (which corresponds to 5 percent) speaking roles go to Asian-Americans. However, they are given only one percent of lead roles in film. White actors account for 76.2 percent of lead roles, while representing 72.4 percent of the population according to the last US census. 

In 2017, "Ghost in the Shell", which is based on the seinen manga "Ghost in the Shell" by Masamune Shirow, provoked disputes over whitewashing. Scarlett Johansson, a white actress, took the role of Motoko Kusanagi, a Japanese character. This was seen as cultural appropriation by some fans of the original manga who expected the role to be taken by an Asian or Asian-American actor.

During Halloween, some people buy, wear, and sell Halloween costumes based on cultural or racial stereotypes. Costumes that depict cultural stereotypes, like "Indian Warrior" or "Pocahottie" are sometimes worn by people who do not belong to the cultural group being stereotyped. These costumes have been criticized as being in poor taste at best and, at worst, blatantly racist and dehumanizing. There have been public protests calling for the end to the manufacture and sales of these costumes and connecting their "degrading" portrayals of Indigenous women to the Missing and Murdered Indigenous Women (MMIW) crisis. In some cases, theme parties have been held where attendees are encouraged to dress up as stereotypes of a certain racial group. A number of these parties have been held at colleges, and at times other than Halloween, including Martin Luther King Jr. Day and Black History Month.

In chapter four of his book "Playing Indian", Native American historian Philip J. Deloria refers to the Koshare Indian Museum and Dancers as an example of "object hobbyists" who adopt the material culture of indigenous peoples of the past ("the vanishing Indian") while failing to engage with contemporary native peoples or acknowledge the history of conquest and dispossession. In the 1950s, the head councilman of the Zuni Pueblo saw a performance and said: "We know your hearts are good, but even with good hearts you have done a bad thing." In Zuni culture, religious object and practices are only for those that have earned the right to participate, following techniques and prayers that have been handed down for generations. In 2015, the Koshare's Winter Night dances were canceled after a late request was received from Cultural Preservation Office (CPO) of the Hopi Nation asking that the troop discontinue their interpretation of the dances of the Hopi and Pueblo Native Americans. Director of the CPO Leigh Kuwanwisiwma saw video of the performances online, and said the performers were "mimicking our dances, but they were insensitive, as far as I'm concerned." In both instances, unable to satisfy the concerns of the tribes and out of respect for the Native Americans, the Koshare Dance Team complied with the requests, removed dances found to be objectionable, and even went so far as to give items deemed culturally significant to the tribes.

The objections from some Native Americans towards such dance teams center on the idea that the dance performances are a form of cultural appropriation which place dance and costumes in inappropriate contexts devoid of their true meaning, sometimes mixing elements from different tribes. In contrast, the dance teams state that "[their] goal is to preserve Native American dance and heritage through the creation of dance regalia, dancing, and teaching others about the Native American culture."

Some people in the transgender community have protested against the casting of straight, cis-gender actors in trans acting roles, such as when Eddie Redmayne played the role of artist Lili Elbe in the film "The Danish Girl" and when Jared Leto played the role of a trans woman named Rayon in "Dallas Buyers Club". The gay community has expressed concerns about the use of straight actors to play gay characters; this occurs in films such as "Call Me by Your Name" (straight actors Armie Hammer and Timothée Chalamet), "Brokeback Mountain" (Heath Ledger and Jake Gyllenhaal), "Philadelphia" (starring Tom Hanks), "Capote" (starring Philip Seymour Hoffman) and "Milk" (with Sean Penn playing the role of the real-life gay rights activist, Harvey Milk). Jay Caruso calls these controversies "wholly manufactured", on the grounds that the actors "are playing a role" using the "art of acting".

In some cases, a culture usually viewed as the target of cultural appropriation can be accused of appropriation, particularly after colonization and an extensive period re-organization of that culture under the nation-state system. For example, the government of Ghana has been accused of cultural appropriation in adopting the Caribbean Emancipation Day and marketing it to African American tourists as an "African festival".

For some members of the South-Asian community, the wearing of a bindi dot as a decorative item, by a non-Hindu, or by a woman who is not South Asian, is considered cultural appropriation.

A common term among Irish people for someone who imitates or misrepresents Irish culture is "Plastic Paddy".

In 2003, Prince Harry of the British royal family used Indigenous Australian art motifs in a painting for a school project. One Aboriginal group labelled it "misappropriation of our culture", saying that to Aboriginal people, the motifs have symbolic meanings "indicative of our spiritualism", whereas when non-Aborigines use the motifs they are simply "painting a pretty picture".

In the Victoria's Secret Fashion Show 2012, former Victoria's Secret model Karlie Kloss donned a Native American-style feathered headdress with leather bra and panties and high-heeled moccasins. This was said to be an example of cultural appropriation because the fashion show is showcasing the company's lingerie and image as a global fashion giant. The outfit was supposed to represent November, and thus "Thanksgiving", in the "Calendar Girls" segment. The outfit met with backlash and criticism as an appropriation of Native American culture and tradition. Victoria's Secret pulled it from the broadcast and apologized for its use. Kloss also commented on the decision by tweeting "I am deeply sorry if what I wore during the VS Show offended anyone. I support VS's decision to remove the outfit from the broadcast."

Avril Lavigne was cited by some as appropriating Japanese culture in her song "Hello Kitty". The song and music video depict Asian women dressed up in matching outfits and Lavigne eating Asian food while dressed in a pink tutu. Lavigne responded by stating "I love Japanese culture and I spend half of my time in Japan. I flew to Tokyo to shoot this video ... specifically for my Japanese fans, "with" my Japanese label, Japanese choreographers "and" a Japanese director "in" Japan." Feedback for Lavigne's song was favorable in Japan, but "[the] people who are blaming the artist for racism [were] non-Japanese."

When Selena Gomez wore the bindi during a performance, there was debate on her reasoning behind wearing the culture specific piece. Some viewed this as "casting her vote for Team India" but it was also viewed as misuse of the symbol as Selena was seen as not supporting or relating the Bindi to its origin of Hinduism, but furthering her own self-expression. In 2014, Pharrell Williams posed in a Native American war bonnet on the cover of "Elle" UK magazine, after much controversy and media surrounding the photo Williams apologized.

Actress Amandla Stenberg made a school-related video called "Don't Cash Crop on My Cornrows" about the use of black hairstyles and black culture by non-black people, accusing Katy Perry and Iggy Azalea of using "black culture as a way of being edgy and gaining attention". Stenberg later criticized Kylie Jenner for allegedly embracing African-American aesthetic values without addressing the issues that affect the community. The African-American hip hop artist Azealia Banks has also criticized Iggy Azalea "for failing to comment on 'black issues' despite capitalising on the appropriation of African American culture in her music." Banks has called Azalea a "wigger" and there have been "accusations of racism against Azalea" focused on her alleged "insensitivity to the complexities of race relations and cultural appropriation."

Rachel Dolezal made headlines in 2015 when it was discovered that she was not African-American, as she had claimed. She is an American former civil rights activist known for being exposed as Caucasian while falsely claiming to be a black woman. Dolezal was president of the National Association for the Advancement of Colored People (NAACP) chapter in Spokane, Washington, from February 7, 2014 until June 15, 2015 when she resigned amid suspicion she had lied about nine alleged hate crimes against her. She received further public scrutiny when her white parents publicly stated that Doležal was a white woman passing as black.

In 2017, in an interview with Billboard magazine regarding her new image, Miley Cyrus criticized what she considered to be overly vulgar aspects of Hip Hop culture while expressing her admiration for the song "Humble" by Kendrick Lamar. This was met with backlash from people who felt Cyrus has a history of appropriating hip hop culture.

In 2011, a group of students at Ohio University started a poster campaign denouncing the use of cultural stereotypes as costumes. The campaign features people of color alongside their respective stereotypes with slogans such as "This is not who I am and this is not okay." The goal of the movement was to raise awareness around racism during Halloween in the university and the surrounding community, but the images also circulated online.

"Reclaim the Bindi" has become a hashtag used by some people of South Asian descent who wear traditional garb, and object to its use by people not of their culture. At the 2014 Coachella festival one of the most noted fashion trends was the bindi, a traditional Hindu head mark. As pictures of the festival surfaced online there was public controversy over the casual wearing of the bindi by non-Indian individuals who did not understand the meaning behind it. #CoachellaShutdown has been used in conjunction with #ReclaimtheBindi in order to protest against the use of the bindi at music festivals, most notably the Coachella Valley Music and Arts Festival. Reclaim the Bindi Week is an event which seeks to promote the traditional cultural significance of the bindi and combat its use as a fashion statement.

John McWhorter, a professor at Columbia University, has criticized the concept, arguing that cultural borrowing and cross-fertilization is a generally positive thing, and is something which is usually done out of admiration, and with no intent to harm, the cultures being imitated; he also argued that the specific term "appropriation," which can mean theft, is misleading when applied to something like culture that is not seen by all as a limited resource: unlike appropriating a physical object, others imitating an idea taken from one group's culture don't inherently deprive that originating group of its use.

In 2016, author Lionel Shriver gave a speech at the Brisbane Writers Festival, asserting the right of authors to write from any point of view, including that of characters from cultural backgrounds other than their own – as writers "should be seeking to push beyond the constraining categories into which we have been arbitrarily dropped by birth. If we embrace narrow group-based identities too fiercely, we cling to the very cages in which others would seek to trap us." She also asserted the right of authors from a cultural majority to write in the voice of someone from a cultural minority, attacking the idea that this constitutes unethical "cultural appropriation". Referring to a case in which U.S. college students were facing disciplinary action for wearing sombreros to a 'tequila party', she said "The moral of the sombrero scandals is clear: "you're not supposed to try on other people's hats". Yet that's what we’re paid to do, isn't it? Step into other people's shoes, and try on their hats."

In 2017, Canadian clinical psychologist, author, and professor of psychology at the University of Toronto Jordan Peterson stated in a Q&A session from a speech entitled "Strengthen the Individual", "The idea of cultural appropriation is nonsense, and that’s that. There’s no difference between cultural appropriation and learning from each other. They’re the same thing. Now, that doesn’t mean that there’s no theft between people; there is. And it doesn’t mean that once you encounter someone else’s ideas, you have an absolute right to those ideas as if they’re your own. But the idea that manifesting some element of another culture in your own behavior is immoral is insane. It’s actually one of the bases of peace."


</doc>
<doc id="4938890" url="https://en.wikipedia.org/wiki?curid=4938890" title="Lebeau, Louisiana">
Lebeau, Louisiana

Lebeau (also spelled LeBeau) is an unincorporated community in St. Landry Parish, Louisiana, United States, in the central part of the state. Nearby communities include Palmetto, Ville Platte and Washington. The community is part of the Opelousas–Eunice Micropolitan Statistical Area.


North Central High School (Hurricanes) - Grades 5–12.

Lebeau Zydeco Festival – an annual festival featuring performances from leading zydeco artist. As of 2018, the festival is hosting the 28th annual celebration. The festival is usually held on the first Saturday in July on the Immaculate Conception Catholic Church Grounds.



</doc>
<doc id="58929051" url="https://en.wikipedia.org/wiki?curid=58929051" title="Reshaping Cultural Policies">
Reshaping Cultural Policies

Reshaping Cultural Policies (styled as Re|Shaping Cultural Policies) is a report series published by UNESCO which monitors the implementation of the UNESCO Convention on the Protection and Promotion of the Diversity of Cultural Expressions (2005). The 2005 UNESCO Convention encourages its 146 parties to introduce policies for culture within a global context and commitment to protect and promote the diversity of cultural expressions. The second and most recent report (2018) subtitled “Advancing Creativity for Development” follows the first report (2015) with the subtitle “A Decade Promoting the Diversity of Cultural Expressions for Development”.

Primarily, the report series draws on reports of all parties to the Convention submitted every four years in which they present and describe the actions they have taken in order to implement the Convention. These reports are called quadrennial periodic reports (QPRs). In addition, the report series includes the analysis of other both governmental and non-governmental sources. In general, the report investigates how implementing the convention reshapes cultural policies. Additionally, it provides evidence of how the implementation process contributes to attaining the United Nations 2030 Sustainable Development Goals (SDGs) to end poverty, protect the planet, and ensure prosperity for every human being. The report series also analyses trends and issues concerning the creative economy, which currently is worth $2,250 billion and employs 30 million people worldwide.

The report puts forward a set of policy recommendations for the future, addressing the adaptation of cultural policies to rapid change in the digital environment, based on human rights and fundamental freedoms of expression. 

“Each Report is not an end-result, but a tool to be used in a long-term process that includes the forging of spaces for policy dialogue, reinforcing stakeholders’ capacities to work together to generate data and information, and advocate for policy innovation both nationally and globally.” 

The reports are published in English, French, Spanish, Russian, Portuguese, Arabic, Chinese, Indonesian, Vietnamese and German. UNESCO is the lead institutional author of the Global Report series and coordinates a broader network of independent experts who author chapters. 

In line with the Parties’ quadrennial periodic reporting, the series is produced every four years. The first cycle spanned the years 2012-2015 and the second runs from 2016 to 2019. Accordingly, the third publication will take place in December 2021.

The 2005 Convention is an international standard setting instrument providing a framework for the governance of culture. In this context, governance of culture refers to policies and measures governments establish to regulate, to promote and to protect all forms of creativity and artistic expressions. The most recent UNESCO Convention in the field of culture and ratified by 146 parties, it is the first international legal tool to encourage governments to invest in creativity. It frames the formulation and implementation of different types of legislative, regulatory, institutional and financial interventions to promote the emergence of dynamic cultural and creative industry sectors around the world.

Within the context of the 2005 Convention, the diversity of cultural expressions "″"refers to the manifold ways in which the cultures of groups and societies find expression. These expressions are passed on within and among groups and societies"″". Specifically, the Convention understands cultural expressions as all forms of creativity and artistic expressions, such as in cinema/audiovisual arts, design, digital arts, music, performing arts, publishing and the visual arts. The 2005 Convention was "since its beginnings, permeated by a material and economic perspective of cultural expressions, focused on the production and consumption of cultural goods and services, with a view to promote more balanced exchanges and sustainable development that takes into account cultural diversity concerns." 

The implementation of the 2005 Convention aims to contribute to achieving several Sustainable Development Goals (SDGs), precisely SDG 4 (Quality Education), SDG 5 (Gender Equality), SDG 8 (Decent Work and Economic Growth), SDG 10 (Reduced Inequalities), SDG 16 (Peace, Justice and Strong Institutions) and SDG 17 (Partnerships for the Goals). The implementation process identifies investing in creativity as a priority for sustainable development. At the global level, the convention calls for countries to provide financial assistance for creativity through their Official Development Assistance (ODA) by investing in the Convention’s International Fund for Cultural Diversity. Additionally, UNESCO, through the 2005 Convention, offers technical assistance to strengthen human and institutional capacities in developing countries.

The director general of UNESCO, Audrey Azoulay referring to the UNESCO General Conference's conviction that cultural activities, goods and services have both an economic and a cultural nature stated: ″[c]ulture is not a commodity: it carries values and identities, it gives markers to live together in a globalized world. Our role is to encourage, question, collect data, to understand and energize creative channels, to encourage the mobility of artists, to stimulate a rapidly changing sector in the new digital environment″. Annika Markovic, Ambassador and Permanent Delegate of Sweden to UNESCO, in 2018, claimed that the report is "“the only global document that presents an overview of cultural development world-wide and monitors state action to protect and promote the diversity of cultural expressions at all levels.”" 

The following aspects thematically summarize the core findings identified by the 2018 report with regard to the implementation of the 2005 UNESCO Convention.

For the first time, national development plans and strategies integrate culture, mainly of countries in the Global South. As a result, cities seem to invest more and more in cultural industries for development. The UN’s 2030 Agenda recognized the role of creativity in sustainable development in the implementation of the SDGs. However, the share of development aid spent on culture today is the lowest it has been in over 10 years. 

According to the report, digital revenues make up 50% of the recorded music market, growing almost 18% over the past year due to a sharp increase in the share of streaming revenues. 

The report states that the internet transforms the cultural value chain into a network platform. E-commerce challenges both culture and trade policies that intend to promote the diversity of cultural expressions. It articulates the urgency to improve data collection on revenues generated through digital channels in order to design better policies and negotiate fair trade agreements. The report claims that monitoring the relationship between large platforms, Big Data, artificial intelligence and the diversity of cultural expressions is crucial to ensure that a variety of distribution platforms and providers promote and protect future artistic creations. 

As informed by the report, attacks against artists have increased in the past years, including in the digital environment where surveillance and online trolling pose new threats to artistic freedom. In 2016, 430 cases were reported around the world (compared to 340 in 2015 and 90 in 2014). Musicians are the most threatened group, while authors also often become a target. In 2016, attacks against authors occurred most often in the Asia-Pacific Region (80 cases), the Middle East and North Africa (51 cases) and Europe (47 cases). The report reveals that meanwhile, there exists an increased awareness with regard to such threats leading to a larger number of initiatives to support the social and economic rights of artists, particularly in African countries. While there exists legal action to affirm the freedom of expression for artists, other laws addressing terrorism and state security repress artistic expressions. 

The report states that half of the persons working in the cultural and creative industries are female. However, a gender gap persists worldwide concerning equal pay, access to funding and prices charged for creative works. Consequently, women remain under-represented in key creative roles and are outnumbered in decision-making positions. Women make up only 34% of Ministers for Culture (compared to 24% in 2005) and only 31% of national arts program directors. Generally, women are represented in specific cultural fields such as arts education and training (60%), book publishing and press (54%), audiovisual and interactive media (26%), as well as design and creative services (33%).

The report demonstrates that predominantly restrictions in terms of mobility represent great challenges to persons pursuing careers in the cultural and creative industries, specifically to those from the Global South. It reveals that a holder of a German passport can travel to 176 countries without a visa while a holder of an Afghan passport can only travel to 24 countries without a visa. As a matter of fact, artists and cultural professionals need to travel to perform, to reach new audiences or to attend a residency or to engage in networking. The report exposes that travel restrictions, including difficulties in obtaining visas oftentimes impedes artists from the Global South to participate in art biennales or film festivals, even when invited to receive an award or to promote their works. 

As stated in the report, the 2005 Convention provides legitimacy for the formulation of cultural policies and their adaptation to changing circumstances and needs. The report underscores that collaborative governance and multi-stakeholder policy making have progressed, notably in some developing countries particularly in the creative economy and cultural education. As a result, parties to the Convention have made considerable progress in fostering digital arts creation, supporting creative entrepreneurship, accelerating the modernization of cultural sectors, promoting distribution and updating copyright legislation. However, the report also reveals a lack in civil society participation in policy making. It underlines the urgency for more effort to ensure the creation of open, transparent and participatory policy processes in order to involve civil society participation in policy making. 

In accordance with the report, the 2005 Convention formally recognizes that cultural goods and services not only have important economic value, but also convey identities, meanings and values. As a consequence, at least eight bilateral and regional free trade agreements concluded between 2015 and 2017 have introduced cultural clauses or list of commitments that promote the objectives and principles of the 2005 Convention. Despite the lack of the promotion of the objectives and principles of the 2005 Convention with regard to the negotiation of mega-regional partnership agreements, some Parties to the Trans Pacific Partnership (TTP) have succeeded in introducing important cultural reservations to protect and promote the diversity of cultural expressions. 

The report’s primary objective is “to provide key actors with better knowledge on how to support evidence-based policy, and to strengthen informed, transparent and participatory systems of governance for culture.” It aims to motivate governments and civil society actors to integrate findings and recommendations into their national cultural policy and development strategies and frameworks. 

Following the findings presented above, the implementation of the 2005 Convention "introduce[s] a range of different policy strategies for integrating culture into development processes" and culture is increasingly regarded as "an economic asset in pursuing sustainable development". Based on its analysis and findings, the Global Report of 2018 suggests the following road map for the parties to the 2005 Convention. Accordingly, parties could tackle major challenges in the implementation of the 2005 Convention by:


Speaking about the visibility of the progress in cultural policies shown by the report series, Bárbara Lovrinić stated that "“[u]nfortunately, where UNESCO is concerned, there is a lack of promotion in the media in general. In the long term, the report could have a positive impact on these issues, which would be enhanced if the public were made more aware of such work.”" She also points out that there is ""a risk that many people will not dwell on the 2005 Convention and the Sustainable Development Goals unless they are already somewhat familiar with the topic.”" With reference to the title of the report series, she concludes that ""cultural policy-making is still far from being reshaped, for it takes a serious amount of time to yield valuable results.”"




</doc>
<doc id="5708" url="https://en.wikipedia.org/wiki?curid=5708" title="Collectivism">
Collectivism

Collectivism is a cultural value that is characterized by emphasis on cohesiveness among individuals and prioritization of the group over self. Individuals or groups that subscribe to a collectivist worldview tend to find common values and goals as particularly salient and demonstrate greater orientation toward in-group than toward out-group. The term “in-group” is thought to be more diffusely defined for collectivistic individuals to include societal units ranging from the nuclear family to a religious or racial/ethnic group. Meta-analytic findings support that collectivism shows a consistent association with discrete values, interpersonal patterns of interaction, cognition, perception and self-construal. While collectivism is often defined in contrast to individualism, the notion that collectivism-individualism is unidimensional has been challenged by contemporary theorists.

The German sociologist Ferdinand Tönnies described an early model of collectivism and individualism using the terms "Gemeinschaft" (community) and "Gesellschaft" (society). "Gemeinschaft" relationships, in which communalism is prioritized, were thought to be characteristic of small, rural village communities. An anthropologist, Redfield (1941) echoed this notion in work contrasting folk society with urban society.

Max Weber (1930) contrasted collectivism and individualism through the lens of religion, believing that Protestants were more individualistic and self-reliant compared to Catholics, who endorsed hierarchical, interdependent relationships among people.

Hofstede (1980) was highly influential in ushering in an era of cross-cultural research making comparisons along the dimension of collectivism versus individualism. Hofstede conceptualized collectivism and individualism as part of a single continuum, with each cultural construct representing an opposite pole. The author characterized individuals that endorsed a high degree of collectivism as being embedded in their social contexts and prioritizing communal goals over individual goals.

Collectivism was an important part of Marxist–Leninist ideology in the Soviet Union, where it played a key part in forming the New Soviet man, willingly sacrificing his or her life for the good of the collective. Terms such as "collective" and "the masses" were frequently used in the official language and praised in agitprop literature, for example by Vladimir Mayakovsky ("Who needs a "1"") and Bertolt Brecht (The Decision, Man Equals Man).

The construct of collectivism is represented in empirical literature under several different names. Most commonly, the term interdependent self-construal is used. Other phrases used to describe the concept of collectivism-individualism include allocentrism-idiocentrism, collective-private self, as well as subtypes of collectivism-individualism (meaning, vertical and horizontal subtypes). Inconsistent terminology is thought to account for some of the difficulty in effectively synthesizing the empirical literature on collectivism.

Typically, collectivism is measured via self-report questionnaire. Meta-analytic findings suggest that there are six instruments that have been used to measure collectivism (and the related construct of individualism) in a manner that best reflects current theoretical thinking.

In one critical model of collectivism, Markus and Kitayama describe the interdependent (i.e., collectivistic) self as fundamentally connected to the social context. As such, one's sense of self depends on and is defined in part by those around them and is primarily manifested in public, overt behavior. As such, the organization of the self is guided by using others as a reference. That is, an interdependent individual uses the unexpressed thoughts, feelings, and beliefs of another person with whom they have a relationship with, as well as the other person's behaviors, to make decisions about their own internal attributes and actions.

Markus and Kitayama also contributed to the literature by challenging Hofstede's unidimensional model of collectivism-individualism. The authors conceptualized these two constructs bidimensionally, such that both collectivism and individualism can be endorsed independently and potentially to the same degree. This notion has been echoed by other prominent theorists in the field.

Some researchers have expanded the collectivism-individualism framework to include a more comprehensive view. Specifically, Triandis and colleagues introduced a theoretical model in which incorporates the notion of relational contexts. The authors argues that the domains of collectivism and individualism can be further described by horizontal and vertical relationships. Horizontal relationships are believed to be status-equal whereas vertical relationships are characterized as hierarchical and status-unequal. As such, horizontal collectivism is manifested as an orientation in which group harmony is highly valued and in-group members are perceived to experience equal standing. Vertical collectivism involves the prioritization of group goals over individual goals, implying a hierarchical positioning of the self in relation to the overarching in-group. The horizontal-vertical individualism-collectivism model has received empirical support and has been used to explore patterns within cultures.

Originated by W. E. B. DuBois, some researchers have adopted a historical perspective on the emergence of collectivism among some cultural groups. DuBois and others argued that oppressed minority groups contend with internal division, meaning that the development of self-identity for individuals from these groups involves the integration of one's own perceptions of their group as well as typically negative, societal views of their group. This division is thought to impact goal formation such that people from marginalized groups tend to emphasize collectivistic over individualistic values.

Some organizational research has found different variations of collectivism. These include institutional collectivism and in-group collectivism. Institutional collectivism is the idea that a work environment creates a sense of collectivist nature due to similar statuses and similar rewards, such as earning the same salary. In-group collectivism is the idea that an individual's chosen group of people, such as family or friend groups, create a sense of collectivist nature. In-group collectivism can be referred to as family collectivism.

A number of classic studies have demonstrated that there is a relationship between collectivism and cognition. These studies support the notion that people from collectivistic cultures tend to demonstrate a holistic cognitive style, which is reflected in processes such as memory, visual perception, attributional style, and categorization schemas. This effect has been replicated extensively by independent research groups, supporting its robustness.


An individual's self-concept can be fundamentally shaped by cultural values. Such processes typically begin in childhood and adolescence and parents are often one of the first critical inputs that shape a child's sense of self-concept. Parents with more collectivistic world views have been shown to speak and interact with their children in a manner that conveys the core tenets of collectivism, such as emphasis on the relationships between objects and interpersonal connections. As such, youth who are parented in this manner tend to develop a sense of self that is defined in relation to others. This sense of self also has been found to be reflected in patterns of structural and functional connectivity in the brain. For example, generally the medial prefrontal cortex (MPFC) is more active when adults think about themselves compared to when they think about someone else. However, for adults who endorse collectivism, the MPFC actually shows greater response when they think about themselves in the context of their close relationships.

Cultural views are believed to have a reciprocal relationship with macro-level processes such as economics, social change, and politics. Societal changes in China exemplifies this well. Beginning in the early 1980s, China experienced dramatic expansion of economic and social structures, resulting in greater income inequality between families, less involvement of the government in social welfare programs, and increased competition for employment. Corresponding with these changes was a shift in ideology among Chinese citizens, especially among those who were younger, away from collectivism (the prevailing cultural ideology) toward individualism. China also saw this shift reflected in educational policies, such that teachers were encouraged to promote the development of their students’ individual opinions and self-efficacy, which prior to the aforementioned economic changes, was not emphasized in Chinese culture.

Attempts to study the association of collectivism and political views and behaviors has largely occurred at the aggregate national level. However, more isolated political movements have also adopted a collectivistic framework. For example, Collectivist anarchism (also known as anarcho-collectivism) is a revolutionary anarchist doctrine that advocates the abolition of both the state and private ownership of the means of production. It instead envisions the means of production being owned collectively and controlled and managed by the producers themselves.


</doc>
<doc id="9986" url="https://en.wikipedia.org/wiki?curid=9986" title="Outline of education">
Outline of education

The following [[Outline (list)|outline]] is provided as an overview of and topical guide to education:

[[Education]] – in the general sense is any act or [[experience]] that has a formative effect on the [[mind]], [[Moral character|character]], or physical ability of an individual. In its technical sense, education is the process by which society deliberately transmits its accumulated [[knowledge]], [[skill]]s, and [[Value (personal and cultural)|values]] from one generation to another. Education can also be defined as the process of becoming an educated person.










[[History of education]]

















[[Category:Education| ]]
[[Category:Learning]]
[[Category:Wikipedia outlines|Education]]

</doc>
<doc id="9252" url="https://en.wikipedia.org/wiki?curid=9252" title="Education">
Education

Education is the process of facilitating learning, or the acquisition of knowledge, skills, values, beliefs, and habits. Educational methods include storytelling, discussion, teaching, training, and directed research. Education frequently takes place under the guidance of educators, however learners may also educate themselves. Education can take place in formal or informal settings and any experience that has a formative effect on the way one thinks, feels, or acts may be considered educational. The methodology of teaching is called pedagogy.

Formal education is commonly divided formally into such stages as preschool or kindergarten, primary school, secondary school and then college, university, or apprenticeship.

A right to education has been recognized by some governments and the United Nations. In most regions, education is compulsory up to a certain age.

Etymologically, the word "education" is derived from the Latin word "ēducātiō" ("A breeding, a bringing up, a rearing") from "ēducō" ("I educate, I train") which is related to the homonym "ēdūcō" ("I lead forth, I take out; I raise up, I erect") from "ē-" ("from, out of") and "dūcō" ("I lead, I conduct").

Education began in prehistory, as adults trained the young in the knowledge and skills deemed necessary in their society. In pre-literate societies, this was achieved orally and through imitation. Story-telling passed knowledge, values, and skills from one generation to the next. As cultures began to extend their knowledge beyond skills that could be readily learned through imitation, formal education developed. Schools existed in Egypt at the time of the Middle Kingdom.

Plato founded the Academy in Athens, the first institution of higher learning in Europe. The city of Alexandria in Egypt, established in 330 BCE, became the successor to Athens as the intellectual cradle of Ancient Greece. There, the great Library of Alexandria was built in the 3rd century BCE. European civilizations suffered a collapse of literacy and organization following the fall of Rome in CE 476.

In China, Confucius (551–479 BCE), of the State of Lu, was the country's most influential ancient philosopher, whose educational outlook continues to influence the societies of China and neighbours like Korea, Japan, and Vietnam. Confucius gathered disciples and searched in vain for a ruler who would adopt his ideals for good governance, but his Analects were written down by followers and have continued to influence education in East Asia into the modern era.

The Aztecs also had a well-developed theory about education, which has an equivalent word in Nahuatl called "tlacahuapahualiztli." It means "the art of raising or educating a person" or "the art of strengthening or bringing up men." This was a broad conceptualization of education, which prescribed that it begins at home, supported by formal schooling, and reinforced by community living. Historians cite that formal education was mandatory for everyone regardless of social class and gender. There was also the word "neixtlamachiliztli", which is "the act of giving wisdom to the face." These concepts underscore a complex set of educational practices, which was oriented towards communicating to the next generation the experience and intellectual heritage of the past for the purpose of individual development and his integration into the community.

After the Fall of Rome, the Catholic Church became the sole preserver of literate scholarship in Western Europe. The church established cathedral schools in the Early Middle Ages as centres of advanced education. Some of these establishments ultimately evolved into medieval universities and forebears of many of Europe's modern universities. During the High Middle Ages, Chartres Cathedral operated the famous and influential Chartres Cathedral School. The medieval universities of Western Christendom were well-integrated across all of Western Europe, encouraged freedom of inquiry, and produced a great variety of fine scholars and natural philosophers, including Thomas Aquinas of the University of Naples, Robert Grosseteste of the University of Oxford, an early expositor of a systematic method of scientific experimentation, and Saint Albert the Great, a pioneer of biological field research. Founded in 1088, the University of Bologne is considered the first, and the oldest continually operating university.

Elsewhere during the Middle Ages, Islamic science and mathematics flourished under the Islamic caliphate which was established across the Middle East, extending from the Iberian Peninsula in the west to the Indus in the east and to the Almoravid Dynasty and Mali Empire in the south.

The Renaissance in Europe ushered in a new age of scientific and intellectual inquiry and appreciation of ancient Greek and Roman civilizations. Around 1450, Johannes Gutenberg developed a printing press, which allowed works of literature to spread more quickly. The European Age of Empires saw European ideas of education in philosophy, religion, arts and sciences spread out across the globe. Missionaries and scholars also brought back new ideas from other civilizations – as with the Jesuit China missions who played a significant role in the transmission of knowledge, science, and culture between China and Europe, translating works from Europe like Euclid's Elements for Chinese scholars and the thoughts of Confucius for European audiences. The Enlightenment saw the emergence of a more secular educational outlook in Europe.

In most countries today, full-time education, whether at school or otherwise, is compulsory for all children up to a certain age. Due to this the proliferation of compulsory education, combined with population growth, UNESCO has calculated that in the next 30 years more people will receive formal education than in all of human history thus far.

Formal education occurs in a structured environment whose explicit purpose is teaching students. Usually, formal education takes place in a school environment with classrooms of multiple students learning together with a trained, certified teacher of the subject. Most school systems are designed around a set of values or ideals that govern all educational choices in that system. Such choices include curriculum, organizational models, design of the physical learning spaces (e.g. classrooms), student-teacher interactions, methods of assessment, class size, educational activities, and more.

Preschools provide education from ages approximately three to seven, depending on the country when children enter primary education. These are also known as nursery schools and as kindergarten, except in the US, where kindergarten is a term often used to describe the earliest levels of primary education. Kindergarten "provide[s] a child-centred, preschool curriculum for three- to seven-year-old children that aim[s] at unfolding the child's physical, intellectual, and moral nature with balanced emphasis on each of them."

Primary (or elementary) education consists of the first five to seven years of formal, structured education. In general, primary education consists of six to eight years of schooling starting at the age of five or six, although this varies between, and sometimes within, countries. Globally, around 89% of children aged six to twelve are enrolled in primary education, and this proportion is rising. Under the Education For All programs driven by UNESCO, most countries have committed to achieving universal enrollment in primary education by 2015, and in many countries, it is compulsory. The division between primary and secondary education is somewhat arbitrary, but it generally occurs at about eleven or twelve years of age. Some education systems have separate middle schools, with the transition to the final stage of secondary education taking place at around the age of fourteen. Schools that provide primary education, are mostly referred to as "primary schools "or "elementary schools". Primary schools are often subdivided into infant schools and junior school.

In India, for example, compulsory education spans over twelve years, with eight years of elementary education, five years of primary schooling and three years of upper primary schooling. Various states in the republic of India provide 12 years of compulsory school education based on a national curriculum framework designed by the National Council of Educational Research and Training.

In most contemporary educational systems of the world, secondary education comprises the formal education that occurs during adolescence. It is characterized by transition from the typically compulsory, comprehensive primary education for minors, to the optional, selective tertiary, "postsecondary", or "higher" education (e.g. university, vocational school) for adults. Depending on the system, schools for this period, or a part of it, may be called secondary or high schools, gymnasiums, lyceums, middle schools, colleges, or vocational schools. The exact meaning of any of these terms varies from one system to another. The exact boundary between primary and secondary education also varies from country to country and even within them but is generally around the seventh to the tenth year of schooling.

Secondary education occurs mainly during the teenage years. In the United States, Canada, and Australia, primary and secondary education together are sometimes referred to as K-12 education, and in New Zealand Year 1–13 is used. The purpose of secondary education can be to give common knowledge, to prepare for higher education, or to train directly in a profession.

Secondary education in the United States did not emerge until 1910, with the rise of large corporations and advancing technology in factories, which required skilled workers. In order to meet this new job demand, high schools were created, with a curriculum focused on practical job skills that would better prepare students for white collar or skilled blue collar work. This proved beneficial for both employers and employees, since the improved human capital lowered costs for the employer, while skilled employees received higher wages.

Secondary education has a longer history in Europe, where grammar schools or academies date from as early as the 16th century, in the form of public schools, fee-paying schools, or charitable educational foundations, which themselves date even further back.

Community colleges offer another option at this transitional stage of education. They provide nonresidential junior college courses to people living in a particular area.

Higher education, also called tertiary, third stage, or postsecondary education, is the non-compulsory educational level that follows the completion of a school such as a high school or secondary school. Tertiary education is normally taken to include undergraduate and postgraduate education, as well as vocational education and training. Colleges and universities mainly provide tertiary education. Collectively, these are sometimes known as tertiary institutions. Individuals who complete tertiary education generally receive certificates, diplomas, or academic degrees.

Higher education typically involves work towards a degree-level or foundation degree qualification. In most developed countries, a high proportion of the population (up to 50%) now enter higher education at some time in their lives. Higher education is therefore very important to national economies, both as a significant industry in its own right and as a source of trained and educated personnel for the rest of the economy.

University education includes teaching, research, and social services activities, and it includes both the undergraduate level (sometimes referred to as tertiary education) and the graduate (or postgraduate) level (sometimes referred to as graduate school). Some universities are composed of several colleges.

One type of university education is a liberal arts education, which can be defined as a "college or university curriculum aimed at imparting broad general knowledge and developing general intellectual capacities, in contrast to a professional, vocational, or technical curriculum." Although what is known today as liberal arts education began in Europe, the term "liberal arts college" is more commonly associated with institutions in the United States such as Williams College or Barnard College.

Vocational education is a form of education focused on direct and practical training for a specific trade or craft. Vocational education may come in the form of an apprenticeship or internship as well as institutions teaching courses such as carpentry, agriculture, engineering, medicine, architecture and the arts.

In the past, those who were disabled were often not eligible for public education. Children with disabilities were repeatedly denied an education by physicians or special tutors. These early physicians (people like Itard, Seguin, Howe, Gallaudet) set the foundation for special education today. They focused on individualized instruction and functional skills. In its early years, special education was only provided to people with severe disabilities, but more recently it has been opened to anyone who has experienced difficulty learning.

While considered "alternative" today, most alternative systems have existed since ancient times. After the public school system was widely developed beginning in the 19th century, some parents found reasons to be discontented with the new system. Alternative education developed in part as a reaction to perceived limitations and failings of traditional education. A broad range of educational approaches emerged, including alternative schools, self learning, homeschooling, and unschooling. Example alternative schools include Montessori schools, Waldorf schools (or Steiner schools), Friends schools, Sands School, Summerhill School, Walden's Path, The Peepal Grove School, Sudbury Valley School, Krishnamurti schools, and open classroom schools. Charter schools are another example of alternative education, which have in the recent years grown in numbers in the US and gained greater importance in its public education system.

In time, some ideas from these experiments and paradigm challenges may be adopted as the norm in education, just as Friedrich Fröbel's approach to early childhood education in 19th-century Germany has been incorporated into contemporary kindergarten classrooms. Other influential writers and thinkers have included the Swiss humanitarian Johann Heinrich Pestalozzi; the American transcendentalists Amos Bronson Alcott, Ralph Waldo Emerson, and Henry David Thoreau; the founders of progressive education, John Dewey and Francis Parker; and educational pioneers such as Maria Montessori and Rudolf Steiner, and more recently John Caldwell Holt, Paul Goodman, Frederick Mayer, George Dennison, and Ivan Illich.

Indigenous education refers to the inclusion of indigenous knowledge, models, methods, and content within formal and non-formal educational systems. Often in a post-colonial context, the growing recognition and use of indigenous education methods can be a response to the erosion and loss of indigenous knowledge and language through the processes of colonialism. Furthermore, it can enable indigenous communities to "reclaim and revalue their languages and cultures, and in so doing, improve the educational success of indigenous students."

Informal learning is one of three forms of learning defined by the Organisation for Economic Co-operation and Development (OECD). Informal learning occurs in a variety of places, such as at home, work, and through daily interactions and shared relationships among members of society. For many learners, this includes language acquisition, cultural norms, and manners.

In informal learning, there is often a reference person, a peer or expert, to guide the learner. If learners have a personal interest in what they are informally being taught, learners tend to expand their existing knowledge and conceive new ideas about the topic being learned. For example, a museum is traditionally considered an informal learning environment, as there is room for free choice, a diverse and potentially non-standardized range of topics, flexible structures, socially rich interaction, and no externally imposed assessments.

While informal learning often takes place outside educational establishments and does not follow a specified curriculum, it can also occur within educational settings and even during formal learning situations. Educators can structure their lessons to directly utilize their students informal learning skills within the education setting.

In the late 19th century, education through play began to be recognized as making an important contribution to child development. In the early 20th century, the concept was broadened to include young adults but the emphasis was on physical activities. L.P. Jacks, also an early proponent of lifelong learning, described education through recreation: "A master in the art of living draws no sharp distinction between his work and his play, his labour and his leisure, his mind and his body, his education and his recreation. He hardly knows which is which. He simply pursues his vision of excellence through whatever he is doing and leaves others to determine whether he is working or playing. To himself, he always seems to be doing both. Enough for him that he does it well." Education through recreation is the opportunity to learn in a seamless fashion through all of life's activities. The concept has been revived by the University of Western Ontario to teach anatomy to medical students.

Autodidacticism (also autodidactism) is a term used to describe self-directed learning. One may become an autodidact at nearly any point in one's life. Notable autodidacts include Abraham Lincoln (U.S. president), Srinivasa Ramanujan (mathematician), Michael Faraday (chemist and physicist), Charles Darwin (naturalist), Thomas Alva Edison (inventor), Tadao Ando (architect), George Bernard Shaw (playwright), Frank Zappa (composer, recording engineer, film director), and Leonardo da Vinci (engineer, scientist, mathematician).

Many large university institutions are now starting to offer free or almost free full courses such as Harvard, MIT and Berkeley teaming up to form edX. Other universities offering open education are prestigious private universities such as Stanford, Princeton, Duke, Johns Hopkins, the University of Pennylvania, and Caltech, as well as notable public universities including Tsinghua, Peking, Edinburgh, University of Michigan, and University of Virginia.

Open education has been called the biggest change in the way people learn since the printing press. Despite favourable studies on effectiveness, many people may still desire to choose traditional campus education for social and cultural reasons.

Many open universities are working to have the ability to offer students standardized testing and traditional degrees and credentials.

The conventional merit-system degree is currently not as common in open education as it is in campus universities, although some open universities do already offer conventional degrees such as the Open University in the United Kingdom. Presently, many of the major open education sources offer their own form of certificate. Due to the popularity of open education, these new kind of academic certificates are gaining more respect and equal "academic value" to traditional degrees.

Out of 182 colleges surveyed in 2009 nearly half said tuition for online courses was higher than for campus-based ones.

A recent meta-analysis found that online and blended educational approaches had better outcomes than methods that used solely face-to-face interaction.

The education sector or education system is a group of institutions (ministries of education, local educational authorities, teacher training institutions, schools, universities, etc.) whose primary purpose is to provide education to children and young people in educational settings. It involves a wide range of people (curriculum developers, inspectors, school principals, teachers, school nurses, students, etc.). These institutions can vary according to different contexts.

Schools deliver education, with support from the rest of the education system through various elements such as education policies and guidelines – to which school policies can refer – curricula and learning materials, as well as pre- and in-service teacher training programmes. The school environment – both physical (infrastructures) and psychological (school climate) – is also guided by school policies that should ensure the well-being of students when they are in school. The Organisation for Economic Co-operation and Development has found that schools tend to perform best when principals have full authority and responsibility for ensuring that students are proficient in core subjects upon graduation. They must also seek feedback from students for quality-assurance and improvement. Governments should limit themselves to monitoring student proficiency.

The education sector is fully integrated into society, through interactions with a large number of stakeholders and other sectors. These include parents, local communities, religious leaders, NGOs, stakeholders involved in health, child protection, justice and law enforcement (police), media and political leadership.

Several UN agencies have asserted that comprehensive sexuality education should be integrated into school curriculum.

Chimombo pointed out education's role as a policy instrument, capable of instilling social change and economic advancement in developing countries by giving communities the opportunity to take control of their destinies. The 2030 Agenda for Sustainable Development, adopted by the United Nations (UN) General Assembly in September 2015, calls for a new vision to address the environmental, social and economic concerns facing the world today. The Agenda includes 17 Sustainable Development Goals (SDGs), including SDG 4 on education.

Since 1909, the ratio of children in the developing world attending school has increased. Before then, a small minority of boys attended school. By the start of the 21st century, the majority of all children in most regions of the world attended school.

Universal Primary Education is one of the eight international Millennium Development Goals, towards which progress has been made in the past decade, though barriers still remain. Securing charitable funding from prospective donors is one particularly persistent problem. Researchers at the Overseas Development Institute have indicated that the main obstacles to funding for education include conflicting donor priorities, an immature aid architecture, and a lack of evidence and advocacy for the issue. Additionally, Transparency International has identified corruption in the education sector as a major stumbling block to achieving Universal Primary Education in Africa. Furthermore, demand in the developing world for improved educational access is not as high as foreigners have expected. Indigenous governments are reluctant to take on the ongoing costs involved. There is also economic pressure from some parents, who prefer their children to earn money in the short term rather than work towards the long-term benefits of education.

A study conducted by the UNESCO International Institute for Educational Planning indicates that stronger capacities in educational planning and management may have an important spill-over effect on the system as a whole. Sustainable capacity development requires complex interventions at the institutional, organizational and individual levels that could be based on some foundational principles:

Nearly every country now has Universal Primary Education.

Similarities – in systems or even in ideas – that schools share internationally have led to an increase in international student exchanges. The European Socrates-Erasmus Program facilitates exchanges across European universities. The Soros Foundation provides many opportunities for students from central Asia and eastern Europe. Programs such as the International Baccalaureate have contributed to the internationalization of education. The global campus online, led by American universities, allows free access to class materials and lecture files recorded during the actual classes.

The Programme for International Student Assessment and the International Association for the Evaluation of Educational Achievement objectively monitor and compare the proficiency of students from a wide range of different nations.

The internationalization of education is sometimes equated by critics with the westernization of education. These critics say that the internationalization of education leads to the erosion of local education systems and indigenous values and norms, which are replaced with Western systems and cultural and ideological values and orientation.

Technology plays an increasingly significant role in improving access to education for people living in impoverished areas and developing countries. However, lack of technological advancement is still causing barriers with regards to quality and access to education in developing countries. Charities like One Laptop per Child are dedicated to providing infrastructures through which the disadvantaged may access educational materials.

The OLPC foundation, a group out of MIT Media Lab and supported by several major corporations, has a stated mission to develop a $100 laptop for delivering educational software. The laptops were widely available as of 2008. They are sold at cost or given away based on donations.

In Africa, the New Partnership for Africa's Development (NEPAD) has launched an "e-school program" to provide all 600,000 primary and high schools with computer equipment, learning materials and internet access within 10 years. An International Development Agency project called nabuur.com, started with the support of former American President Bill Clinton, uses the Internet to allow co-operation by individuals on issues of social development.

India is developing technologies that will bypass land-based telephone and Internet infrastructure to deliver distance learning directly to its students. In 2004, the Indian Space Research Organisation launched EDUSAT, a communications satellite providing access to educational materials that can reach more of the country's population at a greatly reduced cost.

Research into LCPS (low-cost private schools) found that over 5 years to July 2013, debate around LCPSs to achieving Education for All (EFA) objectives was polarized and finding growing coverage in international policy. The polarization was due to disputes around whether the schools are affordable for the poor, reach disadvantaged groups, provide quality education, support or undermine equality, and are financially sustainable. The report examined the main challenges encountered by development organizations which support LCPSs. Surveys suggest these types of schools are expanding across Africa and Asia. This success is attributed to excess demand. These surveys found concern for:

The report showed some cases of successful voucher and subsidy programs; evaluations of international support to the sector are not widespread. Addressing regulatory ineffectiveness is a key challenge. Emerging approaches stress the importance of understanding the political economy of the market for LCPS, specifically how relationships of power and accountability between users, government, and private providers can produce better education outcomes for the poor.

Educational psychology is the study of how humans learn in educational settings, the effectiveness of educational interventions, the psychology of teaching, and the social psychology of schools as organizations. Although the terms "educational psychology" and "school psychology" are often used interchangeably, researchers and theorists are likely to be identified as , whereas practitioners in schools or school-related settings are identified as school psychologists. Educational psychology is concerned with the processes of educational attainment in the general population and in sub-populations such as gifted children and those with specific disabilities.

Educational psychology can in part be understood through its relationship with other disciplines. It is informed primarily by psychology, bearing a relationship to that discipline analogous to the relationship between medicine and biology. Educational psychology, in turn, informs a wide range of specialties within educational studies, including instructional design, educational technology, curriculum development, organizational learning, special education and classroom management. Educational psychology both draws from and contributes to cognitive science and the learning sciences. In universities, departments of educational psychology are usually housed within faculties of education, possibly accounting for the lack of representation of educational psychology content in introductory psychology textbooks (Lucas, Blazek, & Raley, 2006).

Intelligence is an important factor in how the individual responds to education. Those who have higher intelligence tend to perform better at school and go on to higher levels of education. This effect is also observable in the opposite direction, in that education increases measurable intelligence. Studies have shown that while educational attainment is important in predicting intelligence in later life, intelligence at 53 is more closely correlated to intelligence at 8 years old than to educational attainment.

There has been much interest in learning modalities and styles over the last two decades. The most commonly employed learning modalities are:

Other commonly employed modalities include musical, interpersonal, verbal, logical, and intrapersonal.

Dunn and Dunn focused on identifying relevant stimuli that may influence learning and manipulating the school environment, at about the same time as Joseph Renzulli recommended varying teaching strategies. Howard Gardner identified a wide range of modalities in his Multiple Intelligences theories. The Myers-Briggs Type Indicator and Keirsey Temperament Sorter, based on the works of Jung, focus on understanding how people's personality affects the way they interact personally, and how this affects the way individuals respond to each other within the learning environment. The work of David Kolb and Anthony Gregorc's Type Delineator follows a similar but more simplified approach.

Some theories propose that all individuals benefit from a variety of learning modalities, while others suggest that individuals may have preferred learning styles, learning more easily through visual or kinesthetic experiences. A consequence of the latter theory is that effective teaching should present a variety of teaching methods which cover all three learning modalities so that different students have equal opportunities to learn in a way that is effective for them. Guy Claxton has questioned the extent that learning styles such as Visual, Auditory and Kinesthetic(VAK) are helpful, particularly as they can have a tendency to label children and therefore restrict learning. Recent research has argued, "there is no adequate evidence base to justify incorporating learning styles assessments into general educational practice."

Educational neuroscience is an emerging scientific field that brings together researchers in cognitive neuroscience, developmental cognitive neuroscience, educational psychology, educational technology, education theory and other related disciplines to explore the interactions between biological processes and education. Researchers in educational neuroscience investigate the neural mechanisms of reading, numerical cognition, attention, and their attendant difficulties including dyslexia, dyscalculia, and ADHD as they relate to education. Several academic institutions around the world are beginning to devote resources to the establishment of educational neuroscience research.

As an academic field, philosophy of education is "the philosophical study of education and its problems (...) its central subject matter is education, and its methods are those of philosophy". "The philosophy of education may be either the philosophy of the process of education or the philosophy of the discipline of education. That is, it may be part of the discipline in the sense of being concerned with the aims, forms, methods, or results of the process of educating or being educated; or it may be metadisciplinary in the sense of being concerned with the concepts, aims, and methods of the discipline." As such, it is both part of the field of education and a field of applied philosophy, drawing from fields of metaphysics, epistemology, axiology and the philosophical approaches (speculative, prescriptive or analytic) to address questions in and about pedagogy, education policy, and curriculum, as well as the process of learning, to name a few. For example, it might study what constitutes upbringing and education, the values and norms revealed through upbringing and educational practices, the limits and legitimization of education as an academic discipline, and the relation between education theory and practice.

There is no broad consensus as to what education's chief aim or aims are or should be. Different places, and at different times, have used educational systems for different purposes. The Prussian education system in the 19th century, for example, wanted to turn boys and girls into adults who would serve the state's political goals.

Some authors stress its value to the individual, emphasizing its potential for positively influencing students' personal development, promoting autonomy, forming a cultural identity or establishing a career or occupation. Other authors emphasize education's contributions to societal purposes, including good citizenship, shaping students into productive members of society, thereby promoting society's general economic development, and preserving cultural values. 

The purpose of education in a given time and place affects who is taught, what is taught, and how the education system behaves. For example, in the 21st century, many countries treat education as a positional good. In this competitive approach, people want their own students to get a better education than other students. This approach can lead to unfair treatment of some students, especially those from disadvantaged or marginalized groups. For example, in this system, a city's school system may draw school district boundaries so that nearly all the students in one school are from low-income families, and that nearly all the students in the neighboring schools come from more affluent families, even though concentrating low-income students in one school results in worse educational achievement for the entire school system.

In formal education, a curriculum is the set of courses and their content offered at a school or university. As an idea, curriculum stems from the Latin word for "race course", referring to the course of deeds and experiences through which children grow to become mature adults. A curriculum is prescriptive and is based on a more general syllabus which merely specifies what topics must be understood and to what level to achieve a particular grade or standard.

An academic discipline is a branch of knowledge which is formally taught, either at the university – or via some other such method. Each discipline usually has several sub-disciplines or branches, and distinguishing lines are often both arbitrary and ambiguous. Examples of broad areas of academic disciplines include the natural sciences, mathematics, computer science, social sciences, humanities and applied sciences.

Educational institutions may incorporate fine arts as part of K-12 grade curricula or within majors at colleges and universities as electives. The various types of fine arts are music, dance, and theatre.

The Sudbury Valley School offers a model of education without a curricula.

Instruction is the facilitation of another's learning. Instructors in primary and secondary institutions are often called teachers, and they direct the education of students and might draw on many subjects like reading, writing, mathematics, science and history. Instructors in post-secondary institutions might be called teachers, instructors, or professors, depending on the type of institution; and they primarily teach only their specific discipline. Studies from the United States suggest that the quality of teachers is the single most important factor affecting student performance, and that countries which score highly on international tests have multiple policies in place to ensure that the teachers they employ are as effective as possible. With the passing of NCLB in the United States (No Child Left Behind), teachers must be highly qualified. A popular way to gauge teaching performance is to use student evaluations of teachers (SETS), but these evaluations have been criticized for being counterproductive to learning and inaccurate due to student bias.

College basketball coach John Wooden the Wizard of Westwood would teach through quick "This not That" technique. He would show (a) the correct way to perform an action, (b) the incorrect way the player performed it, and again (c) the correct way to perform an action. This helped him to be a responsive teacher and fix errors on the fly. Also, less communication from him meant more time that the player could practice.

It has been argued that high rates of education are essential for countries to be able to achieve high levels of economic growth. Empirical analyses tend to support the theoretical prediction that poor countries should grow faster than rich countries because they can adopt cutting edge technologies already tried and tested by rich countries. However, technology transfer requires knowledgeable managers and engineers who are able to operate new machines or production practices borrowed from the leader in order to close the gap through imitation. Therefore, a country's ability to learn from the leader is a function of its stock of "human capital". Recent study of the determinants of aggregate economic growth have stressed the importance of fundamental economic institutions and the role of cognitive skills.

At the level of the individual, there is a large literature, generally related to the work of Jacob Mincer, on how earnings are related to the schooling and other human capital. This work has motivated a large number of studies, but is also controversial. The chief controversies revolve around how to interpret the impact of schooling. Some students who have indicated a high potential for learning, by testing with a high intelligence quotient, may not achieve their full academic potential, due to financial difficulties.

Economists Samuel Bowles and Herbert Gintis argued in 1976 that there was a fundamental conflict in American schooling between the egalitarian goal of democratic participation and the inequalities implied by the continued profitability of capitalist production.

Many countries are now drastically changing the way they educate their citizens. The world is changing at an ever quickening rate, which means that a lot of knowledge becomes obsolete and inaccurate more quickly. The emphasis is therefore shifting to teaching the skills of learning: to picking up new knowledge quickly and in as agile a way as possible. Finnish schools have even begun to move away from the regular subject-focused curricula, introducing instead developments like phenomenon-based learning, where students study concepts like climate change instead. There are also active educational interventions to implement programs and paths specific to non-traditional students, such as first generation students. 

Education is also becoming a commodity no longer reserved for children. Adults need it too. Some governmental bodies, like the Finnish Innovation Fund Sitra in Finland, have even proposed compulsory lifelong education.




</doc>
<doc id="42845482" url="https://en.wikipedia.org/wiki?curid=42845482" title="United States military veteran suicide">
United States military veteran suicide

United States military veteran suicide is an ongoing phenomenon regarding a reportedly high rate of suicide among U.S. military veterans, in comparison to the general public. According to the most recent report published by the United States Department of Veterans Affairs (VA) in 2016, which analyzed 55 million veterans' records from 1979 to 2014, the current analysis indicates that an average of 20 veterans a day die from suicide.

In 2012 alone, an estimated 6,500 former military personnel died by suicide. More active duty veterans, 177, succumbed to suicide that year than were killed in combat, 176. The Army suffered 52% of the suicides from all branches.

In 2013, the VA released a study that covered suicides from 1999 to 2010, which showed that roughly 22 veterans were dying by suicide per day, or one every 65 minutes. Some sources suggest that this rate may be undercounting suicides. A recent analysis found a suicide rate among veterans of about 30 per 100,000 population per year, compared with the civilian rate of 14 per 100,000. However, the comparison was not adjusted for age and sex.

The total number of suicides differs by age group; 31% of these suicides were by veterans 49 and younger while 69% were by veterans aged 50 and older. As with suicides in general, suicide of veterans is primarily male, with about 97 percent of the suicides being male in the states that reported gender.

In 2015, the Clay Hunt Veterans Suicide Prevention Act passed in the Senate and was then enacted as on February 12, 2015.

In August 2016, the VA released a new report which consisted of the nation's largest analysis of veteran suicide. The report reviewed more than 55 million veterans' records from 1979 to 2014 from every state in the nation. The previous report from 2012 was primarily limited to data on veterans who used VHA health services or from mortality records obtained directly from 20 states and approximately 3 million records. Compared to the data from the 2012 report, which estimated the number of Veteran deaths by suicide to be 22 per day, the current analysis indicates that in 2014, an average of 20 veterans a day died from suicide.

The first suicide prevention center in the United States was opened in Los Angeles in 1958 with funding from the U.S. Public Health Service. In 1966, the Center for Studies of Suicide Prevention (later the Suicide Research Unit) was established at the National Institute of Mental Health (NIMH) of the National Institutes of Health (NIH). Later on, in 1970, the NIMH pushed in Phoenix the discussion about the status of suicide prevention, presented relevant findings about suicide rate and identified the future directions and priorities of the topic.

However, it wasn't until mid-1990s when suicide started being the central issue of the political-social agenda of the United States. Survivors from suicide began to mobilize encouraging the development of a national strategy for suicide prevention. Finally, two Congressional Resolutions—S. Res. 84 and H. Res. 212 of the 105th Congress—recognized suicide as a national problem and suicide prevention as a national priority.

As recommended in the U.N. guidelines, these groups set out to establish a public and private partnership that would be responsible for promoting suicide prevention in the United States. This innovative public-private partnership jointly sponsored a national consensus conference on suicide prevention in Reno, Nevada, which developed a list of 81 recommendations


One of the most important laws about Veterans' Suicide Prevention is the Joshua Omvig Veterans Suicide Prevention Act (JOVSPA) of 2007, supporting the creation of a comprehensive program to reduce the incidence of suicide among veterans. Named for a veteran of Operation Iraqi Freedom who died by suicide in 2005, the act directed the Secretary of the U.S. Department of Veterans Affairs (VA) to implement a comprehensive suicide prevention program for veterans. Components include staff education, mental health assessments as part of overall health assessments, a suicide prevention coordinator at each VA medical facility, research efforts, 24-hour mental health care, a toll-free crisis line, and outreach to and education for veterans and their families. In the summer of 2009, VA added a one-to-one “chat service” for veterans who prefer to reach out for assistance using the Internet.

In 2010, the National Action Alliance for Suicide Prevention was created and, in 2012, the National Strategy was revised. With Obama’s administration suicide prevention strategies for veterans expanded and a goal was formed to make the process of finding and obtaining mental health resources easier for veterans, work to retain and recruit mental health professionals, and make the government programs more accountable for the people they serve.

In 2011, the National Veterans Suicide Prevention Hotline was renamed the Veterans Crisis Line (VCL). The primary mission of the VCL is “to provide 24/7, world-class suicide prevention and crisis intervention services to Veterans, Servicemembers, and their family members.” The VCL faces a number of challenges. It must meet the operational and business demands of responding to over 500,000 calls per year, along with thousands of electronic chats and text messages, and initiating rescue processes when indicated. It must also train staff to respond to Veterans and their family members in individual encounters during which a responder must make an accurate assessment of the needs of the caller under stressful, time-sensitive conditions.

Since its inception in July 2007, the VCL has answered over 3 million calls and initiated the dispatch of emergency services to callers in imminent crisis over 84,000 times. Since launching chat in 2009 and text services in November 2011, the VCL has answered nearly 359,000 and nearly 78,000 requests for chat and text services, respectively. In addition, staff has forwarded more than 504,000 referrals to local VA Suicide Prevention Coordinators on behalf of Veterans to ensure continuity of care with Veterans’ local VA providers. For FY 2016, more than 51,000 chats and 17,000 texts were answered by VCL responders. For FY 2017, nearly 54,000 chats and nearly 16,000 texts were answered by VCL responders. Emergency services were dispatched to over 12,000 callers in immediate crisis in FY 2016, and nearly 19,000 callers in immediate crisis in FY 2017. For FY 2016, nearly 87,000 referrals were made to local Suicide Prevention Coordinators for follow-up care and over 95,000 referrals were made in FY 2017.

The 2018 federal budget expanded mental health screenings for veterans.

A study published in the "Cleveland Clinic Journal of Medicine" found that,
The same study also found that in veterans with PTSD related to combat experience, combat-related guilt may be a significant predictor of suicidal ideation and attempts.

Craig Bryan of the University of Utah National Center for Veterans Studies said that veterans have the same risk factors for suicide as the general population, including feelings of depression, hopelessness, post-traumatic stress disorder, a history of trauma, and access to firearms.

A study done by the "Department of Veterans Affairs" discovered that veterans are more likely to develop symptoms of PTSD for a number of reasons such as:


The "Department of Veterans Affairs" also discovered that where you were deployed and which branch of military you are with can also have drastic effects on your mental status after returning from service. As in most combat wars, your experiences will vary depending on where you are stationed.

Critics of this reporting such as author Tim Worstall in Feb. 2013 claim that there is no epidemic when comparing similar demographic cohorts in the civilian population. He points out that since vets are predominantly male, the suicide rate to compare to is not the general civilian rate, but the rate for males.

Veterans can have difficulty transitioning from the Military to civilian life. Many choose to transition by utilizing their GI Bill or other education benefits. The pursuit of education often facilitates the transition to civilian life. The pursuit of education among Veterans can aggravate post service conditions that are linked to a higher likelihood of suicide but often aids in the transition to civilian life Veterans pursuing education, especially those utilizing the post 9/11 GI Bill, are more likely to have protective factors related to socialization and reintegration than those who are not.


Although higher education has presented many difficulties to returning Veterans, research supports that Veterans often benefit from transitioning from the military into higher education. Academic life often requires Student Veterans to work and interact with other classmates. Most Academic Institutions have Student Veteran Organizations and Resources centers specifically to Aid Military Veterans. Military Education benefits, Primarily the Post 9/11 GI Bill, pay the cost of tuition and provide a housing stipend to Student Veterans. Education benefits often give Veteran Students an income, a goal to continue to work towards and socialization with the general population.




</doc>
<doc id="59424058" url="https://en.wikipedia.org/wiki?curid=59424058" title="National Commission on Teaching and America's Future">
National Commission on Teaching and America's Future

The National Commission on Teaching and America's Future (NCTAF) is a non-profit, non-partisan education policy advocacy organization based in Washington, D.C. Founded in 1994 by then-North Carolina governor Jim Hunt and Stanford University professor Linda Darling-Hammond, the NCTAF focuses its research on improving the teaching profession through recruitment, development, and retention of skilled teachers. In 2017, the NCTAF announced that it will merge with Learning Forward and will operate under the Learning Forward name.

In its 1996 report "What Matters Most: Teaching for America's Future," the NCTAF issued broad recommendations for education leaders and state policymakers to, among other things, overhaul teacher education programs, establish state boards of professional teaching standards, strengthen teacher licensure standards, implement teacher mentoring programs, and create teacher compensation policies that reward knowledge and expertise. The report had wide-reaching impact, with seven states, including Illinois, Indiana, Kentucky, Maine, Missouri, North Carolina, and Ohio, signing on to be partners in implementing the report's recommendations.

In 2001, the NCTAF appointed former US federal election official Tom Carrol its executive director. Carroll announced his retirement in 2014. He was succeeded by Melinda George.



</doc>
<doc id="59480374" url="https://en.wikipedia.org/wiki?curid=59480374" title="Reach Every Reader">
Reach Every Reader

Reach Every Reader is a five-year initiative supported by a $30 million grant from Chan Zuckerberg Initiative co-founders Priscilla Chan and Facebook CEO Mark Zuckerberg. Reach Every Reader was launched by faculty at the Harvard Graduate School of Education and Massachusetts Institute of Technology's Integrated Learning Initiative, and involves collaborators at the Florida Center for Reading Research and Florida State University College of Communication and Information, and the Charlotte-Mecklenburg School District in North Carolina.

The collaboration consists of five projects:


Reach Every Reader will develop a web-based screening tool for reading difficulties that diagnoses underlying causes. The diagnostic screening tool will identify kindergarteners who are at high risk for reading difficulty. The goal is to make this type of screening available to all children. 

The collaboration will also examine which interventions work for which students in order to work toward the development of personalized interventions.

Researchers will work with schools to deliver their interventions to kindergarten students in summer programs and eventually implement them in the school curriculum.

Concern has been expressed that the project involves "crisis talk" that creates pressure for children, and that parents may be concerned about the tracking of their children's personal information.


</doc>
<doc id="29974250" url="https://en.wikipedia.org/wiki?curid=29974250" title="State College of Florida Collegiate School">
State College of Florida Collegiate School

State College of Florida Collegiate School (SCFCS) is a college preparatory school located on State College of Florida's Bradenton campus. It is based on a school in Sweden, with similar views of having students work on their own pace. Classes are available for grades 6-10. The school is largely technology based, utilizing a service, Canvas, from Instructure to assign and turn in schoolwork. Each student is assigned an iPad based on their grade level, and Apple laptops are available for services not available on the iPad. Each student start classes on the college campus in eleventh grade if they pass an enrollment test, called the PERT, and have at least a 3.0 GPA. After completing the program, they are given an Associate degree at graduation, alongside their high school diploma. Following this, for a two-year period, students can be given a tuition-paid scholarship for the Florida Gulf Coast University. The current headmaster is Kelly Monod.

State College of Florida Collegiate School is recognized for its high academic record and high quality work. In the year 2011, SCFCS participated in the Florida Comprehensive Assessment Test (FCAT). In sixth grade reading, SCFCS students scored 85 compared to Manatee County public school district, 63, and all Florida students’ composite of 67. Sixth grade math scores at SCFCS were 72, Manatee County, 48, and Florida, 57. In seventh grade reading, SCFCS students scored 83 compared to Manatee County, 65, and Florida, 68. SCFCS scored 73 in seventh grade math compared to Manatee County at 59 and Florida at 62. In 2016 SCFCS was recognized as a National Blue Ribbon School putting it among some of the most prestigious schools in the country.

Many SCFCS students regularly participate on the college Brain Bowl team, often with great success. SCFCS students Carlyle Styer and Christopher Medrano were a part of the "SCF Fire Team," which won the 2015 FCSAA Brain Bowl State Championship. Carlyle Styer was joined by fellow SCFCS student Kara Stevens, as well as four other SCF students in winning the 2015 NAQT Community College Championship. It is believed that this may be the only instance in which high school students have played a significant role in a quiz bowl national championship at the collegiate level.




</doc>
<doc id="59739835" url="https://en.wikipedia.org/wiki?curid=59739835" title="Independent working class education">
Independent working class education

Independent working class education is an approach to education, particularly adult education, developed by labour activists, whereby the education of working class people is seen as a specifically political process linked to other aspects of class struggle. The term, abbreviated to (IWCE), is particularly linked to the Plebs' League.



</doc>
<doc id="59774284" url="https://en.wikipedia.org/wiki?curid=59774284" title="Skill assessment">
Skill assessment

Competence assessment is a process in which evidence is gathered by the assessor and evaluated against agreed criteria in order to make a judgement of competence. Skill assessment is the comparison of actual performance of a skill with the specified standard for performance of that skill under the circumstances specified by the standard, and evaluation of whether the performance meets or exceed the requirements. Assessment of a skill should comply with the four principles of validity, reliability, fairness and flexibility.

Formative assessment provides feedback for remedial work and coaching, while summative assessment checks whether the competence has been achieved at the end of training. Assessment of combinations of skills and their foundational knowledge may provide greater efficiency, and in some cases competence in one skill my imply competence in other skills. The thoroughness rewired of assessment may depend on the consequences of occasional poor performance.

Validity is the primary requirement. If the assessment is not valid, then the other characteristics are irrelevant. Validity means that an assessment process effectively assesses what it is claimed and intended to assess. To achieve this the assessment tools must address all requirements of the standard to the appropriate depth (neither too much nor too little) and be repeated often enough to ensure that the required performance is repeatable.

The training standard that specifies the competency is the benchmark for assessment, and to be valid the assessment must comply exactly with its requirements, so that nothing required by the standard is omitted, and nothing that is not required is included.

The assessment tools for a skill therefore need to be designed so that they allow the skill to be tested in compliance with the requirements of the standard. It can be useful to map the assessment tools to the specific competences to ensure that they cover the full scope of the standard.

There may be a requirement for periodical validation of assessment tools. This process generally involves mapping the tools against the standard and checking that the tools comply with the other principles of assessment and the rules of evidence.

After validity, reliability is essential. A reliable assessment is one where the evidence elicited and interpretation of evidence is consistent with the skill required, so that the assessment consistently produces outcomes that are compliant with the standard. The assessment decision of a given observed performance should not vary for different assessors. The same evidence should lead to the same outcome.

To achieve this, the assessment tool must provide sufficient guidance for the assessor. In practice the assessment instrument provided to the candidate should be paired with an assessor guide which provides instructions to the assessor to guide their judgement of satisfactory performance or acceptable answers to questions.

To be fair the assessment process must be clearly understood by the candidates, and there must be agreement by both assessors and candidates that candidates’ reasonable needs circumstances are addressed.

The assessment tool can provide evidence that the process is understood and accepted by the candidate, by having a place where a statement to this effect is signed by the candidate at the start of the assessment. A further statement that the assessor has checked with the candidate for any special circumstances or requirements can also be included. Reasonable adjustment must not compromise the validity or reliability of the assessment.

Flexibility of assessment is desirable where reasonably practicable. This is a feature that should be inherent in the assessment tools for the skill, and should take into account the expected variability of circumstances, including variations in candidates, equipment, location, environmental conditions and other things not entirely under the control of the assessor, but within the scope of the competence requirements. Flexibility does not imply bending the rules, or failing to comply with the specifications of the standards. All performance criteria must be addressed.

Formative assessments are formal and informal tests, tasks, quizzes, discussions or observations taken during the learning process. These assessments identify strengths and weaknesses and provide feedback to modify the consequent learning activities to facilitate efficient learning and skill development.

Summative assessments evaluate skills at or after the end of an instructional unit, to ensure that competence has been achieved. At this point remedial work may no longer be practicable.

Integrated assessment is part of the learning and teaching process, and can take place at various stages of a learning programme. Assessments may combine assessment of theory and practice. Some skills may need separate and specific assessment, but others can be combined for efficiency.

Assessment is not an event that only occurs at the end of training, it is most effective when continuous and when providing constant feedback on progress and problems, allowing timely intervention where useful. In many cases a sample of evidence is sufficient to infer competence over a fairly large range, as competence in a skill that requires competence in other skills may be a proxy for those more foundational skills.

Comprehensive planning is usually necessary to produce robust assessment tools that suit the training programme and do justice to both the training standard and the learners.

Assessment of practical skills is usually best done by direct observation of performance in conditions as close as reasonably practicable to the circumstances in which the skill would normally be practiced. Where this is not reasonably practicable, simulations may be appropriate, to whatever level of accuracy is available. Assessment of realistic combinations of skills may save a lot of time, and scenarios may be devised that allow simultaneous and sequential assessments of several skill in one assessment session.

The number of repetitions required will also depend on how critical the skill is considered to be. A single successful demonstration may be sufficient to show that the candidate can perform a task when the consequences are minor. Several sequential faultless performances may be required if another person's life will depend on correct performance.

Assessment tools for practical skills may describe a task to be done, and the assessors guide should generally list the stages of the task and the details the assessor should check off as they are done. Where order is important, this should be mentioned. A checklist may be provided as permanent record, or a video may be taken. In some cases there will be a product which can be retained as long term evidence along with the paperwork or database records.



</doc>
<doc id="59774016" url="https://en.wikipedia.org/wiki?curid=59774016" title="PeaceJam Ghana">
PeaceJam Ghana

Peacejam Ghana is an annual Youth Leadership Conference that is built around the Nobel Peace Prize Laureates who work with young people with the aim of imparting their skills, knowledge and wisdom to them for community and sustainable development.

The conference usually draws students from Junior High and Senior High schools across Ghana who are usually trained and mentored on diverse areas including but not limited to commitment to justice and peace, social responsibility, academic excellence and sustainable development .

Peacejam Ghana started in 2008 by its official chapter, the West Africa Center for Peace Foundation, Ghana (WACPF). Peacejam Ghana has mentored and trained over 5000 students since its inception. Peacejam Ghana has produced many scholars, some of whom have received the TPG Global Impact Youth Fellows scholarship to pursue higher degrees.

Wisdom Addo is the Founder and Executive Director of the West Africa Center for Peace Foundation, Ghana.



</doc>
<doc id="1957928" url="https://en.wikipedia.org/wiki?curid=1957928" title="State College of Florida, Manatee–Sarasota">
State College of Florida, Manatee–Sarasota

State College of Florida, Manatee-Sarasota, or SCF, is a state college with campuses located in Manatee and Sarasota county, Florida. Part of the Florida College System, it is designated a "state college" because it offers a greater number of four-year bachelor's degrees than traditional two-year community colleges.

Founded in 1957 as Manatee Junior College, it was known as Manatee Community College from 1985 to 2009. Today, State College of Florida is the region's oldest and largest public college, operating three campuses in Bradenton, Lakewood Ranch, and Venice.

SCF's official colors are green and blue, and the college's intercollegiate sports teams are known as "The Manatees" and are represented by mascot Maverick the Manatee. The name maverick symbolizes the institutions vision to keep evolving.

State College of Florida, Manatee-Sarasota was established on September 17, 1957, by the Florida Board of Education as Manatee Junior College (MJC). The college came into existence under a plan of the State Board of Education to provide accessible higher education to Florida's population.

In November of 1957 Dr. Samuel R. Neel, Jr became the college's first president and the first classes were held on September 2, 1958, in what was formerly a senior high school; enrollment in the first term was 502 students. The college began administering classes in its own facilities in 1959, where the Bradenton campus stands today. State College of Florida's Bradenton campus is home to The SCF Collegiate School (SCFCS), The Family Heritage House Museum, SCF's Dental Hygiene Clinic, and the athletic facilities for The Manatees. The college's administrative offices are also located on the Bradenton campus.

The Venice center was opened in 1977 by MJC's Board of Trustees. During this period, the center's functions were funded by the donations of residents living in the surrounding communities which included Venice, North Port, and Englewood. It was not until 1983 that the college received an appropriation from the Florida legislature to expand the Venice center into what is now the full-service Venice campus. It was dedicated on March 30th 1985 and the college's name was changed that year to Manatee Community College (MCC). The Venice campus lake is named Lake Jervey and it is dedicated to Dr. Bill Jervey, Jr for his outstanding contributions to the college. 

At the beginning of 2003, MCC opened the Lakewood Ranch campus. The land appropriated for this was donated by the Schroeder-Manatee Ranch. The Lakewood Ranch campus offers credit and non-credit programs of study, as well as technical and workforce development courses. In 2007, the Schroeder-Manatee Ranch donated an additional to the Lakewood Ranch campus. MCC obtained supplementary funding from the Florida legislature, which was allocated for the construction of the Medical Technology and Simulation Building.

In 2009, the State Board of Education unanimously approved a proposal by MCC to begin offering baccalaureate degrees. MCC then changed its name to State College of Florida, Manatee-Sarasota (SCF) to reflect its new status as a four-year state institution. The first bachelor's degree to be offered at the college was a Bachelor of Science in Nursing (B.S.N.) which started in January of 2010. State College of Florida continues to add baccalaureate degree programs based on a combination of regional, state, and national need. Several other bachelor's degree programs are now offered at SCF.

Students can attend classes on campuses located in Bradenton, Venice, and Lakewood Ranch, As well as many business and public-sector sites throughout the community, and from their homes via online.
State College of Florida has been awarded The Association of Florida College's Campus Sustainability Award. And In 2011, the college was awarded The U.S. Green Building Council's Leadership in Energy and Efficient Design (LEED) Gold certification for the construction of the Medical Technology & Simulation Center on its Lakewood Ranch campus. Maintaining sustainability remains a continuous effort at SCF by integrating environmental, social and economic goals through design, planning and operational organization to meet its current needs.
As a part of the Florida College System, State College of Florida falls under the purview of the State Board of Education. SCF is governed by the Florida Legislature and by a District Board of Trustees, consisting of eight members appointed by the Governor to oversee the college's operations.

The college's president is Dr. Carol F. Probstfeld, who was inaugurated as the sixth president of the State College of Florida on November 8, 2013, after serving as the college's vice president of business and administrative services. Before coming to SCF, Dr. Probstfeld served as the vice president for finance and administration and the chief financial officer and treasurer for Notre Dame de Namur University in Belmont, California, and Notre Dame College of Ohio in South Euclid, Ohio.

Dr. Probstfeld has been committed to building and nurturing relationships and focusing on enhancing the student experience. Under her leadership, the "State College of Florida Foundation" launched its first Capital Campaign in 2016 to provide facilities that enhance the student experience. The campaign financed $1 million in technological upgrades for the new Library and Learning Center that opened in February of 2018 and includes a $3.5 million Studio for the Performing Arts and a $9.5 million Health and Human Performance Center. Both of which will be built on the Bradenton campus.

Dr. Probstfeld has also led the college's efforts to boldly engage its students, faculty, staff, and community partners to achieve the goals of the college’s 2015-2020 "Boldly Engaging" strategic plan. In the plan’s first three years, SCF has purchased of land for a new Parrish campus, added signature programs to its Venice campus, enacted multiple strategic enrollment initiatives, created a Leadership Development program to mentor its employees, and launched a comprehensive communications and marketing plan.

State College of Florida is accredited by the Commission on Colleges of the Southern Association of Colleges and Schools to award associate and baccalaureate degrees. Noncredit education is offered under SCF's Corporate & Community Development programs. More than 50 percent of the college-bound high school students in Manatee and Sarasota counties attend SCF each year, with a current enrollment of over 11,000 students. State College of Florida is among the top 100 producers of associate degrees in the United States.

SCF is one of the 25 colleges and universities nationwide to participate in Yale University's Small World Initiative, a project that engages students in real-world research by searching for and identifying antibiotic-producing bacteria in soil and other environments. State College of Florida is also a charter member of the Manufacturing Institute's "M-list," which recognizes schools for excellence in manufacturing education. The Manufacturing Institute is an organization that is dedicated to improving and expanding manufacturing in the United States. SCF was one of eleven Florida College System institutions to be selected, helping Florida lead the nation with the most schools on the list.

State College of Florida's nursing program annually records one of the highest certification rates in the state of Florida and the physical therapy assistant, occupational therapy assistant, dental hygiene and radiography programs have a 100 percent licensure pass rate.

SCF's Venice campus is home to the Gator Engineering program, a collaboration with the University of Florida. Students can take their math and science prerequisites at SCF and upon successful completion will be granted admission to UF's Herbert Wertheim College of Engineering.

State College of Florida has over 50 registered student organizations including an active Student Government and intramural sports. SCF Students can participate in clubs such as Phi Theta Kappa, Model UN, Circle K International, and more. SCF encourages the participation and creation of student organizations that have an impact on the community and foster a sense of school spirit and pride.

The Bradenton and Venice campuses each have their own independent student government associations. State College of Florida's SGA is divided into two parts consisting of the Executive Board, and the General Council. The Executive Board is composed of the Student Body President, Student Body Vice President, Secretary/Treasurer, Inter-Club Council (ICC) President, and the Chief Justice. Executive Board elections are held during the spring semester, but General Council members can join as late as the beginning of the fall semester. Members of the SGA Executive Board also serve on the Student Activities Budget Review Committee (SABR) which manages and allocates funds to SCF'S 50+ clubs and organizations. General Council members can serve on the Campus Activities Board (CAB) which is responsible for planning and organizing campus activities throughout the semester such as the annual spring and fall festivals.

The Brain Bowl team at the State College of Florida has achieved state and national recognition for being one of the top quiz bowl programs in the country. In the 2014-2015 competition season, SCF's "Fire Team" compiled a record of 58-2 against other two-year schools, going on to win championships at tournaments such as the 2014 Delta Burke Invitational, 2015 FCSAA West Central Regional, 2015 FCSAA Brain Bowl State Championship, 2015 NAQT South Florida Community College Sectionals, and the 2015 NAQT Community College Championship Tournament. The team was also invited to compete in NAQT's Intercollegiate Championship Tournament (DII) where the team placed 25th with a record of 7-6, notably defeating four-year schools such as UC Berkeley, Duke University, University of Alabama, and Claremont Colleges in the process.

State College of Florida's award-winning music program is home to over nine different musical ensembles. They include The Bradenton Symphony Orchestra, Symphonic band, Chamber choir, Concert choir, Jazz ensemble, Jazz combo, Guitar ensemble, Keyboard studies, Presidential string quartet, Presidential jazz combo, and the Musical theatre ensemble. State College of Florida's music students perform in multiple concerts throughout the semester as well as numerous community and state events such as the FSCAA Winter Music Symposium. Auditions are open to the community and to students.

Studio 84 Productions, the student theatre and musical theatre company at the State College of Florida does a total of four to five productions per year. Auditions are open to students and to the community. Most theatre graduates have gone on to four-year universities to receive their Bachelor of Arts (B.A.) or Bachelor of Fine Arts (B.F.A.) degrees in Theater and Performing Arts. SCF Theater alumni include American actor Dallas Roberts, various Broadway performers, and many more.

State College of Florida's Bradenton campus includes a weight room and a sand volleyball court. Most of the athletic fields, including the gymnasium, are open to students when not in use. The Venice campus includes a three-quarters of a mile-long fit trail and nature trail that surrounds the campus lake and includes 10 stations for balanced exercise routines. The "State College of Florida Foundation" is currently in the process of raising funds for a brand-new Health and Human Performance Center that will be built on SCF's Bradenton campus. The new 40,348 square-foot facility will feature a full-size gym, training facilities, a state-of-the-art gymnasium, team rooms for The Manatees and for away teams, classrooms, offices, and concession and vending areas.

State College of Florida launched its intercollegiate athletics program in 1957 and adopted the Lancers as their mascot. When MCC decided to change its name to SCF in 2009, the college adopted Maverick the Manatee as the college's new mascot, as well as changing the college's official colors from blue and yellow, to blue and green. 

Currently, the State College of Florida host five intercollegiate sports teams. They include: Men's basketball, Baseball, Softball, Women's tennis, and Women's volleyball. State College of Florida's athletic teams are known today as "The Manatees" and are represented by mascot Maverick the Manatee. They compete in the Suncoast Conference of the Florida State College Activities Association (FSCAA) in Division I of the NJCAA Region VIII. The State College of Florida Manatees have won numerous regional, state and conference titles and have even made several national championship appearances. 

Athletics alumni include MLB players Nick Goody and Josh Lucas.

The Bradenton campus is home to The Family Heritage House Museum, a gallery and research center for the study of African American history and achievements. Exhibits include a timeline of significant events in African American history, including slavery, fights for freedom, community building and education, the Harlem Renaissance, the Civil Rights Movement, Kwanzaa, and the modern era in South Africa. There are also displays about the Underground Railroad and a collection of African masks. Admission is free.

The Samuel R. Neel Performing Arts Center located on SCF's Bradenton campus is an 830-seat auditorium built in 1966. Since then, State College of Florida's Neel Performing Arts Center has been the cultural center of Manatee and Sarasota county and the home of SCF's award-winning music program. It has also served as the premier venue for many prestigious and notable people, including award winning authors John Grisham and Stephen King. The Elizabeth M. Eaton Memorial Pipe Organ, a 50-rank, 3-manual instrument built by master craftsman Charles McManis is situated on the stage of the performing arts center.

The David S. and Anne V. Howard Studio Theatre is a 116-seat performance center built in 2008 on State College of Florida's Bradenton campus. It is the home of Studio 84 Productions, the SCF student theatre company. The Howard Studio Theatre host a number of student performances throughout the semester as well as multiple performances by local and professional theatrical groups.

The Fine Art Gallery on the SCF Bradenton campus features exhibits made by students and faculty, as well as various installations by local and professional artist. The galleries exhibits embrace critical issues and the connections between art, education, and culture.

State College of Florida alumni include authors, musicians, actors, artist, company founders, state representatives, screenwriters, producers, multiple athletes, and many more. Alumni status is open to all graduates of State College of Florida, MJC, MCC, and all former students of SCF who regularly matriculated and left SCF in good standing.
Many of the professors at SCF also publish and conduct research outside of their teaching duties. State College of Florida faculty members maintain an active presence in the community.




</doc>
<doc id="59732997" url="https://en.wikipedia.org/wiki?curid=59732997" title="Inspired Education Group">
Inspired Education Group

Inspired Education Group is a group who operates and builds schools in Europe, the Middle East, Africa, Australia and Latin America.

Inspired was founded by Nadim M Nsouli in 2013, when his group acquired Reddam House in South Africa. Since its founding, Reddam House has acquired and built 9 schools in South Africa, along with the group's flagship school, Reddam House Berkshire, in Wokingham, England. The school grounds in Wokingham were taken over from Bearwood College, in 2015.

Nsouli - the founder, CEO and Chairman - has worked as a lawyer and as an investment banker, and he has led the group since its founding. Inspired’s President is Graeme Crawford, a South African educator and founder of Reddam House. Dr Stephen Spurr is the Group Education Director and was the Head Master of Westminster School in London from 2004 to 2015. He joined Inspired in 2014

The group’s strategy has been described as "buy and build", involving the purchase of existing schools, as well as the building of new schools. It has offices in London, Milan, Auckland, Bogota, Johannesburg,and Dubai.

Schools in other European countries that form part of the Inspired group include St. George's International School in Switzerland, St. John's International School in Belgium, St. Louis School in Italy and Sotogrande International School in Spain. In the Middle East, the group has acquired British School of Bahrain. Inspired's Latin American schools include Blue Valley School in Costa Rica, Colegio San Mateo in Colombia, and Cambridge College Lima in Peru. By 2017, Inspired operated more than 30 schools, and as of 2018 educating over 35,000 students in 46 schools.

Inspired acquired part of New Zealand’s biggest private-education provider ACG Education’s schools division in 2018 from Pacific Equity Partners for about $500 million. 



</doc>
<doc id="60044763" url="https://en.wikipedia.org/wiki?curid=60044763" title="Educational architecture">
Educational architecture

Educational architecture is a denomination for the construction of education.

Originally, the term was only used for the physical building where education was given, for example a school. Later the term was also used for the design of the education process. An educational architect can therefore also be someone without an official architect's title. Both the methodical as the physical structure of the education influence the learning outcomes.

Examples of educational architecture as (re)design of the physical place are

Examples of educational architecture as (re)design of the education process are



</doc>
<doc id="33590643" url="https://en.wikipedia.org/wiki?curid=33590643" title="Sainsbury Institute for Art">
Sainsbury Institute for Art

The Sainsbury Institute for Art (SIfA) is based in the Sainsbury Centre for Visual Arts at the University of East Anglia in the United Kingdom. 

It is an umbrella organization that brings together the activities and expertise of the Sainsbury Centre for Visual Arts, the School of World Art Studies and Museology (WAM), the Sainsbury Institute for the Study of Japanese Arts and Cultures (SISJAC) and the Sainsbury Research Unit for the Arts of Africa, Oceania and the Americas (SRU). "The Institute works to develop an integrated approach to art as a global phenomenon through a combination of disciplinary approaches, exhibitions and programming".SIfA was officially opened on 16 November 2011. Neil MacGregor, Director of the British Museum, gave the inaugural lecture. The institute's study area was designed by Foster and Partners.

The Sainsbury Institute has among other divisions the Centre for Archaeology and Heritage which was established in 2011. The Centre focuses on research projects in the field of archaeology in Japan as well as the cultural heritage, working as a hub of researchers and students interested in the prehistoric to historic background of Japanese culture.

In 2003, the facilities of the Lisa Sainsbury Library was inaugurated by Orita Masaki, the Ambassador of Japan on the Norwich headquarters of the Sainsbury Institute. Researchers of Japanese studies can make appointment to use the library for reference books and digitized materials.

Ex-officio Members

David Richardson, Vice-Chancellor, University of East Anglia (Chair)

Valerie Amos, Baroness Amos

Peter Hesketh

Elizabeth Esteve-Coll

Masatomo Kawai

Non-ex-officio Members

Tim Lankester KCB

Stephen McEnally

David Warren (diplomat)

Ex-officio Participating Observer

Sarah Barrow

Philip Gilmartin

Simon Kaner

Nicole Rousmaniere

Japan based non-ex-officio Participating Observer

Tadashi Kobayashi




</doc>
<doc id="60000072" url="https://en.wikipedia.org/wiki?curid=60000072" title="Low socioeconomic status students">
Low socioeconomic status students

Education is the foundation of development for every country and is the basis for predicting the success of a country in the future. At the current time, businesses and companies need a lot of high-quality workers, and high school diploma no longer guarantees a good paying job for a student. Therefore, the US government uses billions of dollars to promote higher education. However, this strategy still falls short because the development of education is not only about money, but it is also about the appropriateness of development strategies for different groups of students. There are many different groups of students, who face different barriers to college success, such as low-income students, first-generation students, low socioeconomic status (SES) students, or students from different races and ethnic groups. Low SES students are one of the groups that have the biggest population and face barriers the most. To create suitable strategies for low SES students, we must understand clearly about how their backgrounds have effects on academic success and how this group of students impacts on society and economy at large. Low SES students are less likely to succeed in college because they face more barriers to college success, and this is a significant problem to worry about because low SES group make many negative effects on the education system, economic and society. 

Determining if college is the right fit for a student should be weighed against many factors, several mentioned here. Much effort has been put into encouraging High School graduates to go to college for academic degrees rather than for training in industrial and other trade fields that face worker shortages. The national push to get bachelor's degrees has left vocational programs with an image problem, and the nation with far fewer skilled workers than is needed.

There is a gap between low SES students’ outcome and their counterparts based on the statistic of graduation rates and drop-out rates. In 2012, there were only 14% of low SES students who attained bachelor's degree or higher while the percentage of middle SES students is 29%, and high SES students are 60%. Low SES students were more likely to quit school after high school and more likely to attain some post-secondary education than their counterparts, but they were four times less likely to achieve a bachelor's degree or higher education compared to a high SES student. Low SES students tend to attend a lower level of education than their counterparts. If they attend a bachelor's degree or advanced degree, the graduation chance of low SES students is much lower than their peers. In 2009, low-income students from the age of 19-25 were five times more likely to drop out of high school than their counterparts from high-income families. Based on two statistics from National Center of Educations Statistics, students from low SES families are more likely to drop out of school, more likely to attend lower education, and even if they attend higher education, they are less likely to complete. Low SES students are less successful in college than their peers from middle and high SES families because they face more barriers to college success.

One of the major factors that influence low SES students' decision to go to college is the financial barrier. Students from low SES families are more likely to undertake educational routes that are not as prestigious due to the financial factor, and they have lower expected levels of educational attainment as compared to middle and high SES students. Education in the US is costly, and tuition fees are the first thing that students from low SES families wonder about when choosing a college. Low SES students usually choose a lower level of education as it is cheaper and takes less time than higher education. As a result, low SES students are more likely to choose institutions that are not fit and under their educational abilities. Also, low SES students have more nutrition and health issues, and they are more likely to work more time than their counterparts while going to college. Therefore, the financial barrier makes low SES students have lower expectations, less time for school, and face more health and nutrition issues.

The second factor that makes low SES students less successful in college is psychological issues. Because socioeconomic status (SES) is based on income, education, and occupation, most low SES students are from families that have a lower level of education. According to the article Educational Background, High School Stress, and Academic Success by Morazes, students who don't have college-educated parents face more stressful events in their life; as a result, they are less likely to be successful in college than their counterparts. Low SES students have more stressful things to think about, such as making money, reaching the financial aid requirement, and family responsibility. Also, parents from low SES families usually have little experiences about college, as such, low SES students are less likely to share difficulties in college with their parents. Therefore, they have a more stressful life than their peers from middle and high SES families. As a result, low SES students usually have many issues such as feeling not belong to the college, feeling more challenging in college, and feeling not prepared enough to respond to academic challenges. Psychological issues are the main factor that makes students feeling more challenging and dropping out of college.

The third factor that contributes to this problem is academic preparation for college. According to Digest Education of Statistics, the groups of students who have a low level of parental education, and who are from low-income families have lower average SAT mean scores than their peers from high SES families, as well as the overall average SAT, mean scores. Moreover, low SES students are more likely to have a lack of social soft skills such as decision-making skills, leadership skills, or teamwork skills. The lack of academic skills as well as soft skills, is the main reason that leads to the poor outcomes of low SES students.

The percentage of jobs which require post-secondary education has increased over to almost two times from 1973 (28%) to 2018 (62%). And this number means the same as the job opportunities for people who don't have or have only a high school diploma is getting smaller (from 72% in 1973 to 38% in 2018). Moreover, workers who have a college degree earn more money than who don't, and the difference of annual earnings between workers with and without a college degree is continuously increasing ($7,499 in 1965 to $17,500 in 2012). Therefore, if low SES students are more successful in college, we will solve many problems for the economy and society of the US. First, the attainment college degree or higher will make the average income of the US increasing and the jobless rate decreasing. Second, if people who have low-income backgrounds make more money, the budget of the government for Medicaid and financial aid will be smaller. Third, if this problem can be solved, the quality of Americans life will be improving in many fields such as mental and physical health, education, individual's satisfaction, social relationships, and living environment. Fourth, if low SES students are more successful in college, the human resources of the US will grow in quality as well as quantity. Finally, the problem of low SES students is like a cycle because low SES backgrounds make students less successful in college, and the poor outcomes of students lead students to stay low SES. Therefore, the most impossible way to help low SES students get rid of their backgrounds is creating a better educational environment for them.


</doc>
<doc id="60526394" url="https://en.wikipedia.org/wiki?curid=60526394" title="Berlin International University of Applied Sciences">
Berlin International University of Applied Sciences

Berlin International University of Applied Sciences (formerly known and BAU IB or BAU International Berlin - University of Applied Sciences) is a private, non-profit institution of higher education in Berlin, Germany. It was founded in 2012 as Campus of Bahçeşehir University Istanbul and promoted in 2014 as a university in its own right by the state of Berlin.

Berlin International is organized into five separate academic units – two faculties, preparatory school, research institute, and a library – with the campus being located in Charlottenburg. It represents an intercultural educational environment that provides students with the tools to develop their intellectual growth, experiences and creativity.

Berlin International was founded in 2012 on the initiative of the Turkish entrepreneur Enver Yücel, the Founder and Chairman of the BAU Global Education Network, an international network of higher institutions spread all over the world. It was first established as Campus of Bahçeşehir University Istanbul and later, in 2014, became a higher education institution in its own right. In June 2014, Berlin International was granted permission by the Berlin Senate Department of Education, Youth and Science ("Senatsverwaltung für Bildung, Jugend und Wissenschaft") to begin trial operation. The degree programmes began in October 2014 with its first students.
Berlin International’s campus is located in the commercial building ensemble SALZUFER 6. It’s located in Charlottenburg, which is on the border with Tiergarten. The campus has new classrooms, computer labs, design studios and a room for students working in groups. All teaching facilities are equipped with whiteboards and projects, as well as sound equipment and internet access. The Event & Video Conference Hall is equipped with a video conferencing system by Cisco Systems that uses multiple cameras. The conference hall is used to connect to other campuses that are part of the BAU Global Network for shared teaching.

Berlin International is governed by one president and one vice president. They oversee the academic programmes of the university. Their work is reviewed by the Academic Senate, the University Advisory Board, and by a representative of a non-profit management company. The Chancellor is in charge of the operational management Berlin International.

The current President is Prof. Dr. Dr. h.c. mult. Hans-Dieter Klingemann. Prof. Dr. Peter Mantel is the current Vice President, and Turgut Tülü, MBA is the current Chancellor and General Manager.

In 2014, the university (under its former name, BAU IB) established a University Advisory Board (Hochschulrat). The Advisory Board can have anywhere between 4 and 11 members who meet twice a year to advise the presidency regarding the strategy of the university. They also advise on matters such as new study programmes, research projects, and the recruitment of professors and students. The term of office is 4 years, with members serving two terms at maximum (re-appointment is allowed only once). 

Berlin International has two faculties – the Faculty of Design and the Faculty of Business Administration – with a total of seven study programmes. All programmes are taught in English, and feature interdisciplinary teaching. For students who don't meet the necessary criteria for English language certification, Berlin International also has an English Preparatory School. All research activities at Berlin International are coordinated and supported by the Research Institute. The university library, Hans-Dieter Klingemann Library, is named after its president.

The Faculty of Business Administration offers study programmes in Business Administration and Digital Business & Management. Berlin International also provides its students with career-oriented professional training and intercultural qualifications.


The Faculty of Design offers study programmes in Graphic Design & Visual Communication, Interior Design, Product Design, and Architecture, that have an international, intercultural and interdisciplinary focus.


All study programmes at Berlin International are taught in English. In order to apply and follow the courses effectively if accepted, students need to have a B2 level (or higher) English language certificate. If the student doesn't obtain such certificate, they can register for the English Preparatory School. The English Preparatory School has a year-long programme taught by a native speaker that prepares students to study in English in all four language skills, as well as vocabulary and grammar.

The Research Institute was created to provide support to members of Berlin International in their research activities. The Institute is led by both of the faculties together. Members of Berlin International who are interested to develop a new project that would be of benefit to the university, can contact the Institute for help. Rooms, equipment, books and other resources can be requested from the head of the Institute to ensure a successful funding for the project.

The Hans-Dieter Klingemann Library contains all academic information at Berlin International. In compliance with the study programmes, the library collects the required information and makes accessible print and digital literature for its students and faculty. The library also offers LibGuides, guided tours and tutorials, that help students and staff better identify the information they need from the library. Works produced by the staff and students at Berlin International, such as theses and research papers, journal articles and book publications, are acquired by the Hans-Dieter Klingemann Library.

The Center for Intercultural Dialog (CfID) was established in May 2015, with the goal of strengthening the profile factors of Berlin International. One of those factors include interdiscplinarity. That's why the main purpose of the CfID is to offer an interdiscplinary platform where researchers and experts can exchange their knowledge and experience. Additionally, the CfID encourages the emergence of new ideas, projects and collaborations. 

Some of the CfID's long-term cooperation with educational, research and cultural institutions, include the Berlin State Museums and the Dresden State Art Collections. The main focus of such cooperation projects is the improvement of intercultural competences, which is another profile factor of Berlin International. All projects by the CfID are supported by the Commissioner for Culture and Media of Federal German Republic (BKM), the German Academic Exchange Service (DAAD) with funds of the Federal Foreign Office, the Presidency for Turks abroad of the Prime Ministry of the Republic of Turkey and the Registered Society - Friends of the Museum of Islamic Art in the Pergamon Museum.

Berlin International is open to students from all over the world. All applicants can apply for their degree of choice online through Berlin International’s portal. Candidates need to complete the online application and upload all necessary documents. For the programmes at the Faculty of Design it is required to submit a portfolio. The portfolio is then followed by an admissions interview.

All programmes at Berlin International are taught in English. Therefore, candidates need only proof of English proficiency, no German knowledge is required. In case the candidate’s native language isn’t English and they don’t have a certificate, Berlin International offers a Proficiency Examination. This exam can only be taken if the candidate gets accepted and has paid the registration fee. If the candidate doesn’t pass the proficiency exam, Berlin International has a year-long programme for studying English at the English Preparatory School.

Berlin International offers scholarships that consist of a twenty-five percent reduction of the tuition fee. A scholarship is granted for an academic year and covers the twelve months of a fall term and a spring term. Applications can be made by students admitted to one of the study programmes in the two weeks following the official start of the fall term. Re-application is possible. All applications are handed in to the Students Affairs Office.

The German federal government provides student loans for German students in need of financial support. Only a part of each loan has to be paid back. The situation of each student is evaluated individually, according to the general criteria.

The students at Berlin International can apply for financial support when they begin their studies. Student who have resided in Germany for a number of years, are also eligible for this support. Once the study programmes at Berlin International have started, the university also provides its own BAföG counselling to students. Applying is possible both before and after applicants have started their studies at Berlin International.

As of June 5, 2015, Berlin International is accredited as a state-recognized institution of higher education in Germany by the Berlin Senate Department of Education, Youth and Science ("Senatsverwaltung für Bildung, Jugend und Wissenschaft"). programme accreditation for the Bachelor in Business Administration was granted by the accreditation agency ACQUIN on September 29, 2015. On December 7, 2015, three more programmes were accredited by ACQUIN - Bachelor in Communication Design, Bachelor in Interior Design, and Bachelor in Product Design.




</doc>
<doc id="60792359" url="https://en.wikipedia.org/wiki?curid=60792359" title="Model G20">
Model G20

A Model G20, also known as a Model G20 Summit, is an educational simulation for high school and college students. Students role play as government ministers from one of the G20 countries or their guests and negotiate solutions to defined problems. During a G20 summit, students learn about diplomacy, international relations, the G20, and other issues related to a theme of the summit. Some individual schools have Model G20 clubs for students interested in these topics.

It is similar to a Model United Nations. At the end of summits, individual delegates and entire delegations are often given awards for their performance.

At American University in Washington, D.C., Model G20s have been hosted by the School of International Service since 2017 for both undergraduate and graduate students. It was established by Cecilia Nahón, the former ambassador of Argentina to the United States and a participant in actual G20 summits.

, Cağaloğlu Anadolu Lisesi in Istanbul, Turkey has held a Model G20 every year since 2016. The first year, 80 students attended. The third annual Model G20 in 2018 was held at Istanbul Aydın University with students from Turkey and other nations attending.

The Knovva Academy Model G20 Summit has been held in cities around the world since 2016, including in Beijing, Boston, and Cambridge. The summit in Boston is held at Harvard University. At the 2019 Beijing summit, high school students from more than 20 countries attended. Delegates at Knovva Academy Model G20 summits attend several days of academic workshops and keynote speeches preparing them for the summits. They also spend time traveling in the host country. 

In addition to hosting Model G20s, Knovva Academy also sends a group to the Y20 summit, the official youth portion of the G20 that takes place in advance of the meeting of heads of state. Attendance at Knovva Academy events is by invitation only, with students needing to submit academic records and complete an interview.



</doc>
<doc id="1149904" url="https://en.wikipedia.org/wiki?curid=1149904" title="Geoarchaeology">
Geoarchaeology

Geoarchaeology is a multi-disciplinary approach which uses the techniques and subject matter of geography, geology and other Earth sciences to examine topics which inform archaeological knowledge and thought. Geoarchaeologists study the natural physical processes that affect archaeological sites such as geomorphology, the formation of sites through geological processes and the effects on buried sites and artifacts post-deposition. Geoarchaeologists' work frequently involves studying soil and sediments as well as other geographical concepts to contribute an archaeological study. Geoarchaeologists may also use computer cartography, geographic information systems (GIS) and digital elevation models (DEM) in combination with disciplines from human and social sciences and earth sciences. Geoarchaeology is important to society because it informs archaeologists about the geomorphology of the soil, sediments and the rocks on the buried sites and artifacts they're researching on. By doing this we are able locate ancient cities and artifacts and estimate by the quality of soil how "prehistoric" they really are.

Column sampling is a technique of collecting samples from a section for analyzing and detecting the buried processes down the profile of the section. Narrow metal tins are hammered into the section in a series to collect the complete profile for study. If more than one tin is needed they are arranged offset and overlapping to one side so the complete profile can be rebuilt offsite in laboratory conditions.

Loss on ignition testing for soil organic content.- a technique of measuring organic content in soil samples. Samples taken from a known place in the profile collected by column sampling are weighed then placed in a fierce oven which burns off the organic content. The resulting cooked sample is weighed again and the resulting loss in weight is an indicator of organic content in the profile at a certain depth. These readings are often used to detect buried soil horizons. A buried soil's horizons may not be visible in section and this horizon is an indicator of possible occupation levels. Ancient land surfaces especially from the prehistoric era can be difficult to discern so this technique is useful for evaluating an areas potential for prehistoric surfaces and archaeological evidence. Comparative measurements down the profile are made and a sudden rise in organic content at some point in the profile combined with other indicators is strong evidence for buried surfaces.

The magnetic susceptibility of a material is a measure of its ability to become magnetised by an external magnetic field (Dearing, 1999). The magnetic susceptibility of a soil reflects the presence of magnetic iron-oxide minerals such as maghaematite; just because a soil contains a lot of iron does not mean that it will have high magnetic susceptibility. Magnetic forms of iron can be formed by burning and microbial activity such as occurs in top soils and some anaerobic deposits. Magnetic iron compounds can also be found in igneous and metamorphic rocks.

The relationship between iron and burning means that magnetic susceptibility is often used for:

The relationship between soil formation and magnetic susceptibility means that it can also be used to:

Phosphate in man-made soils derives from people, their animals, rubbish and bones. 100 people excrete about 62 kg of phosphate annually, with about the same from their rubbish. Their animals excrete even more. A human body contains about 650g of PO4,(500g-80% in the skeleton), which results in elevated levels in burial sites. Most is quickly immobilised on the clay of the soil and ‘fixed’, where it can persist for thousands of years. For a 1 ha site this corresponds to about 150 kg PO4 ha-1yr-1 about 0.5% to 10% of that already present in most soils. Therefore, it doesn’t take long for human occupation to make orders of magnitude differences to the phosphate concentration in soil. Phosphorus exist in different ‘pools’ in the soil 1) organic (available), 2) occluded (adsorbed), 3) bound (chemically bound). Each of these pools can be extracted using progressively more aggressive chemicals. Some workers (Eidt especially), think that the ratios between these pools can give information about past land use, and perhaps even dating.
Whatever the method of getting the phosphorus from the soil into solution, the method of detecting it is usually the same. This uses the ‘molybdate blue’ reaction, where the depth of the colour is proportional to phosphorus concentration. In the lab, this is measured using a colorimeter, where light shining through a standard cell produces an electric current proportional to the light attenuation. In the field, the same reaction is used on detector sticks, which are compared to a colour chart.

Phosphate concentrations can be plotted on archaeological plans to show former activity areas, and is also used to prospect for sites in the wider landscape.

The particle size distribution of a soil sample may indicate the conditions under which the strata or sediment were deposited. Particle sizes are generally separated by means of dry or wet sieving (coarse samples such as till, gravel and sands, sometimes coarser silts) or by measuring the changes of the density of a dispersed solution (in sodiumpyrophosphate, for example))of the sample (finer silts, clays). A rotating clock-glass with a very fine-grained dispersed sample under a heat lamp is useful in separating particles.

The results are plotted on curves which can be analyzed with statistical methods for particle distribution and other parameters.

The fractions received can be further investigated for cultural indicators, macro- and microfossils and other interesting features, so particle size analysis is in fact the first thing to do when handling these samples.

Trace element geochemistry is the study of the abundances of elements in geological materials that do not occur in a large quantity in these materials. Because these trace elements' concentrations are determined by a large number of particular situations under which a certain geological material is formed, they are usually unique between two locations which contain the same type of rock or other geological material.

Geoarchaeologists use this uniqueness in trace element geochemistry to trace ancient patterns of resource-acquisition and trade. For example, researchers can look at the trace element composition of obsidian artifacts in order to "fingerprint" those artifacts. They can then study the trace element composition of obsidian outcrops in order to determine the original source of the raw material used to make the artifact.

Geoarchaeologists study the mineralogical characteristics of pots through macroscopic and microscopic analyses. They can use these characteristics to understand the various manufacturing techniques used to make the pots, and through this, to know which production centers likely made these pots. They can also use the mineralogy to trace the raw materials used to make the pots to specific clay deposits.

Naturally occurring Ostracods in freshwater bodies are impacted by changes in salinity and pH due to human activities. Analysis of Ostracod shells in sediment columns show the changes brought about by farming and habitation activities. This record can be correlated with age dating techniques to help identify changes in human habitation patterns and population migrations.

Archaeological geology is a term coined by Werner Kasig in 1980. It is a sub-field of geology which emphasises the value of earth constituents for human life.





</doc>
<doc id="6786225" url="https://en.wikipedia.org/wiki?curid=6786225" title="Distance decay">
Distance decay

Distance decay is a geographical term which describes the effect of distance on cultural or spatial interactions. The distance decay effect states that the interaction between two locales declines as the distance between them increases. Once the distance is outside of the two locales' activity space, their interactions begin to decrease.

With the advent of faster travel, distance has less effect than it did in the past, except where places previously connected by now-abandoned railways, for example, have fallen off the beaten path. Advances in communications technology, such as telegraphs, telephones, broadcasting, and internet, have further decreased the effects of distance.

Distance decay is graphically represented by a curving line that swoops concavely downward as distance along the x-axis increases. Distance decay can be mathematically represented as an Inverse-square law by the expression

formula_1 
or
formula_2,

where I is interaction and d is distance. It can take other forms such as negative exponential, i.e.

formula_3

Distance decay is evident in town/city centres. It can refer to various things which decline with greater distance from the center of the Central Business District (CBD):

Distance decay weighs into the decision to migrate, leading many migrants to move less far.

Related terms include "friction of distance", which describes the force that creates distance decay and Waldo R. Tobler's "First law of geography", an informal statement that "All things are related, but near things are more related than far things." 
"Loss of Strength Gradient" holds that the amount of a nation's military power that could be brought to bear in any part of the world depends on geographic distance.




</doc>
<doc id="6974596" url="https://en.wikipedia.org/wiki?curid=6974596" title="Land cover">
Land cover

Land cover is the physical material at the surface of the earth. Land covers include grass, asphalt, trees, bare ground, water, etc. Earth cover is the expression used by ecologist Frederick Edward Clements that has its closest modern equivalent being vegetation. The expression continues to be used by the Bureau of Land Management.

There are two primary methods for capturing information on land cover: field survey and analysis of remotely sensed imagery. Land change models can be built from these types of data to assess future shifts in land cover 

One of the major land cover issues (as with all natural resource inventories) is that every survey defines similarly named categories in different ways. For instance, there are many definitions of "forest"—sometimes within the same organisation—that may or may not incorporate a number of different forest features (e.g., stand height, canopy cover, strip width, inclusion of grasses, and rates of growth for timber production). Areas without trees may be classified as forest cover "if the intention is to re-plant" (UK and Ireland), while areas with many trees may not be labelled as forest "if the trees are not growing fast enough" (Norway and Finland). 

"Land cover" is distinct from "land use", despite the two terms often being used interchangeably. Land use is a description of how people "utilize" the land and of socio-economic activity. Urban and agricultural land uses are two of the most commonly known land use classes. At any one point or place, there may be multiple and alternate land uses, the specification of which may have a political dimension. The origins of the "land cover/land use" couplet and the implications of their confusion are discussed in Fisher et al. (2005).

Following table is Land Cover statistics by Food and Agriculture Organization (FAO) with 14 classes.



</doc>
<doc id="3439019" url="https://en.wikipedia.org/wiki?curid=3439019" title="Landlocked developing countries">
Landlocked developing countries

Landlocked developing countries (LLDC) are developing countries that are landlocked. The economic and other disadvantages experienced by such countries makes the majority of landlocked countries least developed countries (LDC), with inhabitants of these countries occupying the bottom billion tier of the world's population in terms of poverty. Apart from Europe, there is not a single successful highly developed landlocked country as measured by the Human Development Index (HDI), and nine of the twelve countries with the lowest HDI scores are landlocked. Landlocked European countries are exceptions in terms of development outcomes due to their close integration with the regional European market. Landlocked countries that rely on transoceanic trade usually suffer a cost of trade that is double that of their maritime neighbours. Landlocked countries experience economic growth 6% less than their non-landlocked countries, holding other variables constant.

About 468 million people live in current LLDCs.

The United Nations has an Office of the High Representative for the Least Developed Countries, Landlocked Developing Countries and Small Island Developing States (UN-OHRLLS). It mainly holds the view that high transport costs due to distance and terrain result in the erosion of competitive edge for exports from landlocked countries. In addition, it recognizes the constraints on landlocked countries to be mainly physical, including lack of direct access to the sea, isolation from world markets and high transit costs due to physical distance. It also attributes geographic remoteness as one of the most significant reasons why developing landlocked nations cannot alleviate themselves, while European landlocked cases are mostly developed because of short distances to the sea through well-developed countries. One other commonly cited factor is the administrative burdens associated with border crossings as there is a heavy load of bureaucratic procedures, paperwork, custom charges, and most importantly, traffic delay due to border wait times, which affect delivery contracts. Delays and inefficiency compound geographically, where a 2 to 3 week wait due to border customs between Uganda and Kenya makes it impossible to book ships ahead of time in Mombasa, furthering delivery contract delays. Despite these explanations, it is also important to consider the transit countries that neighbour LLDCs, from whose ports the goods of LLDCs are exported.

Although Adam Smith and traditional thought hold that geography and transportation are the culprits for keeping LLDCs from realizing development gains, Faye, Sachs and Snow hold the argument that no matter the advancement of infrastructure or lack of geographic distance to a port, landlocked nations are still dependent on their neighbouring transit nations. Outlying this specific relationship of dependency, Faye et al. insist that though LLDCs vary across the board in terms of HDI index scores, LLDCs almost uniformly straddle at the bottom of HDI rankings in terms of region, suggesting a correlated dependency relationship of development for landlocked countries with their respective regions. In fact, HDI levels decrease as one moves inland along the major transit route that runs from the coast of Kenya, across the country before going through Uganda, Rwanda and then finally Burundi. Just recently, it has been economically modeled that if the economic size of a transit country is increased by just 1%, a subsequent increase of at least 2% is experienced by the landlocked country, which shows that there is hope for LLDCs if the conditions of their transit neighbours are addressed. In fact, some LLDCs are seeing the brighter side of such a relationship, with the Central Asian nations geographic location between three BRIC nations (China, Russia and India) hungry for the region's oil and mineral wealth serving to boost economic development. The three major factors that LLDCs are dependent on their transit neighbours are dependence on transit infrastructure, dependence on political relations with neighbours, and dependence on internal peace and stability within transit neighbours.

Burundi has relatively good internal road networks, but it cannot export its goods using the most direct route to the sea since the inland infrastructure of Tanzania is poorly connected to the port of Dar es Salaam. Thus Burundi relies on Kenya's port of Mombasa for export; but this route was severed briefly in the 1990s when political relations with Kenya deteriorated. Further, Burundi's exports could not pass through Mozambique around the same time due to violent civil conflict. Thus, Burundi had to export its goods using a 4500 km route, crossing several borders and changing transport modes, to reach the port of Durban in South Africa.


The mineral resource-rich countries of Central Asia and Mongolia offer a unique set of landlocked cases to explore in more depth, as these are nations where economic growth has grown exceptionally in recent years. In Central Asia, oil and coal deposits have influenced development: Kazakhstan’s GDI per capita in purchasing power parity was five times greater than Kyrgyzstan's in 2009. Despite substantial development growth, these nations are not on a stable and destined path to being well developed, as the exploitation of their natural resources translates into an overall low average income and disparity of income, and because their limited deposits of resources allow growth only in the short term, and most importantly because dependence on unprocessed materials increases the risk of shocks due to variations in market prices. And though it is widely conceived that free trade can permit faster economic growth, Mongolia is now subjected to a new geopolitical game about the traffic on its railway lines between China and Russia. Russian Railways now effectively owns 50% of Mongolia's rail infrastructure, which could mean more efficient modernization and the laying of new rail lines, but in reality also translates into powerful leverage to pressure the government of Mongolia to concede unfair terms for license grants of coal, copper, and gold mines. Thus, it can be argued that these nations with extraordinary mineral wealth should pursue economic diversification. All of these nations possess education qualifications, as they are inheritors of the Soviet Union's social education system. This implies that it is due to poor economic policies that more than 40% of the labour force is bogged down in the agricultural sector instead of being diverted into secondary or tertiary economic activity. Yet, it cannot be ignored that Mongolia benefits exceptionally from its proximity to two giant BRIC nations, resulting in a rapid development of railway ports along its borders, especially along the Chinese border, as the Chinese seek to direct coking coal from Mongolia to China's northwestern industrial core as well as for transportation to Japan and South Korea, resulting in revenue generation through the port of Tianjin.

Nepal is another landlocked country with extreme dependency on its transit neighbour India. India does not have poor relations with Nepal, nor does it lack relevant transport infrastructure or internal stability. In the 1970s, Nepal suffered from large commodity concentration and a high geographic centralization in its export trade: over 98% of its exports were to India, and 90% of its imports came from India. As a result of all this, Nepal had a poor trade bargaining position. In the 1950s, Nepal was forced to comply with India's external tariffs as well as the prices of India's exports. This was problematic since the two countries have different levels of development, resulting in greater gains for India which was larger, more advanced and with more resources. It was feared that a parasitic relationship might emerge, since India had a head start in industrialization, and dominated Nepal in manufacturing, which could reduce Nepal to being just a supplier of raw materials. Because of these problems, and Nepal's inability to develop its own infant industries (as it could not compete with Indian manufactures) treaties were drafted in 1960 and 1971, with amendments to the equal tariffs conditions, and terms of trade have since progressed.

In August, 2003, the International Ministerial Conference of Landlocked and Transit Developing Countries and Donor Countries on Transit Transport Cooperation (Almaty Ministerial Conference) was held in Almaty, Kazakhstan, setting the necessities of LLDCs in a universal document whereas there were no coordinated efforts on the global scale to serve the unique needs of LLDCs in the past. Other than acknowledging the main forms of dependency that must be addressed, it also acknowledged the additional dependency issue where neighbouring transit countries are often observed to export the same products as their landlocked neighbours. One result of the conference was a direct call for donor countries to step in to direct aid into setting up suitable infrastructure of transit countries to alleviate the burden of supporting LLDCs in regions of poor development in general. The general objectives of the Almaty Program of Action is as follows:






</doc>
<doc id="5266320" url="https://en.wikipedia.org/wiki?curid=5266320" title="Indices of deprivation 2004">
Indices of deprivation 2004

The Indices of deprivation 2004 (ID 2004) is a deprivation index at the small area level, created by the British Department for Communities and Local Government(DCLG).

It is unusual in its inclusion of a measure of geographical access as an element of deprivation and in its direct measure of poverty (through data on benefit receipts). The ID 2004 is based on the idea of distinct dimensions of deprivation which can be recognised and measured separately. These are then combined into a single overall measure. The Index is made up of seven distinct dimensions of deprivation called Domain Indices. Whilst it is known as the ID2004, most of the data actually dates from 2001.

Communities and Local Government (previously the Office of Deputy Prime Minister) commissioned the Social Disadvantage Research Centre (SDRC) at the Department of Social Policy and Social Work at the University of Oxford to update the Indices of deprivation 2004 (ID 2004) for England. Following an extensive public consultation (see Annex A), an independent academic peer review and a significant programme of work, the new Indices of Deprivation 2007 were produced in December 2007.

The new Index of Multiple Deprivation 2007 (IMD 2007) is a Lower layer Super Output Area (LSOA) level measure of multiple deprivation, and is made up of seven LSOA level domain indices. There are also two supplementary indices (Income Deprivation Affecting Children and Income Deprivation Affecting Older People). Summary measures of the IMD 2007 are presented at local authority district level and county council level. The LSOA level Domain Indices and IMD 2007, together with the local authority district and county summaries are referred to as the Indices of Deprivation 2007 (ID 2007).(Rusty 2009)

The ID 2007 are based on the approach, structure and methodology that were used to create the previous ID 2004. The ID 2007 updates the ID 2004 using more up-to-date data. The new IMD 2007 contains seven domains which relate to income deprivation, employment deprivation, health deprivation and disability, education skills and training deprivation, barriers to housing and services, living environment deprivation, and crime.








Each Domain contains a number of indicators, totalling 37. Two supplementary indexes have been created as a subset of the Income domain. These relate to income deprivation affecting children and income deprivation affecting older people.

The Indices of deprivation 2004 are measured at the Lower Layer Super Output Area level. Super Output Areas were developed by the Office for National Statistics (ONS) from the Census 2001 Output Areas. There are two levels, the lowest (which the Index is based upon) being smaller than wards and containing a minimum of 1,000 people and 400 households. The middle layer contains a minimum of 5,000 people and 2,000 households. Earlier proposals to introduce Upper Layer Super Output Areas were dropped due to lack of demand. 

In addition to Super Output Areas, Summaries of the ID 2004 are presented at District level, County level and Primary Care Trust (PCT) level.

While each SOA is of higher resolution than the highest resolution "ward" index data of the IMD2000 and therefore better at identifying "pockets" of deprivation within wards the 2004 system has its problems. Some areas of deprivation can still be hidden because of the size of SOAs. Examples of this can be found by comparing central areas of Keighley using the Bradford District Deprivation Index (a Deprivation index developed by Bradford Council produced at 1991 Census Enumeration District level) with the ID2004.
Additionally SOAs were tasked with providing complete coverage of England and Wales - this combined with the minimum population and household counts within each SOA means that large areas of agricultural, commercial and industrial land have to be included within a residential area that borders them - thus when some very deprived residential areas are mapped, a large area of supposed deprivation emerges, however most of it may not be so but rather has a wide area of relative affluence around it - these can appear to be a greater problem than many smaller completely residential SOAs in which higher concentrations of deprived people live but mixed with more affluent neighbours.



</doc>
<doc id="13387896" url="https://en.wikipedia.org/wiki?curid=13387896" title="Geographic targeting">
Geographic targeting

Geographic targeting is a viable way for resource allocation, especially to alleviate poverty in a country. In this context, public expenditure and policy interventions can be deployed to reach the neediest people in the poorest areas.

Geographical targeting for poverty alleviation employs a variety of techniques, such as database, and geographic information systems to construct poverty maps.


</doc>
<doc id="3439212" url="https://en.wikipedia.org/wiki?curid=3439212" title="Small Island Developing States">
Small Island Developing States

Small Island Developing States (SIDS) are a group of small island countries that tend to share similar sustainable development challenges, including small but growing populations, limited resources, remoteness, susceptibility to natural disasters, vulnerability to external shocks, excessive dependence on international trade, and fragile environments. Their growth and development is also held back by high communication, energy and transportation costs, irregular international transport volumes, disproportionately expensive public administration and infrastructure due to their small size, and little to no opportunity to create economies of scale.

The SIDS were first recognized as a distinct group of developing countries at the United Nations Conference on Environment and Development in June 1992. The Barbados Programme of Action was produced in 1994 to assist the SIDS in their sustainable development efforts. The United Nations Office of the High Representative for the Least Developed Countries, Landlocked Developing Countries and Small Island Developing States (UN-OHRLLS) represents this group of states.

Many SIDS now recognise the need to move towards low-carbon, climate resilient economies, as set out in the Caribbean Community (CARICOM) implementation plan for climate change-resilient development. SIDS often rely heavily on imported fossil fuels, spending an ever-larger proportion of their GDP on energy imports. Renewable technologies have the advantage of providing energy at a lower cost than fossil fuels and making SIDS more sustainable. Barbados has been successful in adopting the use of solar water heaters (SWHs). A 2012 report published by the Climate & Development Knowledge Network showed that its SWH industry now boasts over 50,000 installations. These have saved consumers as much as US$137 million since the early 1970s. The report suggested that Barbados's experience could be easily replicated in other SIDS with high fossil fuel imports and abundant sunshine.

Currently, the United Nations Department of Economic and Social Affairs lists 57 small island developing states. These are broken down into three geographic regions: the Caribbean; the Pacific; and Africa, Indian Ocean, Mediterranean and South China Sea (AIMS)., including Associate Members of the Regional Commissions. Each of these regions has a regional cooperation body: the Caribbean Community, the Pacific Islands Forum and the Indian Ocean Commission respectively, which many SIDS are members or associate members of. In addition, most (but not all) SIDS are members of the Alliance of Small Island States (AOSIS), which performs lobbying and negotiating functions for the SIDS within the United Nations system. The UNCTAD website states that "the UN never established criteria to determine an official list of SIDS" but it maintains a shorter, unofficial list on its website for analytical purposes.


 


</doc>
<doc id="10063629" url="https://en.wikipedia.org/wiki?curid=10063629" title="Rank-size distribution">
Rank-size distribution

Rank-size distribution is the distribution of size by rank, in decreasing order of size. For example, if a data set consists of items of sizes 5, 100, 5, and 8, the rank-size distribution is 100, 8, 5, 5 (ranks 1 through 4). This is also known as the rank-frequency distribution, when the source data are from a frequency distribution. These are particularly of interest when the data vary significantly in scale, such as city size or word frequency. These distributions frequently follow a power law distribution, or less well-known ones such as a stretched exponential function or parabolic fractal distribution, at least approximately for certain ranges of ranks; see below.

A rank-size distribution is not a probability distribution or cumulative distribution function. Rather, it is a discrete form of a quantile function (inverse cumulative distribution) in reverse order, giving the size of the element at a given rank.

In the case of city populations, the resulting distribution in a country, a region, or the world will be characterized by its largest city, with other cities decreasing in size respective to it, initially at a rapid rate and then more slowly. This results in a few large cities and a much larger number of cities orders of magnitude smaller. For example, a rank 3 city would have one-third the population of a country's largest city, a rank 4 city would have one-fourth the population of the largest city, and so on.

When any log-linear factor is ranked, the ranks follow the Lucas numbers, which consist of the sequentially additive numbers 1, 3, 4, 7, 11, 18, 29, 47, 76, 123, 199, etc. Like the more famous Fibonacci sequence, each number is approximately 1.618 (the Golden ratio) times the preceding number. For example, the third term in the sequence above, 4, is approximately 1.618, or 4.236; the fourth term, 7, is approximately 1.618, or 6.854; the eighth term, 47, is approximately 1.618, or 46.979. With higher values, the figures converge. An equiangular spiral is sometimes used to visualize such sequences.

A rank-size (or rank-frequency) distribution is often segmented into ranges. This is frequently done somewhat arbitrarily or due to external factors, particularly for market segmentation, but can also be due to distinct behavior as rank varies.

Most simply and commonly, a distribution may be split in two, termed the head and tail. If a distribution is broken into three pieces, the third (middle) piece has several terms, generically middle, also belly, torso, and body. These frequently have some adjectives added, most significantly "long tail", also "fat belly", "chunky middle", etc. In more traditional terms, these may be called "top-tier", "mid-tier", and "bottom-tier".

The relative sizes and weights of these segments (how many ranks in each segment, and what proportion of the total population is in a given segment) qualitatively characterizes a distribution, analogously to the skewness or kurtosis of a probability distribution. Namely: is it dominated by a few top members (head-heavy, like profits in the recorded music industry), or is it dominated by many small members (tail-heavy, like internet search queries), or distributed in some other way? Practically, this determines strategy: where should attention be focused?

These distinctions may be made for various reasons. For example, they may arise from differing properties of the population, as in the 90–9–1 principle, which posits that in an internet community, 90% of the participants of a community only view content, 9% of the participants edit content, and 1% of the participants actively create new content. As another example, in marketing one may pragmatically consider the head as all members that receive personalized attention, such as personal phone calls; while the tail is everything else, which does not receive personalized attention, for example receiving form letters; and the line is simply as far as resources allow, or where it makes business sense to stop.

Purely quantitatively, a conventional way of splitting a distribution into head and tail is to consider the head to be the first "p" portion of ranks, which account for formula_1 of the overall population, as in the 80:20 Pareto principle, where the top 20% (head) comprises 80% of the overall population. The exact cutoff depends on the distribution – each distribution has a single such cutoff point—and for power laws can be computed from the Pareto index.

Segments may arise naturally due to actual changes in behavior of the distribution as rank varies. Most common is the king effect, where behavior of the top handful of items does not fit the pattern of the rest, as illustrated at top for country populations, and above for most common words in English Wikipedia. For higher ranks, behavior may change at some point, and be well-modeled by different relations in different regions; on the whole by a piecewise function. For example, if two different power laws fit better in different regions, one can use a broken power law for the overall relation; the word frequency in English Wikipedia (above) also demonstrates this.

The Yule–Simon distribution that results from preferential attachment (intuitively, "the rich get richer" and "success breeds success") simulates a broken power law and has been shown to "very well capture" word frequency versus rank distributions. It originated from trying to explain the population verses rank in different species. It has also been show to fit city population versus rank better.

The rank-size rule (or law), describes the remarkable regularity in many phenomena, including the distribution of city sizes, the sizes of businesses, the sizes of particles (such as sand), the lengths of rivers, the frequencies of word usage, and wealth among individuals.

All are real-world observations that follow power laws, such as Zipf's law, the Yule distribution, or the Pareto distribution. If one ranks the population size of cities in a given country or in the entire world and calculates the natural logarithm of the rank and of the city population, the resulting graph will show a log-linear pattern. This is the rank-size distribution.

One study claims that the rank size rule "works" because it is a "shadow" or coincidental measure of the true phenomenon. The true value of rank size is thus not as an accurate mathematical measure (since other power-law formulas are more accurate, especially at ranks lower than 10) but rather as a handy measure or "rule of thumb" to spot power laws. When presented with a ranking of data, is the third-ranked variable approximately one-third the value of the highest-ranked one? Or, conversely, is the highest-ranked variable approximately ten times the value of the tenth-ranked one? If so, the rank size rule has possibly helped spot another power law relationship.

While Zipf's law works well in many cases, it tends to not fit the largest cities in many countries; one type of deviation is known as the King effect. A 2002 study found that Zipf's law was rejected for 53 of 73 countries, far more than would be expected based on random chance. The study also found that variations of the Pareto exponent are better explained by political variables than by economic geography variables like proxies for economies of scale or transportation costs. A 2004 study showed that Zipf's law did not work well for the five largest cities in six countries. In the richer countries, the distribution was flatter than predicted. For instance, in the United States, although its largest city, New York City, has more than twice the population of second-place Los Angeles, the two cities' metropolitan areas (also the two largest in the country) are much closer in population. In metropolitan-area population, New York City is only 1.3 times larger than Los Angeles. In other countries, the largest city would dominate much more than expected. For instance, in the Democratic Republic of the Congo, the capital, Kinshasa, is more than eight times larger than the second-largest city, Lubumbashi. When considering the entire distribution of cities, including the smallest ones, the rank-size rule does not hold. Instead, the distribution is log-normal. This follows from Gibrat's law of proportionate growth.

Because exceptions are so easy to find, the function of the rule for analyzing cities today is to compare the city-systems in different countries. The rank-size rule is a common standard by which urban primacy is established. A distribution such as that in the United States or China does not exhibit a pattern of primacy, but countries with a dominant "primate city" clearly vary from the rank-size rule in the opposite manner. Therefore, the rule helps to classify national (or regional) city-systems according to the degree of dominance exhibited by the largest city. Countries with a primate city, for example, have typically had a colonial history that accounts for that city pattern. If a normal city distribution pattern is expected to follow the rank-size rule (i.e. if the rank-size principle correlates with central place theory), then it suggests that those countries or regions with distributions that do not follow the rule have experienced some conditions that have altered the normal distribution pattern. For example—the presence of multiple regions within large nations such as China and the United States tends to favor a pattern in which more large cities appear than would be predicted by the rule. By contrast, small countries that had been connected (e.g. colonially/economically) to much larger areas will exhibit a distribution in which the largest city is much larger than would fit the rule, compared with the other cities—the excessive size of the city theoretically stems from its connection with a larger system rather than the natural hierarchy that central place theory would predict within that one country or region alone.



</doc>
<doc id="15516115" url="https://en.wikipedia.org/wiki?curid=15516115" title="Geo-replication">
Geo-replication

Geo-replication systems are designed to improve the distribution of data across geographically distributed data networks. This is intended to improve the response time for applications such as web portals. Geo-replication can be achieved using software, hardware or a combination of the two. 

Geo-replication software is a network performance-enhancing technology that is designed to provide improved access to portal or intranet content for uses at the most remote parts of large organizations. It is based on the principle of storing complete replicas of portal content on local servers, and then keeping the content on those servers up-to-date using heavily compressed data updates.

Geo-replication technologies are used to provide replication of the content of portals, intranets, web applications, content and data between servers, across wide area networks WAN to allow users at remote sites to access central content at LAN speeds. 

Geo-replication software can improve the performance of data networks that suffer limited bandwidth, latency and periodic disconnection. Terabytes of data can be replicated over a wide area network, giving remote sites faster access to web applications.

Geo-replication software uses a combination of data compression and content caching technologies. differencing technologies can also be employed to reduce the volume of data that has to be transmitted to keep portal content accurate across all servers. This update compression can reduce the load that portal traffic place on networks, and improve the response time of a portal.

Remote users of web portals and collaboration environments will frequently experience network bandwidth and latency problems which will slow down their experience of opening and closing files, and otherwise interacting with the portal. Geo-replication technology is deployed to accelerate the remote end user portal performance to be equivalent to that experienced by users locally accessing the portal in the central office.

To deliver this reduction in the size of the required data updates across a portal, geo-replication systems often use differencing engine technologies. These systems are able to difference the content of each portal server right down to the byte level. This knowledge of the content that is already on each server enables the system to rebuild any changes to the content on one server, across each of the other servers in the deployment from content already hosted on those other servers. This type of differencing system ensures that no content, at the byte level, is ever sent to a server twice.

Geo-replication systems are often extended to deliver local replication beyond the server and down to the laptop used by a single user. Server to laptop replication enables mobile users to have access to a local replica of their business portal on a standard laptop. This technology may be employed to provide in the field access to portal content by, for example, sales forces and combat forces.




</doc>
<doc id="286960" url="https://en.wikipedia.org/wiki?curid=286960" title="Mainland">
Mainland

Mainland is a contiguous landmass that is larger and often politically, economically and/or demographically more significant than politically associated remote territories, such as exclaves or oceanic islands situated outside the continental shelf. 

In geography, "mainland" can denote the continental (i.e. non-insular) part of any polity or the main island within an island nation. In geopolitics, "mainland" is sometimes used interchangeably with terms like Metropole as an antonym to overseas territories. In the sense of "heartland", mainland is the opposite of periphery.

The term is relative- in Tasmania, continental Australia is the mainland, while to residents of Flinders Island, the main island of Tasmania is also "the mainland".




</doc>
<doc id="404571" url="https://en.wikipedia.org/wiki?curid=404571" title="Spatial mismatch">
Spatial mismatch

Spatial mismatch is the mismatch between where low-income households reside and suitable job opportunities. In its original formulation (see below) and in subsequent research, it has mostly been understood as a phenomenon affecting African-Americans, as a result of residential segregation, economic restructuring, and the suburbanization of employment.

Spatial mismatch was first proposed by John F. Kain in a seminal 1968 article, "Housing Segregation, Negro Employment, and Metropolitan Decentralization". That article did not specifically use the term "spatial mismatch", and Kain disclaimed credit. 

In 1987, William Julius Wilson was an important exponent, elaborating the role of economic restructuring, as well as the departure of the black middle-class, in the development of a ghetto underclass in the United States.

After World War I, many wealthy Americans started decentralizing out of the cities and into the suburbs. During the second half of the 20th century, department stores followed the trend of moving into the suburbs. In 1968, Kain formulated the “Spatial Mismatch Hypothesis”, but he did not refer to it by this term. His hypothesis was that black workers reside in segregated zones that are distant and poorly connected to major centers of growth. The phenomenon has many implications for inner-city residents dependent on low-level entry jobs. For example, distance from work centers can lead to increasing unemployment rates and further dampen poverty outcomes for the region at large.

In 2007, Laurent Gobillon, Harris Selod, and Yves Zenou suggested that there are seven different factors that support the spatial mismatch phenomenon. Four factors are attributed to potential workers accessibility and initiatives. The remaining three factors stress employers' reluctance to divert away from the negative stigma of city people and in particular minorities when hiring.


Growth of ghost cities in China, mostly from not yet agglomerated areas between or adjacent metropolitan areas or coal mining towns, as in the case of the most famous example, Kangbashi New Area of Ordos, are an example of spatial mismatch. In the case of places near metropolitan areas, it represents less of a risk going forward than in mining areas.



</doc>
<doc id="23668992" url="https://en.wikipedia.org/wiki?curid=23668992" title="Geocriticism">
Geocriticism

Geocriticism is a method of literary analysis and literary theory that incorporates the study of geographic space. The term designates a number of different critical practices. In France, Bertrand Westphal has elaborated the concept of "géocritique" in several works. In the United States, Robert Tally has argued for a geocriticism as a critical practice suited to the analysis of what he has termed "literary cartography".

Some of the first expressly "geocritical" writings emerged from symposia organized by Westphal at the University of Limoges. Westphal's foundational essay, "Pour une approche géocritique des textes" constitutes a manifesto for geocriticism. Westphal's theory is elaborated in greater detail in his "Geocriticism: Real and Fictional Spaces", translated by Tally, who also provides a brief introduction. But there are also many works addressing similar themes and using similar methods that might be considered geocritical, even if the term "geocriticism" is not used.

In Westphal's theory, geocriticism is based on three theoretical concepts: spatio-temporality, transgressivity, and referentiality. 

The idea that space and time form a continuum (space-time) is a tenet of modern physics. In the field of literary theory, geocriticism is an interdisciplinary method of literary analysis that focuses not only on such temporal data as relations between the life and times of the author (as in biographical criticism), the history of the text (as in textual criticism), or the story (as studied by narratology), but also on spatial data. Geocriticism therefore has affinities with geography, architecture, urban studies, and so on; it also correlates to philosophical concepts such as deterritorialization.
Following the work of Michel Foucault, Gilles Deleuze, Henri Lefebvre and Mikhail Bakhtin, among others, a geocritical approach to literature recognizes that representations of space are often transgressive, crossing the boundaries of established norms while also reestablishing new relations among people, places, and things. Cartography is no longer seen as the exclusive province of the state or the government; rather, various agents or groups may be responsible for representing the geographic spaces at the same time and with different effects. In practice, therefore, geocriticism is multifocal, examining a variety of topics at once, thus differentiating itself from practices that focus on the singular point of view of the traveler or protagonist. 

Geocriticism also assumes a literary referentiality between world and text, or, in other words, between the referent and its representation. By questioning the relations between a given space's nature and its actually existing condition, the geocritical approach allows for a study of fiction that points also to the theory of possible worlds, such as may be seen in the work on third space by the American geographer Edward Soja ("Thirdspace"). Tally's book "Spatiality", an introduction to spatiality studies in literature and critical theory, includes a chapter on geocriticism.

Geocriticism frequently involves the study of places described in the literature by various authors, but it can also study the effects of literary representations of a given space. An example of the range of geocritical practices can be found in Tally's collection "Geocritical Explorations: Space, Place, and Mapping in Literary and Cultural Studies".

Geocriticism derives some of its practices from precursors whose theoretical work helped establish space as a valid topic for literary analysis. For example, in "The Poetics of Space" and elsewhere, Gaston Bachelard studied literary works to develop a typology of places according to their connotations. Maurice Blanchot's writings have legitimized the idea of literary space, an imaginary place for the creation of the work of literature. One might also look at the developments of cultural studies and especially postcolonial studies, such as Raymond Williams's "The Country and the City" or Edward Said's "Culture and Imperialism", which employ what Said has called a "geographical inquiry into historical experience." Fredric Jameson's concept of cognitive mapping and his theoretical engagement with the postmodern condition also highlight the importance of spatial representation and aesthetic productions, including literature, film, architecture, and design. In "The Atlas of European Novel, 1800-1900", Franco Moretti has examined the diffusion of literary spaces in Europe, focusing on the complex relationship between the text and space. Moretti has also promulgated a theory of literary history, or literary geography, that would use maps to bring to light new connections between the texts studied and their social spaces. And, in his study of Herman Melville's literary cartography, Robert Tally has offered a geocritical approach to certain texts. 

Geocriticism has intellectual and methodological affiliations with such fields as Literature and the Environment or ecocriticism, regional literature, urban studies, sociological and philosophical approaches to literature, and utopian studies.

Notes
Further reading


</doc>
<doc id="2857072" url="https://en.wikipedia.org/wiki?curid=2857072" title="Triangulated irregular network">
Triangulated irregular network

A triangulated irregular network (TIN) is a representation of a continuous surface consisting entirely of triangular facets, used mainly as Discrete Global Grid in primary elevation modeling.

The vertices of these triangles are created from field recorded spot elevations through a variety of means including surveying through conventional, Global Positioning System Real-Time Kinematic (GPS RTK), photogrammetry, or some other means. Associated with three-dimensional data ("x", "y", and "z") and topography, TINs are useful for the description and analysis of general horizontal ("x" and "y") distributions and relationships.

Digital TIN data structures are used in a variety of applications, including geographic information systems (GIS), and computer aided drafting (CAD) for the visual representation of a topographical surface. A TIN is a vector-based representation of the physical land surface or sea bottom, made up of irregularly distributed nodes and lines with three-dimensional coordinates ("x", "y", and "z") that are arranged in a network of non-overlapping triangles.

A TIN comprises a triangular network of vertices, known as mass points, with associated coordinates in three dimensions connected by edges to form a triangular tessellation. Three-dimensional visualizations are readily created by rendering of the triangular facets. In regions where there is little variation in surface height, the points may be widely spaced whereas in areas of more intense variation in height the point density is increased.

A TIN used to represent terrain is often called a digital elevation model (DEM), which can be further used to produce digital surface models (DSM) or digital terrain models (DTM). An advantage of using a TIN over a rasterized digital elevation model (DEM) in mapping and analysis is that the points of a TIN are distributed variably based on an algorithm that determines which points are most necessary to create an accurate representation of the terrain. Data input is therefore flexible and fewer points need to be stored than in a raster DEM, with regularly distributed points. While a TIN may be considered less suited than a raster DEM for certain kinds of GIS applications, such as analysis of a surface's slope and aspect, it is often used in CAD to create contour lines. A DTM and DSM can be formed from a DEM. A DEM can be interpolated from a TIN.

TIN are based on a Delaunay triangulation or constrained Delaunay. Delaunay conforming triangulations are recommended over constrained triangulations. This is because the resulting TINs are likely to contain fewer long, skinny triangles, which are undesirable for surface analysis. Additionally, natural neighbor interpolation and Thiessen (Voronoi) polygon generation can only be performed on Delaunay conforming triangulations. A constrained Delaunay triangulation can be considered when you need to explicitly define certain edges that are guaranteed not to be modified (that is, split into multiple edges) by the triangulator. Constrained Delaunay triangulations are also useful for minimizing the size of a TIN, since they have fewer nodes and triangles where breaklines are not densified.

The TIN model was developed in the early 1970s as a simple way to build a surface from a set of irregularly spaced points. The first triangulated irregular network program for GIS was written by W. Randolph Franklin, under the direction of David Douglas and Thomas Peucker (Poiker), at Simon Fraser University in 1973.



</doc>
<doc id="19021764" url="https://en.wikipedia.org/wiki?curid=19021764" title="Spatial justice">
Spatial justice

Spatial justice links together social justice and space, most notably in the works of geographers David Harvey and Edward W. Soja. The organization of space is a crucial dimension of human societies and reflects social facts and influences social relations (Henri Lefebvre, 1968, 1972). Consequently, both justice and injustice become visible in space. Therefore, the analysis of the interactions between space and society is necessary to understand social injustices and to formulate territorial policies aiming at tackling them. It is at this junction that the concept of spatial justice has been developed.

According to this political theory, space being a fundamental dimension of human societies, social justice is embedded in it. So the understanding of interactions between space and societies is essential to the understanding of social injustices and to a reflection on planning policies that aims at reducing them. This reflection can be guided by the concept of spatial justice, which ties Social Justice with space.
Spatial justice is a crucial challenge because it is the ultimate goal of many planning policies. However, the diversity of definitions of "Justice" (and of the possible "social contracts" that legitimate them), is high and the political objectives of regional planning or urban planning can be quite different and even contradictory.

Therefore, it is important to analyze the concept of spatial justice, which is still rarely questioned (particularly since the work of Anglo-American radical geographers in the 1970s–1980s) to the extent that it has been taken for granted. These past few years, several events and publications have demonstrated the rising interest of human and social sciences for the concept of spatial justice.

The concept of spatial justice opens up several perspectives for social sciences. Building on the work of several famous Justice philosophers (John Rawls, 1971; Iris Marion Young, 1990, 2000), two contrasting approaches of justice have polarized the debate: one focuses on redistribution issues, the other concentrates on decision-making processes. 
A first set of approaches consists in asking questions about spatial or socio-spatial distributions and working to achieve an equal geographical distribution of society's wants and needs, such as job opportunities, access to health care, good air quality, et cetera. This is of particular concern in regions where the population has difficulty moving to a more spatially just location due to poverty, discrimination, or political restrictions (such as apartheid pass laws). Even in free, developed nations, access to many places are limited. Geographer Don Mitchell points to the mass privatization of once-public land as a common example of spatial injustice. In this distributive justice perspective, the access to material and immaterial goods, or to social positions indicates whether the situation is fair or not. At the scale of urban space, questions of accessibility, walkability and transport equity can also be seen as matters of distribution of spatial resources.

Another way of tackling the concept of spatial justice is to focus on decision-making procedures: this approach also raises issues of representations of space, of territorial or other identities and of social practices. For instance, focusing on minorities allows to explore their spatial practices but also to investigate how these are experienced and managed by various agents: this may lead to reveal forms of oppression or discrimination that a universalist approach might disregard otherwise.
In sum, depending on the chosen approach, either questions are asked about spatial distributions because justice is evaluated from "results", or questions are asked about space representations, (spatial or not) identities and experiences because justice is defined as a process. Spatial justice stands as a unifying concept for the social sciences: its coherence stems from a reflection on the modalities of the political decision-making and on the policies implemented in order to improve spatial distributions.

The emergence of the concept of sustainable development has also fostered a debate on environmental equity. It questions our ontological relationship to the world, and the possibility of a fair policy addressing the needs of mankind, present and future, local and global, and of new forms of governance. The notion of "Environmental Justice" was created in the 1970s–1980s in North American cities to denounce the spatial overlapping between forms of racial discrimination and social-economic exclusion, industrial pollutions and vulnerability to natural hazards.





</doc>
<doc id="16971924" url="https://en.wikipedia.org/wiki?curid=16971924" title="Economic restructuring">
Economic restructuring

Economic restructuring refers to the phenomenon of Western urban areas shifting from a manufacturing to a service sector economic base. This transformation has affected demographics including income distribution, employment, and social hierarchy; institutional arrangements including the growth of the corporate complex, specialized producer services, capital mobility, informal economy, nonstandard work, and public outlays; as well as geographic spacing including the rise of world cities, spatial mismatch, and metropolitan growth differentials.

As cities experience a loss of manufacturing jobs and growth of services, sociologist Saskia Sassen affirms that a widening of the social hierarchy occurs where high-level, high-income, salaried professional jobs expands in the service industries alongside a greater incidence of low-wage, low-skilled jobs, usually filled by immigrants and minorities. A "missing middle" eventually develops in the wage structure. Several effects of this social polarization include the increasing concentration of poverty in large U.S. cities, the increasing concentration of black and Hispanic populations in large U.S. cities, and distinct social forms such as the underclass, informal economy, and entrepreneurial immigrant communities. In addition, the declining manufacturing sector leaves behind strained blue-collared workers who endure chronic unemployment, economic insecurity, and stagnation due to the global economy's capital flight. Wages and unionization rates for manufacturing jobs also decline. One other qualitative dimension involves the feminization of the job supply as more and more women enter the labor force usually in the service sector.

Both costs and benefits are associated with economic restructuring. Greater efficiency, job creation, gentrification, and enhanced national competitiveness are associated with social exclusion and inclusion. The low-skilled, low-income population faces the loss of opportunities, full participation in society, lack of access in labor market and school, weak position in housing markets, limited political participation, and restricted social-cultural integration. Conversely, high-skilled, high-income professionals enjoy social inclusion with modern amenities, conveniences, social participation, and full access to public resources.

Furthermore, sociologist William Julius Wilson argues that the deindustrialization of manufacturing employment have exacerbated joblessness in impoverished African American communities correlating with a rise in single-mother households, high premature mortality rates, and increasing incarceration rates among African American males. With some African Americans gaining professional upward mobility through affirmative action and equal opportunity sanctions in education and employment, African Americans without such opportunities fall behind. This creates a growing economic class division among the African American demographic accentuated by global economic restructuring without government response to the disadvantaged. Furthermore, Wilson asserts that as the black middle class leave the predominantly black inner city neighborhoods, informal employment information networks are eroded. This isolates poor, inner city residents from the labor market compounding the concentration of poverty, welfare dependency, rise of unemployment, and physical isolation in these areas.

City youth are also affected such as in New York City. The declines in education, health care, and social services and the dearth of jobs for those with limited education and training along with the decay of public environments for outdoor play and recreation have all contributed to fewer autonomous outdoor play or "hanging out" places for young people. This in turn affects their gross motor development, cultural build-up, and identity construction. Children become prisoners of home relying on television and other outlets for companionship. Contemporary urban environments restricts the opportunities for children to forge and negotiate peer culture or acquire necessary social skills. Overall, their ecologies have eroded in recent years brought about by global restructuring.

When the 1973 oil crisis affected the world capitalist economy, economic restructuring was used to remedy the situation by geographically redistributing production, consumption, and residences.
City economies across the globe moved from goods-producing to service-producing outlets.
Breakthroughs in transportation and communications made industrial capital much more mobile. Soon, producer services emerged as a fourth basic economic sector where routine low-wage service employment moved to low-cost sites and advanced corporate services centralized in cities. These technological upheavals brought about changes in institutional arrangements with the prominence of large corporations, allied business and financial services, nonprofit and public sector enterprises. Global cities such as New York and London become centers for international finance and headquarters for multinational corporations offering cross currency exchange services as well as buildup of foreign banking and trading. Other cities become regional headquarters centers of low-wage manufacturing. In all these urban areas the corporate complex grows offering banking, insurance, advertising, legal council, and other service functions. Economic restructuring allows markets to expand in size and capacity from regional to national to international scopes.

Altogether, these institutional arrangements buttressed by improved technology reflect the interconnectedness and internationalization of firms and economic processes. Consequently, capital, goods, and people rapidly flow across borders. Where the mode of regulation began with Fordism and Taylorization in the industrial age then to mass consumption of Keynesian economics policies, it evolves to differentiated and specialized consumption through international competition. Additionally, in the labor market, nonstandard work arrangements develop in the form of part-time work, temporary agency and contract company employment, short-term employment, contingent work, and independent contracting. Global economic changes and technological improvements in communications and information systems encouraged competitive organizations to specialize in production easily and assemble temporary workers quickly for specific projects. Thus, the norm of standard, steady employment unravels beginning in the mid-1970s.

Another shift in institutional arrangement involves public resources. As economic restructuring encourages high-technology service and knowledge-based economies, massive public de-investment results. Across many parts of the U.S. and the industrialized Western nations, steep declines in public outlays occur in housing, schools, social welfare, education, job training, job creation, child care, recreation, and open space. To remedy these cutbacks, privatization is installed as a suitable measure. Though it leads to some improvements in service production, privatization leads to less public accountability and greater unevenness in the distribution of resources. With this reform in privatizing public services, neoliberalism has become the ideological platform of economic restructuring. Free market economic theory has dismantled Keynesian and collectivists’ strategies and promoted the Reagan and Thatcher politics of the 1980s. Soon free trade, flexible labor, and capital flight are used from Washington D.C. to London to Moscow. Moreover, economic restructuring requires decentralization as states hand down power to local governments. Where the federal government focuses on mainly warfare-welfare concerns, local governments focus on productivity. Urban policy reflects this market-oriented shift from once supporting government functions to now endorsing businesses.

Urban landscapes especially in the U.S. have significantly altered in response to economic restructuring. Cities such as Baltimore, Detroit, St. Louis and others face population losses which result in thousands of abandoned homes, unused buildings, and vacant lots, contributing to urban decay. Such transformations frustrate urban planning and revitalization, fostering deviance in the forms of drug-related activity and vagrancy. Older, compact, industrial U.S. cities have been rendered obsolete. Urban spaces become playgrounds for the urban gentry, wastelands for low-paid service workers, and denizens for the underground economy. In some areas, gentrification projects have caused displacement of poverty-stricken residents. Sunbelt cities such as Miami and Atlanta rise to become key business centers while Snowbelt cities such as Buffalo and Youngstown decline. Even housing markets respond to economic restructuring with decaying housing stocks, escalating housing prices, depleting tax base, changes in financing, and reduction in federal support for housing. Soon, spatial divisions among wealthy and poor households exacerbate. Moreover, with the movement of blue-collared employment from central cities, geographically entrenched housing discrimination, and suburban land use policy, African American youths in inner cities become victims of spatial mismatch, where their residences provide only weak and negative employment growth and they usually lack access to intrametropolitan mobility. High-order services, an expanding sector in the industrialized world, become spatially concentrated in a relative small number of large metropolitan areas, particularly in suburban office agglomerations.

In cultural terms, economic restructuring has been associated with postmodernity as its counterpart concerning flexible accumulation. Additionally, the term carries with it three core themes: historical, radical rupture into post-industrial economic order; priority of economic forces over social/political forces; and structure over agency where the process is independent of human will, as it takes place according to economic logic (Logan & Swanstrom 1990). In addition, economic restructuring demonstrates the increasing complex and human-capital intensive modern society in Western nations.



</doc>
<doc id="8081066" url="https://en.wikipedia.org/wiki?curid=8081066" title="Fundamental plane (spherical coordinates)">
Fundamental plane (spherical coordinates)

The fundamental plane in a spherical coordinate system is a plane of reference that divides the sphere into two hemispheres. The latitude of a point is then the angle between the fundamental plane and the line joining the point to the centre of the sphere.

For a geographic coordinate system of the Earth, the fundamental plane is the Equator. Celestial coordinate systems have varying fundamental planes:



</doc>
<doc id="27288010" url="https://en.wikipedia.org/wiki?curid=27288010" title="Boundary problem (spatial analysis)">
Boundary problem (spatial analysis)

A boundary problem in analysis is a phenomenon in which geographical patterns are differentiated by the shape and arrangement of boundaries that are drawn for administrative or measurement purposes. This is distinct from and must not be confused with the boundary problem in the philosophy of science that is also called the demarcation problem.

In spatial analysis, four major problems interfere with an accurate estimation of the statistical parameter: the boundary problem, scale problem, pattern problem (or spatial autocorrelation), and modifiable areal unit problem (Barber 1988). The boundary problem occurs because of the loss of neighbours in analyses that depend on the values of the neighbours. While geographic phenomena are measured and analyzed within a specific unit, identical spatial data can appear either dispersed or clustered depending on the boundary placed around the data. In analysis with point data, dispersion is evaluated as dependent of the boundary. In analysis with area data, statistics should be interpreted based upon the boundary.

In geographical research, two types of areas are taken into consideration in relation to the boundary: an area surrounded by fixed natural boundaries (e.g., coastlines or streams), outside of which neighbours do not exist (Henley 1981), or an area included in a larger region defined by arbitrary artificial boundaries (e.g., an air pollution boundary in modeling studies or an urban boundary in population migration) (Haining 1990). In an area isolated by the natural boundaries, the spatial process discontinues at the boundaries. In contrast, if a study area is delineated by the artificial boundaries, the process continues beyond the area.

If a spatial process in an area occurs beyond a study area or has an interaction with neighbours outside artificial boundaries, the most common approach is to neglect the influence of the boundaries and assume that the process occurs at the internal area. However, such an approach leads to a significant model misspecification problem (Upton and Fingleton 1985).

That is, for measurement or administrative purposes, geographic boundaries are drawn, but the boundaries per se can bring about different spatial patterns in geographic phenomena (BESR 2002). It has been reported that the difference in the way of drawing the boundary significantly affects identification of the spatial distribution and estimation of the statistical parameters of the spatial process (Cressie 1992; Fotheringham and Rogerson 1993; Griffith 1983; Martin 1987). The difference is largely based on the fact that spatial processes are generally unbounded or fuzzy-bounded (Leung 1987) but the processes are expressed in data imposed within boundaries for analysis purposes (Miller 1999). Although the boundary problem was discussed in relation to artificial and arbitrary boundaries, the effect of the boundaries also occurs according to natural boundaries as long as it is ignored that properties at sites on the natural boundary such as streams are likely to differ from those at sites within the boundary (Martin 1989).

The boundary problem occurs with regard not only to horizontal boundaries but also to vertically drawn boundaries according to delineations of heights or depths (Pineda 1993). For example, biodiversity such as the density of species of plants and animals is high near the surface, so if the identically divided height or depth is used as a spatial unit, it is more likely to find fewer number of the plant and animal species as the height or depth increases.

Boundary problem: urban sprawl in central Florida (an evaluation by land cover analysis with raster datasets vs. an evaluation by population density bounded in the census tract)

By drawing a boundary around a study area, two types of problems in measurement and analysis takes place (Fotheringham and Rogerson 1993). The first is an edge effect. This effect originates from the ignorance of interdependences that occur outside the bounded region. Griffith (1980; 1983) and Griffith and Amrhein (1983) highlighted problems according to the edge effect. A typical example is a cross-boundary influence such as cross-border jobs, services and other resources located in a neighbouring municipality (McGuire 1995).

The second is a shape effect that results from the artificial shape delineated by the boundary. As an illustration of the effect of the artificial shape, point pattern analysis tends to provide higher levels of clustering for the identical point pattern within a unit that is more elongated (Fotheringham and Rogerson 1993). Similarly, the shape can influence interaction and flow among spatial entities (Arlinghaus and Nystuen 1990; Ferguson and Kanaroglou 1998; Griffith 1982). For example, the shape can affect the measurement of origin-destination flows since these are often recorded when they cross an artificial boundary. Because of the effect set by the boundary, the shape and area information is used to estimate travel distances from surveys (Rogerson 1990) or to locate traffic counters, travel survey stations, or traffic monitoring systems (Kirby 1997). From the same perspective, Theobald (2001; retrieved from BESR 2002) argued that measures of urban sprawl should consider interdependences and interactions with nearby rural areas.

In spatial analysis, the boundary problem has been discussed along with the modifiable areal unit problem (MAUP) inasmuch as MAUP is associated with the arbitrary geographic unit and the unit is defined by the boundary (Rogerson 2006). For administrative purposes, data for policy indicators are usually aggregated within larger units (or enumeration units) such as census tracts, school districts, municipalities and counties. The artificial units serve the purposes of taxation and service provision. For example, municipalities can effectively respond to the need of the public in their jurisdictions. However, in such spatially aggregated units, spatial variations of detailed social variables cannot be identified. The problem is noted when the average degree of a variable and its unequal distribution over space are measured (BESR 2002).




</doc>
<doc id="25313082" url="https://en.wikipedia.org/wiki?curid=25313082" title="Pan-region">
Pan-region

A pan-region is a geographic region or state’s sphere of economic, political and cultural influence extending beyond that state's borders. For example, the pan-region of the United States of America (USA) regions both bordering the USA and its close neighbours including, Canada, Mexico, and many South America other states.

The idea of pan-regions or spheres of economic and cultural influence was first developed by Karl Ernst Haushofer (8/27/1869-3/10/1946), a German General, geographer and geo-politician. Pan-regions contributed to Geopolitic or the German theories of foreign policy during the interwar period (1918–1939) or the time from the end of World War I and the beginning of World War II. Haushofer’s pan-regions divided the world under three supreme leading states in economy, politics and culture. Those three states included the USA who controlled North America and much of South America, Germany who controlled Europe, much of Africa and western Asia and Japan who controlled central, eastern, and the islands of southern Asia. These leading states could expect their regions to develop economic and political alliance with their leading state as well as yield to sanctions and major cultural designations.

Historically, the world was divided into three spheres of control, however after the end of World War II, Germany and Japan’s control over their various regions have diminished with the success of other nations. For example, German control over Europe has suffered with the development of the European Union and emergence of other foreign powers. Japan also is beginning to lose economic dominance over its pan-region with the emergence of a thriving Chinese economy.


</doc>
<doc id="28016564" url="https://en.wikipedia.org/wiki?curid=28016564" title="Two-step floating catchment area method">
Two-step floating catchment area method

The two-step floating catchment area (2SFCA) method is a method for combining a number of related types of information into a single, immediately meaningful, index that allows comparisons to be made across different locations. Its importance lies in the improvement over considering the individual sources of information separately, where none on its own provides an adequate summary.

The two-step floating catchment area (2SFCA) method is a special case of a gravity model of spatial interaction that was developed to measure spatial accessibility to primary care physicians. 2SFCA can also be used to measure other accessibility such as accessibility to jobs, to cancer care facilities, etc. It was inspired by the spatial decomposition idea first proposed by Radke and Mu (2000).

The 2SFCA method not only has most of the advantages of a gravity model, but is also intuitive to interpret, as it uses essentially a special form of physician-to-population ratio. It is easy to implement in a GIS environment. In essence, the 2SFCA method measures spatial accessibility as a ratio of primary-care physicians to population, combining two steps:

It has been recently enhanced by considering distance decay within catchments and called the enhanced two-step floating catchment area (E2SFCA) method.

Furthermore, the use of capping certain services according to nearby population size,can improve the accuracy when analyzing across areas of different environments (i.e. rural and urban).

The method has been applied to other related public health issues, such as access to healthy food retailers.




</doc>
<doc id="27891886" url="https://en.wikipedia.org/wiki?curid=27891886" title="Solar equator">
Solar equator

The solar equator is the latitude on Earth at which the Sun is directly overhead; where the sun is vertically above at midday. Because of the inclination of the Earth's orbit the solar equator varies during the year, from the Tropic of Capricorn on the December solstice to the Tropic of Cancer on the June solstice. During the equinoxes, the sun is directly overhead on the geographic Equator and the sun can never be overhead areas outside of the tropics.



</doc>
<doc id="10943769" url="https://en.wikipedia.org/wiki?curid=10943769" title="Place identity">
Place identity

Place identity or place-based identity refers to a cluster of ideas about place and identity in the fields of geography, urban planning, urban design, landscape architecture, environmental psychology, ecocriticism and urban sociology/ecological sociology. Place identity is sometimes called urban character, neighbourhood character or local character. Place identity has become a significant issue in the last 25 years in urban planning and design. Place identity concerns the meaning and significance of places for their inhabitants and users, and how these meanings contribute to individuals' conceptualizations of self. Place identity also relates to the context of modernity, history and the politics of representation. In other words, historical determinism, which intersects historical events, social spaces and groups by gender, class, ethnicity. In this way, it explores how spaces have evolved over time by exploring the social constructs through time and the development of space, place and power. To the same extent, the politics of representation is brought into context, as the making of place identity in a community also relates to the exclusion or inclusion in a community. Through this, some have argued that place identity has become an area for social change because it gives marginalized communities agency over their own spaces. In the same respect, it is argued that place identity has also been used to intervene social change and perpetuate oppression from a top-down approach by creating segregated spaces for marginalized communities.

In some ways it is related to the concepts of place attachment and sense of place. Place identity is largely related to the concepts of community formation because it recognizes that geographical spaces do not solely bond a community together but rather there are social bonds that account for community formation. Those social forces often are feelings of belonging and security, which involve theoretical formations of community. Theoretical formations of community, which were identified in "Community: Seeking Safety in an Insecure World" (Bauman, 2001) as bonds formed by similar locality, culture, language, kinship and/or experiences. In addition, identity also conceives feelings of security and freedom as one is able to self-identify and especially, when it comes to being able to foster agency over community formation. In addition, the similar and shared experiences of culture, language and locality foster the sense of community. This fostering of community is largely seen as an extension of agency because when a community is able to achieve a sense of place and place attachment, this allows for individuals to reinforce their own identities and strengthen their bonds within their community.

Methodologies for understanding place identity primarily involve qualitative techniques, such as interviewing, participant observation, discourse analysis and mapping a range of physical elements. Some urban planners, urban designers and landscape architects use forms of deliberative planning, design charettes and participatory design with local communities as a way of working with place identity to transform existing places as well as create new ones. This kind of planning and design process is sometimes referred to as placemaking.

The following case studies are examples of how place identity is researched on the field.

In a study by Lee Cuba and David M. Hummon (1993), they focus on Cape Cod, Massachusetts residents and how social and environmental factors are associated with place identity. Place identity in regards to "at-homeness" was defined by existence, affiliations, and locus. Community members were asked if they feel at home in Cape Cod to measure the positive responses for existence. The open-ended responses to why community members feel at home were used to measure place affiliation. A close-ended question, "Do you associate feeling at home with living in this particular house or apartment, with living in this community, or with living on the Cape, in general?" was used to measure locus. Most respondents reported they did feel "at home".

Michigan and the Great Lakes are analyzed to see the values and connections shared within the residents of Michigan. A questionnaire was given to Michigan residents to see how attached the residents are. The questionnaire consisted of statements and the statements were evaluated through the five-point Likert scale. As a result, the data revealed "Michigan's voters have developed a strong sense of place regarding the state".

These two case studies shows that place has a lot more to offer than just a physical location. Understanding how to measure a sense of place assist policy makers in decision making and creating potential policy implementation. They will take the community's issues into consideration during the planning process once they understand the values of a community.

Cuba, L. & Hummon, D.M. (1993). A place to call home: Identification with dwelling, community, and region. The Sociological Quarterly, 34 (1), 111-131.

Hague, C. and Jenkins, P. (Eds) (2005). Place identity, planning and participation, London ; New York : Routledge, 2005. (hard cover) 0415262429 (soft cover) 0203646754 (ebook)

Proshansky, H. M. (1978). 'The city and self-identity', Journal of Environment and Behaviour, Vol. 10, pp. 57–83

Nanzer, B. (2004). Measuring sense of place: A scale of Michigan. Administrative Theory & Praxis, 26 (3), 362-382.

Proshansky, H. M., Fabian, A. K. and Kaminoff, R. (1983). 'Place-identity: Physical world socialization of the self', Journal of Environmental Psychology, Vol. 3, pp. 57–83

Relph, E (1976) Place and placelessness. London: Pion, 1976 ()

Roudavski, Stanislav (2008). "Staging Places as Performances: Creative Strategies for Architecture" (PhD, University of Cambridge)


</doc>
<doc id="32038850" url="https://en.wikipedia.org/wiki?curid=32038850" title="Indices of deprivation 2010">
Indices of deprivation 2010

The Indices of Deprivation 2010 (ID 2010) is a deprivation index at the small area level, created by the British Department for Communities and Local Government (DCLG) and released on 24 March 2011. It follows the ID2007 and because much of the datasets are the same or similar between indices allows a comparison of "relative deprivation" of an area between the two indices.

While it is known as the ID2010, most of the data actually dates from 2008.


According to the research, the most deprived area in the country is in the village of Jaywick on the Essex coast.


</doc>
<doc id="23797849" url="https://en.wikipedia.org/wiki?curid=23797849" title="Laminar sublayer">
Laminar sublayer

The laminar sublayer, also called the viscous sublayer, is the region of a mainly-turbulent flow that is near a no-slip boundary and in which the flow is laminar. As such, it is a type of boundary layer. The existence of the laminar sublayer can be understood in that the flow velocity decreases towards the no-slip boundary. Because of this, the Reynolds number decreases until at some point the flow crosses the threshold from turbulent to laminar.

The laminar sublayer is important for river-bed ecology: below the laminar-turbulent interface, the flow is stratified, but above it, it rapidly becomes well-mixed. This threshold can be important in providing homes and feeding grounds for benthic organisms.

Whether the roughness due to the bed sediment or other factors are smaller or larger than this sublayer has an important bearing in hydraulics and sediment transport. Flow is defined as hydraulically rough if the roughness elements are larger than the laminar sublayer (thereby perturbing the flow), and as hydraulically smooth if they are smaller than the laminar sublayer (and therefore ignorable by the main body of the flow).


</doc>
<doc id="5949047" url="https://en.wikipedia.org/wiki?curid=5949047" title="Hjulström curve">
Hjulström curve

The Hjulström curve, named after Filip Hjulström (1902–1982), is a graph used by hydrologists and geologists to determine whether a river will erode, transport, or deposit sediment. It was originally published in his doctoral thesis "Studies of the morphological activity of rivers as illustrated by the River Fyris." in 1935. The graph takes sediment particle size and water velocity into account. 

The upper curve shows the critical erosion velocity in cm/s as a function of particle size in mm, while the lower curve shows the deposition velocity as a function of particle size. Note that the axes are logarithmic. 

The plot shows several key concepts about the relationships between erosion, transportation, and deposition. For particle sizes where friction is the dominating force preventing erosion, the curves follow each other closely and the required velocity increases with particle size. However, for cohesive sediment, mostly clay but also silt, the "erosion" velocity increases with decreasing grain size, as the cohesive forces are relatively more important when the particles get smaller. The critical velocity for deposition, on the other hand, depends on the settling velocity, and that decreases with decreasing grainsize. The Hjulström curve shows that sand particles of a size around 0.1 mm require the lowest stream velocity to erode.

The curve was expanded by Åke Sundborg in 1956. He significantly improved the level of detail in the cohesive part of the diagram, and added lines for different modes of transportation. The result is called the "Sundborg diagram", or the "Hjulström-Sundborg Diagram", in the academic literature.

This curve dates back to early 20th century research on river geomorphology and has no more than a historical value nowadays, although its simplicity is still attractive. Among the drawbacks of this curve are that it does not take the water depth into account and more importantly, that it does not show that sedimentation is caused by flow velocity "deceleration" and erosion is caused by flow "acceleration". The dimensionless Shields Diagram is now unanimously accepted for initiation of sediment motion in rivers. Much work was done on river sediment transport formulae in the second half of the 20th century and that work should be used preferably to Hjulström's curve.



</doc>
<doc id="36248807" url="https://en.wikipedia.org/wiki?curid=36248807" title="Geo-literacy">
Geo-literacy

As defined by National Geographic, geo-literacy is "the ability to use geographic understanding and geographic reasoning to make decisions".

The term "geo-literacy" arose from the National Geographic Society's "Fight against Geographic Illiteracy." The organization released various media to help explain the concept to the general public. In an editorial, Daniel C. Edelson, vice president for education at National Geographic, said, "The National Geographic Society's concern for geo-literacy comes from our mission. We see geo-literacy as providing the tools that will enable communities to protect natural and cultural resources, reduce violent conflict, and improve the quality of life worldwide. However, having a geo-literate populace is also critical for maintaining economic competitiveness, quality of life, and national security in our modern, interconnected world.", and have released various media to help explain it to the general public. In addition, the National Geographic Society set up the Fund for Geo-literacy, in which donations help fund the printing of materials for education, professional development for the educators, and programs to help build awareness of the importance of geo-literacy.

According to Edelson, the 3 components of geo-literacy are:

"Kid World Citizen", a site which provides "multicultural, educational activities to teach...kids about the world", and who, listed the following "age-appropriate lessons to increase geo-literacy in primary school students":


In 2012, InTeGrate ("a community effort to improve geoscience literacy and build a workforce that can make use of geoscience to solve societal issues") held a Module Author Meeting from May 16–18 on the topic.

In 2002, Robert E. Nolan of the Education Resources Information Center published a research report/journal article entitled "Geo-Literacy: How Well Adults Understand the World in Which They Live", which included "a test of physical and geopolitical geography...completed by 321 adults". The years of formal education and age were correlated with geographic literacy, and informal learning, such as travel, reading, media, was used as the primary source of geographic knowledge for those with higher educational attainment. A notable finding was that women, regardless of education level, scored significantly lower than men."

In 2001, the Arizona Geographic Alliance launched a project called "The GeoLiteracy Project" that integrated geography education into reading and writing instruction. In this case, their term "GeoLiteracy" referred to the integration of geography and traditional language arts literacy. 

In 1997, Linda Ferguson and Eva LaMar established an educational project they called "The Geo-Literacy Project". LaMar describes geo-literacy as "the use of visual learning and communication tools to build an in-depth understanding -- or literacy -- of geography, geology, and local history." 



</doc>
<doc id="36908659" url="https://en.wikipedia.org/wiki?curid=36908659" title="Mountain research">
Mountain research

Mountain research or "montology", traditionally also known as "orology" (from Greek "oros" ὄρος for 'mountain' and "logos" λόγος), is a field of research that regionally concentrates on the Earth's surface's part covered by mountain landscapes.

Different approaches have been developed to define "mountainous" areas. While some use an altitudinal difference of 300 m inside an area to define that zone as mountainous, others consider differences from 1000 m or more, depending on the areas' latitude. Additionally, some include steepness to define mountain regions, hence excluding high plateaus (e.g. the Andean Altiplano or the Tibetan Plateau), zones often seen to be mountainous. A more pragmatic but useful definition has been proposed by the Italian Statistics Office ISTAT, which classifies municipalities as mountainous


The United Nations Environmental Programme has produced a map of mountain areas worldwide using a combination of criteria, including regions with


In a broader sense, mountain research is considered any research "in" mountain regions: for instance disciplinary studies on Himalayan plants, Andean rocks, Alpine cities, or Carpathian people. It is comparable to research that concentrates on the Arctic and Antarctic (polar research) or coasts (coastal research).

In a narrower sense, mountain research focuses "on" mountain regions, their description and the explanation of the human-environment interaction in (positive) and the sustainable development of (normative) these areas. So-defined mountain research is situated at the nexus of natural sciences, social sciences and humanities. Drawing on Alexander von Humboldt's work in the Andean realm, mountain geography and ecology are considered core areas of study; nevertheless important contributions are coming from anthropology, geology, economics, history or spatial planning. In sum, a narrowly defined mountain research applies an interdisciplinary and integrative regional approach. Slaymaker summarizes:

Mountain research or "orology"—not to be confused with orography—, is sometimes denominated "montology". This term stems from Carl Troll's "mountain geoecology"—geoecology being Troll's English translation of the German "Landschaftsökologie"—and appeared at a meeting in Cambridge, Massachusetts in 1977. Since then, scholars such as Jack D. Ives, Bruno Messerli and Robert E. Rhoades have claimed the development of montology as interdisciplinary mountain research. The term montology was included in the Oxford English Dictionary in 2002. It defines montology as:

On the one hand, the term "montology" received criticism due to the mix of Latin ("mōns", pl. "montēs") and Greek ("logos"). On the other hand, however, this is also the—well accepted—case in several, already established disciplines such as glaciology or sociology.

The following list includes peer-reviewed journals that have a focus on mountain research and are open to both the natural and the social sciences:





</doc>
<doc id="38262946" url="https://en.wikipedia.org/wiki?curid=38262946" title="Land systems">
Land systems

Land systems constitute the terrestrial component of the Earth system and encompass all processes and activities related to the human use of land, including socioeconomic, technological and organizational investments and arrangements, as well as the benefits gained from land and the unintended social and ecological outcomes of societal activities. Changes in land systems have large consequences for the local environment and human well-being and are at the same time pervasive factors of global environmental change. Land provides vital resources to society, such as food, fuel, fibres and many other ecosystem services that support production functions, regulate risks of natural hazards, or provide cultural and spiritual services. By using the land, society alters and modifies the quantity and quality of the provision of these services.

Land system changes are the direct result of human decision making at multiple scales ranging from local land owners decisions to national scale land use planning and global trade agreements. The aggregate impact of many local land system changes has far reaching consequences for the Earth System, that feedback on ecosystem services, human well-being and decision making. As a consequence, land system change is both a cause and consequence of socio-ecological processes.

The Global Land Programme (GLP) of Future Earth is an interdisciplinary community of science and practice fostering the study of land systems and the co-design of solutions for global sustainability.


</doc>
<doc id="9177450" url="https://en.wikipedia.org/wiki?curid=9177450" title="Easting and northing">
Easting and northing

The terms easting and northing are geographic Cartesian coordinates for a point. Easting refers to the eastward-measured distance (or the "x"-coordinate), while northing refers to the northward-measured distance (or the "y"-coordinate). When using common projections such as the transverse Mercator projection, these are distances projected on an imaginary surface similar to a bent sheet of paper, and are not the same as distances measured on the curved surface of the Earth.
Easting and northing coordinates are commonly measured in metres from the axes of some horizontal datum. However, other units (e.g., survey feet) are also used. The coordinates are most commonly associated with the Universal Transverse Mercator coordinate system (UTM), which has unique zones that cover the Earth to provide detailed referencing.

Locations can be found using easting/northing (or " x", "y") pairs. The pair is usually represented conventionally with easting first, northing second.

For example, the peak of Mount Assiniboine (at ) in UTM Zone 11 is represented by codice_1. Other conventions can also be used, such as a truncated grid reference, which would shorten the example coordinates to codice_2.

Negative northing and easting values indicate a position due south and west of the origin, respectively.

Usually associated with a map projection is a "natural origin", e.g., at which the ellipsoid and flat map surfaces coincide. To ensure that the northing and easting coordinates on a map are not negative, map projections may set up a "false origin", specified in terms of "false northing" and "false easting" values, that offset the true origin.



</doc>
<doc id="711728" url="https://en.wikipedia.org/wiki?curid=711728" title="Governmentality">
Governmentality

Governmentality is a concept first developed by the French philosopher Michel Foucault in the later years of his life, roughly between 1977 and his death in 1984, particularly in his lectures at the Collège de France during this time.

The concept has been elaborated further from an "Anglo-Neo Foucauldian" perspective in the social sciences, especially by authors such as Peter Miller, Nikolas Rose, and Mitchell Dean. Governmentality can be understood as:

Governmentality may also be understood as:

This term was thought by some commentators to be made by the "...linking of governing ("gouverner") and modes of thought ("mentalité")". In fact, it was not coined by uniting words "gouvernement" and "mentalité", but simply by making "gouvernement" into "gouvernementalité" just like "musical" into "musicalité" [i.e. government + -al- "adjective" + -ité "abstract noun"] (see Michel Senellart's "Course Context" in Foucault's "Security, territory, population" lectures). To fully understand this concept, it is important to realize that in this case, Foucault does not only use the standard, strictly political definition of "governing" or government used today, but he also uses the broader definition of governing or government that was employed until the eighteenth century. That is to say, that in this case, for Foucault, "...'government' also signified problems of self-control, guidance for the family and for children, management of the household, directing the soul, etc." In other words, for our purposes, government is "...the conduct of conduct..."

In his lectures at the Collège de France, Foucault often defines governmentality as the "art of government" in a wide sense, i.e. with an idea of "government" that is not limited to state politics alone, that includes a wide range of control techniques, and that applies to a wide variety of objects, from one's control of the self to the "biopolitical" control of populations. In the work of Foucault, this notion is indeed linked to other concepts such as biopolitics and power-knowledge. The genealogical exploration of the modern state as "problem of government" does not only deepen Foucault's analyses on sovereignty and biopolitics; it offers an analytics of government which refines both Foucault's theory of power and his understanding of freedom.

The concept of "governmentality" develops a new understanding of power. Foucault encourages us to think of power not only in terms of hierarchical, top-down power of the state. He widens our understanding of power to also include the forms of social control in disciplinary institutions (schools, hospitals, psychiatric institutions, etc.), as well as the forms of knowledge. Power can manifest itself positively by producing knowledge and certain discourses that get internalised by individuals and guide the behaviour of populations. This leads to more efficient forms of social control, as knowledge enables individuals to govern themselves.

"Governmentality" applies to a variety of historical periods and to different specific power regimes. However, it is often used (by other scholars and by Foucault himself) in reference to "neoliberal governmentality", i.e. to a type of governmentality that characterizes advanced liberal democracies. In this case, the notion of governmentality refers to societies where power is de-centered and its members play an active role in their own self-government, e.g. as posited in neoliberalism. Because of its active role, individuals need to be regulated from 'inside'. A particular form of governmentality is characterized by a certain form of knowledge ("savoir" in French). In the case of neoliberal governmentality (a kind of governmentality based on the predominance of market mechanisms and of the restriction of the action of the state) the knowledge produced allows the construction of auto-regulated or auto-correcting selves.

In his lecture titled Governmentality, Foucault gives us a definition of governmentality:
As Foucault's explicit definition is rather broad, perhaps further examination of this definition would be useful.

We shall begin with a closer inspection of the first part of Foucault's definition of governmentality:

This strand of the three-part definition states that governmentality is, in other words, all of the components that make up a government that has as its end the maintenance of a well-ordered and happy society (population). The government's means to this end is its "apparatuses of security," that is to say, the techniques it uses to provide this society a feeling of economic, political, and cultural well-being. The government achieves these ends by enacting "political economy," and in this case, the meaning of economy is the older definition of the term, that is to say, "economy at the level of the entire state, which means exercising towards its inhabitants, and the wealth and behavior of each and all, a form of surveillance and control as attentive as that of the head of a family over his household and his goods". Thus, we see that this first part of the definition states that governmentality is a government with specific ends, means to these ends, and particular practices that should lead to these ends.

The second part of Foucault's definition (the "resulting, on the one hand, in formation of a whole series of specific governmental apparatuses, and, on the other, in the development of a whole complex of savoirs") presents governmentality as the long, slow development of Western governments which eventually took over from forms of governance like sovereignty and discipline into what it is today: bureaucracies and the typical methods by which they operate.

The next and last part of Foucault's definition of governmentality can be restated as the evolution from the Medieval state, which maintained its territory and an ordered society within this territory through a blunt practice of simply imposing its laws upon its subjects, to the early Renaissance state, which became more concerned with the "disposing of things", and so began to employ strategies and tactics to maintain a content and thus stable society, or in other words to "render a society governable".

Thus, if one takes these three definitions together, governmentality may be defined as the process through which a form of government with specific ends (a happy and stable society), means to these ends ("apparatuses of security"), and with a particular type of knowledge ("political economy"), to achieve these ends, evolved from a medieval state of justice to a modern administrative state with complex bureaucracies.

The concept of governmentality segues from Foucault's ethical, political and historical thoughts from the late 1970s to the early 1980s. His most widely known formulation of this notion is his lecture entitled "Security, territory and population" (1978). A deeper and richer reflection on the notion of governmentality is provided in Foucault's course on "The Birth of Biopolitics" at the Collège de France in 1978-1979. The course was first published in French in 2004 as "Naissance de la biopolitique: Cours au Collège de France (1978-1979)" (Paris: Gallimard & Seuil). This notion is also part of a wider analysis on the topic of disciplinary institutions, on neoliberalism and the "Rule of Law", the "microphysics of power" and also on what Foucault called biopolitics. In the second and third volumes of "The History of Sexuality", namely, "The Use of Pleasure" (1984) and "The Care of the Self" (1984), and in his lecture on "Technologies of the Self" (1982), Foucault elaborated a distinction between subjectivation and forms of subjectification by exploring how selves were fashioned and then lived in ways which were both heteronomously and autonomously determined. Also, in a series of lectures and articles, including "The Birth of Biopolitics" (1979), ""Omnes et Singulatim": Towards a Criticism of Political Reason" (1979), "The Subject and Power" (1982) and "What is Enlightenment?" (1984), he posed questions about the nature of contemporary social orders, the conceptualization of power, human freedom and the limits, possibilities and sources of human actions, etc. that were linked to his understanding of the notion of "governmentality".

The notion of governmentality (not to confuse with governance) gained attention in the English-speaking academic world mainly through the edited book "The Foucault Effect" (1991), which contained a series of essays on the notion of governmentality, together with a translation of Foucault's 1978 short text on "gouvernementalité".

Hunt and Wickham, in their work "Foucault and Law" [1994] begin the section on governmentality with a very basic definition derived from Foucault's work. They state, "governmentality is the dramatic expansion in the scope of government, featuring an increase in the number and size of the governmental calculation mechanisms" [1994:76]. In other words, governmentality describes the new form of governing that arose in the mid-eighteenth century that was closely allied with the creation and growth of the modern bureaucracies. In giving this definition, Hunt and Wickham conceive of the term as consisting of two parts 'governmental' and '–ity' - governmental meaning pertaining to the government of a country; and the suffix –ity meaning the study of. They acknowledge that this definition lacks some of Foucault's finer nuances and try to redress this by explaining some more of Foucault's ideas, including reason of state, the problem of population, modern political economy, liberal securitisation, and the emergence of the human sciences" [1994:77].

Kerr's approach to the term is more complex. He conceives of the term as an abbreviation of "governmental rationality" [1999:174]. In other words, it is a way of thinking about the government and the practices of the government. To him it is not "a zone of critical-revolutionary study, but one that conceptually reproduces capitalist rule" [1999:197] by asserting that some form of government (and power) will always be necessary to control and constitute society. By defining governmentality only in terms of the state, Kerr fails to take account of other forms of governance and the idea of mentalities of government in this broader sense.

Dean's understanding of the term incorporates both other forms of governance and the idea of mentalities of government, as well as Hunt and Wickham's, and Kerr's approaches to the term. In line with Hunt and Wickham's approach, Dean acknowledges that in a very narrow sense, governmentality can be used to describe the emergence of a government that saw that the object of governing power was to optimise, use and foster living individuals as members of a population [1999:19]. He also includes the idea of government rationalities, seeing governmentality as one way of looking at the practices of government. In addition to the above, he sees government as anything to do with conducting oneself or others. This is evident in his description of the word in his glossary: "Governmentality: How we think about governing others and ourselves in a wide variety of contexts..." [1999:212]. This reflects that the term government to Foucault meant not so much the political or administrative structures of the modern state as the way in which the conduct of individuals or of groups may be directed. To analyse government is to analyse those mechanisms that try to shape, sculpt, mobilise and work through the choices, desires, aspirations, needs, wants and lifestyles of individuals and groups [Dean, 1999:12].

Dean's main contribution to the definition of the term, however, comes from the way he breaks the term up into 'govern' 'mentality', or mentalities of governing—mentality being a mental disposition or outlook. This means that the concept of governmentality is not just a tool for thinking about government and governing but also incorporates how and what people who are governed think about the way they are governed. He defines thinking as a "collective activity" [1999:16], that is, the sum of the knowledge, beliefs and opinions held by those who are governed. He also raises the point that a mentality is not usually "examined by those who inhabit it" [1999:16]. This raises the interesting point that those who are governed may not understand the unnaturalness of both the way they live and the fact that they take this way of life for granted—that the same activity in which they engage in "can be regarded as a different form of practice depending on the mentalities that invest it" [1999:17]. Dean highlights another important feature of the concept of governmentality—its reflexivity. He explains:
"On the one hand, we govern others and ourselves according to what we take to be true about who we are, what aspects of our existence should be worked upon, how, with what means, and to what ends. On the other hand, the ways in which we govern and conduct ourselves give rise to different ways of producing truth. [1999:18]

By drawing attention to the 'how and why', Dean connects "technologies of power" [Lemke, 2001:191] to the concept of governmentality. According to Dean any definition of governmentality should incorporate all of Foucault's intended ideas. A complete definition of the term governmentality must include not only government in terms of the state, but government in terms of any "conduct of conduct" [Dean, 1999:10]. It must incorporate the idea of mentalities and the associations that go with that concept: that it is an attitude towards something, and that it is not usually understood "from within its own perspective" [1999:16], and that these mentalities are collective and part of a society's culture. It must also include an understanding of the ways in which conduct is governed, not just by governments, but also by ourselves and others.

The semantic linking of governing and mentalities in governmentality indicates that it is not possible to study technologies of power without an analysis of the mentality of rule underpinning them. The practice of going to the gym, expounded below, is a useful example because it shows how our choices, desires, aspirations, needs, wants and lifestyles have been mobilised and shaped by various technologies of power.

A mentality of rule is any relatively systematic way of thinking about government. It delineates a discursive field in which the exercise of power is 'rationalised' [Lemke, 2001:191]. Thus Neo-liberalism is a mentality of rule because it represents a method of rationalising the exercise of government, a rationalisation that obeys the internal rule of maximum economy [Foucault, 1997:74]. Fukuyama [in Rose, 1999: 63] writes "a liberal State is ultimately a limited State, with governmental activity strictly bounded by the sphere of individual liberty". However, only a certain type of liberty, a certain way of understanding and exercising freedom is compatible with Neo-liberalism. If Neo-liberalist government is to fully realize its goals, individuals must come to recognize and act upon themselves as both free and responsible [Rose, 1999:68]. Thus Neo-liberalism must work to create the social reality that it proposes already exists. For as Lemke states, a mentality of government "is not pure, neutral knowledge that simply re-presents the governing reality" [Lemke, 2001:191] instead, Neo-liberalism constitutes an attempt to link a reduction in state welfare services and security systems to the increasing call for subjects to become free, enterprising, autonomous individuals. It can then begin to govern its subjects, not through intrusive state bureaucracies backed with legal powers, the imposition of moral standards under a religious mandate, but through structuring the possible field of action in which they govern themselves, to govern them through their freedom. Through the transformation of subjects with duties and obligations, into individuals, with rights and freedoms, modern individuals are not merely 'free to choose' but obliged to be free, "to understand and enact their lives in terms of choice" [Rose, 1999:87]. This freedom is a different freedom to that offered in the past. It is a freedom to realize our potential and our dreams through reshaping the way in which we conduct our lives.

Cartographic mapping has historically been a key strategy of governmentality. Harley, drawing on Foucault, affirms that State-produced maps "extend and reinforce the legal statutes, territorial imperatives, and values stemming from the exercise of political power". Typically, State-led mapping conforms to Bentham's concept of a panopticon, in which 'the one views the many'. From a Foucauldian vantage point, this was the blueprint for disciplinary power.

Through processes of neoliberalism, the State has "hollowed out" some of its cartographic responsibilities and delegated power to individuals who are at a lower geographical scale. 'People's cartography' is believed to deliver a more democratic spatial governance than traditional top-down State-distribution of cartographic knowledge. Thus subverting Harley's theory that mapping is uniquely a source of power for the powerful. Joyce challenges Foucauldian notions of Panopticism, contending that neoliberal governmentality is more adequately conceptualised by an omniopticon - 'the many surveilling the many'. Collaborative mapping initiatives utilising GPS technology are arguably omniopticons, with the ability to reverse the panoptic gaze.

Through our freedom, particular self-governing capabilities can be installed in order to bring our own ways of conducting and evaluating ourselves into alignment with political objectives [Rose, 1996:155]. These capabilities are enterprise and autonomy. Enterprise here designates an array of rules for the conduct of one's everyday existence: energy, initiative, ambition, calculation, and personal responsibility. The enterprising self will make an enterprise of its life, seek to maximize its own human capital, project itself a future, and seek to shape life in order to become what it wishes to be. The enterprising self is thus both an active self and a calculating self, a self that calculates about itself and that acts upon itself in order to better itself [Rose, 1996:154]. Autonomy is about taking control of our undertakings, defining our goals, and planning to achieve our needs through our own powers [Rose, 1996:159]. The autonomy of the self is thus not the eternal antithesis of political power, but one of the objectives and instruments of modern mentalities for the conduct of conduct [Rose, 1996:155].

These three qualities: freedom, enterprise and autonomy are embodied in the practice of going to the gym. It is our choice to go the gym, our choice which gym to go to. By going to the gym we are working on ourselves, on our body shape and our physical fitness. We are giving ourselves qualities to help us perform better than others in life, whether to attract a better mate than others, or to be able to work more efficiently, more effectively and for longer without running out of steam to give us an advantage over our competitors. When we go to the gym, we go through our own discipline, on our own timetable, to reach our own goals. We design and act out our routine by ourselves. We do not need the ideas or support of a team, it is our self that makes it possible. The practice of going to the gym, of being free, enterprising, autonomous, is imbued with particular technologies of power.

Technologies of power are those "technologies imbued with aspirations for the shaping of conduct in the hope of producing certain desired effects and averting certain undesired ones" [Rose, 1999:52]. The two main groups of technologies of power are technologies of the self, and technologies of the market. Foucault defined technologies of the self as techniques that allow individuals to effect by their own means a certain number of operations on their own bodies, minds, souls, and lifestyle, so as to transform themselves in order to attain a certain state of happiness, and quality of life. Technologies of the market are those technologies based around the buying and selling of goods that enable us to define who we are, or want to be. These two technologies are not always completely distinct, as both borrow bits of each other from time to time.

Technologies of the self refer to the practices and strategies by which individuals represent to themselves their own ethical self-understanding. One of the main features of technologies of self is that of expertise. Expertise has three important aspects. First, its grounding of authority in a claim to scientificity and objectivity creates distance between self-regulation and the state that is necessary with liberal democracies. Second, expertise can "mobilise and be mobilised within political argument in distinctive ways, producing a new relationship between knowledge and government. Expertise comes to be accorded a particular role in the formulation of programs of government and in the technologies that seek to give them effect" [Rose, 1996:156]. Third, expertise operates through a relationship with the self-regulating abilities of individuals. The plausibility inherent in a claim to scientificity binds "subjectivity to truth and subjects to experts" [Rose, 1996:156]. Expertise works through a logic of choice, through a transformation of the ways in which individuals constitute themselves, through "inculcating desires for self-development that expertise itself can guide and through claims to be able to allay the anxieties generated when the actuality of life fails to live up to its image [Rose, 1999:88].

The technologies of the self involved in the practice of, for example, going to the gym are the: technology of responsibilisation, technology of healthism, technology of normalisation and technology of self-esteem.

In line with its desire to reduce the scope of government (e.g. welfare) Neo-liberalism characteristically develops indirect techniques for leading and controlling individuals without being responsible for them. The main mechanism is through the technology of responsibilisation. This entails subjects becoming responsibilised by making them see social risks such as illness, unemployment, poverty, etc. not as the responsibility of the state, but actually lying in the domain for which the individual is responsible and transforming it into a problem of 'self-care' [Lemke, 2001:201] and of 'consumption'. The practice of going to the gym can be seen as a result of responsibilisation, our responsibility to remain free of illness so as to be able to work and to care for our dependants (children, elderly parents etc.) This technology somewhat overlaps with the technology of healthism.

Healthism links the "public objectives for the good health and good order of the social body with the desire of individuals for health and well-being" [Rose, 1999:74]. Healthy bodies and hygienic homes may still be objectives of the state, but it no longer seeks to discipline, instruct, moralise or threaten us into compliance. Rather "individuals are addressed on the assumption that they want to be healthy and enjoined to freely seek out the ways of living most likely to promote their own health" [Rose, 1999:86-87] such as going to the gym. However while the technology of responsibilisation may be argued to be a calculated technique of the state, the wave of Healthism is less likely to be a consequence of state planning, but arising out of the newer social sciences such as nutrition and human movement. Healthism assigns, as do most technologies of the self, a key role to experts. For it is experts who can tell us how to conduct ourselves in terms of safe, precise techniques to improve cardiovascular fitness, muscle strength, and overall health. The borrowing from technologies of the market by technologies of the self can be clearly seen in the area of healthism. The idea of health, the goal of being healthy, the joys brought by good health and the ways of achieving it are advertised to us in the same manner as goods and services are marketed by sales people. By adhering to the principles of healthism, our personal goals are aligned with political goals and we are thus rendered governable.

Another technology of power arising from the social sciences is that of normalisation. The technology of norms was given a push by the new methods of measuring population. A norm is that "which is socially worthy, statistically average, scientifically healthy and personally desirable". The important aspect of normality, is that while the norm is natural, those who wish to achieve normality will do so by working on themselves, controlling their impulses in everyday conduct and habits, and inculcating norms of conduct into their children, under the guidance of others. Norms are enforced through the calculated administration of shame. Shame entails an anxiety over the exterior behaviour and appearance of the self, linked to an injunction to care for oneself in the name of achieving quality of life [Rose, 1999:73]. Norms are usually aligned with political goals, thus the norm would be fit, virile, energetic individuals, able to work, earn money, and spend it and thus sustain the economy. For instance, the practice of going to the gym allows one to achieve this 'normality'. Through shame we are governed into conforming with the goals of Neo-liberalism.

Self-esteem is a practical and productive technology linked to the technology of norms, which produces of certain kinds of selves. Self-esteem is a technology in the sense that it is a specialised knowledge of how to esteem ourselves to estimate, calculate, measure, evaluate, discipline, and to judge our selves. The 'self-esteem' approach considers a wide variety of social problems to have their source in a lack of self-esteem on the part of the persons concerned. 'Self-esteem' thus has much more to do with self-assessment than with self-respect, as the self continuously has to be measured, judged and disciplined in order to gear personal 'empowerment' to collective yardsticks. These collective yardsticks are determined by the norms previously discussed. Self-esteem is a technology of self for "evaluating and acting upon ourselves so that the police, the guards and the doctors do not have to do so". By taking up the goal of self-esteem, we allow ourselves to be governable from a distance. The technology of self-esteem and other similar psychological technologies also borrow from technologies of the market, namely consumption. A huge variety of self-help books, tapes, videos and other paraphernalia are available for purchase by the individual.

The technologies of the market that underlie the practice of going to the gym can be described as the technology of desire, and the technology of identity through consumption. The technology of desire is a mechanism that induces in us desires that we work to satisfy. Marketers create wants and artificial needs in us through advertising goods, experiences and lifestyles that are tempting to us. These advertisements seek to convey the sense of individual satisfaction brought about by the purchase or use of this product. We come to desire these things and thus act in a manner that allows us to achieve these things, whether by working harder and earning more money or by employing technologies of the self to shape our lifestyle to the manner we desire . The borrowing of technologies of the self by technologies of the market extends even further in this case. Marketers use the knowledge created by psyche- discourses, especially psychological characteristics as the basis of their market segmentation. This allows them to appeal more effectively to each individual. Thus we are governed into purchasing commodities through our desire.

The technology of identity through consumption utilises the power of goods to shape identities. Each commodity is imbued with a particular meaning, which is reflected upon those who purchase it, illuminating the kind of person they are, or want to be. Consumption is portrayed as placing an individual within a certain form of life. The technology of identity through consumption can be seen in the choices that face the gym attendee. To go to an expensive gym because it demonstrates wealth/success or to go to a moderately priced gym so as to appear economical. The range of gym wear is extensive. Brand name to portray the abilities portrayed in its advertising, expensive to portray commitment, or cheap to portray your unconcern for other people's opinions. All of these choices of consumption are used to communicate our identity to others, and thus we are governed by marketers into choosing those products that identify with our identity.

These technologies of the market and of the self are the particular mechanisms whereby individuals are induced into becoming free, enterprising individuals who govern themselves and thus need only limited direct governance by the state. The implementation of these technologies is greatly assisted by experts from the social sciences. These experts operate a regime of the self, where success in life depends on our continual exercise of freedom, and where our life is understood, not in terms of fate or social status, but in terms of our success or failure in acquiring the skills and making the choices to actualise ourself. If we engage in the practice of going to the gym, we are undertaking an exercise in self-government. We do so by drawing upon certain forms of knowledge and expertise provided by gym instructors, health professionals, of the purveyors of the latest fitness fad. Depending on why we go to the gym, we may calculate number of calories burned, heart-rate, or muscle size. In all cases, we attend the gym for a specific set of reasons underpinned by the various technologies of the self and the market. The part of ourselves we seek to work upon, the means by which we do so, and who we hope to become, all vary according to the nature of the technology of power by which we are motivated [Dean, 1999:17]. All of these various reasons and technologies are underpinned by the mentality of government that seeks to transform us into a free, enterprising, autonomous individual: Neo-liberalism. Furthermore, Neo-liberalism seeks to create and disseminate definitions of freedom, autonomy and what it means to be enterprising that re-create forms of behavior amenable to neo-liberal goals.

Ecogovernmentality (or eco-governmentality) is the application of Foucault's concepts of biopower and governmentality to the analysis of the regulation of social interactions with the natural world. Timothy W. Luke theorized this as environmentality and green governmentality. Ecogovernmentality began in the mid-1990s with a small body of theorists (Luke, Darier, and Rutherford) the literature on ecogovernmentality grew as a response to the perceived lack of Foucauldian analysis of environmentalism and in environmental studies.

Following Michel Foucault, writing on ecogovernmentality focuses on how government agencies, in combination with producers of expert knowledge, construct "The Environment." This construction is viewed both in terms of the creation of an object of knowledge and a sphere within which certain types of intervention and management are created and deployed to further the government's larger aim of managing the lives of its constituents. This governmental management is dependent on the dissemination and internalization of knowledge/power among individual actors. This creates a decentered network of self-regulating elements whose interests become integrated with those of the State.

According to Foucault, there are several instances where the Western, "liberal art of government" enters into a period of crisis, where the logic of ensuring freedom (which was defined against the background of risk or danger) necessitates actions "which potentially risk producing exactly the opposite."

The inherently contradictory logics that lead to such contradictions are identified by Foucault as:


Examples of this contradictory logic which Foucault cites are the policies of the Keynesian welfare state under F.D. Roosevelt, the thought of the German liberals in the Freiburg school, and the thought of American libertarian economists such as the Chicago School which attempt to free individuals from the lack of freedom perceived to exist under socialism and fascism, but did so by using state interventionist models.

These governmental crises may be triggered by phenomena such as a discursive concern with increasing economic capital costs for the exercise of freedom, e.g., prices for purchasing resources, the need for excessive state coercion and interventionism to protect market freedoms, e.g., anti-trust and anti-monopoly legislation that leads to a "legal strait-jacket" for the state, local protests rejecting the disciplinary mechanisms of the market society and state. and finally, the destructive and wasteful effects of ineffective mechanisms for producing freedom.

Scholars have recently suggested that the concept of governmentality may be useful in explaining the operation of evidence-based health care and the internalization of clinical guidelines relating to best practice for patient populations, such as those developed by the American Agency for Health Care Research and Quality and the British National Institute for Health and Clinical Excellence (NICE). Recent research by Fischer and colleagues at the University of Oxford has renewed interest in Foucault's exploration of potential resistance to governmentality, and its application to health care, drawing on Foucault's recently published final lectures at the College de France.

Jeffreys and Sigley (2009) highlight that governmentality studies have focused on advanced liberal democracies, and preclude considerations of non-liberal forms of governmentality in both western and non-western contexts. Recent studies have broken new ground by applying Foucault's concept of governmentality to non-western and non-liberal settings, such as China. Jeffreys (2009) for example provides a collection of essay on China's approach to governance, development, education, the environment, community, religion, and sexual health where the notion of 'Chinese governmentally' is based not on the notion of 'freedom and liberty' as in the western tradition but rather, on a distinct rational approach to planning and administration. Such new studies thus use Foucault's Governmentalities to outline the nature of shifts in governance and contribute to emerging studies of governmentality in non-western contexts.


http://www.inderscience.com/info/inarticle.php?artid=67421
https://eurasianpublications.com/Eurasian-Journal-of-Economics-and-Finance/Vol.4-No.2-2016.aspx
https://eurasianpublications.com/Eurasian-Journal-of-Economics-and-Finance/Vol.4-No.2-2016.aspx


</doc>
<doc id="501118" url="https://en.wikipedia.org/wiki?curid=501118" title="Hermit kingdom">
Hermit kingdom

The term hermit kingdom can be used to refer to any country, organization or society which willfully walls itself off, either metaphorically or physically, from the rest of the world. The country of North Korea has been considered a prime example of a hermit kingdom.

Korea in the age of Joseon dynasty was the subject of the first use of the term, in William Elliot Griffis' 1882 book "Corea: The Hermit Nation", and Korea was frequently described as a hermit kingdom until 1905 when it became a protectorate of Japan. The term is still commonplace throughout Korea and it is often used by Koreans themselves to describe pre-modern Korea. 

Today, the term is often applied to North Korea in news and social media, and in 2009 it was used by United States Secretary of State Hillary Clinton. 



</doc>
<doc id="16953152" url="https://en.wikipedia.org/wiki?curid=16953152" title="Extreme environment">
Extreme environment

An extreme environment is a habitat that is considered very hard to survive in due to its considerably extreme conditions such as temperature, accessibility to different energy sources or under high pressure. For an area to be considered an extreme environment, it must contain certain conditions and aspects that are considered very hard for other life forms to survive. Pressure conditions may be extremely high or low; high or low content of oxygen or carbon dioxide in the atmosphere; high levels of radiation, acidity, or alkalinity; absence of water; water containing a high concentration of salt or sugar; the presence of sulphur, petroleum, and other toxic substances.

Examples of extreme environments include the geographical poles, very arid deserts, volcanoes, deep ocean trenches, upper atmosphere, Mt Everest, outer space, and the environments of every planet in the Solar System except the Earth. Any organisms living in these conditions are often very well adapted to their living circumstances, which is usually a result of long-term evolution. Physiologists have long known that organisms living in extreme environments are especially likely to exhibit clear examples of evolutionary adaptation because of the presumably intense past natural selection they have experienced.

The distribution of extreme environments on Earth has varied through geological time. Humans generally do not inhabit extreme environments. There are organisms referred to as extremophiles that do live in such conditions and are so well-adapted that they readily grow and multiply. Extreme environments are usually hard to survive in

Most of the moons and planets in the Solar System are also extreme environments. Astrobiologists have not yet found life in any environments beyond Earth, though experiments have shown that tardigrades can survive the harsh vacuum and intense radiation of outer space. The conceptual modification of conditions in locations beyond Earth, to make them more habitable by humans and other terrestrial organisms, is known as terraforming.

Among extreme environments are places that are alkaline, acidic, or unusually hot or cold or salty, or without water or oxygen. There are also places altered by humans, such as mine tailings or oil impacted habitats.

Many different habitats can be considered extreme environments, such as the polar ice caps, the driest spots in desserts, and abysmal depths in the ocean. Many different places on the Earth demand that species become highly specialized if they are to survive. In particular, microscopic organisms that can't be seen with the naked eye often thrive in surprising places. 

Due to the dangerously low temperatures, the amount of species that can survive in the these remote areas is very slim. Over years of evolution and adaptation to this extremely cold environment, both microscopic and larger species have survived and thrived no matter what conditions they are faced. By changing their eating patterns and due to their dense pelt or their body fat, only a few species have been capable of adapting to such harsh conditions and have learned how the thrive in these cold environments.  

A desert is known for its extreme temperatures and extremely dry climate. The type of species that reside in this area have adapted to these harsh conditions over years and years. Species that are able to store water and have learned how to protect themselves from the suns harsh rays are the only ones who are capable of surviving in these extreme environments.  

The oceans depths and temperatures contains some of the most extreme conditions for any species to survive. The deeper one travels, the higher the pressure and the lower the visibility gets, causing completely blacked out conditions. Many of these conditions are too intense for humans to travel to, so instead of sending humans down to these depths to collect research, scientists are using smaller submarines or deep sea drones to study these creatures and extreme environments. 

There are many different species that are either commonly known or not known amongst many people. These species have either adapted over time into these extreme environments or they have resided their entire life no matter how many generations. The different species that are able to live in these environments because of their flexibility with adaptation. Many can adapt to different climate conditions and hibernate if need be to survive.

The following list contains only a few species that live in extreme environments . 

Different Types of Species 







</doc>
<doc id="44426150" url="https://en.wikipedia.org/wiki?curid=44426150" title="Spatial association">
Spatial association

Spatial association is the degree to which things are similarly arranged in space. Analysis of the distribution patterns of two phenomena is done by map overlay. If the distributions are similar, then the spatial association is strong, and vice versa. In a Geographic Information System, the analysis can be done quantitatively. For example, a set of observations (as points or extracted from raster cells) at matching locations can be intersected and examined by regression analysis.

Like spatial autocorrelation, this can be a useful tool for spatial prediction. In spatial modeling, the concept of spatial association allows the use of covariates in a regression equation to predict the geographic field and thus produce a map.


</doc>
<doc id="14389994" url="https://en.wikipedia.org/wiki?curid=14389994" title="Natural landscape">
Natural landscape

A natural landscape is the original landscape that exists before it is acted upon by human culture. The natural landscape and the cultural landscape are separate parts of the landscape. However, in the twenty-first century landscapes that are totally untouched by human activity no longer exist, so that reference is sometimes now made to degrees of naturalness within a landscape.

In "Silent Spring" (1962) Rachel Carson describes a roadside verge as it used to look: "Along the roads, laurel, viburnum and alder, great ferns and wildflowers delighted the traveler’s eye through much of the year" and then how it looks now following the use of herbicides: "The roadsides, once so attractive, were now lined with browned and withered vegetation as though swept by fire". Even though the landscape before it is sprayed is biologically degraded, and may well contains alien species, the concept of what might constitute a natural landscape can still be deduced from the context.

The phrase "natural landscape" was first used in connection with landscape painting, and landscape gardening, to contrast a formal style with a more natural one, closer to nature. Alexander von Humboldt (1769 – 1859) was to further conceptualize this into the idea of a natural landscape "separate" from the cultural landscape. Then in 1908 geographer Otto Schlüter developed the terms original landscape ("Urlandschaft") and its opposite cultural landscape ("Kulturlandschaft") in an attempt to give the science of geography a subject matter that was different from the other sciences. An early use of the actual phrase "natural landscape" by a geographer can be found in Carl O. Sauer's paper "The Morphology of Landscape" (1925).

The concept of a natural landscape was first developed in connection with landscape painting, though the actual term itself was first used in relation to landscape gardening. In both cases it was used to contrast a formal style with a more natural one, that is closer to nature. Chunglin Kwa suggests, "that a seventeenth-century or early-eighteenth-century person could experience natural scenery ‘just like on a painting,’ and so, with or without the use of the word itself, designate it as a landscape." With regard to landscape gardening John Aikin, commented in 1794: "Whatever, therefore, there be of "novelty" in the singular scenery of an artificial garden, it is soon exhausted, whereas the infinite diversity of a natural landscape presents an inexhaustible flore of new forms". Writing in 1844 the prominent American landscape gardener Andrew Jackson Downing comments: "straight canals, round or oblong pieces of water, and all the regular forms of the geometric mode ... would evidently be in violent opposition to the whole character and expression of natural landscape".

In his extensive travels in South America, Alexander von Humboldt became the first to conceptualize a natural landscape separate from the cultural landscape, though he does not actually use these terms. Andrew Jackson Downing was aware of, and sympathetic to, Humboldt's ideas, which therefore influenced American landscape gardening.

Subsequently, the geographer Otto Schlüter, in 1908, argued that by defining geography as a "Landschaftskunde" (landscape science) would give geography a logical subject matter shared by no other discipline. He defined two forms of landscape: the "Urlandschaft" (original landscape) or landscape that existed before major human induced changes and the "Kulturlandschaft" (cultural landscape) a landscape created by human culture. Schlüter argued that the major task of geography was to trace the changes in these two landscapes.

The term natural landscape is sometimes used as a synonym for wilderness, but for geographers natural landscape is a scientific term which refers to the biological, geological, climatological and other aspects of a landscape, not the cultural values that are implied by the word wilderness.

Matters are complicated by the fact that the words nature and natural have more than one meaning. On the one hand there is the main dictionary meaning for nature: "The phenomena of the physical world collectively, including plants, animals, the landscape, and other features and products of the earth, as opposed to humans or human creations". On the other hand, there is the growing awareness, especially since Charles Darwin, of humanities biological affinity with nature.

The dualism of the first definition has its roots is an "ancient concept", because early people viewed "nature, or the nonhuman world […] as a divine "Other", godlike in its separation from humans". In the West, Christianity's myth of the fall, that is the expulsion of humankind from the Garden of Eden, where all creation lived in harmony, into an imperfect world, has been the major influence. Cartesian dualism, from the seventeenth century on, further reinforced this dualistic thinking about nature. 
With this dualism goes value judgement as to the superiority of the natural over the artificial. Modern science, however, is moving towards a holistic view of nature.

What is meant by natural, within the American conservation movement, has been changing over the last century and a half.

In the mid-nineteenth century American began to realize that the land was becoming more and more domesticated and wildlife was disappearing. This led to the creation of American National Parks and other conservation sites. Initially it was believed that all that was needed to do was to separate what was seen as natural landscape and "avoid disturbances such as logging, grazing, fire and insect outbreaks". This, and subsequent environmental policy, until recently, was influenced by ideas of the wilderness. However, this policy was not consistently applied, and in Yellowstone Park, to take one example, the existing ecology was altered, firstly by the exclusion of Native Americans and later with the virtual extermination of the wolf population.

A century later, in the mid-twentieth century, it began to be believed that the earlier policy of "protection from disturbance was inadequate to preserve park values", and that is that direct human intervention was necessary to restore the landscape of National Parks to its ‘’natural’’ condition. In 1963 the Leopold Report argued that "A national park should represent a vignette of primitive America". This policy change eventually led to the restoration of wolves in Yellowstone Park in the 1990s.

However, recent research in various disciplines indicates that a pristine natural or "primitive" landscape is a myth, and it now realised that people have been changing the natural into a cultural landscape for a long while, and that there are few places untouched in some way from human influence. The earlier conservation policies were now seen as cultural interventions. The idea of what is natural and what artificial or cultural, and how to maintain the natural elements in a landscape, has been further complicated by the discovery of global warming and how it is changing natural landscapes.

Also important is a reaction recently amongst scholars against dualistic thinking about nature and culture. Maria Kaika comments: "Nowadays, we are beginning to see nature and culture as intertwined once again – not ontologically separated anymore […].What I used to perceive as a compartmentalized world, consisting of neatly and tightly sealed, autonomous ‘space envelopes’ (the home, the city, and nature) was, in fact, a messy socio-spatial continuum”. And William Cronon argues against the idea of wilderness because it "involves a dualistic vision in which the human is entirely outside the natural" and affirms that "wildness (as opposed to wilderness) can be found anywhere" even "in the cracks of a Manhattan sidewalk". According to Cronon we have to "abandon the dualism that sees the tree in the garden as artificial […] and the tree in the wilderness as natural […] Both in some ultimate sense are wild." Here he bends somewhat the regular dictionary meaning of wild, to emphasise that nothing natural, even in a garden, is fully under human control.

The landscape of Europe has considerably altered by people and even in an area, like the Cairngorm Mountains of Scotland, with a low population density, only " the high summits of the Cairngorm Mountains, consist entirely of natural elements. These "high summits" are of course only part of the Cairngorms, and there are no longer wolves, bears, wild boar or lynx in Scotland's wilderness. The Scots pine in the form of the Caledonian forest also covered much more of the Scottish landscape than today.

The Swiss National Park, however, represent a more natural landscape. It was founded in 1914, and is one of the earliest national parks in Europe.
Visitors are not allowed to leave the motor road, or paths through the park, make fire or camp. The only building within the park is Chamanna Cluozza, mountain hut. It is also forbidden to disturb the animals or the plants, or to take home anything found in the park. Dogs are not allowed. Due to these strict rules, the Swiss National Park is the only park in the Alps who has been categorized by the IUCN as a strict nature reserve, which is the highest protection level.

No place on the Earth is unaffected by people and their culture. People are part of biodiversity, but human activity affects biodiversity, and this alters the natural landscape. Mankind have altered landscape to such an extent that few places on earth remain pristine, but once free of human influences, the landscape can return to a natural or near natural state.
Even the remote Yukon and Alaskan wilderness, the bi-national Kluane-Wrangell-St. Elias-Glacier Bay-Tatshenshini-Alsek park system comprising Kluane, Wrangell-St Elias, Glacier Bay and Tatshenshini-Alsek parks, a UNESCO World Heritage Site, is not free from human influence, because the Kluane National Park lies within the traditional territories of the Champagne and Aishihik First Nations and Kluane First Nation who have a long history of living in this region. Through their respective Final Agreements with the Canadian Government, they have made into law their rights to harvest in this region.

Cultural forces intentionally or unintentionally, have an influence upon the landscape. Cultural landscapes are places or artifacts created and maintained by people. Examples of cultural intrusions into a landscape are: fences, roads, parking lots, sand pits, buildings, hiking trails, management of plants, including the introduction of invasive species, extraction or removal of plants, management of animals, mining, hunting, natural landscaping, farming and forestry, pollution. Areas that might be confused with a natural landscape include public parks, farms, orchards, artificial lakes and reservoirs, managed forests, golf courses, nature center trails, gardens.



</doc>
<doc id="47470974" url="https://en.wikipedia.org/wiki?curid=47470974" title="Glacial refugium">
Glacial refugium

A glacial refugium ("plural refugia") is a geographic region which made possible the survival of flora and fauna in times of ice ages and allowed for post-glacial re-colonization. Different types of glacial refugia can be distinguished, namely nunatak, peripheral and lowland refugia. Glacial refugia have been suggested as a major cause of the distributions of flora and fauna in both temperate and tropical latitudes. However, in spite of the continuing use of historical refugia to explain modern-day species distributions, especially in birds, doubt has been cast on the validity of such inferences, as much of the differentiation between populations observed today may have occurred before or after their restriction to refugia.

Traditionally, the identification of glacial refugia have occurred through the assessment of palaeoecological evidence, to determine the origins of modern taxa.  For example, paleoecological approaches, which focus on the study of fossil organisms and their remains, have been used to reconstruct the distributions of pollen in Europe, for the 13,000 years since the last glaciation.  Researchers in this case ultimately established the spread of forest trees from the mountainous southern fringe of Europe, which suggests that this area served as a glacial refugia during this time.

In studies exploring the extent of glacial refugia in mountain species, three distinct types of glacial refugia have been identified.

A nunatak is a type of glacial refugia that is located on the snow-free, exposed peaks of mountains, which lie above the ice sheet during glaciations.  The identification of ‘diversity hotspots’ in areas, which should have been migration regions during major glacial episodes, is evidence for nunatak glacial refugia.  For example, the Monte Rosa mountain ranges, the Avers, and the Engadine and the Bernina are all floristically rich proposed nunatak regions, which are indicative nunatak glacial survival.

Peripheral glacial refugia still exists within the mountain system but contrary to nunataks, which exist on the peaks, this type of refugia is located along the borders of mountain systems.  Evidence for this type of mountain refugia can be found along the borders of the Carpathian Mountains, Pyrenees or European Alps, all of which were formally glaciated mountain systems.  Specifically, using the amplified fragment length polymorphism (AFLP) technique, researchers have been able to infer the survival of "Phyteuma globulariifolium" in peripheral refugia, in the European Alps.

Lowland glacial refugia, unlike nunatak and peripheral glacial refugia, is a type of refugia that exists outside of the mountain system in the lowlands.  Situated beyond the limits of ice shields, lowland refugia has been identified for a number of plant and animal species.  For example, through allozyme analysis, researchers have been able to confirm the continuous distribution of "Zygaena exulans" in the between the foothills of the Pyrenees and the Alps during the last ice age.



</doc>
<doc id="898161" url="https://en.wikipedia.org/wiki?curid=898161" title="Geopark">
Geopark

A geopark is a unified area that advances the protection and use of geological heritage in a sustainable way, and promotes the economic well-being of the people who live there. There are global geoparks and national geoparks.

A UNESCO definition of "global geopark" is a unified area with a geological heritage of international significance. Geoparks use that heritage to promote awareness of key issues facing society in the context of our dynamic planet. Many geoparks promote awareness of geological hazards, including volcanoes, earthquakes and tsunamis and many help prepare disaster mitigation strategies with local communities. Geoparks embody records of past climate changes and are indicators of current climate changes as well as demonstrating a "best practise" approach to using renewable energy and employing the best standards of "green tourism". Tourism industry promotion in geoparks, as a geographically sustainable and applicable tourism model, aims to sustain, and even enhance, the geographical character of a place.

Geoparks also inform about the sustainable use and need for natural resources, whether they are mined, quarried or harnessed from the surrounding environment while at the same time promoting respect for the environment and the integrity of the landscape. Geoparks are not a legislative designation though the key heritage sites within a geopark are often protected under local, regional or national legislation. The multidisciplinary nature of the concept of geopark and tourism promotion in geoparks differentiates itself from other models of sustainable tourism. In fact, sustainable tourism promotion within geoparks encompasses many of the features of sustainable tourism including geo-tourism (geo-site tourism: as a basic factor), community-based tourism and integrated rural tourism (as a vital need), ecotourism, and cultural heritage tourism.

The Global Geoparks Network (GGN) is supported by United Nations Educational, Scientific and Cultural Organization (UNESCO). Many national geoparks and other local geoparks projects also exist which are not included in the Global Geoparks Network.

The geoparks initiative was launched by UNESCO in response to the perceived need for an international initiative that recognizes sites representing an earth science interest. Global Geoparks Network aims at enhancing the value of such sites while at the same time creating employment and promoting regional economic development. The Global Geoparks Network works in synergy with UNESCO's World Heritage Centre and Man and the Biosphere (MAB) World Network of Biosphere Reserves.

The Global Geoparks Network (GGN) is a UNESCO activity established in 1998. According to UNESCO, for a geopark to apply to be included in the GGN, it needs to:


See Members of the Global Geoparks Network.




</doc>
<doc id="47802272" url="https://en.wikipedia.org/wiki?curid=47802272" title="Edgelands">
Edgelands

Edgelands are the transitional, liminal areas of space to be found on the boundaries of country and town—with the spread of urbanisation, an increasingly important facet of the twenty-first century world.

The concept of Edgelands was introduced by Marion Shoard in 2002, to cover the disorganised but often fertile hinterland between planned town and over-managed country. However a century and a half earlier, Victor Hugo had already highlighted the existence of what he called "bastard countryside...ugly but bizarre, made up of two different natures, which surrounds certain great cities"; while Richard Jeffries similarly explored the London edgeland in "Nature near London" (1883).
Alice Coleman (Kings College London, dept geography) in 2nd Land Use Survey of Great Britain, refers to "rurban fringe". Indicating a similar landscape but with negative overtones.

Nevertheless it was only in the last decades of the twentieth century - as a distinct realm of Nature increasingly disappeared beneath the commodifying impact of globalising late capitalism - that the significance of the unstructured borderlands between organised town and organised country, part man-made, part natural, both for wildlife and for human exploration, came into fuller focus. Psychogeography charted the London orbital, while bombsites, canal banks and brownfield sites were documented in poetry and prose, film and photography; and the borderlands as an untapped, transgressive resource became almost the object of a new cult.




</doc>
<doc id="47827949" url="https://en.wikipedia.org/wiki?curid=47827949" title="Internet geography">
Internet geography

Internet geography, also called cybergeography, is a subdiscipline of geography that studies the spatial organization of the Internet, from social, economic, cultural, and technological perspectives. The core assumption of Internet geography is that the location of servers, websites, data, services, and infrastructure is key to understand the development and the dynamics of the Internet. Among the topics covered by this discipline, of particular importance are information geography and digital divides.



</doc>
<doc id="50516307" url="https://en.wikipedia.org/wiki?curid=50516307" title="Primary care service area">
Primary care service area

Primary Care Service Areas are geographic areas that are self-sufficient markets of primary care. These areas are designed in a manner such that the majority of patients living in these areas use primary care services form within the area. This ensures that any geographic targeting of policies and resources reach the patients they are meant for. These geographies have been created in Australia, United States and Switzerland using big data and Geographic information systems. In Australia, while they have been developed for the state of New South Wales, they have not found application among policymakers, where, as of 2016 much larger geographies called Primary Health Networks are used for primary care management. However, they have found an especially wide audience amongst policymakers and researchers in the United States, where they were first developed. Thus for example the Health Resources and Services Administration uses them to designate areas of workforce shortage. Primary Care Service Areas are thus for example an appropriate geography for measuring primary care physician supply or geographic access to General practitioners.



</doc>
<doc id="50427403" url="https://en.wikipedia.org/wiki?curid=50427403" title="International date line in Judaism">
International date line in Judaism

The international date line in Judaism is used to demarcate the change of one calendar day to the next in the Jewish calendar. The Jewish calendar defines days as running from sundown to sundown rather than midnight to midnight. So in the context of Judaism, an international date line demarcates when the line of sundown moving across the Earth's surface stops being the sundown ending and starting one day and starts being the sundown ending and starting the following day.

However, the conventional International Date Line is a relatively recent geographic and political construct whose exact location has moved from time to time depending on the needs of different interested parties. While it is well-understood why the conventional date line is located in the Pacific Ocean, there are not really objective criteria for its exact placement within the Pacific. In that light, it cannot be taken for granted that the conventional International Date Line can (or should) be used as a date line under Jewish law. In practice, within Judaism the "halakhic" date line is similar to, but not necessarily identical with, the conventional Date Line, and the differences can have consequences under religious law.

Many of the opinions about the "halakhic" date line are structured as a response to the question of what days someone should observe as Shabbat and Jewish holidays. Shabbat occurs every seven days at any location on earth. It is normally thought to occur on Saturday—or more precisely, from Friday at sundown to Saturday at nightfall. But if the "halakhic" date line is not identical to the conventional Date Line, it is possible that what is Saturday with respect to the conventional Date Line is not Saturday with respect to the "halakhic" date line, at least in some places.

There are several opinions regarding where exactly the "halakhic" date line should be according to Jewish law, and at least one opinion that says that no "halakhic" date line really exists.

1. "90 degrees east of Jerusalem." The concept of a "halakhic" date line is mentioned in the "Baal HaMeor," a 12th-century Talmudic commentary, which seems to indicate that the day changes in an area where the time is six hours ahead of Jerusalem (90 degrees east of Jerusalem, about 125.2°E, a line now known to run through Australia, the Philippines, China and Russia). This line, which he refers to as the "K'tzai Hamizrach" (the easternmost line), is used to calculate the day of Rosh Hashanah, the Jewish New Year. According to some sources it is alluded to in both the Babylonian Talmud (Rosh Hashanah and Eruvin) and in the Jerusalem Talmud. The "Kuzari" of Yehuda Halevi, also a 12th-century work, seems to agree with this ruling.

Later decisors like the "Chazon Ish" (twentieth century) fundamentally agree with this ruling. However, they recognize practical issues associated with the pure use of a line of longitude for this purpose. As an example, 125.2°E passes directly through Dongfeng Street in Changchun, China. If this line of longitude were used strictly, people could simply avoid Shabbat altogether by crossing the street. To prevent that, the Chazon Ish rules that the contiguous land masses to the east of that line of longitude are considered secondary ("tafel") to the land masses west of that line. As a result, he rules that the date line runs along 125.2°E when over water, but curves around the eastern coast of mainland Asia and Australia. By this view, Russia, China and Australia are west of the date line and observe Shabbat on local Saturday. Japan, New Zealand and Tasmania are east of the date line and should observe Shabbat on local Sunday, as defined by the conventional International Date Line. By this view, the Philippines and Indonesia would have portions west of the line and portions east of the line.

2. "180 degrees east of Jerusalem." Rabbi Yechiel Michel Tucazinsky ruled that the International Date Line is 180 degrees east of Jerusalem. That would mean that the date line, rather than being near 180°, would be at 144.8°W. By this view, places east of the conventional International Date Line but west of 144.8°W—Alaska, Hawaii and a variety of archipelagos in the Pacific—would observe Shabbat on the local Friday instead of the local Saturday.

It is possible (but not certain) under this view to apply the principal of "tafel" described above as well. In that event, mainland Alaska would be east of the date line, but the Aleutian Islands would be west of the date line.

3. "Mid-Pacific." A variety of decisors rule that the date line runs in the middle of the Pacific Ocean, close to (but not necessarily the same as) the conventional International Date Line. According to this point of view, all of the major populated areas of the Pacific (such as New Zealand, Japan, Alaska and Hawaii) observe Shabbat on local Saturday (that is, consistent with the conventional International Date Line). Only certain Pacific islands, generally having few or no permanent Jewish residents, might not observe Shabbat on local Saturday.

4. "Following local custom/There is no fixed date line." According to Rabbi Menachem Mendel Kasher, there is no clear tradition or Talmudic source dictating any of the preceding opinions as binding. For that reason, and consistent with a responsum of the Radbaz, Rabbi Kasher starts with the default law that a Jew not knowing the proper day for Shabbat should count days from the last time s/he observed Shabbat, and that every seven days is Shabbat. In his view, established Jewish communities are presumed to have fixed their calendars according to this principle. Therefore, Shabbat in an established community is whatever day the community has established. Rabbi Isser Zalman Meltzer and Rabbi Zvi Pesach Frank apparently agree with this position. This position does not in and of itself require a formal date line to be established, and Rabbi Kasher does not seem to think that it is necessary to do so. But the "de facto" result of this position is consistent with the conventional International Date Line, at least anywhere there is an established Jewish community.

In practice, the conventional International Date Line (or another mid-Pacific line near it) is the "de facto" date line under Jewish law, at least for established Jewish communities. The communities of Japan, New Zealand, Hawaii, and French Polynesia all observe Shabbat on local Saturday "(i.e.," Friday night until Saturday night). No known Jewish community observes Shabbat on a day other than local Saturday. However, that practical conclusion is reached in two different ways, resulting in somewhat different practice patterns in each case.

Following local custom/There is no fixed date line. As noted above, according to this point of view, Shabbat is simply observed on the date previously established as Shabbat by the local community—uniformly, local Saturday—without any need for any further observance. This appears to be the default practice for residents of such places as Japan, New Zealand and Hawaii. At minimum, it is difficult to find evidence of other practices by residents of those areas.

Establishment of a date line by a majority among three halakhic positions. The travelers' guide of the Star-K kosher supervision service, compiled according to the rulings of its rabbinic administrator, Rabbi Moshe Heinemann, uses the following approach, which is also cited by others. According to this approach, the first three numbered sections above constitute three valid, parallel, "halakhic" rulings. Shabbat is consequently fully observed on whichever day is consistent with the majority view among those opinions (two out of three). However, out of respect to the minority view of the third ruling, and with an eye toward not desecrating Shabbat, Torah-level prohibitions are to be avoided on the day consistent with the minority view, although that day is otherwise considered a weekday. According to this rule, practice is as follows: 
The Star-K's international kosher supervision staff follows this approach, and there is evidence that some other travelers also do. Authorities suggesting this approach often advise travelers to avoid the zone of doubt entirely near weekends, or to consult with a competent rabbinical authority directly.

The issues discussed in the previous section apply "per se" to individuals or communities in fixed locations. However, the act of crossing the date line (wherever it may be drawn) introduces a number of additional issues under Jewish law. Questions potentially affected include:


In some cases, crossing the date line (wherever it may be drawn) has a specific impact on practice or prohibitions under Jewish law. In others, an individual's count of days (by the experience of sunset and sunrise) is the determining factor, regardless of the crossing of the date line. Details around specific questions, cases and rulings of Jewish law are beyond the scope of this article.

Before Israeli astronaut Ilan Ramon flew on the Space Shuttle "Columbia" in 2003, he decided (after consultation with rabbis) to observe Shabbat according to time in his last residence, Cape Canaveral, since he would be crossing the date line and observing sunset many times per day. Judith Resnik, the first American Jewish astronaut in space, lit (electronic) Shabbat candles according to the time in Houston, TX, her home and the location of Mission Control.



</doc>
<doc id="2269821" url="https://en.wikipedia.org/wiki?curid=2269821" title="Tobler's first law of geography">
Tobler's first law of geography

The First Law of Geography, according to Waldo Tobler, is "everything is related to everything else, but near things are more related than distant things." This first law is the foundation of the fundamental concepts of spatial dependence and spatial autocorrelation and is utilized specifically for the inverse distance weighting method for spatial interpolation and to support the regionalized variable theory for kriging.

Tobler first presented his seminal idea during a meeting of the International Geographical Union's Commission on Qualitative Methods held in 1969 and later published by him in 1970. Though simple in its presentation, this idea is profound. Without it, "the full range of conditions anywhere on the Earth's surface could in principle be found packed within any small area. There would be no regions of approximately homogeneous conditions to be described by giving attributes to area objects. Topographic surfaces would vary chaotically, with slopes that were everywhere infinite, and the contours of such surfaces would be infinitely dense and contorted. Spatial analysis, and indeed life itself, would be impossible."

Less well known is his second law, which complements the first: "The phenomenon external to an area of interest affects what goes on inside".

The theory is based upon the concept of the friction of distance "where distance itself hinders interaction between places. The farther two places are apart, the greater the hindrance", or cost. For example, one is less likely to travel across town to purchase a sandwich than walk to the corner store for the same sandwich. In this example hindrance, or cost, can readily be counted in time and transportation costs which are added to the price of the purchase and thus result in high levels of friction. The friction of distance and the increase in cost combine causing the distance decay effect.


</doc>
<doc id="2371378" url="https://en.wikipedia.org/wiki?curid=2371378" title="Surroundings">
Surroundings

Surroundings are the area around a given physical or geographical point or place. The exact definition depends on the field. Surroundings can also be used in geography (when it is more precisely known as vicinity, or vicinage) and mathematics, as well as philosophy, with the literal or metaphorically extended definition.

In thermodynamics, the term (and its synonym, environment) is used in a more restricted sense, meaning everything outside the thermodynamic system. Often, the simplifying assumptions are that energy and matter may move freely within the surroundings, and that the surroundings have a uniform composition.



</doc>
<doc id="18963910" url="https://en.wikipedia.org/wiki?curid=18963910" title="Geography">
Geography

Geography (from Greek: , "geographia", literally "earth description") is a field of science devoted to the study of the lands, features, inhabitants, and phenomena of the Earth and planets. The first person to use the word γεωγραφία was Eratosthenes (276–194 BC). Geography is an all-encompassing discipline that seeks an understanding of Earth and its human and natural complexities—not merely where objects are, but also how they have changed and come to be.

Geography is often defined in terms of two branches: human geography and physical geography. Human geography deals with the study of people and their communities, cultures, economies, and interactions with the environment by studying their relations with and across space and place. Physical geography deals with the study of processes and patterns in the natural environment like the atmosphere, hydrosphere, biosphere, and geosphere.

The four historical traditions in geographical research are: spatial analyses of natural and the human phenomena, area studies of places and regions, studies of human-land relationships, and the Earth sciences. Geography has been called "the world discipline" and "the bridge between the human and the physical sciences".

Geography is a systematic study of the Universe and its features. Traditionally, geography has been associated with cartography and place names. Although many geographers are trained in toponymy and cartology, this is not their main preoccupation. Geographers study the space and the temporal database distribution of phenomena, processes, and features as well as the interaction of humans and their environment. Because space and place affect a variety of topics, such as economics, health, climate, plants and animals, geography is highly interdisciplinary. The interdisciplinary nature of the geographical approach depends on an attentiveness to the relationship between physical and human phenomena and its spatial patterns.

Geography as a discipline can be split broadly into two main subsidiary fields: human geography and physical geography. The former largely focuses on the built environment and how humans create, view, manage, and influence space. The latter examines the natural environment, and how organisms, climate, soil, water, and landforms produce and interact. The difference between these approaches led to a third field, environmental geography, which combines physical and human geography and concerns the interactions between the environment and humans.

Physical geography (or physiography) focuses on geography as an Earth science. It aims to understand the physical problems and the issues of lithosphere, hydrosphere, atmosphere, pedosphere, and global flora and fauna patterns (biosphere).

Human geography is a branch of geography that focuses on the study of patterns and processes that shape the human society. It encompasses the human, political, cultural, social, and economic aspects.

Various approaches to the study of human geography have also arisen through time and include:

Integrated geography is concerned with the description of the spatial interactions between humans and the natural world. It requires an understanding of the traditional aspects of physical and human geography, as well as the ways that human societies conceptualize the environment. Integrated geography has emerged as a bridge between human and physical geography, as a result of the increasing specialisation of the two sub-fields. Furthermore, as the human relationship with the environment has changed as a result of globalization and technological change, a new approach was needed to understand the changing and dynamic relationship. Examples of areas of research in environmental geography include: emergency management, environmental management, sustainability, and political ecology.

Geomatics is concerned with the application of computers to the traditional spatial techniques used in cartography and topography. Geomatics emerged from the quantitative revolution in geography in the mid-1950s. Today, geomatics methods include spatial analysis, geographic information systems (GIS), remote sensing, and global positioning systems (GPS). Geomatics has led to a revitalization of some geography departments, especially in Northern America where the subject had a declining status during the 1950s.

Regional geography is concerned with the description of the unique characteristics of a particular region such as its natural or human elements. The main aim is to understand, or define the uniqueness, or character of a particular region that consists of natural as well as human elements. Attention is paid also to regionalization, which covers the proper techniques of space delimitation into regions.


As spatial interrelationships are key to this synoptic science, maps are a key tool. Classical cartography has been joined by a more modern approach to geographical analysis, computer-based geographic information systems (GIS).

In their study, geographers use four interrelated approaches:

Cartography studies the representation of the Earth's surface with abstract symbols (map making). Although other subdisciplines of geography rely on maps for presenting their analyses, the actual making of maps is abstract enough to be regarded separately. Cartography has grown from a collection of drafting techniques into an actual science.

Cartographers must learn cognitive psychology and ergonomics to understand which symbols convey information about the Earth most effectively, and behavioural psychology to induce the readers of their maps to act on the information. They must learn geodesy and fairly advanced mathematics to understand how the shape of the Earth affects the distortion of map symbols projected onto a flat surface for viewing. It can be said, without much controversy, that cartography is the seed from which the larger field of geography grew. Most geographers will cite a childhood fascination with maps as an early sign they would end up in the field.

Geographic information systems (GIS) deal with the storage of information about the Earth for automatic retrieval by a computer, in an accurate manner appropriate to the information's purpose. In addition to all of the other subdisciplines of geography, GIS specialists must understand computer science and database systems. GIS has revolutionized the field of cartography: nearly all mapmaking is now done with the assistance of some form of GIS software. GIS also refers to the science of using GIS software and GIS techniques to represent, analyse, and predict the spatial relationships. In this context, GIS stands for "geographic information science".

Remote sensing is the science of obtaining information about Earth features from measurements made at a distance. Remotely sensed data comes in many forms, such as satellite imagery, aerial photography, and data obtained from hand-held sensors. Geographers increasingly use remotely sensed data to obtain information about the Earth's land surface, ocean, and atmosphere, because it: (a) supplies objective information at a variety of spatial scales (local to global), (b) provides a synoptic view of the area of interest, (c) allows access to distant and inaccessible sites, (d) provides spectral information outside the visible portion of the electromagnetic spectrum, and (e) facilitates studies of how features/areas change over time. Remotely sensed data may be analysed either independently of, or in conjunction with other digital data layers (e.g., in a geographic information system).

Geostatistics deal with quantitative data analysis, specifically the application of statistical methodology to the exploration of geographic phenomena. Geostatistics is used extensively in a variety of fields, including hydrology, geology, petroleum exploration, weather analysis, urban planning, logistics, and epidemiology. The mathematical basis for geostatistics derives from cluster analysis, linear discriminant analysis and non-parametric statistical tests, and a variety of other subjects. Applications of geostatistics rely heavily on geographic information systems, particularly for the interpolation (estimate) of unmeasured points. Geographers are making notable contributions to the method of quantitative techniques.

Geographic qualitative methods, or ethnographical research techniques, are used by human geographers. In cultural geography there is a tradition of employing qualitative research techniques, also used in anthropology and sociology. Participant observation and in-depth interviews provide human geographers with qualitative data.

The oldest known world maps date back to ancient Babylon from the 9th century BC. The best known Babylonian world map, however, is the "Imago Mundi" of 600 BC. The map as reconstructed by Eckhard Unger shows Babylon on the Euphrates, surrounded by a circular landmass showing Assyria, Urartu and several cities, in turn surrounded by a "bitter river" (Oceanus), with seven islands arranged around it so as to form a seven-pointed star. The accompanying text mentions seven outer regions beyond the encircling ocean. The descriptions of five of them have survived. In contrast to the "Imago Mundi", an earlier Babylonian world map dating back to the 9th century BC depicted Babylon as being further north from the center of the world, though it is not certain what that center was supposed to represent.

The ideas of Anaximander (c. 610–545 BC): considered by later Greek writers to be the true founder of geography, come to us through fragments quoted by his successors. Anaximander is credited with the invention of the gnomon, the simple, yet efficient Greek instrument that allowed the early measurement of latitude. Thales is also credited with the prediction of eclipses. The foundations of geography can be traced to the ancient cultures, such as the ancient, medieval, and early modern Chinese. The Greeks, who were the first to explore geography as both art and science, achieved this through Cartography, Philosophy, and Literature, or through Mathematics. There is some debate about who was the first person to assert that the Earth is spherical in shape, with the credit going either to Parmenides or Pythagoras. Anaxagoras was able to demonstrate that the profile of the Earth was circular by explaining eclipses. However, he still believed that the Earth was a flat disk, as did many of his contemporaries. One of the first estimates of the radius of the Earth was made by Eratosthenes.

The first rigorous system of latitude and longitude lines is credited to Hipparchus. He employed a sexagesimal system that was derived from Babylonian mathematics. The meridians were sub-divided into 360°, with each degree further subdivided into 60 (minutes). To measure the longitude at different locations on Earth, he suggested using eclipses to determine the relative difference in time. The extensive mapping by the Romans as they explored new lands would later provide a high level of information for Ptolemy to construct detailed atlases. He extended the work of Hipparchus, using a grid system on his maps and adopting a length of 56.5 miles for a degree.

From the 3rd century onwards, Chinese methods of geographical study and writing of geographical literature became much more comprehensive than what was found in Europe at the time (until the 13th century). Chinese geographers such as Liu An, Pei Xiu, Jia Dan, Shen Kuo, Fan Chengda, Zhou Daguan, and Xu Xiake wrote important treatises, yet by the 17th century advanced ideas and methods of Western-style geography were adopted in China.
During the Middle Ages, the fall of the Roman empire led to a shift in the evolution of geography from Europe to the Islamic world. Muslim geographers such as Muhammad al-Idrisi produced detailed world maps (such as Tabula Rogeriana), while other geographers such as Yaqut al-Hamawi, Abu Rayhan Biruni, Ibn Battuta, and Ibn Khaldun provided detailed accounts of their journeys and the geography of the regions they visited. Turkish geographer, Mahmud al-Kashgari drew a world map on a linguistic basis, and later so did Piri Reis (Piri Reis map). Further, Islamic scholars translated and interpreted the earlier works of the Romans and the Greeks and established the House of Wisdom in Baghdad for this purpose. Abū Zayd al-Balkhī, originally from Balkh, founded the "Balkhī school" of terrestrial mapping in Baghdad. Suhrāb, a late tenth century Muslim geographer accompanied a book of geographical coordinates, with instructions for making a rectangular world map with equirectangular projection or cylindrical equidistant projection.

Abu Rayhan Biruni (976–1048) first described a polar equi-azimuthal equidistant projection of the celestial sphere. He was regarded as the most skilled when it came to mapping cities and measuring the distances between them, which he did for many cities in the Middle East and the Indian subcontinent. He often combined astronomical readings and mathematical equations, in order to develop methods of pin-pointing locations by recording degrees of latitude and longitude. He also developed similar techniques when it came to measuring the heights of mountains, depths of the valleys, and expanse of the horizon. He also discussed human geography and the planetary habitability of the Earth. He also calculated the latitude of Kath, Khwarezm, using the maximum altitude of the Sun, and solved a complex geodesic equation in order to accurately compute the Earth's circumference, which was close to modern values of the Earth's circumference. His estimate of 6,339.9 km for the Earth radius was only 16.8 km less than the modern value of 6,356.7 km. In contrast to his predecessors, who measured the Earth's circumference by sighting the Sun simultaneously from two different locations, al-Biruni developed a new method of using trigonometric calculations, based on the angle between a plain and mountain top, which yielded more accurate measurements of the Earth's circumference, and made it possible for it to be measured by a single person from a single location.
The European Age of Discovery during the 16th and the 17th centuries, where many new lands were discovered and accounts by European explorers such as Christopher Columbus, Marco Polo, and James Cook revived a desire for both accurate geographic detail, and more solid theoretical foundations in Europe. The problem facing both explorers and geographers was finding the latitude and longitude of a geographic location. The problem of latitude was solved long ago but that of longitude remained; agreeing on what zero meridian should be was only part of the problem. It was left to John Harrison to solve it by inventing the chronometer H-4 in 1760, and later in 1884 for the International Meridian Conference to adopt by convention the Greenwich meridian as zero meridian.

The 18th and the 19th centuries were the times when geography became recognized as a discrete academic discipline, and became part of a typical university curriculum in Europe (especially Paris and Berlin). The development of many geographic societies also occurred during the 19th century, with the foundations of the Société de Géographie in 1821, the Royal Geographical Society in 1830, Russian Geographical Society in 1845, American Geographical Society in 1851, and the National Geographic Society in 1888. The influence of Immanuel Kant, Alexander von Humboldt, Carl Ritter, and Paul Vidal de la Blache can be seen as a major turning point in geography from a philosophy to an academic subject.

Over the past two centuries, the advancements in technology with computers have led to the development of geomatics and new practices such as participant observation and geostatistics being incorporated into geography's portfolio of tools. In the West during the 20th century, the discipline of geography went through four major phases: environmental determinism, regional geography, the quantitative revolution, and critical geography. The strong interdisciplinary links between geography and the sciences of geology and botany, as well as economics, sociology and demographics have also grown greatly, especially as a result of earth system science that seeks to understand the world in a holistic view.





</doc>
<doc id="3280844" url="https://en.wikipedia.org/wiki?curid=3280844" title="Fictional geography">
Fictional geography

Fictional geography is the use of maps, text and imagery to create lands and territories to accompany works of fiction. Depending on the completeness and complexity of the work, varying media, levels of collaboration and a number of other factors, the depiction of geographical components to works of fiction can range from simple drawings of a small area as in "The Twenty-One Balloons" by William Pène du Bois to an entire fictional world as in "The Lord of the Rings" by Tolkien or even an entire galaxy as in "Star Trek" and its variants.

One of the most notable examples of fictional geography is that created by J. R. R. Tolkien to produce the Shire and its expansion to include all of Middle-earth.



</doc>
<doc id="31655501" url="https://en.wikipedia.org/wiki?curid=31655501" title="Hemispheres of Earth">
Hemispheres of Earth

In geography and cartography, the hemispheres of Earth refer to any division of the globe into two hemispheres (from Ancient Greek , meaning "half of a sphere").

The most common such divisions are by latitudinal or longitudinal markers:

The East–West division can also be seen in a cultural sense, as a division into two cultural hemispheres.

However, other schemes have sought to divide the planet in a way that maximizes the preponderance of one geographic feature or another in each division:

The Earth may also be split into hemispheres of day and night by the terrestrial terminator.



</doc>
<doc id="55633" url="https://en.wikipedia.org/wiki?curid=55633" title="Region">
Region

In geography, regions are areas that are broadly divided by physical characteristics (physical geography), human impact characteristics (human geography), and the interaction of humanity and the environment (environmental geography). Geographic regions and sub-regions are mostly described by their imprecisely defined, and sometimes transitory boundaries, except in human geography, where jurisdiction areas such as national borders are defined in law.

Apart from the global continental regions, there are also hydrospheric and atmospheric regions that cover the oceans, and discrete climates above the land and water masses of the planet. The land and water global regions are divided into subregions geographically bounded by large geological features that influence large-scale ecologies, such as plains and features.

As a way of describing spatial areas, the concept of regions is important and widely used among the many branches of geography, each of which can describe areas in regional terms. For example, ecoregion is a term used in environmental geography, cultural region in cultural geography, bioregion in biogeography, and so on. The field of geography that studies regions themselves is called regional geography.

In the fields of physical geography, ecology, biogeography, zoogeography, and environmental geography, regions tend to be based on natural features such as ecosystems or biotopes, biomes, drainage basins, natural regions, mountain ranges, soil types. Where human geography is concerned, the regions and subregions are described by the discipline of ethnography.

A region has its own nature that could not be moved. The first nature is its natural environment (landform, climate, etc.). The second nature is its physical elements complex that were built by people in the past. The third nature is its socio-cultural context that could not be replaced by new immigrants.

Global regions distinguishable from space, and are therefore clearly distinguished by the two basic terrestrial environments, land and water. However, they have been generally recognised as such much earlier by terrestrial cartography because of their impact on human geography. They are divided into largest of land regions, known as continents, and the largest of water regions known as oceans. There are also significant regions that do not belong to either classification, such as archipelago regions that are littoral regions, or earthquake regions that are defined in geology.

Continental regions are usually based on broad experiences in human history and attempts to reduce very large areas to more manageable regionalization for the purpose of study. As such they are conceptual constructs, usually lacking distinct boundaries. Oceanic division into maritime regions are used in conjunction with the relationship to the central area of the continent, using directions of the compass.

Some continental regions are defined by the major continental feature of their identity, such as the Amazon basin, or the Sahara, which both occupy a significant percentage of their respective continental land area.

To a large extent, major continental regions are mental constructs created by considering an efficient way to define large areas of the continents. For the most part, the images of the world are derived as much from academic studies, the media, or from personal experience of global exploration. They are a matter of collective human knowledge of its own planet and are attempts to better understand their environments.

Regional geography is a branch of geography that studies regions of all sizes across the Earth. It has a prevailing descriptive character. The main aim is to understand or define the uniqueness or character of a particular region, which consists of natural as well as human elements. Attention is paid also to regionalization, which covers the proper techniques of space delimitation into regions.

Regional geography is also considered as a certain approach to study in geographical sciences (similar to quantitative or critical geographies; for more information, see history of geography).

Human geography is a branch of geography that focuses on the study of patterns and processes that shape human interaction with various discrete environments. It encompasses human, political, cultural, social, and economic aspects among others that are often clearly delineated. While the major focus of human geography is not the physical landscape of the Earth (see physical geography), it is hardly possible to discuss human geography without referring to the physical landscape on which human activities are being played out, and environmental geography is emerging as a link between the two. Regions of human geography can be divided into many broad categories:

The field of historical geography involves the study of human history as it relates to places and regions or the study of how places and regions have changed over time.

D. W. Meinig, a historical geographer of America, describes many historical regions in his book "The Shaping of America: A Geographical Perspective on 500 Years of History". For example, in identifying European "source regions" in early American colonization efforts, he defines and describes the "Northwest European Atlantic Protestant Region", which includes sub-regions such as the "Western Channel Community", which itself is made of sub-regions such as the "English West Country" of Cornwall, Devon, Somerset, and Dorset.

In describing historic regions of America, Meinig writes of "The Great Fishery" off the coast of Newfoundland and New England, an oceanic region that includes the Grand Banks. He rejects regions traditionally used in describing American history, like New France, "West Indies", the Middle Colonies, and the individual colonies themselves (Province of Maryland, for example). Instead he writes of "discrete colonization areas," which may be named after colonies but rarely adhere strictly to political boundaries. Historic regions of this type Meinig writes about include "Greater New England" and its major sub-regions of "Plymouth," "New Haven shores" (including parts of Long Island), "Rhode Island" (or "Narragansett Bay"), "the Piscataqua," "Massachusetts Bay," "Connecticut Valley," and to a lesser degree, regions in the sphere of influence of Greater New England, "Acadia" (Nova Scotia), "Newfoundland and The Fishery/The Banks."

Other examples of historical regions include Iroquoia, Ohio Country, Illinois Country, and Rupert's Land.

A tourism region is a geographical region that has been designated by a governmental organization or tourism bureau as having common cultural or environmental characteristics. These regions are often named after a geographical, former, or current administrative region or may have a name created for tourism purposes. The names often evoke certain positive qualities of the area and suggest a coherent tourism experience to visitors. Countries, states, provinces, and other administrative regions are often carved up into tourism regions to facilitate attracting visitors.

Some of the more famous tourism regions based on historical or current administrative regions include Tuscany in Italy and Yucatán in Mexico. Famous examples of regions created by a government or tourism bureau include the United Kingdom's Lake District and California's Wine Country.
great plains region

Natural resources often occur in distinct regions. Natural resource regions can be a topic of physical geography or environmental geography, but also have a strong element of human geography and economic geography. A coal region, for example, is a physical or geomorphological region, but its development and exploitation can make it into an economic and a cultural region. Some examples of natural resource regions include the Rumaila Field, the oil field that lies along the border or Iraq and Kuwait and played a role in the Gulf War; the Coal Region of Pennsylvania, which is a historical region as well as a cultural, physical, and natural resource region; the South Wales Coalfield, which like Pennsylvania's coal region is a historical, cultural, and natural region; the Kuznetsk Basin, a similarly important coal mining region in Russia; Kryvbas, the economic and iron ore mining region of Ukraine; and the James Bay Project, a large region of Quebec where one of the largest hydroelectric systems in the world has been developed.

Sometimes a region associated with a religion is given a name, like Christendom, a term with medieval and renaissance connotations of Christianity as a sort of social and political polity. The term Muslim world is sometimes used to refer to the region of the world where Islam is dominant. These broad terms are very vague when used to describe regions.

Within some religions there are clearly defined regions. The Roman Catholic Church, the Church of England, the Eastern Orthodox Church, and others, define ecclesiastical regions with names such as diocese, eparchy, ecclesiastical provinces, and parish.

For example, the United States is divided into 32 Roman Catholic ecclesiastical provinces. The Lutheran Church–Missouri Synod is organized into 33 geographic "districts", which are subdivided into "circuits" (the Atlantic District (LCMS), for example). The Church of Jesus Christ of Latter-day Saints uses regions similar to dioceses and parishes, but uses terms like ward and stake.

In the field of political geography, regions tend to be based on political units such as sovereign states; subnational units such as administrative regions, provinces, states (in the United States), counties, townships, territories, etc.; and multinational groupings, including formally defined units such as the European Union, the Association of Southeast Asian Nations, and NATO, as well as informally defined regions such as the Third World, Western Europe, and the Middle East.

The word "region" is taken from the Latin "regio" (derived from "regere", to rule), and a number of countries have borrowed the term as the formal name for a type of subnational entity (e.g., the "región", used in Chile). In English, the word is also used as the conventional translation for equivalent terms in other languages (e.g., the "область" ("oblast"), used in Russia alongside a broader term "регион").

The following countries use the term "region" (or its cognate) as the name of a type of subnational administrative unit:
The Canadian province of Québec also uses the "administrative region" ("région administrative").

Scotland had local government regions from 1975 to 1996.

In Spain the official name of the autonomous community of Murcia is "Región de Murcia". Also, some single-province autonomous communities such as Madrid use the term "región" interchangeably with "comunidad autónoma".

Two län (counties) in Sweden are officially called 'regions': Skåne and Västra Götaland, and there is currently a controversial proposal to divide the rest of Sweden into large regions, replacing the current counties.

The government of the Philippines uses the term "region" (in Filipino, "rehiyon") when it's necessary to group provinces, the primary administrative subdivision of the country. This is also the case in Brazil, which groups its primary administrative divisions ("estados"; "states") into "grandes regiões" (greater regions) for statistical purposes, while Russia uses "экономические районы" (economic regions) in a similar way, as does Romania and Venezuela.

The government of Singapore makes use of the term "region" for its own administrative purposes.

The following countries use an administrative subdivision conventionally referred to as a region in English:

China has five 自治区 ("zìzhìqū") and two 特別行政區 (or 特别行政区; "tèbiéxíngzhèngqū"), which are translated as "autonomous region" and "special administrative region", respectively.

There are many relatively small regions based on local government agencies such as districts, agencies, or regions. In general, they are all regions in the general sense of being bounded spatial units. Examples include electoral districts such as Washington's 6th congressional district and Tennessee's 1st congressional district; school districts such as Granite School District and Los Angeles Unified School District; economic districts such as the Reedy Creek Improvement District; metropolitan areas such as the Seattle metropolitan area, and metropolitan districts such as the Metropolitan Water Reclamation District of Greater Chicago, the Las Vegas-Clark County Library District, the Metropolitan Police Service of Greater London, as well as other local districts like the York Rural Sanitary District, the Delaware River Port Authority, the Nassau County Soil and Water Conservation District, and C-TRAN.

The traditional territorial divisions of some countries are also commonly rendered in English as "regions". These informal divisions do not form the basis of the modern administrative divisions of these countries, but still define and delimit local regional identity and sense of belonging. Examples include:


Functional regions are usually understood to be the areas organised by the horizontal functional relations (flows, interactions) that are maximised within a region and minimised across its borders so that the principles of internal cohesiveness and external separation regarding spatial interactions are met (see, for instance, Farmer and Fotheringham, 2011; Klapka, Halas, 2016; Smart, 1974). A functional region is not an abstract spatial concept, but to a certain extent it can be regarded as a reflection of the spatial behaviour of individuals in a geographic space. 
The functional region is conceived as a general concept while its inner structure, inner spatial flows, and interactions need not necessarily show any regular pattern, only selfcontainment. The concept of self-containment remains the only crucial defining characteristic of a functional region. Nodal regions, functional urban regions, daily urban systems, local labour-market areas (LLMAs), or travel-to-work areas (TTWAs) are considered to be special instances of a general functional region that need to fulfil some specific conditions regarding, for instance, the character of the region-organising interaction or the presence of urban cores, (Halas et al., 2015).

In military usage, a region is shorthand for the name of a military formation larger than an Army Group and smaller than an Army Theater or simply Theater. The full name of the military formation is Army Region. The size of an Army Region can vary widely but is generally somewhere between about 1 million and 3 million soldiers. Two or more Army Regions could make up an Army Theater. An Army Region is typically commanded by a full General (US four stars), a Field Marshal, or General of the Army (US five stars), or Generalissimo (Soviet Union). Due to the large size of this formation, its use is rarely employed. Some of the very few examples of an Army Region are each of the Eastern, Western, and southern (mostly in Italy) fronts in Europe during World War II. The military map unit symbol for this echelon of formation (see Military organization and APP-6A) consists of six Xs.

Media geography is a spatio-temporal understanding, brought through different gadgets of media, nowadays, media became inevitable at different proportions and everyone supposed to consumed at different gravity. The spatial attributes are studied with the help of media outputs in shape of images which are contested in nature and pattern as well where politics is inseparable. Media geography is giving spatial understanding of mediated image.





</doc>
<doc id="3190431" url="https://en.wikipedia.org/wiki?curid=3190431" title="Spatial analysis">
Spatial analysis

Complex issues arise in spatial analysis, many of which are neither clearly defined nor completely resolved, but form the basis for current research. The most fundamental of these is the problem of defining the spatial location of the entities being studied.

Classification of the techniques of spatial analysis is difficult because of the large number of different fields of research involved, the different fundamental approaches which can be chosen, and the many forms the data can take.

Spatial analysis can perhaps be considered to have arisen with early attempts at cartography and surveying but many fields have contributed to its rise in modern form. Biology contributed through botanical studies of global plant distributions and local plant locations, ethological studies of animal movement, landscape ecological studies of vegetation blocks, ecological studies of spatial population dynamics, and the study of biogeography. Epidemiology contributed with early work on disease mapping, notably John Snow's work of mapping an outbreak of cholera, with research on mapping the spread of disease and with location studies for health care delivery. Statistics has contributed greatly through work in spatial statistics. Economics has contributed notably through spatial econometrics. Geographic information system is currently a major contributor due to the importance of geographic software in the modern analytic toolbox. Remote sensing has contributed extensively in morphometric and clustering analysis. Computer science has contributed extensively through the study of algorithms, notably in computational geometry. Mathematics continues to provide the fundamental tools for analysis and to reveal the complexity of the spatial realm, for example, with recent work on fractals and scale invariance. Scientific modelling provides a useful framework for new approaches.

Spatial analysis confronts many fundamental issues in the definition of its objects of study, in the construction of the analytic operations to be used, in the use of computers for analysis, in the limitations and particularities of the analyses which are known, and in the presentation of analytic results. Many of these issues are active subjects of modern research.

Common errors often arise in spatial analysis, some due to the mathematics of space, some due to the particular ways data are presented spatially, some due to the tools which are available. Census data, because it protects individual privacy by aggregating data into local units, raises a number of statistical issues. The fractal nature of coastline makes precise measurements of its length difficult if not impossible. A computer software fitting straight lines to the curve of a coastline, can easily calculate the lengths of the lines which it defines. However these straight lines may have no inherent meaning in the real world, as was shown for the coastline of Britain.

These problems represent a challenge in spatial analysis because of the power of maps as media of presentation. When results are presented as maps, the presentation combines spatial data which are generally accurate with analytic results which may be inaccurate, leading to an impression that analytic results are more accurate than the data would indicate.

The definition of the spatial presence of an entity constrains the possible analysis which can be applied to that entity and influences the final conclusions that can be reached. While this property is fundamentally true of all analysis, it is particularly important in spatial analysis because the tools to define and study entities favor specific characterizations of the entities being studied. Statistical techniques favor the spatial definition of objects as points because there are very few statistical techniques which operate directly on line, area, or volume elements. Computer tools favor the spatial definition of objects as homogeneous and separate elements because of the limited number of database elements and computational structures available, and the ease with which these primitive structures can be created.

Spatial dependency is the co-variation of properties within geographic space: characteristics at proximal locations appear to be correlated, either positively or negatively. Spatial dependency leads to the spatial autocorrelation problem in statistics since, like temporal autocorrelation, this violates standard statistical techniques that assume independence among observations. For example, regression analyses that do not compensate for spatial dependency can have unstable parameter estimates and yield unreliable significance tests. Spatial regression models (see below) capture these relationships and do not suffer from these weaknesses. It is also appropriate to view spatial dependency as a source of information rather than something to be corrected.

Locational effects also manifest as spatial heterogeneity, or the apparent variation in a process with respect to location in geographic space. Unless a space is uniform and boundless, every location will have some degree of uniqueness relative to the other locations. This affects the spatial dependency relations and therefore the spatial process. Spatial heterogeneity means that overall parameters estimated for the entire system may not adequately describe the process at any given location.

Spatial measurement scale is a persistent issue in spatial analysis; more detail is available at the modifiable areal unit problem (MAUP) topic entry. Landscape ecologists developed a series of scale invariant metrics for aspects of ecology that are fractal in nature. In more general terms, no scale independent method of analysis is widely agreed upon for spatial statistics.

Spatial sampling involves determining a limited number of locations in geographic space for faithfully measuring phenomena that are subject to dependency and heterogeneity. Dependency suggests that since one location can predict the value of another location, we do not need observations in both places. But heterogeneity suggests that this relation can change across space, and therefore we cannot trust an observed degree of dependency beyond a region that may be small. Basic spatial sampling schemes include random, clustered and systematic. These basic schemes can be applied at multiple levels in a designated spatial hierarchy (e.g., urban area, city, neighborhood). It is also possible to exploit ancillary data, for example, using property values as a guide in a spatial sampling scheme to measure educational attainment and income. Spatial models such as autocorrelation statistics, regression and interpolation (see below) can also dictate sample design.

The fundamental issues in spatial analysis lead to numerous problems in analysis including bias, distortion and outright errors in the conclusions reached. These issues are often interlinked but various attempts have been made to separate out particular issues from each other.

In a paper by Benoit Mandelbrot on the coastline of Britain it was shown that it is inherently nonsensical to discuss certain spatial concepts despite an inherent presumption of the validity of the concept. Lengths in ecology depend directly on the scale at which they are measured and experienced. So while surveyors commonly measure the length of a river, this length only has meaning in the context of the relevance of the measuring technique to the question under study.
The locational fallacy refers to error due to the particular spatial characterization chosen for the elements of study, in particular choice of placement for the spatial presence of the element.

Spatial characterizations may be simplistic or even wrong. Studies of humans often reduce the spatial existence of humans to a single point, for instance their home address. This can easily lead to poor analysis, for example, when considering disease transmission which can happen at work or at school and therefore far from the home.

The spatial characterization may implicitly limit the subject of study. For example, the spatial analysis of crime data has recently become popular but these studies can only describe the particular kinds of crime which can be described spatially. This leads to many maps of assault but not to any maps of embezzlement with political consequences in the conceptualization of crime and the design of policies to address the issue.

This describes errors due to treating elements as separate 'atoms' outside of their spatial context. The fallacy is about transferring individual conclusions to spatial units.

The ecological fallacy describes errors due to performing analyses on aggregate data when trying to reach conclusions on the individual units. Errors occur in part from spatial aggregation. For example, a pixel represents the average surface temperatures within an area. Ecological fallacy would be to assume that all points within the area have the same temperature. This topic is closely related to the modifiable areal unit problem.

A mathematical space exists whenever we have a set of observations and quantitative measures of their attributes. For example, we can represent individuals' incomes or years of education within a coordinate system where the location of each individual can be specified with respect to both dimensions. The distance between individuals within this space is a quantitative measure of their differences with respect to income and education. However, in spatial analysis, we are concerned with specific types of mathematical spaces, namely, geographic space. In geographic space, the observations correspond to locations in a spatial measurement framework that capture their proximity in the real world. The locations in a spatial measurement framework often represent locations on the surface of the Earth, but this is not strictly necessary. A spatial measurement framework can also capture proximity with respect to, say, interstellar space or within a biological entity such as a liver. The fundamental tenet is Tobler's First Law of Geography: if the interrelation between entities increases with proximity in the real world, then representation in geographic space and assessment using spatial analysis techniques are appropriate.

The Euclidean distance between locations often represents their proximity, although this is only one possibility. There are an infinite number of distances in addition to Euclidean that can support quantitative analysis. For example, "Manhattan" (or "Taxicab") distances where movement is restricted to paths parallel to the axes can be more meaningful than Euclidean distances in urban settings. In addition to distances, other geographic relationships such as connectivity (e.g., the existence or degree of shared borders) and direction can also influence the relationships among entities. It is also possible to compute minimal cost paths across a cost surface; for example, this can represent proximity among locations when travel must occur across rugged terrain.

 Spatial data comes in many varieties and it is not easy to
Urban and Regional Studies deal with large tables of spatial data obtained from censuses and surveys. It is necessary to simplify the huge amount of detailed information in order to extract the main trends. Multivariable analysis (or Factor analysis, FA) allows a change of variables, transforming the many variables of the census, usually correlated between themselves, into fewer independent "Factors" or "Principal Components" which are, actually, the eigenvectors of the data correlation matrix weighted by the inverse of their eigenvalues. This change of variables has two main advantages:

Factor analysis depends on measuring distances between observations : the choice of a significant metric is crucial. The Euclidean metric (Principal Component Analysis), the Chi-Square distance (Correspondence Analysis) or the Generalized Mahalanobis distance (Discriminant Analysis ) are among the more widely used. More complicated models, using communalities or rotations have been proposed.

Using multivariate methods in spatial analysis began really in the 1950s (although some examples go back to the beginning of the century) and culminated in the 1970s, with the increasing power and accessibility of computers. Already in 1948, in a seminal publication, two sociologists, Wendell Bell and Eshref Shevky, had shown that most city populations in the US and in the world could be represented with three independent factors : 1- the « socio-economic status » opposing rich and poor districts and distributed in sectors running along highways from the city center, 2- the « life cycle », i.e. the age structure of households, distributed in concentric circles, and 3- « race and ethnicity », identifying patches of migrants located within the city. In 1961, in a groundbreaking study, British geographers used FA to classify British towns. Brian J Berry, at the University of Chicago, and his students made a wide use of the method, applying it to most important cities in the world and exhibiting common social structures. 
The use of Factor Analysis in Geography, made so easy by modern computers, has been very wide but not always very wise.

Since the vectors extracted are determined by the data matrix, it is not possible to compare factors obtained from different censuses. A solution consists in fusing together several census matrices in a unique table which, then, may be analyzed. This, however, assumes that the definition of the variables has not changed over time and produces very large tables, difficult to manage. A better solution, proposed by psychometricians, groups the data in a « cubic matrix », with three entries (for instance, locations, variables, time periods). A Three-Way Factor Analysis produces then three groups of factors related by a small cubic « core matrix ». This method, which exhibits data evolution over time, has not been widely used in geography. In Los Angeles, however, it has exhibited the role, traditionally ignored, of Downtown as an organizing center for the whole city during several decades.

Spatial autocorrelation statistics measure and analyze the degree of dependency among observations in a geographic space. Classic spatial autocorrelation statistics include Moran's formula_1, Geary's formula_2, Getis's formula_3 and the standard deviational ellipse. These statistics require measuring a spatial weights matrix that reflects the intensity of the geographic relationship between observations in a neighborhood, e.g., the distances between neighbors, the lengths of shared border, or whether they fall into a specified directional class such as "west". Classic spatial autocorrelation statistics compare the spatial weights to the covariance relationship at pairs of locations. Spatial autocorrelation that is more positive than expected from random indicate the clustering of similar values across geographic space, while significant negative spatial autocorrelation indicates that neighboring values are more dissimilar than expected by chance, suggesting a spatial pattern similar to a chess board.

Spatial autocorrelation statistics such as Moran's formula_1 and Geary's formula_2 are global in the sense that they estimate the overall degree of spatial autocorrelation for a dataset. The possibility of spatial heterogeneity suggests that the estimated degree of autocorrelation may vary significantly across geographic space. Local spatial autocorrelation statistics provide estimates disaggregated to the level of the spatial analysis units, allowing assessment of the dependency relationships across space. formula_3 statistics compare neighborhoods to a global average and identify local regions of strong autocorrelation. Local versions of the formula_1 and formula_2 statistics are also available.

Spatial stratified heterogeneity, referring to the within-strata variance less than the between strata-variance, is ubiquitous in ecological phenomena, such as ecological zones and many ecological variables. Spatial stratified heterogeneity of an attribute can be measured by geographical detector "q"-statistic:
where a population is partitioned into "h" = 1, ..., "L" strata; "N" stands for the size of the population, σ stands for variance of the attribute. The value of "q" is within [0, 1], 0 indicates no spatial stratified heterogeneity, 1 indicates perfect spatial stratified heterogeneity.The value of "q" indicates the percent of the variance of an attribute explained by the stratification.The "q" follows a noncentral "F" probability density function.

Spatial interpolation methods estimate the variables at unobserved locations in geographic space based on the values at observed locations. Basic methods include inverse distance weighting: this attenuates the variable with decreasing proximity from the observed location. Kriging is a more sophisticated method that interpolates across space according to a spatial lag relationship that has both systematic and random components. This can accommodate a wide range of spatial relationships for the hidden values between observed locations. Kriging provides optimal estimates given the hypothesized lag relationship, and error estimates can be mapped to determine if spatial patterns exist.

Spatial regression methods capture spatial dependency in regression analysis, avoiding statistical problems such as unstable parameters and unreliable significance tests, as well as providing information on spatial relationships among the variables involved. Depending on the specific technique, spatial dependency can enter the regression model as relationships between the independent variables and the dependent, between the dependent variables and a spatial lag of itself, or in the error terms. Geographically weighted regression (GWR) is a local version of spatial regression that generates parameters disaggregated by the spatial units of analysis. This allows assessment of the spatial heterogeneity in the estimated relationships between the independent and dependent variables. The use of Bayesian hierarchical modeling in conjunction with Markov chain Monte Carlo (MCMC) methods have recently shown to be effective in modeling complex relationships using Poisson-Gamma-CAR, Poisson-lognormal-SAR, or Overdispersed logit models. 
Spatial stochastic processes, such as Gaussian processes are also increasingly being deployed in spatial regression analysis. Model-based versions of GWR, known as spatially varying coefficient models have been applied to conduct Bayesian inference. Spatial stochastic process can become computationally effective and scalable Gaussian process models, such as Gaussian Predictive Processes and Nearest Neighbor Gaussian Processes (NNGP).

Spatial interaction or "gravity models" estimate the flow of people, material or information between locations in geographic space. Factors can include origin propulsive variables such as the number of commuters in residential areas, destination attractiveness variables such as the amount of office space in employment areas, and proximity relationships between the locations measured in terms such as driving distance or travel time. In addition, the topological, or connective, relationships between areas must be identified, particularly considering the often conflicting relationship between distance and topology; for example, two spatially close neighborhoods may not display any significant interaction if they are separated by a highway. After specifying the functional forms of these relationships, the analyst can estimate model parameters using observed flow data and standard estimation techniques such as ordinary least squares or maximum likelihood. Competing destinations versions of spatial interaction models include the proximity among the destinations (or origins) in addition to the origin-destination proximity; this captures the effects of destination (origin) clustering on flows. Computational methods such as artificial neural networks can also estimate spatial interaction relationships among locations and can handle noisy and qualitative data.

Spatial interaction models are aggregate and top-down: they specify an overall governing relationship for flow between locations. This characteristic is also shared by urban models such as those based on mathematical programming, flows among economic sectors, or bid-rent theory. An alternative modeling perspective is to represent the system at the highest possible level of disaggregation and study the bottom-up emergence of complex patterns and relationships from behavior and interactions at the individual level. 

Complex adaptive systems theory as applied to spatial analysis suggests that simple interactions among proximal entities can lead to intricate, persistent and functional spatial entities at aggregate levels. Two fundamentally spatial simulation methods are cellular automata and agent-based modeling. Cellular automata modeling imposes a fixed spatial framework such as grid cells and specifies rules that dictate the state of a cell based on the states of its neighboring cells. As time progresses, spatial patterns emerge as cells change states based on their neighbors; this alters the conditions for future time periods. For example, cells can represent locations in an urban area and their states can be different types of land use. Patterns that can emerge from the simple interactions of local land uses include office districts and urban sprawl. Agent-based modeling uses software entities (agents) that have purposeful behavior (goals) and can react, interact and modify their environment while seeking their objectives. Unlike the cells in cellular automata, simulysts can allow agents to be mobile with respect to space. For example, one could model traffic flow and dynamics using agents representing individual vehicles that try to minimize travel time between specified origins and destinations. While pursuing minimal travel times, the agents must avoid collisions with other vehicles also seeking to minimize their travel times. Cellular automata and agent-based modeling are complementary modeling strategies. They can be integrated into a common geographic automata system where some agents are fixed while others are mobile.

Calibration plays a pivotal role in both CA and ABM simulation and modelling approaches. Initial approaches to CA proposed robust calibration approaches based on stochastic, Monte Carlo methods. ABM approaches rely on agents' decision rules (in many cases extracted from qualitative research base methods such as questionnaires). Recent Machine Learning Algorithms calibrate using training sets, for instance in order to understand the qualities of the built environment.

Spatial analysis of a conceptual geological model is the main purpose of any MPS algorithm. The method analyzes the spatial statistics of the geological model, called the training image, and generates realizations of the phenomena that honor those input multiple-point statistics.

A recent MPS algorithm used to accomplish this task is the pattern-based method by Honarkhah. In this method, a distance-based approach is employed to analyze the patterns in the training image. This allows the reproduction of the multiple-point statistics, and the complex geometrical features of the training image. Each output of the MPS algorithm is a realization that represents a random field. Together, several realizations may be used to quantify spatial uncertainty.

One of the recent methods is presented by Tahmasebi et al. uses a cross-correlation function to improve the spatial pattern reproduction. They call their MPS simulation method as the CCSIM algorithm. This method is able to quantify the spatial connectivity, variability and uncertainty. Furthermore, the method is not sensitive to any type of data and is able to simulate both categorical and continuous scenarios. CCSIM algorithm is able to be used for any stationary, non-stationary and multivariate systems and it can provide high quality visual appeal model.,

Geospatial analysis, or just spatial analysis, is an approach to applying statistical analysis and other analytic techniques to data which has a geographical or spatial aspect. Such analysis would typically employ software capable of rendering maps processing spatial data, and applying analytical methods to terrestrial or geographic datasets, including the use of geographic information systems and geomatics.

Geographic information systems (GIS) — a large domain that provides a variety of capabilities designed to capture, store, manipulate, analyze, manage, and present all types of geographical data — utilizes geospatial analysis in a variety of contexts, operations and applications.

Geospatial analysis, using GIS, was developed for problems in the environmental and life sciences, in particular ecology, geology and epidemiology. It has extended to almost all industries including defense, intelligence, utilities, Natural Resources (i.e. Oil and Gas, Forestry ... etc.), social sciences, medicine and Public Safety (i.e. emergency management and criminology), disaster risk reduction and management (DRRM), and climate change adaptation (CCA). Spatial statistics typically result primarily from observation rather than experimentation.

Vector-based GIS is typically related to operations such as map overlay (combining two or more maps or map layers according to predefined rules), simple buffering (identifying regions of a map within a specified distance of one or more features, such as towns, roads or rivers) and similar basic operations. This reflects (and is reflected in) the use of the term spatial analysis within the Open Geospatial Consortium (OGC) “simple feature specifications”. For raster-based GIS, widely used in the environmental sciences and remote sensing, this typically means a range of actions applied to the grid cells of one or more maps (or images) often involving filtering and/or algebraic operations (map algebra). These techniques involve processing one or more raster layers according to simple rules resulting in a new map layer, for example replacing each cell value with some combination of its neighbours’ values, or computing the sum or difference of specific attribute values for each grid cell in two matching raster datasets. Descriptive statistics, such as cell counts, means, variances, maxima, minima, cumulative values, frequencies and a number of other measures and distance computations are also often included in this generic term spatial analysis. Spatial analysis includes a large variety of statistical techniques (descriptive, exploratory, and explanatory statistics) that apply to data that vary spatially and which can vary over time. Some more advanced statistical techniques include Getis-ord Gi* or Anselin Local Moran's I which are used to determine clustering patterns of spatially referenced data.

Geospatial analysis goes beyond 2D and 3D mapping operations and spatial statistics. It includes: 

Traditionally geospatial computing has been performed primarily on personal computers (PCs) or servers. Due to the increasing capabilities of mobile devices, however, geospatial computing in mobile devices is a fast-growing trend. The portable nature of these devices, as well as the presence of useful sensors, such as Global Navigation Satellite System (GNSS) receivers and barometric pressure sensors, make them useful for capturing and processing geospatial information in the field. In addition to the local processing of geospatial information on mobile devices, another growing trend is cloud-based geospatial computing. In this architecture, data can be collected in the field using mobile devices and then transmitted to cloud-based servers for further processing and ultimate storage. In a similar manner, geospatial information can be made available to connected mobile devices via the cloud, allowing access to vast databases of geospatial information anywhere where a wireless data connection is available.

Geographic information systems (GIS) and the underlying geographic information science that advances these technologies have a strong influence on spatial analysis. The increasing ability to capture and handle geographic data means that spatial analysis is occurring within increasingly data-rich environments. Geographic data capture systems include remotely sensed imagery, environmental monitoring systems such as intelligent transportation systems, and location-aware technologies such as mobile devices that can report location in near-real time. GIS provide platforms for managing these data, computing spatial relationships such as distance, connectivity and directional relationships between spatial units, and visualizing both the raw data and spatial analytic results within a cartographic context.

Geovisualization (GVis) combines scientific visualization with digital cartography to support the exploration and analysis of geographic data and information, including the results of spatial analysis or simulation. GVis leverages the human orientation towards visual information processing in the exploration, analysis and communication of geographic data and information. In contrast with traditional cartography, GVis is typically three- or four-dimensional (the latter including time) and user-interactive.

Geographic knowledge discovery (GKD) is the human-centered process of applying efficient computational tools for exploring massive spatial databases. GKD includes geographic data mining, but also encompasses related activities such as data selection, data cleaning and pre-processing, and interpretation of results. GVis can also serve a central role in the GKD process. GKD is based on the premise that massive databases contain interesting (valid, novel, useful and understandable) patterns that standard analytical techniques cannot find. GKD can serve as a hypothesis-generating process for spatial analysis, producing tentative patterns and relationships that should be confirmed using spatial analytical techniques.

Spatial decision support systems (SDSS) take existing spatial data and use a variety of mathematical models to make projections into the future. This allows urban and regional planners to test intervention decisions prior to implementation.






</doc>
<doc id="17351446" url="https://en.wikipedia.org/wiki?curid=17351446" title="Geographical feature">
Geographical feature

Geographical features are naturally-created features of the Earth. Natural geographical features consist of landforms and ecosystems. For example, terrain types, (physical factors of the environment) are natural geographical features. Conversely, human settlements or other engineered forms are considered types of artificial geographical features.

There are two different terms to describe habitats: ecosystem and biome. An ecosystem is a community of organisms. In contrast, biomes occupy large areas of the globe and often encompass many different kinds of geographical features, including mountain ranges.

Biotic diversity within an ecosystem is the variability among living organisms from all sources, including "inter alia", terrestrial, marine and other aquatic ecosystems. Living organisms are continually engaged in a set of relationships with every other element constituting the environment in which they exist, and ecosystem describes any situation where there is relationship between organisms and their environment.

Biomes represent large areas of ecologically similar communities of plants, animals, and soil organisms. Biomes are defined based on factors such as plant structures (such as trees, shrubs, and grasses), leaf types (such as broadleaf and needleleaf), plant spacing (forest, woodland, savanna), and climate. Unlike ecozones, biomes are not defined by genetic, taxonomic, or historical similarities. Biomes are often identified with particular patterns of ecological succession and climax vegetation.

A landform comprises a geomorphological unit and is largely defined by its surface form and location in the landscape, as part of the terrain, and as such is typically an element of topography. Landforms are categorized by features such as elevation, slope, orientation, stratification, rock exposure, and soil type. They include berms, mounds, hills, cliffs, valleys, rivers, and numerous other elements. Oceans and continents are the highest-order landforms.

A body of water is any significant accumulation of water, usually covering the Earth. The term "body of water" most often refers to oceans, seas, and lakes, but it may also include smaller pools of water such as ponds, creeks or wetlands. Rivers, streams, canals, and other geographical features where water moves from one place to another are not always considered bodies of water, but they are included as geographical formations featuring water.

A settlement is a permanent or temporary community in which people live. Settlements range in components from a small number of dwellings grouped together to the largest of cities with surrounding urbanized areas. Other landscape features such as roads, enclosures, field systems, boundary banks and ditches, ponds, parks and woods, mills, manor houses, moats, and churches may be considered part of a settlement.

Engineered geographic features include highways, bridges, airports, railroads, buildings, dams, and reservoirs, and are part of the anthroposphere because they are man-made geographic features.

Cartographic features are types of abstract geographical features, which appear on maps but not on the planet itself, even though they are located on the planet. For example, the Equator is shown on maps of the Earth, but it does not physically exist. It is a theoretical line used for reference, navigation, and measurement.



</doc>
<doc id="31346116" url="https://en.wikipedia.org/wiki?curid=31346116" title="Geographical cluster">
Geographical cluster

A geographical cluster is a localised anomaly, usually an excess of something given the distribution or variation of something else. Often it is considered as an incidence rate that is unusual in that there is more of some variable than might be expected. Examples would include: a local excess disease rate, a crime hot spot, areas of high unemployment, accident blackspots, unusually high positive residuals from a model, high concentrations of flora or fauna, physical features or events like earthquake epicenters etc... 

Identifying these extreme regions may be useful in that there could be implicit geographical associations with other variables that can be identified and would be of interest. Pattern detection via the identification of such geographical clusters is a very simple and generic form of geographical analysis that has many applications in many different contexts. The emphasis is on localized clustering or patterning because this may well contain the most useful information. 

A geographical cluster is different from a high concentration as it is generally second order, involving the factoring in of the distribution of something else. 

Identifying geographical clusters can be an important stage in a geographical analysis. Mapping the locations of unusual concentrations may help identify causes of these. Some techniques include the Geographical Analysis Machine and Besag and Newell's cluster detection method.


</doc>
<doc id="53452291" url="https://en.wikipedia.org/wiki?curid=53452291" title="Geography of aging">
Geography of aging

Geography of aging or gerontological geography is an emerging field of knowledge of Human Geography that analyzes the socio-spatial implications of aging of the population from the understanding of the relationships between the physical-social environment and the elderly, at different scales, micro (City, region, country), etc.

Since the 1970s in a number of developed countries such as the United States, Canada, the United Kingdom, Germany, Sweden, France, Spain, Australia, New Zealand and Japan, there have been increasing studies focusing on the understanding of spatial patterns of aging population, as well as aspects related to residential changes and provision of health and social services. Among the geographers of aging is S. Harper, who identified the phenomenon of aging associated with the social construction of old age and the processes of residential mobility of this group to the urban periphery, mainly nursing homes and sheltered housing.

The contribution of geographers of aging, such as Graham D. Rowles, SM. Golant, S. Harper, G. Laws, are contributing to environmental gerontology by understanding the environmental aspects of gerontology in developed and developing countries. Also in Spain, some geographers, such as Gloria Fernández-Mayoralas, Fermina Rojo-Pérez and Vicente Rodríguez-Rodríguez, have made outstanding contributions to the study of residential strategies, access to health services, and, in general, quality of Life of the elderly, as well as the impacts of Northern European retirees on the Costa del Sol (Spain).

In Latin America and Spain, Diego Sánchez-González has shed light on the deepening of issues such as the physical-built and social environment and the quality of life of the elderly; the importance of the natural environment (therapeutic natural landscape) on active and healthy aging in the place; residential strategies for the maintenance of the elderly in the communities; the socio-environmental vulnerability of the elderly in the face of climate change; as well as issues related to the attachment to the place (identity and public space); elderly people with disabilities and social exclusion; leisure and tourism of elderly; and the planning of gerontological and geriatric services.



</doc>
<doc id="57078824" url="https://en.wikipedia.org/wiki?curid=57078824" title="Earth section paths">
Earth section paths

Earth section paths are paths on the earth defined by the intersection of a reference ellipsoid and a plane. Common examples of earth sections include the great ellipse and normal sections. This page provides a unifying approach to all earth sections and their associated geodetic problems.

The indirect problem for earth sections is: given two points, formula_1 and formula_2 on the surface of the reference ellipsoid, find the length, formula_3, of the short arc of a spheroid section from formula_1 to formula_2 and also find the departure and arrival (true north referenced) azimuths of that curve, formula_6 and formula_7. Let formula_8 have geodetic latitude formula_9 and longitude formula_10 (k=1,2). This problem is best solved using analytic geometry in ECEF coordinates.
Let formula_11 and formula_12 be the ECEF coordinates of the two points, computed using the geodetic to ECEF transformations discussed here.

To define the section plane select any third point formula_13 not on the line from formula_14 to formula_15. Choosing formula_13 to be on the surface normal at formula_1 will define the normal section at formula_1. If formula_13 is the origin then the earth section is the great ellipse. (The origin would be co-linear with 2 antipodal points so a different point must be used in that case). Since there are infinitely many choices for formula_13, the above problem is really a class of problems (one for each plane). Let formula_13 be given. To put the equation of the plane into the standard form, formula_22, where formula_23, requires the components of a unit vector, formula_24, normal to the section plane. These components may be computed as follows: The vector from formula_13 to formula_14 has components formula_27, and the vector from formula_14 to formula_15 has components formula_30. Therefore, formula_31 = formula_32×formula_33), where formula_34 is the unit vector in the direction of formula_35. The orientation convention used here is that formula_31 points to the left of the path. If this is not the case then redefine formula_37 = -formula_37. Finally, the parameter d for the plane may be computed using the dot product of formula_31 with a vector from the origin to any point on the plane, such as formula_14, i.e. d = formula_41. The equation of the plane (in vector form) is thus formula_31 ⋅ formula_43 = d, where formula_43 is the position vector of (x, y, z).

A unit vector pointing up at any point on the ellipsoid is: formula_45=formula_46, a unit vector pointing north is formula_47=formula_48, and east is formula_49=formula_50. A vector tangent to the path is:
formula_51 so the east component of formula_52 is formula_53, and the north component is formula_54. Therefore, the azimuth may be obtained from a two-argument arctangent function, formula_55=formula_56. Use this method at both formula_1 and formula_2 to get formula_6 and formula_7.

The (non-trivial) intersection of a plane and ellipsoid is an ellipse. Therefore, the arc length, formula_3, on the section path from formula_1 to formula_2 is an elliptic integral that may be computed to any desired accuracy using a truncated series. Before this can be done the ellipse must be defined and the limits of integration computed.
Let the ellipsoid given by formula_64, and let formula_65.
If p=0 then the section is a horizontal circle of radius formula_66, which has no solution if formula_67.

If p>0 then Gilbertson showed that the ECEF coordinates of the center of the ellipse is formula_68, where formula_69,

the semi-major axis is formula_70, in the direction formula_71, and
the semi-minor axis is formula_72, in the direction formula_73, which has no solution if formula_74.

The polar form relative to center for the equation of an ellipse is formula_75, where formula_76, relates to the ellipse eccentricity, not the spheroid eccentricity (see ellipse). Let P be a point on the ellipse and formula_77, then the vector from formula_78 to formula_43 has components formula_80. Using an argument similar to the one for azimuth above, let formula_81, then formula_82, and formula_83, and formula_84. In this way we obtain the central angles formula_85 and formula_86 corresponding to formula_1 and formula_2 respectively. Care must be taken to ensure that 0 ≤ formula_89 ≤ formula_90 ≤ formula_91. Then the arc length along the ellipse is given by formula_3 =formula_93 Substituting formula_94 above into this formula, performing the indicated operations, using one more term than Gilbertson's expression and regrouping, results in 
formula_95, where
Alternatively, expansions for the Meridian arc may be used here by replacing the spheroid eccentricity with the section ellipse eccentricity.

The direct problem is given formula_97, the distance, formula_98, and departure azimuth, formula_6, find formula_100 and the arrival azimuth, formula_7.
Construct the tangent vector at formula_97, formula_103, where formula_104 and formula_105 are unit vectors pointing north and east (respectively) at formula_97. Pick a vector, formula_37, to define the section plane, paying attention to orientation. Observe that formula_37 must not be in span{formula_109} (otherwise the plane would be tangent to the earth at formula_97, so no path would result). The normal vector formula_31 = formula_32×formula_113), together with formula_97 defines the plane.
This is a 2-d problem in span{formula_116}, which will be solved with the help of the arc length formula above. The basic approach is to use Newton-Raphson iteration to arrive at formula_100. The basis of the estimate is that the position vector of any point on the section ellipse may be expressed in terms of the position vector of the center and the central angle as 
formula_118.
To get an initial estimate of formula_119, let formula_120, formula_121=Central_Angleformula_122 (see the arc length section above),
formula_123, formula_124.

Now initialize formula_125 = formula_126, and iterate the following steps:
exit when formula_128

No more than three iterations are usually necessary, although nearly antipodal cases can be problematic.
Finally, let formula_129, and formula_100 = ECEF_to_Geoformula_131 using Bowring’s 1985 algorithm, or the algorithm here.

Alternatively, inversion of the arc length series may be used to avoid iterations.

Azimuth may be obtained by the same method as the indirect problem: formula_132=formula_133, where the subscript 2 indicates evaluation of the associated quantity at formula_2.

Let formula_13 be the origin, so that formula_136 = the position vector of formula_14. The above approach provides an alternative to that of others, such as Bowring.

The normal section at formula_1 is determined by letting formula_136 = formula_140 (the surface normal at formula_1). The above approach provides an alternative to that of others, such as Bowring.

The mean normal section from formula_1 to formula_2 is determined by letting formula_136 = formula_145. This is a good approximation to the geodesic from formula_1 to formula_2 for aviation or sailing.

A class of sections may be imagined by rotating formula_140 about the chord connecting formula_1 and formula_150 All of these may be solved with the single approach above.

Let two section planes be given: formula_151⋅formula_43 = formula_153, and formula_154⋅formula_43 = formula_156. Assuming that the two planes are not parallel, the line of intersection is on both planes. Hence orthogonal to both normals, i.e. in the direction of formula_157.

Since formula_151 and formula_154 are not colinear formula_151, formula_154, formula_162 is a basis for formula_163. Therefore, there exist constants formula_164 and formula_165 such that the line of intersection of the 2 planes is given by formula_43 = formula_167 + formula_168 + tformula_162, where t is an independent parameter.

Since this line is on both section planes, it satisfies both: 
formula_164 + formula_165(formula_151·formula_154) = formula_153, and 
formula_164(formula_151·formula_154) + formula_165 = formula_156.

Solving these equations for formula_180 and formula_181 gives 
formula_164 [1 - (formula_183 ] = formula_153 - formula_156(formula_151·formula_154), and 
formula_165 [1 - (formula_183 ] = formula_156 - formula_153(formula_151·formula_154).

Define the “dihedral angle”, formula_55, by formula_195 = formula_196·formula_197.
Then formula_164 = formula_199 , and formula_165 = formula_201.

On the intersection line we have formula_43 = formula_13 + tformula_162, where formula_13 = formula_167 + formula_168.
Hence: formula_208 = formula_209 + tformula_210, formula_211 = formula_212 + tformula_213, and formula_214 = formula_215 + tformula_216, where
formula_209= formula_218 + formula_219, formula_212 = formula_221 + formula_222, and formula_215 = formula_224 +formula_225.
and formula_226=(formula_227,formula_228,formula_229), for i=1,2,3.

To find the intersection of this line with the earth, plug the line equations into formula_64, to get
formula_231, where formula_232 = formula_233, 
formula_234 = formula_235,
formula_236 = formula_237.

Therefore, the line intersects the earth at formula_238. If formula_239, then there is no intersection. If formula_240, then the line is tangent to the earth at formula_241 (i.e. the sections intersect at that single point).

Observe that formula_242 since formula_151 and formula_154are not colinear. Plugging t into
formula_43 = formula_13 + tformula_162, gives the points of intersection of the earth sections.

on a earth section path may be found by dropping the subscripts on the given section; formula_248, formula_249, and setting formula_250, so that formula_251. Then solve for formula_252 such that formula_240.

Since formula_254, and formula_255, we must have formula_256. Plugging t into formula_43 = formula_258, gives the points of intersection of the earth sections. Alternatively, just set formula_259.

on a earth section path may be found by dropping the subscripts on the given section; formula_248, formula_249, and setting formula_262, where formula_263 is the longitude to be solved for such that formula_240.

Alternatively, just set formula_265.


</doc>
<doc id="57425862" url="https://en.wikipedia.org/wiki?curid=57425862" title="Geographic contiguity">
Geographic contiguity

Geographic contiguity is the characteristic in geography of political or geographical land divisions, as a group, not being interrupted by other land or water. Such divisions are referred to as being "contiguous." In the United States, for example, the "48 contiguous states" excludes Hawaii and Alaska, which do not share borders with other U.S. states.

Other examples of geographical contiguity might include the "contiguous European Union" excluding member states such as the United Kingdom, Ireland, Sweden, Finland, Malta and Cyprus (these being non-contiguous), or the "contiguous United Kingdom" referring to all parts of the country excepting Northern Ireland (it being geographically non-contiguous).

Two or more contiguous municipalities can be consolidated into one, or one municipality can consist of many noncontiguous elements. For example, the Financially Distressed Municipalities Act allows the commonwealth of Pennsylvania to merge contiguous municipalities to reduce financial distress.

Geographic contiguity is important in biology, especially animal ranges. For a particular species, its habitat may be a 'contiguous range', or it might be broken, requiring periodic, typically seasonal migrations (see: Disjunct distribution). The same concept of contiguous range is true for human transportation studies in an attempt to understand census geography. It also comes into play with electoral geography and politics.


</doc>
<doc id="128608" url="https://en.wikipedia.org/wiki?curid=128608" title="Population density">
Population density

Population density (in agriculture: standing stock and standing crop) is a measurement of population per unit area or unit volume; it is a quantity of type number density. It is frequently applied to living organisms, and most of the time to humans. It is a key geographical term. In simple terms population density refers to the number of people living in an area per kilometer square.

Population density is population divided by total land area or water volume, as appropriate.

Low densities may cause an extinction vortex and lead to further reduced fertility. This is called the Allee effect after the scientist who identified it. Examples of the causes in low population densities include:

For humans, population density is the number of people per unit of area, usually quoted per square kilometer or square mile (which may include or exclude, for example, areas of water or glaciers). Commonly this may be calculated for a county, city, country, another territory or the entire world.

The world's population is around 7,500,000,000 and Earth's total area (including land and water) is 510,000,000 square kilometers (197,000,000 sq. mi.). Therefore, the worldwide human population density is around 7,500,000,000 ÷ 510,000,000 = 14.7 per km (38 per sq. mi). If only the Earth's land area of 150,000,000 km (58,000,000 sq. mi.) is taken into account, then human population density is 50 per km (129 per sq. mile). This includes all continental and island land area, including Antarctica. If Antarctica is also excluded, then population density rises to over 55 people per km (over 142 per sq. mile). However, over half of the Earth's land mass consists of areas inhospitable to human habitation, such as deserts and high mountains, and population tends to cluster around seaports and fresh-water sources. Thus, this number by itself does not give any helpful measurement of human population density.

Several of the most densely populated territories in the world are city-states, microstates and dependencies. These territories have a relatively small area and a high urbanization level, with an economically specialized city population drawing also on rural resources outside the area, illustrating the difference between high population density and overpopulation.

The potential to maintain the agricultural aspects of deserts is extremely limited as there is not enough precipitation to support a sustainable land. The population in these areas are extremely low. Therefore, cities in the Middle East, such as Dubai, have been increasing in population and infrastructure growth at a fast pace.

Cities with high population densities are, by some, considered to be overpopulated, though this will depend on factors like quality of housing and infrastructure and access to resources. Most of the most densely populated cities are in Southeast Asia, though Cairo and Lagos in Africa also fall into this category.

City population and especially area are, however, heavily dependent on the definition of "urban area" used: densities are almost invariably higher for the central city area than when suburban settlements and the intervening rural areas are included, as in the areas of agglomeration or metropolitan area, the latter sometimes including neighboring cities. For instance, Milwaukee has a greater population density when just the inner city is measured, and the surrounding suburbs excluded.

In comparison, based on a world population of seven billion, the world's inhabitants, as a loose crowd taking up ten square feet (one square metre) per person (Jacobs Method), would occupy a space a little larger than Delaware's land area.

The Gaza Strip (exclave of Palestine) has a population of 1.85 million and a population density of 5,046 pop/km.

Although arithmetic density is the most common way of measuring population density, several other methods have been developed to provide a more accurate measure of population density over a specific area.





</doc>
<doc id="19877" url="https://en.wikipedia.org/wiki?curid=19877" title="Map">
Map

A map is a symbolic depiction emphasizing relationships between elements of some space, such as objects, regions, or themes.

Many maps are static, fixed to paper or some other durable medium, while others are dynamic or interactive. Although most commonly used to depict geography, maps may represent any space, real or fictional, without regard to context or scale, such as in brain mapping, DNA mapping, or computer network topology mapping. The space being mapped may be two dimensional, such as the surface of the earth, three dimensional, such as the interior of the earth, or even more abstract spaces of any dimension, such as arise in modeling phenomena having many independent variables.

Although the earliest maps known are of the heavens, geographic maps of territory have a very long tradition and exist from ancient times. The word "map" comes from the medieval Latin "Mappa mundi", wherein "mappa" meant napkin or cloth and "mundi" the world. Thus, "map" became the shortened term referring to a two-dimensional representation of the surface of the world.

Cartography or "map-making" is the study and practice of crafting representations of the Earth upon a flat surface (see History of cartography), and one who makes maps is called a cartographer.

Road maps are perhaps the most widely used maps today, and form a subset of navigational maps, which also include aeronautical and nautical charts, railroad network maps, and hiking and bicycling maps. In terms of quantity, the largest number of drawn map sheets is probably made up by local surveys, carried out by municipalities, utilities, tax assessors, emergency services providers, and other local agencies. Many national surveying projects have been carried out by the military, such as the British Ordnance Survey: a civilian government agency, internationally renowned for its comprehensively detailed work.

In addition to location information, maps may also be used to portray contour lines indicating constant values of elevation, temperature, rainfall, etc.

The orientation of a map is the relationship between the directions on the map and the corresponding compass directions in reality. The word "orient" is derived from Latin , meaning east. In the Middle Ages many maps, including the T and O maps, were drawn with east at the top (meaning that the direction "up" on the map corresponds to East on the compass). The most common cartographic convention is that north is at the top of a map.

Maps not oriented with north at the top:

Many maps are drawn to a scale expressed as a ratio, such as 1:10,000, which means that 1 unit of measurement on the map corresponds to 10,000 of that same unit on the ground. The scale statement can be accurate when the region mapped is small enough for the curvature of the Earth to be neglected, such as a city map. Mapping larger regions, where curvature cannot be ignored, requires projections to map from the curved surface of the Earth to the plane. The impossibility of flattening the sphere to the plane without distortion means that the map cannot have constant scale. Rather, on most projections the best that can be attained is accurate scale along one or two paths on the projection. Because scale differs everywhere, it can only be measured meaningfully as point scale per location. Most maps strive to keep point scale variation within narrow bounds. Although the scale statement is nominal it is usually accurate enough for most purposes unless the map covers a large fraction of the earth. At the scope of a world map, scale as a single number is practically meaningless throughout most of the map. Instead, it usually refers to the scale along the equator.
Some maps, called cartograms, have the scale deliberately distorted to reflect information other than land area or distance. For example, this map (at the right) of Europe has been distorted to show population distribution, while the rough shape of the continent is still discernible.

Another example of distorted scale is the famous London Underground map. The basic geographical structure is respected but the tube lines (and the River Thames) are smoothed to clarify the relationships between stations. Near the center of the map stations are spaced out more than near the edges of map.

Further inaccuracies may be deliberate. For example, cartographers may simply omit military installations or remove features solely in order to enhance the clarity of the map. For example, a road map may not show railroads, smaller waterways or other prominent non-road objects, and even if it does, it may show them less clearly (e.g. dashed or dotted lines/outlines) than the main roads. Known as decluttering, the practice makes the subject matter that the user is interested in easier to read, usually without sacrificing overall accuracy. Software-based maps often allow the user to toggle decluttering between ON, OFF and AUTO as needed. In AUTO the degree of decluttering is adjusted as the user changes the scale being displayed.

Geographic maps use a projection to translating the three-dimensional real surface of the geoid to a two-dimensional picture. Projection always distorts the surface. There are many ways to apportion the distortion, and so there are many map projections. Which projection to use depends on the purpose of the map.

The various features shown on a map are represented by conventional signs or symbols. For example, colors can be used to indicate a classification of roads. Those signs are usually explained in the margin of the map, or on a separately published characteristic sheet.

Some cartographers prefer to make the map cover practically the entire screen or sheet of paper, leaving no room "outside" the map for information about the map as a whole.
These cartographers typically place such information in an otherwise "blank" region "inside" the mapcartouche, map legend, title, compass rose, bar scale, etc.
In particular, some maps contain smaller "sub-maps" in otherwise blank regions—often one at a much smaller scale showing the whole globe and where the whole map fits on that globe, and a few showing "regions of interest" at a larger scale in order to show details that wouldn't otherwise fit.
Occasionally sub-maps use the same scale as the large map—a few maps of the contiguous United States include a sub-map to the same scale for each of the two non-contiguous states.

To communicate spatial information effectively, features such as rivers, lakes, and cities need to be labeled. Over centuries cartographers have developed the art of placing names on even the densest of maps. Text placement or name placement can get mathematically very complex as the number of labels and map density increases. Therefore, text placement is time-consuming and labor-intensive, so cartographers and GIS users have developed automatic label placement to ease this process.

Maps of the world or large areas are often either 'political' or 'physical'. The most important purpose of the political map is to show territorial borders; the purpose of the physical is to show features of geography such as mountains, soil type or land use including infrastructure such as roads, railroads and buildings. Topographic maps show elevations and relief with contour lines or shading. Geological maps show not only the physical surface, but characteristics of the underlying rock, fault lines, and subsurface structures.

From the last quarter of the 20th century, the indispensable tool of the cartographer has been the computer. Much of cartography, especially at the data-gathering survey level, has been subsumed by Geographic Information Systems (GIS). The functionality of maps has been greatly advanced by technology simplifying the superimposition of spatially located variables onto existing geographical maps. Having local information such as rainfall level, distribution of wildlife, or demographic data integrated within the map allows more efficient analysis and better decision making. In the pre-electronic age such superimposition of data led Dr. John Snow to identify the location of an outbreak of cholera. Today, it is used by agencies of the human kind, as diverse as wildlife conservationists and militaries around the world.

Even when GIS is not involved, most cartographers now use a variety of computer graphics programs to generate new maps.

Interactive, computerised maps are commercially available, allowing users to "zoom in" or "zoom out" (respectively meaning to increase or decrease the scale), sometimes by replacing one map with another of different scale, centered where possible on the same point. In-car global navigation satellite systems are computerised maps with route-planning and advice facilities which monitor the user's position with the help of satellites. From the computer scientist's point of view, zooming in entails one or a combination of:


For example:

"See also: Webpage (Graphics), PDF (Layers), MapQuest, Google Maps, Google Earth, OpenStreetMap or Yahoo! Maps."

The maps that reflect the territorial distribution of climatic conditions based on the results of long-term observations are called climatic maps. These maps can be compiled both for individual climatic features (temperature, precipitation, humidity) and for combinations of them at the earth's surface and in the upper layers of the atmosphere. Climatic maps afford a very convenient overview of the climatic features in a large region and permit values of climatic features to be compared in different parts of the region. Through interpolation the maps can be used to determine the values of climatic features in any particular spot.

Climatic maps generally apply to individual months and to the year as a whole, sometimes to the four seasons, to the growing period, and so forth. On maps compiled from the observations of ground meteorological stations, atmospheric pressure is converted to sea level. Air temperature maps are compiled both from the actual values observed on the surface of the earth and from values converted to sea level. The pressure field in free atmosphere is represented either by maps of the distribution of pressure at different standard altitudes—for example, at every kilometer above sea level—or by maps of baric topography on which altitudes (more precisely geopotentials) of the main isobaric surfaces (for example, 900, 800, and 700 millibars) counted off from sea level are plotted. The temperature, humidity, and wind on aeroclimatic maps may apply either to standard altitudes or to the main isobaric surfaces.

Isolines are drawn on maps of such climatic features as the long-term mean values (of atmospheric pressure, temperature, humidity, total precipitation, and so forth) to connect points with equal values of the feature in question—for example, isobars for pressure, isotherms for temperature, and isohyets for precipitation. Isoamplitudes are drawn on maps of amplitudes (for example, annual amplitudes of air temperature—that is, the differences between the mean temperatures of the warmest and coldest month). Isanomals are drawn on maps of anomalies (for example, deviations of the mean temperature of each place from the mean temperature of the entire latitudinal zone). Isolines of frequency are drawn on maps showing the frequency of a particular phenomenon (for example, annual number of days with a thunderstorm or snow cover). Isochrones are drawn on maps showing the dates of onset of a given phenomenon (for example, the first frost and appearance or disappearance of the snow cover) or the date of a particular value of a meteorological element in the course of a year (for example, passing of the mean daily air temperature through zero). Isolines of the mean numerical value of wind velocity or isotachs are drawn on wind maps (charts); the wind resultants and directions of prevailing winds are indicated by arrows of different length or arrows with different plumes; lines of flow are often drawn. Maps of the zonal and meridional components of wind are frequently compiled for the free atmosphere. Atmospheric pressure and wind are usually combined on climatic maps. Wind roses, curves showing the distribution of other meteorological elements, diagrams of the annual course of elements at individual stations, and the like are also plotted on climatic maps.

Maps of climatic regionalization, that is, division of the earth's surface into climatic zones and regions according to some classification of climates, are a special kind of climatic map.

Climatic maps are often incorporated into climatic atlases of varying geographic range (globe, hemispheres, continents, countries, oceans) or included in comprehensive atlases. Besides general climatic maps, applied climatic maps and atlases have great practical value. Aeroclimatic maps, aeroclimatic atlases, and agroclimatic maps are the most numerous.

Maps exist of the Solar System, and other cosmological features such as star maps. In addition maps of other bodies such as the Moon and other planets are technically not "geo"graphical maps.

Diagrams such as schematic diagrams and Gantt charts and treemaps display logical relationships between items, rather than geographical relationships. Topological in nature, only the connectivity is significant. The London Underground map and similar subway maps around the world are a common example of these maps.

General-purpose maps provide many types of information on one map. Most atlas maps, wall maps, and road maps fall into this category. The following are some features that might be shown on general-purpose maps: bodies of water, roads, railway lines, parks, elevations, towns and cities, political boundaries, latitude and longitude, national and provincial parks. These maps give a broad understanding of location and features of an area. The reader may gain an understanding of the type of landscape, the location of urban places, and the location of major transportation routes all at once.


Some countries required that all published maps represent their national claims regarding border disputes. For example:

In 2010, the People's Republic of China began requiring that all online maps served from within China be hosted there, making them subject to Chinese laws.









</doc>
<doc id="26044771" url="https://en.wikipedia.org/wiki?curid=26044771" title="Outline of geography">
Outline of geography

The following outline is provided as an overview of and topical guide to geography:

Geography – study of earth and its people.


As "the bridge between the human and physical sciences," geography is divided into two main branches:

Other branches include:

All the branches are further described below...










Regional geography – study of world regions. Attention is paid to unique characteristics of a particular region such as its natural elements, human elements, and regionalization which covers the techniques of delineating space into regions. Regional geography breaks down into the study of specific regions.

Region – an area, defined by physical characteristics, human characteristics, or functional characteristics. The term is used in various ways among the different branches of geography. A region can be seen as a collection of smaller units, such as a country and its political divisions, or as one part of a larger whole, as in a country on a continent.

List of supercontinents
A "supercontinent" is a landmass comprising more than one continental core, or craton.


Continent – one of several large landmasses on Earth. They are generally identified by convention rather than any specific criteria, but seven areas are commonly regarded as continents. They are:

Subregion (list)

Ecozone
The World Wildlife Fund (WWF) developed a system of eight biogeographic realms (ecozones):

Ecoregion
Ecozones are further divided into ecoregions. The World has over 800 terrestrial ecoregions. "See Lists of ecoregions by country."


Topics pertaining to the geographical study of the World throughout history:













Topics common to the various branches of geography include:


Geographic feature – component of a planet that can be referred to as a location, place, site, area, or region, and therefore may show up on a map. A geographic feature may be natural or artificial.


Natural geographic feature – an ecosystem or natural landform.

Ecosystem – community of living organisms in conjunction with the nonliving components of their environment (things like air, water and mineral soil), interacting as a system. These biotic and abiotic components are regarded as linked together through nutrient cycles and energy flows. 

Natural landform – terrain or body of water. Landforms are topographical elements, and are defined by their surface form and location in the landscape. Landforms are categorized by traits such as elevation, slope, orientation, stratification, rock exposure, and soil type. Some landforms are artificial, such as certain islands, but most landforms are natural.



Artificial geographic feature – a thing that was made by humans that may be indicated on a map. It may be physical and exist in the real world (like a bridge or city), or it may be abstract and exist only on maps (such as the Equator, which has a defined location, but cannot be seen where it lies).



Some awards and competitions in the field of geography:

A geographer is a scientist who studies Earth's physical environment and human habitat. Geographers are historically known for making maps, the subdiscipline of geography known as cartography. They study the physical details of the environment and also its effect on human and wildlife ecologies, weather and climate patterns, economics, and culture. Geographers focus on the spatial relationships between these elements.



Educational frameworks upon which primary and secondary school curricula for geography are based upon include:



</doc>
<doc id="1019827" url="https://en.wikipedia.org/wiki?curid=1019827" title="Polity">
Polity

A polity is an identifiable political entity. It can be defined as any group of people who have a collective identity, who have a capacity to mobilize resources, and are organized by some form of institutionalized hierarchy. A polity can be the government of a country, or country subdivision, or any other group of people organized for governance (such as a corporate board). 

In geopolitics, a polity can be manifested in different forms, such as a state, an empire, an international organization, a political organization and other identifiable, resource-manipulating organizational structures. A polity, like a state, does not need to be a sovereign unit. The most preeminent polities today are Westphalian states and nation-states, commonly referred to as "nations".

It therefore encapsulates a vast multitude of organizations, many of which form the fundamental apparatus of contemporary states such as their subordinate civil and local government authorities. Polities do not need to be in control of any geographic areas, as not all political entities and governments have controlled the resources of one fixed geographic area. The historical Steppe Empires originating from the Eurasian Steppe are the most prominent example of non-sedentary polities. These polities differ from "states" because of their lack of a fixed, defined territory. "Empires" also differ from "states" in that their territories are not statically defined or permanently fixed, and consequently that their body politic was also dynamic and fluid.

It is useful, then, to think of a polity as a political community. A polity can be defined either as a faction within a larger (usually state) entity or, at different times, as the entity itself. Kurds in Iraqi Kurdistan, for example, are parts of their own separate and distinct polity. They are also, though, members of the sovereign state of Iraq which is itself a polity, albeit one which is much less specific and, as a result, much less cohesive. It is therefore possible for an individual to belong to more than one polity at a time.

Thomas Hobbes was a highly significant figure in the conceptualisation of polities, and in particular of states. Hobbes considered notions of the state and the body politic in his most notable work, "Leviathan".

In previous centuries, "body politic" was also understood to mean "the physical person of the sovereign:" emperor, king or dictator in monarchies and despotisms, and the electorate in republics. As many polities have become more democratic in the last few centuries the body politic, where sovereignty is bestowed, has grown to a much greater size than simply the ruling elite, such as the monarchy. In present times, it may also refer to the representation of a group, such as ones drawn along ethnic or gender lines. Cabinets in liberal democracies are chosen to represent the body politic.




</doc>
<doc id="2103140" url="https://en.wikipedia.org/wiki?curid=2103140" title="Public value">
Public value

Public value describe the value that an organization contributes to society. The term was originally coined by Harvard professor Mark H. Moore who saw it as the equivalent of shareholder value in public management. Public value is supposed to provide managers with a notion of how entrepreneurial activity can contribute to the common good. Nowadays, public value is no longer limited to the public sector, but is used by all types of organization, including non-governmental organizations and private sector firms. Therefore, the public value researcher Timo Meynhardt from the University of St. Gallen and HHL Leipzig Graduate School of Management uses the term to generally raise the question about organizations' contribution to the common good. He believes that current management concepts, such as shareholder value, stakeholder value, customer value, sustainability or corporate social responsibility, should legitimize themselves in regard to their impact on the common good.

In his (social-)psychological-based concept, public value emerges for individuals from the experiences made in social structures and relationships. Hence, it can be seen as a prerequisite and a resource for successful living.

"Public values are those providing normative consensus about (1) the rights, benefits, and prerogatives to which citizens should (and should not) be entitled; (2) the obligations of citizens to society, the state and one another; and (3) the principles on which governments and policies should be based." Bozeman, 2007

"Public value is value for the public. Value for the public is a result of evaluations about how basic needs of individuals, groups and the society as a whole are influenced in relationships involving the public. Public value then is also value from the public, i.e., “drawn” from the experience of the public. The public is an indispensable operational fiction of society. Any impact on shared experience about the quality of the relationship between the individual and society can be described as public value creation. Public value creation is situated in relationships between the individual and society, founded in individuals, constituted by subjective evaluations against basic needs, activated by and realized in emotional-motivational states, and produced and reproduced in experience-intense practices." Meynhardt, 2009

"The definition that remains equates managerial success in the public sector with initiating and reshaping public sector enterprises in ways that increase their value to the public in both the short and the long run." Moore, 1995

"Public Value (or Public Value Capital) then is the combined view of the public about what they regard as valuable." Talbot, 2006

The research program on public value was kicked off by Professor Mark H. Moore of Harvard's Kennedy School of Government, who published a book on the subject, "Creating Public Value. Strategic Management in Government", in 1995. In this sense, public value can be instituted as an organising principle in a public sector organisation, providing a focus in the context of which individual employees are free to pursue and propose new ideas about how to improve the working of the organisation, in terms of efficiency or services. Public organisations seeking to use public value as a principle need to create a corporate culture in which the pursuit of public values by employees is rewarded just as pursuing shareholder value is rewarded in private corporations. 

The concept has been taken up initially by academics, think tanks and NGOs, and later by a number of public sector organisations in the United Kingdom and other countries.

In 2004 it was used by the BBC as the cornerstone of its manifesto for the renewal of its charter.

In 2006 Accenture launched the Institute for Public Service Value (IPSV), to explore how public value is created in government organizations. Greg Parston, co-founder and former Chief Executive of the Office for Public Management, and a collaborator with Professor Moore, was appointed Director. Among many other studies, IPSV conducted the Global Cities Forum in 2007-2009, which facilitated citizens' deliberations on their experiences and expectations of public value in 17 cities around the world. 

In 2006, the Center for Technology in Government (CTG) in partnership with SAP AG, conducted research on the topic of public value in the context of governments' investments in information technology (IT). The results of this research found that governments' ability to realize the full value of IT investments is not completely measurable in terms of financial results. More specifically, the five U.S. and international governments studied, looked for the full value of government IT investments in both the internal value to government operations and the broader political and social returns to the public at large.

From this point of view, there are two sources of public value: 
In November 2006, UK-based The Work Foundation published a report on their project, titled "Deliberative democracy and the role of public managers""," followed in October 2008 by "Public Value: The Next Steps in Public Service Reform" 

The German Federal Employment Agency uses the public value concept to better understand its contribution to society that goes beyond simple task fulfillment and make it a yardstick for management decisions. An empirical study has shown that a particular value of this organization is seen in its contribution to social peace in Germany.

Public value is also taken up by private sector companies that want to maintain a license to operate and understand what implications new strategies and projects might have in terms of public value creation/ destruction. Such analyses can be done using a Public Value Scorecard as proposed by Timo Meynhardt and Peter Gomez. Public value acknowledges that established business paradigms such as customer value or stakeholder value risk overemphasizing certain aspects of business' value contribution to society at the expense of other important dimensions. It pledges for a redefinition of the entire notion of value creation as it takes utilitarian and hedonistic as well as political and moral aspects of value creation into account.

A number of firms use public value to obtain management information helping to take strategic decisions. Examples include:





</doc>
<doc id="508535" url="https://en.wikipedia.org/wiki?curid=508535" title="Local administrative unit">
Local administrative unit

Generally, a local administrative unit (LAU) is a low level administrative division of a country, ranked below a province, region, or state. Not all countries describe their locally governed areas this way, but it can be descriptively applied anywhere to refer to counties, municipalities, etc.

In the European Union, LAUs are basic components of Classification of Territorial Units for Statistics (NUTS) regions. For each EU member country, two levels of Local Administrative Units (LAU) are defined: LAU 1 and LAU 2, which were previously called NUTS 4 and NUTS 5 respectively, until the NUTS regulation went into force in July 2003. For some countries, the LAU 1 level is not defined, and thus equivalent to the NUTS 3 level. A similar statistical system is defined for the candidate countries and members of the European Free Trade Association.




</doc>
<doc id="3605920" url="https://en.wikipedia.org/wiki?curid=3605920" title="Political agenda">
Political agenda

A political agenda is a list of subjects or problems to which government officials as well as individuals outside the government are paying serious attention at any given time. It is most often shaped by political and policy elites, but can also be influenced by non-governmental activist groups, private sector lobbyists, think tanks, courts, and world events. Media coverage has also been linked to the success of the rise of political parties and their ability to get their ideas on the agenda. Although the media does often have an effect on the political agenda, these results are not always immediate. When there is a great time difference between decisions and results it is called a political agenda lag.

Political agenda is also strongly tied to state centralization. The more centralized a state, the more citizens will likely try and affect the political agenda. For this reason, many political elites tend to prefer a non-centralized state where they can maintain more control over the political agenda.

The “Political Agenda Effect” asserts that when citizens from different backgrounds get together, their agenda will change in a way that takes their demands away from elites to focus more on public goods. The “Escalation Effect” contends that if citizens get together, this will induce elites to form national resources to fight against them and maintain the political agenda the way they desire.

The impact agenda is the increasing requirements for researchers to prove that there are real world impacts from their research. It is related to the political agenda because often governments measure a positive real world impact only in terms of the political agenda they have. When it comes to building the political agenda, there are three main models which are commonly cited: the outside initiative model, mobilization model, and inside initiative model.

The political agenda is essentially defined as what governmental officials find important to discuss. Those closest to the policy process have the biggest control on what issues reach the political agenda. They are the ones with the most power to decide which ideas or issues have the most importance, and which ideas or issues are unimportant. For example, the President of the United States, has the power to make treaties, appoint ambassadors, appoint judges of the supreme court etc. These types of powers ultimately shape what voices are present in parliament and subsequently what issues reach the political agenda.

Some non-governmental activist groups, such as neighborhood associations, advocate for civic beautification or improvement of communities. Many other important activist groups, like those oriented towards human rights and social justice, campaign for broad ideals. These groups work to put continuous pressure on government leaders that shape the agenda. If enough pressure is exerted onto political leaders through activist groups, it can change which issues and ideas ultimately reach the political agenda. For example the American Bar Association (ABA) and the American Medical Association (AMA), usually try to influence politicians on professional jobs.

Think tanks are in need of financial backing. Most times wealthy and established investors who wish to advance a certain idea or cause onto the political agenda establish them. These issues or causes may include: economics, taxes, foreign policy, global development, education, children and families, or healthcare. Examples of think tanks that promote a certain political perspective onto the political agenda are the Heritage Foundation and American Enterprise Institute which are highly conservative. On the other side, the Center for American Progress, are more liberal with their motives.

When the courts make a decision that changes a previous line of thinking, that idea immediately is on the political agenda because laws and public administration must change accordingly. The Mabo decision by the High Court in 1992 which overturned previous laws about establishing native titles is an example of this.

When something unexpected happens it can force the political agenda to change immediately. For example, when Hurricane Katrina or the World Trade Centre attacks occurred they were unexpected but priority changing events. When big world events (i.e. disasters/tragedies) occur they are often followed by a policy response as well, and so what issues and ideas reach the political agenda are sometimes changed simply due to what happened in the world.

There are three main theories on how political agendas are set and which groups have the greatest say in the decisions regarding them. They are; the pluralist theory, the elitist theory, and the institutional theory.

The pluralist theory suggests that policy-making is divided into several categories or “arenas”. Groups that do not have any power in one particular arena, most often have power in another arena. There is a marketplace for competing policies, and interests, and any group may win the arena. Elections often determine who gets to decide on each public policy.

In the elitist theory a main power elite dominates the entire agenda setting process to serve their own interests. These interests hold the power in all the arenas and they always win every election. There are very few people that actually organize into separate interest groups. In order to retain power and control, the main elite works at keeping key issues off the agenda. This suppression of issues threatens democracy.

This theory believes that legislative committees and bureaucratic institutions are the main controllers of the agenda. Because social interests and issues have much impact on what is considered by the legislative committees and bureaucratic institutions, individuals do not benefit from agenda decisions. This type of system leads to more conservative policy decisions than those under the pluralist scenario, but far more conservative than under the elite scenario.

The media is tightly linked to what issues gain importance on the political agenda. It affects what ideas become widespread and therefore what is demanded from politicians. Numerous studies have done research to prove this:

Hajo B Boomgaarden and Rens Vliegenthart write on the media’s relation to political agenda in their article "Explaining the rise of anti-immigrant parties: The role of news media content". In this article they study the media coverage on anti-immigration in the Netherlands for the period of 1990 to 2002 and found that it directly relates to the success of anti-immigration populist parties such as Centrumdemocraten (CD), the Centrum Partij (CP), and the Lijst Pim Fortuyn (LPF) during the same time period. Their analysis used the importance of news media as the explanatory factor of why anti-immigration gained prevalence on the political agenda, while controlling for other real world factors and developments at the time such as the influence of the economy, immigration, or the leadership of then President Pim Fortuyn. This was done by conducting a content analysis of five of the most popular Dutch national newspapers. The empirical results showed support of anti-immigration was around 4% in 1994, and rose to 16% in 2001 during the same time that media coverage of anti-immigration was at its peak. This means, the test showed that media content can be held at least partly responsible for the rise of anti-immigrant parties in the Netherlands and the changing of the political agenda in this way.

A similar study done by Julie Sevenans, Stefaan Walgrave & Gwendolyn Joanna Epping compares the behavior of politicians in comparison to the media on a global scale. The study was completed during one week, in Flemish Belgium. Every day, eight news outlets were studied and fully coded for a total of 2448 cases. The study looked at individual politicians cognitive attention for these specific news stories, via a face-to face survey of MPs to see if they recalled, hadtalked about, or considered the content covered in these news outlets. The results showed that the prominence and usefulness of a news story affect whether a news story is noticed, talked about or considered by MPs. This work showed that political agenda-setting effects most likely begin from the selective adoption on the cognitive, and individual level of MPs. Politicians both consume the news much how regular citizens by paying more attention the most prominent stories. However, they are also selective in that they pay the most attention to news that is political in nature or match their interests. More specifically, politicians pay more attention to: news that is more prominent, about the region their parliament is responsible for, issues they are personally specialized in, news about issues that are salient for their party, and news about politics. All of these claims were confirmed by statistical analysis. Relating to the political agenda, the implications of the fact that MPs care so much about media reports are twofold: some MPs may think media coverage is reflective of public opinion, while others may feel the media affect what the public sees as important. In either case, politicians are interpreting that the public cares about major news stories and taking this into account when setting the political agenda.

George Edwards and Dan Wood conducted a time series analysis of presidential, mass media and congressional attention to five political issues: crime, education, health care, U.S.-Soviet relations, and the Arab-Israeli conflict. The end conclusion was that most of the time presidents react corresponding to fluctuations in media attention on an issue. It too showed a relationship between the media and political agenda.

Although the media does often have an effect on the political agenda, these results are not always immediate. Dearing and Rogers (1996) conducted a study on this and concluded that time lags from what is in the media transferring in the political agenda can take up to a few weeks to several months.

The political agenda is tied to state centralization because the more centralized a state is, the more political elites have control over the political agenda. However if a state is too centralized, the more the public may feel they need they need to advocate to change the political agenda as well. The Political Agenda can be further broken down into two concepts: the political agenda effect, and the escalation effect.

The political agenda effect states that state centralization alters the dynamics of political action and conflict in society. State centralization, which involves elites coordinating nationally, induces citizens to organize nationally as well, rather than at the local or the “parochial” level. When this happens and citizens from different regions, sectors, interests, backgrounds, or ethnicity all join together to organize and discuss certain policies their agenda will change in a direction that switches their demands from power-holders to focus more on public goods. In this case then a state that has a higher level of centralization it may incite citizens to try and change the agenda themselves. Therefore, political elites might instead prefer a non-centralized state where they can still maintain more control over the political agenda. Elites may strategically opt for a non-centralized state in order to induce the citizens to not organize nationally and thus avert the political agenda effect.

The “Escalation Effect” contends that if citizens get together, it will force elites to form national resources to fight against them and maintain the political agenda the way they desire. In the case that citizens band together in a national organization, this will entice political elites to also form a national organization and pool their resources together in attempt to fight against the citizens. National organizations created by citizens might have a lower probability of success in comparison to organizations formed by elites, but in either case they will still indirectly benefit the weaker citizen groups, who would have otherwise remained unorganized. An escalation of the conflict can be seen as ensuing in this scenario.

The beginnings of the concept of the “impact agenda” can be traced to William Waldegrave’s 1993 white paper “Realizing Our Potential”. The impact agenda describes how there are increasing requirements set out by the state for researchers to relate their studies to real world issues in order to validate their research and access government funding. This is shown by the fact that the Biological and Sciences Research Council announced in 2012 that it expects its institutes to detail impact. This idea has been heavily criticized by scientists for allowing non-scientists to pick winners and losers and for constraining researchers to only create an impact that is aligned with the government's political agenda.

Roger Cobb, Jennie Keith Ross and Marc Howard Ross developed the “models of agenda building” theory to specify three different models: the outside initiative model, mobilization model, and inside initiative model. These models are designed to show the different ways the political agenda changes. The study related success of an idea being translated from the "public agenda" (being discussed regularly) to the “formal agenda” (government taking serious considerations into making changes in that specific area). Success in this study meant an issue was placed on the formal agenda and given attention by decision makers. Results showed that achieving agenda status is more difficult in modern nations than in smaller nations rooted in face-to-face interaction. More specifically:
The study also found that there are components of political agendas that hold true across nations and across different models:

The outside initiative model discusses the process where issues arise in non-governmental organizations and then are expanded to reach the formal agenda. The order of events starts with a grievance, an expansion of interest supported by nongovernmental groups, and then an exertion of pressure onto decision makers. It is about the process through which issues arise in non-governmental groups and are then expanded sufficiently to reach, first the public agenda and then the formal agenda. The outside initiative model is most prevalent in egalitarian societies.

The mobilization model is focused around political agenda issues that are initiated within government and subsequently reach the public agenda and formal agenda status. Its focus is on the internal mechanism and how politicians work to get ideas formalized onto the agenda. However, success in implementation does require support from the public under this model as well. The mobilization model is most commonly linked with hierarchical societies, or those societies which emphasize a wide gap between the leader and his or her followers.

The inside initiative model describes when issues are initiated within government, but supporters make no effort to expand it to the public. It is a model that is opposed to public participation. Instead, supporters of the issues rely solely on their own ability to apply the right amount of pressure to ensure formal agenda status. The inside access model is most often seen in societies with high concentrations of wealth and status.


</doc>
<doc id="3680801" url="https://en.wikipedia.org/wiki?curid=3680801" title="Head of state succession">
Head of state succession

Head of state succession is the process by which nations transfer leadership of their highest office from one person to another. The succession of a head of state can be brought about through various means, the most common of which include:


The changing of national leadership has been the topic of several films, novels, and television series, including the following:



</doc>
<doc id="3219525" url="https://en.wikipedia.org/wiki?curid=3219525" title="Public-benefit corporation">
Public-benefit corporation

Public-benefit corporations are a specific type of corporation that allow for public benefit to be a charter purpose in addition to the traditional corporate goal of maximizing profit for shareholders. Depending on the country they may also be known as crown corporations, statutory corporations, or government owned corporations having monopoly over a specific service or market.. 

The Public Utility Vehicle Modernization Program may be given as an example of public benefit, coming from a governmental organization. 
Secondly, the model of a public utility corporation shall represent an example for the private sector of the economy.

A public authority is a type of public-benefit corporation that takes on a more bureaucratic role, such as the maintenance of public infrastructure, that often has broad powers to regulate or maintain public property. These agencies are known in some countries as statutory authorities, statutory boards, government owned corporations, regulatory agencies, QUANGO or independent government agencies.

Authorities borrow from both municipal corporation law (that is, the laws responsible for the creation of cities, towns, and other forms of local government) and private corporations law. Other public-benefit corporations resemble private non-profit organizations, and take on roles that private corporations might otherwise perform. These corporations often operate in heavily regulated industries, such as broadcasting and transportation.

Corporations such as these are often found in common law jurisdictions such as the Commonwealth countries and the United States.

Although corporations are now typically associated with private business, historically corporations began as means to serve defined and limited public purposes. Corporation history has roots primarily in government subdivisions and religious institutions, where the institution itself is identifiable independently of its membership's mortality. For example, if the Pope dies, the Catholic Church continues to exist, just as it continues to exist as generations pass on and get replaced by new members.

Public-benefit corporations likely have their direct roots in mercantile capitalism. In the early days of European exploration and colonization, a government or monarch would sometimes grant a charter to an entity defining a legal body ("corporation") and make potentially risky investments. While certainly not public-benefit corporations by today's standards, entities such as the Massachusetts Bay Company, Hudson's Bay Company, and the Dutch East India Company arguably are prototypical examples of publicly chartered (in this case, crown-chartered) corporations successfully undertaking defined activities with the support of privately contributed investments.

The modern era of delegation of government authority to a chartered corporation is marked by the United Kingdom Port of London Authority, established 1908. According to the Port of London Acts The Authority is a public trust established to "administer, preserve and improve the Port of London." The goal was to create an entity that would be run self-sufficiently like a private company yet remain under the control of the government. The name "Authority" is derived from the founding act of Parliament which repeatedly stated that "Authority is hereby given..." The special status of this entity and the fact that it remained subject to administrative law was established by the UK courts in "" [1919] 1 KB 176.

Public-benefit corporations are generally governed by boards of directors, which are appointed, rather than elected, and, internally, reflect bureaucratic forms. The corporation is government-owned and performs a specific, narrow function for the public good.

Public-benefit corporations are most often created by statute. In many Commonwealth countries, public-benefit corporations continue to receive charters from the British monarchy. In the United States, they receive their charters usually from states, but possibly from the federal government.

Public authorities are usually created with a specific mandate, such as the construction of bridges, mass transit, etc. Unlike departments or ministries of the state, these corporations usually are enabled by statute to raise revenues through bond issues.

For more information, read below about individual jurisdictions.

The first reference to public-benefit corporations in United Kingdom law is in the Health and Social Care (Community Health and Standards) Act 2003, which established NHS Foundation Trusts as public-benefit corporations. Schedule 1 of the Act sets out the requirements for a public-benefit corporation which include a membership made up of individuals living in a specific area, employees of the corporation and service users, and a board of governors some of whom are elected by the members based on "constituencies" such as staff, users or public. British authorities have used other terms with similar functions to public-benefit corporations such as statutory authority, QUANGO and crown corporation.

Public-benefit corporations are distinguishable from public authorities in that the latter do not have a membership.

Examples of other bodies which have a similar role to, whilst not being formally called, public-benefit corporations include the BBC, which is incorporated by royal charter. Many universities have charters going back centuries, and so are also chartered corporations.

Via Rail in Canada is an independent crown corporation offering intercity passenger rail services in Canada. The Canadian Broadcasting Corporation is another example.

The Province of Ontario shares two international public-benefit corporations with the U.S. state of New York:

In Russia the law "On Noncommercial Organizations" describes the status state corporations. It is a special form of noncommercial partnership founded by the state to fulfill socially significant tasks. The activities of each corporation are described in a special federal law. Assets transferred to a state corporation are not state property from the legal point of view. Under the law "On Noncommercial Organizations", property transferred to as the investment in a partnership is the property of the partnership. The partnership itself is no one's property. It manages its assets as described in its charter. The rights of the founder are considerable in the partnership, but they are still not ownership rights. There is only one founder in a state corporation, and it is the Russian Federation. That is why the state corporation is independent. It is a set of assets that are managed for purposes established in its charter by managers appointed by the founder. State corporations, as a rule, are subordinate not to the government, but to the Russian president, and act to accomplish some important goal. The state corporations can manage those assets as demanded by the sketchily described goals and tasks of the charters and as allowed by the supervisory council, on which there is no one the president does not trust.

The U.S. Constitution is silent about the Federal Government's creation of corporations; the power to define and create corporations (other than as agencies of the U.S. government) is mostly reserved to the individual states. The interstate commerce clause of the constitution gives implicit authority to create private federally chartered commercial corporations; the most numerous are federally chartered banks and similar financial institutions. The federal government has established certain corporations by an act of Congress, mostly non-profit organizations serving the public interest, such as the Civil Air Patrol, as well as various charitable, fraternal, and veterans' organizations. In addition, certain parastatals, which are for-profit, but may exercise unique powers, such as Fannie Mae and Freddie Mac, have federal charters.

Private corporations were not common in the early United States, and were created by an act of a state legislature, typically for a public purpose, such as for the building and maintenance of a toll bridge or toll road or water utility. Today private corporations may be created by simply filing appropriate documents with the appropriate department of a State.

Federal government public benefit corporations are often Independent agencies of the United States government as form of Government-owned corporation. Examples of federal public-benefit corporations created, owned and operated by the U.S. government include Amtrak, the United States Postal Service and the Corporation for Public Broadcasting. Many public authorities in the United States are interstate compacts or local and regional entities spanning multiple municipalities on the county or state level.


California Corporation law designates three types of non-profit corporations — Religious Corporations (for example, a religious order might be incorporated as one of these), Mutual Benefit Corporations (a condominium association) and a Public Benefit Corporation (often things like hospitals or colleges). The assets of a public benefit corporation are irrevocably dedicated to its charitable purpose. (Generally beginning in California Corporation Code at §5100 — https://web.archive.org/web/20120120002651/http://www.leginfo.ca.gov/cgi-bin/displaycode?section=corp&group=05001-06000&file=5110-5111)

Under California law a Public Benefit Corporation may be created by a public entity — as the two examples above suggest, but the definition in the California Codes is very specific.

The Colorado General Assembly in House Bill 13-1138 allows for Public Benefit Companies. Section 7-101-503(2), C.R.S., defines public benefit as "one or more positive effects or reduction of negative effects on one or more categories of persons, entities, communities, or interests other than shareholders in their capacities as shareholders, including effects of an artistic, charitable, cultural, economic, educational, environmental, literary, medical, religious, scientific, or technological nature."

Ello is an example of a Colorado company which operates under the PBC laws.

In July 2013, Governor Markell signed into law a new type of public benefit corporation.

The General Corporation Law (Title 8, Chapter 1 of the Delaware Code) was recently amended by Senate Bill No. 47, effective August 1, 2013, adding a new subchapter XV, which authorizes the creation of Public Benefits Corporations. As defined in the GCL, a PBC is a for-profit corporation intended to produce a public benefit and operate in a responsible and sustainable manner. The PBC is to be managed in a manner that balances stockholders' pecuniary interests, the best interests of those materially affected by the corporation's conduct and the public benefit for which the PBC is formed.

In June 2015, Senate Bill No. 75 amended Delaware PBC rules to make it easier to form, operate or convert into a PBC, by facilitating the naming of PBCs, simplifying the issuance of stock options in PBCs and reducing the voting threshold for conversion from 90 percent to two-thirds of stockholders.

The Fourth Estate is an example of a Delaware company that operates under the state's public benefit corporation statute. Kickstarter is also a public benefit corporation chartered in Delaware.



As of February 2016, the Georgia legislature is considering House Bill 1052, which would add benefit corporations to Georgia's existing for-profit corporate code.

The Bi-State Development Agency is a bi-state agency managing public transportation between southern Illinois and Missouri. It serves the St. Louis metropolitan area.

The Regional Transportation Authority (RTA) oversees funding and operation of public transit in the Illinois portion of the Chicago metropolitan area.

The Illinois State Toll Highway Authority


Effective December 1, 2012, the Commonwealth of Massachusetts allows for the charter of public benefit corporations. Public benefit corporations are incorporated under Chapter 156A or 156D and may choose to prioritize environmental and social aims over profit. 

The state of Minnesota has enacted a Public Benefit Corporation Act, effective January 2015. A Minnesota public benefit corporation is defined as an entity created under the state's business corporation statute, which "elects in its articles to pursue general public benefit..." "General public benefit," in turn, is defined as "a net material positive impact from the business and operations...on society, the environment, and the well-being of present and future generations."

See "Bi-State Development Agency".

The New Jersey Turnpike Authority (NJTA) is a public-benefit corporation in New Jersey, created by the New Jersey Turnpike Authority Act of 1948.

The Delaware River and Bay Authority controls the Delaware Memorial Bridge between Delaware and New Jersey, and is a bi-state agency. The Delaware River Port Authority is a bi-state agency of New Jersey and Pennsylvania. The Port Authority of New York and New Jersey is a bi-state agency shared with New York.

NJ Transit, formed in 1979 operates bus, light rail and passenger rail service in New Jersey and in neighboring states as well as funding and planning of bus and rail services and programs.

Although "Public Benefit Corporation" is not a statutorily defined term under State laws (New Jersey Statutes or the New Jersey Administrative Code), such corporations are among those included within the statutorily defined term "State Agency".


The widespread use of public authorities in the United States was pioneered in New York state by Robert Moses. New York likely has the most extensive number of public-benefit corporations in the country. The approval of the New York State Public Authorities Control Board is required in some cases when creating an authority. An authority may at times levy taxes and tolls; this means that they are not part of the usual state budgetary process, and gives them a certain independence. Their most admired ability by the New York State and local government, is to circumvent strict public debt limits in the New York State Constitution. Furthermore, they may make contracts; because of public authorities' corporate status, there is generally no remedy against the chartering State for the breach of such contracts. On the other hand, as agents of the state, public authorities are not subject to many laws governing private corporations, and are not subject to municipal regulation. Employees of public authorities usually are not state employees, but are employees of the authority. Public authorities can also often condemn property.

Among the major public-benefit corporations in New York state are the Port Authority of New York and New Jersey, a bistate authority; and the Metropolitan Transportation Authority, which manages most of the public transportation in and around New York City.


Articles of incorporation may be filed listing the new entity as a Public Benefit company. Existing companies may be converted to Public Benefit. A checklist of requirements can be found at the Oregon Secretary of State, Public Benefit Corporation Page.

Tennessee is arguably the banner state for the Tennessee Valley Authority's (TVA's) operations, which span a region extending into seven states (most of Tennessee and parts of six others), but the TVA is actually a federally owned public authority. The TVA has been key in aiding the region's economic development, most notably in the 1930s during the Great Depression.


Like Maine, the state of Vermont defines public-benefit corporations broadly. They include public-benefit corporations founded by the state and by private entities. The Vermont Economic Development Authority is an example of a state-owned public-benefit corporation.


More broadly, a public-benefit corporation could be any corporation that exists for a charitable purpose, though these are generally called non-profit corporations if they are not founded by a government. Some jurisdictions (the U.S. State of Maine, for instance) might define a public-benefit corporation broadly. In California, public-benefit corporations are one of several types of non-profit corporations.




</doc>
<doc id="250522" url="https://en.wikipedia.org/wiki?curid=250522" title="Regime">
Regime

In politics, a regime (also known as "régime", from the original French spelling) is the form of government or the set of rules, cultural or social norms, etc. that regulate the operation of a government or institution and its interactions with society.

While the word "régime" originates as a synonym for any type of government, modern usage has given it a negative connotation, implying an authoritarian government or dictatorship. Webster's definition states that the word "régime" refers simply to a form of government, while Oxford English Dictionary defines "regime" as "a government, especially an authoritarian one". 

Contemporary academic usage of the term "regime" is broader than popular and journalistic usage, meaning "an intermediate stratum between the government (which makes day-to-day decisions and is easy to alter) and the state (which is a complex bureaucracy tasked with a range of coercive functions)." In global studies and international relations the concept of "regime" is also used to name international regulatory agencies (see International regime), which lie outside of the control of national governments. Some authors thus distinguish analytically between institutions and regimes while recognizing that they are bound up with each other:

In other words, regimes can be defined as sets of protocols and norms embedded either in institutions or institutionalized practices – formal such as states or informal such as the "liberal trade regime" – that are publicly enacted and relatively enduring.



</doc>
<doc id="51254" url="https://en.wikipedia.org/wiki?curid=51254" title="Father of the House">
Father of the House

Father of the House is a title that has been traditionally bestowed, unofficially, on certain members of some legislatures, most notably the House of Commons in the United Kingdom. In some legislatures the title refers to the longest continuously-serving member, while in others it refers to the oldest member. Recently, the title Mother of the House or Mother of Parliament has also been used, although the usage varies between countries; it is simply the female alternative to Father of the House, being applied when the relevant member is a woman.

The "Father of the House" is a title that is bestowed on the senior member of the House of Commons who has the longest continuous service. If two or more members have the same length of current uninterrupted service, then whoever was sworn in earliest, as listed in "Hansard", is named as Father of the House. Traditionally, however, the qualification used for the Father of the House are not entirely clear and may have included the oldest member, the member with the longest aggregate service, or the member who entered the House longest ago.

The only formal duty of the Father of the House is to preside over the election of the Speaker of the House of Commons. However, the relevant Standing Order does not refer to this member by the title of "Father of the House", referring instead to the longest-serving member of the House present who is not a Minister of the Crown. Until 1971, the Clerk of the House of Commons presided over the election of the speaker. As the clerk is never a member, and therefore is not permitted to speak, he would silently stand and point at the Member who was to speak. However, this procedure broke down at the election of a new Speaker in 1971 and was changed upon the recommendation of a Select Committee.

The current Father of the House of Commons is Kenneth Clarke, Conservative MP for Rushcliffe, who began his continuous service at the 1970 general election. Dennis Skinner, Labour MP for Bolsover, also began continuous service at the 1970 general election, but was sworn in after Clarke.

The first recorded usage of the title dates back to 1816 an engraved portrait of Whitshed Keene by Charles
Picart, dated 1 February. Henry Campbell-Bannerman was simultaneously Father of the House and Prime Minister from May 1907 until soon before his death during April 1908. On 13 June 2017, Harriet Harman was dubbed "Mother of the House" by Prime Minister Theresa May, in recognition of her status as the longest-continuously-serving woman MP.

The title 'Father of the House' is not used in the House of Lords. The longest-serving member is recorded on the House website, though no duties or special distinctions are associated with the position , the longest-serving member is The Lord Denham (Conservative), who first took his seat on 13 December 1949 (having succeeded his father in the peerage the previous year). The House of Lords Act 1999 repealed the automatic right of hereditary peers to be members of the House of Lords; Denham was one of those elected to continue as a member under section 2 of the Act.

, the longest-serving life peer is The Baroness Masham of Ilton (Crossbench), who is also the longest-serving female member of the House. She first took her seat on 25 February 1970.

In Australia, the current member of the House of Representatives with the longest period of continuous service, whether a Minister or not, is known as "Father of the House". Similarly, the current member of the Senate with the longest period of continuous service is known as "Father of the Senate". The longer-serving of the two Fathers is called "Father of the Parliament".

As in Britain, these terms have no official status. However, unlike Britain:

Since 6 February 2015, Senator Ian Macdonald, who was first appointed during 1990, has been the Father of the Senate.

Philip Ruddock, who was first elected during 1973, was the Father of the House of Representatives and Father of the Parliament from 1 September 1998 until his retirement on 9 May 2016. He was succeeded by Senator Ian Macdonald as Father of the Parliament and Kevin Andrews as Father of the House.

The longest-serving member of the House of Commons who is not a cabinet minister is known as the Dean of the House, and presides over the election of the Speaker at the beginning of each Parliament. The same term is used for the equivalent position in the United States House of Representatives.

Starting with the Frankfurter Nationalversammlung (Frankfurt Parliament) of 1848, all German parliaments had a father of the House, usually called "Alterspräsident" (President by right of age). This tradition was continued into the Weimar Republic and, after being discontinued in Nazi Germany, was resumed by the present Parliament (Bundestag) in the Federal Republic, whose rules of procedure mandate that the father of the house presides over the Parliament (Bundestag) at the start of each legislative period.

In accordance with tradition, the Alterspräsident first ascertains himself that he is indeed the oldest member (since: 2017 longest sitting member) of the Bundestag by stating his date of birth (since 2017: the number of years, he or she has served in the Bundestag) and asking if anyone is present, who was born before this date (since 2017: who has served more years). If no older (longer-serving) member of the Bundestag is present (which is usually the case) he will formally declare that he indeed is the Alterspräsident and will start proceedings.

As acting President of the Bundestag (Bundestagspräsident) he delivers the first programmatic speech and supervises the election of the President of the Bundestag. He then yields his power to the newly elected President of the Bundestag, who will in turn supervise the elections of the Vice Presidents of the Bundestag.

The rules of order of the Bundestag also state that the Alterspräsident shall act as President of the Bundestag at any given time during a legislative period, if the whole Presidium (i.e. the President and the Vice Presidents of the Bundestag) is altogether unable to perform its duties.

As the Alterspräsident's opening speech usually draws a certain amount of public attention, the position has recently attracted controversy, when the Party of Democratic Socialism (the succcesor of the Socialist Unity Party of Germany) obtained the position by including aged independents (Stefan Heym in 1994, Fred Gebhardt in 1998) in their party lists. In 2017, the Bundestag changed its rules of procedure to have the member with the longest service in the Bundestag serve as father of the house, rather than the oldest member.

In Hong Kong, there is no such term as "Father of the House". Instead, the longest-serving member was termed the Senior Unofficial Member and was the highest-ranking unofficial member of the Executive Council and the Legislative Council until the title was abolished during 1995 and 1992 respectively.

After the transfer of the sovereignty of Hong Kong, James To became the de facto longest-serving member of the Legislative Council since 2016 after several members who had been served since the 1st Legislative Council retired.

In Hungary, the term refers to the oldest member of the National Assembly (previously House of Representatives, the lower house). Before the open session, the senior chairperson and junior notaries review the mandates of all the elected MPs in addition to their own. He or she presides over the newly elected parliament until the appointment of the officials.

In the beginning of each Knesset, before the election of a permanent speaker, there is a temporary speaker. In the past it was the oldest member of Knesset, now it is the longest-serving member. Michael Eitan is the most recent Knesset member to serve in this capacity, doing so from February 24 - March 30, 2010. In 2013 it was Benyamin Ben-Eliezer who had this position, and during 2015, it was Amir Peretz.

In the Republic of Ireland, the term Father of the Dáil is an unofficial title applied to the longest-serving Teachta Dála (TD) in Dáil Éireann. The current Father is the former Taoiseach and Fine Gael party leader, Enda Kenny, TD, since the retirement of Séamus Pattison at the 2007 general election. On a number of occasions, two or more people have shared the position of Father of the Dáil.

In Malaysia the term "Father of the House" is rarely used. Tengku Razaleigh Hamzah who was elected during 1974, has been the longest-serving MP in the Dewan Rakyat. He was the oldest-serving MP aged until former Prime Minister Tun Dr. Mahathir Mohamad was reelected to the Dewan Rakyat at of age.

In New Zealand, the term "Father of the House" (alternatively, "Mother of the House"), as an unofficial title, designates the longest-continuously-serving MP of the House of Representatives. The Father of the House has no official role in Parliament. Former Cabinet Minister Nick Smith became the longest-serving member in March 2018, having served continuously since the 1990 general election.

Norway doesn't have such a tradition. In most cases the Stortingspresident or a member of the presidium from the previous term are asked to lead the proceedings until a new President is elected.

Traditionally when a new Russian parliament is formed the eldest deputy opens and manages the first session until a chairman is elected. In the history of the post-Soviet Dumas these were:

In the National Assembly of the Republic of Serbia, the oldest MP serves as the Acting Speaker presiding over the constitutive session, before the Speaker is elected.

Until his death on 23 March 2015, former Prime Minister Lee Kuan Yew was the longest-serving Member of Parliament (Tanjong Pagar) and thus the Father of the House. , Emeritus Senior Minister Goh Chok Tong is Father of the House, as the longest-serving MP (Marine Parade).

In Sweden the Riksdagsordningen law states that the member of the Riksdag who has held their elected seat for the longest shall be the "Ålderspresident", which translates to "President by age". The Ålderspresident acts as speaker of the Riksdag after each election, before the Speaker of the Riksdag has been elected. The Ålderspresident also acts as speaker in case of hindrance on behalf of the Speaker and all three Deputy Speakers.

Members of the Riksdag who has held the position of Ålderspresident:




</doc>
<doc id="4900279" url="https://en.wikipedia.org/wiki?curid=4900279" title="Interest articulation">
Interest articulation

Interest articulation is a way for members of a society to express their needs to a system of government. It can range from personal contact with government officials to the development of interest groups (e.g. trade unions, professional associations, religious groups) who act in the interest of larger groups of people. Interest articulation can have different effects in different types of government and can include both legal (i.e.: lobbying, peaceful protest, phone calls and letters to policymakers) and illegal activities (e.g. assassination, riots). Interest articulation leads to interest aggregation.

The types of interest groups, as identified by Gabriel Almond, are:



</doc>
<doc id="727075" url="https://en.wikipedia.org/wiki?curid=727075" title="Compulsory purchase order">
Compulsory purchase order

A compulsory purchase order (CPO) is a legal function in the United Kingdom and Ireland that allows certain bodies to obtain land or property without the consent of the owner. It may be enforced if a proposed development is considered one for public betterment; for example, when building motorways where a landowner does not want to sell. Similarly, if town councils wish to develop a town centre, they may issue compulsory purchase orders. CPOs can also be used to acquire historic buildings in order to preserve them from neglect.

In Ireland, CPOs became quite common in the early 21st century due to the massive road upgrade programme under the National Development Plan. CPOs are also used for railway projects. If one objects to the issuing of a CPO, one may appeal to the High Court. Compensation is available to ensure that the person is restored, as far as possible, to the financial position they were in before the land and property were compulsorily purchased.

In the United Kingdom, most orders are made as subordinate legislation under powers given to local authorities in existing legislation (e.g. an order for road works is made under the Highways Act 1980). Whilst the powers are strong, the authority must demonstrate that the taking of the land is necessary and there is a "compelling case in the public interest". Owners or occupiers can challenge this, and their objection will be heard by an independent inspector.

Compensation rights usually include the value of the property, costs of acquiring and moving to a new property, and sometimes additional payments. Costs of professional advice regarding compensation are usually reimbursed by the authority, so that people affected by a compulsory purchase order can seek advice from a solicitor and a surveyor and expect to be reimbursed.



</doc>
<doc id="5162951" url="https://en.wikipedia.org/wiki?curid=5162951" title="Exclusive mandate">
Exclusive mandate

An exclusive mandate is a government's assertion of its legitimate authority over a certain territory, part of which another government controls with stable, "de facto" sovereignty. It is also known as a claim to sole representation or an exclusive authority claim. The concept was particularly important during the Cold War period when a number of states were divided on ideological grounds.

For nearly all of the 41 years that Germany was split into two countries, the Federal Republic of Germany (West Germany) claimed to be the sole legitimate successor to the German Reich that existed from 1871 to 1945. This claim was initially based solely on the government's mandate by virtue of free elections. To that end, it claimed Berlin, capital of united Germany from 1871 to 1945, as its capital, with the provisional capital in Bonn.

In a statement made before the Bundestag, German Chancellor Konrad Adenauer asserted this mandate as early as October 21, 1949, in response to the constitution of the German Democratic Republic (GDR) coming into effect. The Secretary of State Summit of the three western powers on September 18, 1950 in New York City, supported Chancellor Adenauer's claim.

When the Soviet Union proclaimed the sovereignty of the GDR, the West German Bundestag once again unanimously insisted that the Federal Republic was the sole legitimate representative of the German people. At the Treaties of Paris (""), at which the Federal Republic of Germany was admitted into the North Atlantic Treaty Organization, the allied nations adopted the position which the three western allies had already confirmed at the Nine-Power Conference in London: that the Federal Republic had the exclusive right to act on behalf of the entire German people in matters of foreign policy. The western nations thereby recognized the Federal Republic as the only lawful government for Germany as a whole.

Aside from such considerations pertaining to international law, the reunification clause of the Basic Law suggested that international recognition of the German Democratic Republic was to be avoided, so as not to sever the constitutional mandate to a unified German state.

Until 1973, the Federal Republic took a strict line in claiming an exclusive mandate for all of Germany. Under the Hallstein Doctrine, the Federal Republic broke diplomatic relations with states that maintained diplomatic relations with the GDR, except for the Soviet Union. On different levels, such as in international sports, there were, however, a wide range of international cooperations which even led to unified German teams in six Olympic Games. Over time, especially after the election of a social-liberal coalition led by Willy Brandt in 1969, the exclusive mandate was softened, as it severely limited the Federal Republic's domestic and international autonomy. Starting in 1973, under the "Ostpolitik" policy, the Federal Republic took the line that the Democratic Republic was a "de facto" government within a single German nation, in respect of which the Federal Republic was the sole representative "de jure", but limited to its own territorial extent; hence relinquishing any claim to be "de jure" the government of Germany as a whole.

Judicially, an exclusive mandate had been claimed to have arisen from the proposition that the German state as a whole had been preserved, that only one German state could legitimately exist, and that that one state was identical with the Federal Republic. The German Democratic Republic was therefore held to be an illegally constituted Soviet puppet state occupying territory that rightfully belonged to the Federal Republic, thus lacking autonomy. An alternate view held that the GDR was in a state of civil war with the FRG government, and therefore could not be recognized as a state under international law. A third, the so-called "umbrella state" theory, entails the existence of two fragment states under the umbrella of a single German nation that had been formed in 1871 and which had never actually been annihilated; this theory arose in the late 1960s and was maintained in a ruling of the Federal Constitutional Court of Germany of 31 July 1973 upholding the "Basic Treaty" by which relations between East and West Germany were normalised. Crucially, although the Constitutional Court reaffirmed the proposition that the pre-1945 German state had been preserved and organised, albeit partially, in the institutions of the Federal Republic, the Justices explicitly rejected the proposition that this would imply an exclusive mandate; "...identity does not require exclusivity".

With the admission of both German states to the United Nations in 1973, matters regarding the exclusive mandate were no longer relevant. Nevertheless, the Constitutional Court maintained that the Federal Republic continued to bear a responsibility for the whole German people; albeit that this responsibility could only be discharged in respect of Germans physically present in its territory or within its jurisdiction. Accordingly, the Federal Republic of Germany did not recognize a distinct citizenship for the German Democratic Republic; if East Germans presented themselves in West Germany, or at a West German embassy in a third country, they could obtain a West German passport. Generally, the Federal Republic considered East Germans to be German citizens under the old 1871–1945 all-German citizenship (i.e. "Bundesbürger", citizens of West Germany). Refugees who fled from the GDR were therefore not deported, and automatically qualified for West German citizenship.

In addition, visitors from the GDR would receive a West German passport upon request, for example, in order to ease travel to the United States. After the fall of the Berlin wall in November 1989, East Germans were greeted with Begrüßungsgeld (100 West German Deutsche Mark) and could travel freely within West Germany, while West German access to the East was still hindered for some weeks by visa and the Mindestumtausch mandatory minimum exchange of 25 DM.

The 1949 constitution of the German Democratic Republic also acknowledged that Germany was an indivisible republic, and thus there was only one German citizenship. The GDR, therefore, was also founded on the premise of being the "de jure" sovereign representative of all Germany. Initially, it regarded the West German regime as an illegally constituted NATO puppet state, a line accepted by most of the Eastern bloc. The GDR erected the Berlin Wall in 1961 partly to prevent Germans moving freely within Germany. In 1974, however, the reunification clause was stricken from the GDR's constitution. Thereafter, it regarded itself as a separate state from West Germany. The Communist regime collapsed in the fall of 1989. East Germany lingered on for another year until it declared its accession to the Federal Republic in the German reunification of 1990.

Since the end of the Chinese civil war in 1949, the Republic of China was limited to Taiwan (taken from Japan in 1945, ceded by Qing China in 1895 - although renounced in 1952) and a few islands near Fujian, while the People's Republic of China controlled mainland China, and since 1950 also the island of Hainan. Both Chinese governments claimed sovereignty over all of China, and regard the other government as being in rebellion. Until 1971, the Republic of China was a permanent member of the UN Security Council with veto power. Since then, however, it was excluded in favor of the People's Republic of China, and since 1972, it was also excluded from all UN-subcommittees. Since the death of Chiang Kai-shek in 1975, Republic of China no longer aggressively asserts its exclusive mandate and most of the world's nations have since broken their official diplomatic ties with Republic of China (except for 21 nations including Holy See as of 2008). Nevertheless, most nations, as well as the People's Republic government, continue to maintain unofficial relations.

Since the 1990s, the stance of the Republic of China has softened. When the ROC established ties with Kiribati in 2003, it did not demand that Kiribati break its existing ties with the PRC. However, the PRC's stance has not softened and it does not maintain diplomatic relations with the 22 countries that recognize the ROC. The ROC also participates in sporting events under the name "Chinese Taipei" and the World Trade Organization as the "Separate Customs Territory of Taiwan, Penghu, Kinmen, and Matsu".

When South Korea and North Korea were created within months of each other in 1948, both claimed sovereignty over all of Korea. Both states claimed that the other was an unlawfully constituted puppet state of the United States and the Soviet Union, respectively. In 1991, however, both nations joined the UN, as part of their reconciliation policy.

The Democratic Republic of Vietnam was proclaimed in 1945; the Republic of Vietnam gained its independence from France in 1954. While elections were intended to be held in 1955 to reunite the country, they never took place. For the next 20 years, both staked claims to all of Vietnam, claiming that the other was an illegally constituted puppet state. This continued until South Vietnam unconditionally surrendered to North Vietnam in 1975.

When some European countries (such as Switzerland) started recognizing North Vietnam towards the end of the Vietnam war, South Vietnam did not interrupt its diplomatic relations with them. Switzerland thus recognized North Vietnam in 1971 but also turned its consulate in Saigon (South Vietnam) into an embassy until the end of the war in 1975.

In 1979, Vietnam invaded and occupied Cambodia (at that time was ruled by the Khmer Rouge as Democratic Kampuchea) establishing the People's Republic of Kampuchea, but it was dismissed by the People's Republic of China as a "puppet state". At the time, both of the countries had disputed the claims of being the sole legitimate representative of all the Khmer people of Cambodia in the United Nations. This resulted in its seat being retained by the Coalition Government of Democratic Kampuchea, a coalition government formed in 1982 as a government in exile and composed of the royalist FUNCINPEC party, the republican Khmer People's National Liberation Front and the Khmer Rouge-backed Party of Democratic Kampuchea.

A similar situation occurred at the start of the Syrian Civil War in March 2011 when two governments claimed sovereignty over the whole Syria: The Syrian government headed by Bashar al-Assad and the various opposition groups seeking to remove Assad consisting of the National Coalition for Syrian Revolutionary and Opposition Forces, Syrian National Council and the Syrian Interim Government. Both entities are considered puppet entities backed by the Russian Federation/Iran and the United States/Saudi Arabia.

In addition, the Islamic State of Iraq and the Levant (ISIS/ISIL), a Sunni Islamist fundamentalist militant group, controlled part of the Syrian territory along with portions of neighbouring Iraq.

In a more ambiguous situation, the Kurdish territory of northeast Syria became controlled by Syrian Kurdish federal state Rojava when Syrian government forces left the area, or areas were liberated from ISIL occupation.



</doc>
<doc id="5265708" url="https://en.wikipedia.org/wiki?curid=5265708" title="Public participation">
Public participation

Public participation (citizen participation) is a political principle or practice, and may also be recognised as a right. The terms public participation, often called P2 by practitioners, is sometimes used interchangeably with the concept or practice of stakeholder engagement and/or popular participation.

Generally public participation seeks and facilitates the involvement of those potentially affected by or interested in a decision. This can be in relation to individuals, governments, institutions, companies or any other entities that affect public interests. The principle of public participation holds that those who are affected by a decision have a right to be involved in the decision-making process. Public participation implies that the public's contribution will influence the decision.

Public participation may be regarded as a way of empowerment and as vital part of democratic governance.

In the context of knowledge management the establishment of ongoing participatory processes is seen by some in the facilitator of collective intelligence and inclusiveness, shaped by the desire for the participation of the whole community or society.

Public participation is part of "people centred" or "human centric" principles, which have emerged in Western culture over the last thirty
years, and has had some bearings of education, business, public policy and international relief and development programs. Public participation is advanced by the humanist movements. Public participation may be advanced as part of a "people first" paradigm shift. In this respect public participation may challenge the concept that "big is better" and the logic of centralized
hierarchies, advancing alternative concepts of "more heads are better than one" and arguing that public participation can sustain productive and durable change.

The role of public participation in economic and human development was enshrined in the 1990 African Charter for Popular Participation in Development and Transformation.

In 1990 practitioners established the International Association for Public Practitioners in order to respond to the increasing interest in the practice, and in turn established the International Association for Public Participation (IAP2). The practice is well established globally and the International Association of Public Participation now has affiliate organizations across the globe.

Participatory budgeting is a process of democratic deliberation and decision-making, in which ordinary city residents decide how to allocate part of a municipal or public budget. Participatory budgeting is usually characterized by several basic design features: identification of spending priorities by community members, election of budget delegates to represent different communities, facilitation and technical assistance by public employees, local and higher level assemblies to deliberate and vote on spending priorities, and the implementation of local direct-impact community projects.
Participatory budgeting may be used by towns and cities around the world, and has been widely publicised in Porto Alegre, Brazil, were the first full participatory budgeting process was developed starting in 1989.

In economic development theory, there is a school of participatory development. The desire to increase public participation in humanitarian aid and development has led to the establishment of a numerous context-specific, formal methodologies, matrices, pedagogies and ad hoc approaches. These include conscientization and praxis; Participatory action research (PAR), rapid rural appraisal (RRA) and participatory rural appraisal (PRA); appreciation influence control analysis (AIC); "open space" approaches; Objectives Oriented Project Planning (ZOPP); vulnerability analysis and capacity analysis.

In some countries public participation has become a central principle of public policy making. In the UK and Canada it has been observed that all levels of government have started to build citizen and stakeholder engagement into their policy-making processes. This may involve large-scale consultations, focus group research, online discussion forums, or deliberative citizens' juries. There are many different public participation mechanisms, although these often share common features (for a list over 100, and a typology of mechanisms, see Rowe and Frewer, 2005).

Public participation is viewed as a tool, intended to inform planning, organising or funding of activities. Public participation may also be used to measure attainable objectives, evaluate impact, and identify lessons for future practice.

In the United States public participation in administrative rulemaking refers to the process by which proposed rules are subject to public comment for a specified period of time. Public participation is typically mandatory for rules promulgated by executive agencies of the US government. Statutes or agency policies may mandate public hearings during this period.

In recent years loss of public trust in authorities and politicians has become a widespread concern in many democratic societies. Public participation is a regarded as one potential solution to the crisis in public trust and governance, particularly in the UK, Europe, and other democracies. The idea is that public should be involved more fully in the policy process in that authorities seek public views and participation, instead of treating the public as simply passive recipients of policy decisions.

The underlying assumption by political theorists, social commentators, and even politicians is that public participation increase public trust in authorities, improving citizen political efficacy, enhancing democratic ideals and even improving the quality of policy decisions. However, the assumed benefits of public participation in restoring public trust are yet to be confirmed.

Public participation may also be viewed as accountability enhancing. The argument being that public participation can be a means for the participating communities to hold public authorities accountable for implementation. In the United Kingdom citizens are used to ensure the fair and humane detention of prisoners. Volunteers comprise the Independent Monitoring Board that reports on the fair and humane detention of prisoners and detainees.

In recent years public participation has become to be seen as a vital part of addressing environmental problems and bringing about sustainable development. In this context the limits of solely relying on technocratic bureaucratic monopoly of decision making, and it is argued that public participation allows governments to adopt policies and enact laws that are relevant to communities and take into account their needs.

Public participation is recognised as an environmental principle, see Environmental Principles and Policies, and has been enshrined in the Rio Declaration.

With growing complexities of the environmental issues, public participation has come to the fore in academic analysis concerning the contemporary debates about environmental governance.

There have emerged a number of arguments in favor of a more participatory approach, which stress that public participation is a crucial element in environmental governance that contributes to better decision making. It is recognised that environmental problems cannot be solved by government alone. Participation in environmental decision-making effectively links the public to environmental governance. By involving the public, who are at the root of both causes and solutions of environmental problems, in environmental discussions, transparency and accountability are more likely to be achieved, thus secures the democratic legitimacy of decision-making that good environmental governance depends on. Arguably, a strong public participation in environmental governance could increase the commitment among stockholders, which strengthens the compliance and enforcement of environmental laws. GIS can provide a valuable tool for such work (see GIS and environmental governance). In addition, some opponents argue that the right to participate in environmental decision-making is a procedural right that "can be seen as part of the fundamental right to environmental protection". From this ethical perspective, environmental governance is expected to operate within a framework coinciding the "constitutional principle of fairness (inclusive of equality)", which inevitably requires the fulfillment of "environmental rights" and ultimately calls for the engagement of public. Further, in the context of considerable scientific uncertainties surrounding environmental issues, public participation helps to counter such uncertainties and bridges the gap between scientifically-defined environmental problems and the experiences and values of stakeholders. Through joint effort of the government and scientists in collaboration with the public, better governance of environment is expected to be achieved by making the most appropriate decision possible.

Although broad agreements exist, the notion of public participation in environmental decision-making has been subject to a sustained critique concerning the real outcome of participatory environmental governance. Critics argue that public participation tends to focus on reaching a consensus between actors who share the same values and seek the same outcomes. However, the uncertain nature of many of the environmental issues would undermine the validity of public participation, given that in many cases the actors come to the table of discussion hold very different perceptions of the problem and solution which are unlikely to be welded into a consensus due to the incommensurability of different positions. This may run the risk of expert bias, which generates further exclusion as those who are antagonistic to the consensus would be marginalised in the environmental decision-making process, which violates the assumed advantage of participatory approach to produce democratic environmental decisions. This raises the further question of whether consensus should be the measure of a successful outcome of participation. As Davies suggests, participative democracy could not guarantee the substantive environmental benefits 'if there are competing views of what the environment should be like and what it is valuable for'. Consequently, who should be involved at what points in the process of environmental decision-making and what is the goal of this kind of participation become central to the debates on public participation as a key issue in environmental governance.

Citizen science is a coined term commonly used to describe the participation of non-scientists in scientific research.

Liz Richardson, a Visiting Fellow in the Centre for Analysis of Social Exclusion (CASE) at the London School of Economics and an editor for the journal Local Government Studies, has long advocated for the greater inclusion of non-professional scientists in policy research. She emphasizes that it is academia's responsibly to facilitate the "democratization of policy research" noting several benefits of having citizens involved in not just the contribution of data, but also the framing and development of research itself (2014). She notes that the biggest disadvantage of citizen science is the reliance on using citizens as only contributing members of the scientific endeavors and pushes for a more community-based participatory research method which would include laypeople in the entirety of the research process while emphasizing the scientific method popularized by citizen science.

In their 2017 article, Colin Chapman and Crona Hodges outline what they believe to be the key to success in applying citizen science to policy development: data which is "suitable, robust, and of a known quality for evidence-based policy making" (2017). They identified several barriers to applying citizen science to policy development including a lack of suitability between the data collected and the policy in question and skepticism regarding the data collected by non-experts.

In some jurisdictions the right to public participation is enshrined by law. The right to public participation may also be conceived of as human right, or as manifestation of the right to freedom of association and freedom of assembly. As such the Netherlands, Germany, Denmark and Sweden, have public participation and freedom of information provisions in their legal systems since before the Middle Ages. Democracy and public participation are closely connected democratic societies have incorporated public participation rights into their laws for centuries. For example, in the US the right to petition has been part of the first Amendment of the US constitution since 1791. More recently, since the 1970s in New Zealand numerous laws (e.g.: health, local government, environmental management) require government officials to "consult" those affected by a matter and take their views into consideration when making decisions.

Effective public participation depends on the public having accessing to accurate and comprehensive information. Hence laws regarding public participation often deal with the issue of the right to know, access of information and freedom of information.

The right to participation may also be advanced in the context of equality and group rights, meant to ensure equal and full participation of a designated group in society. For example, in the context of disabled people.

The Rio Declaration of 1992 enshrines public participation in its 27 principles. Principle 10 states that "environmental issues are best handled with participation of all concerned citizens, at the relevant level". The Rio Declaration continues, drawing a close link between access to information and public participation: 

At the national level, each individual shall have appropriate access to information concerning the environment that is held by public authorities, including information on hazardous materials and activities in their communities, and the opportunity to participate in decision-making processes. States shall facilitate and encourage public awareness and participation by making information widely available. Effective access to judicial and administrative proceedings, including redress and remedy, shall be provided.

The 2006 Convention on the Rights of Persons with Disabilities recognised that "disability results from the interaction between persons with impairments and attitudinal and environmental barriers that hinders their full and effective participation in society on an equal basis with others" and that "persons with disabilities continue to face barriers in their participation as equal members of society."

The Convention makes participation of disabled one of its principles, stating "The principles of the present Convention shall be:...Full and effective participation and inclusion in society;", subsequently enshrining the right of disabled to participate fully and equally in the community, education, all aspect of life (in the context of habilitation and rehabilitation), political and public life, cultural life, leisure and sports.


</doc>
<doc id="13686672" url="https://en.wikipedia.org/wiki?curid=13686672" title="Courtesy resolution">
Courtesy resolution

Courtesy resolution is a non-controversial resolution in the nature of congratulations on the birth of a child, celebration of a wedding anniversary, congratulations of an outstanding citizen achievement or a similar event. It is "a resolution expressing thanks for assistance or commending meritorious accomplishments." An example of a courtesy resolution is the resolution at the end of the political convention thanking everyone for their time.

For a Courtesy Resolution, only the affirmative vote is taken and this is usually a voice vote.


</doc>
<doc id="16096931" url="https://en.wikipedia.org/wiki?curid=16096931" title="Pantisocracy">
Pantisocracy

Pantisocracy (from the Greek πᾶν and ἰσοκρατία meaning "equal or level government by/for all") was a utopian scheme devised in 1794 by the poets Samuel Taylor Coleridge and Robert Southey for an egalitarian community. It is a system of government where all rule equally. They originally intended to establish such a community on the banks of the Susquehanna River in the United States, but by 1795 Southey had doubts about the viability of this and proposed moving the project to Wales. The two men were unable to agree on the location, causing the project to collapse.

Coleridge and Southey believed that contemporary society and politics were responsible for cultures of servitude and oppression. Having abandoned these corrupting influences along with personal property for a fresh start in the wilderness, the Pantisocrats hoped that men might be governed by the “dictates of rational benevolence.”

As spelled out by Southey, the utopian community he and Coleridge planned was to be built on two principles: "Pantisocracy" (meaning government by all) and "Aspheterism" (meaning general ownership of property). The scheme called for a small group of educated individuals to give up their possessions and labor together for the common good. Few regulations would be necessary to govern the colony and decisions would be made so as to avoid one man having more power than another. Coleridge envisioned Pantisocracy as a way to minimize the greed among men. Additionally, Coleridge and Southey hoped to enjoy a more relaxing existence than was possible in England, and expected that each member of the community would have to work just two to three hours per day to sustain the colony.

The Pantisocrats viewed their attempt as not only a search for personal domestic peace, but also as an attempt to change the status quo in England. One influence on the plan was disillusionment with the French Revolution and with the current politics of England, from which Coleridge may have sought solace through a utopian escape. Coleridge viewed the utopian scheme as an experiment that, if successful, might be gradually extended to a larger citizenship. Coleridge also hoped that through a more active, natural lifestyle he would live a healthier and more wholesome existence with his family.

Like many utopian societies, the Pantisocracy envisioned by Coleridge and Southey owed its origins to Plato's ideal commonwealth, envisioned in the later books of "The Republic" and in "Critias". More modern examples for the Pantisocrats included Sir Thomas More’s "Utopia", Francis Bacon’s "New Atlantis", Tommaso Campanella’s "Civitas Solis", and the accounts of Cotton Mather.

The Pantisocrats were also heavily influenced by contemporary travel accounts of the new world. Many writers who visited the new world (including J. P. Brissot, Thomas Cooper, and Joseph Priestley) described a fresh and inviting country, whose inhabitants were untainted by the evils of society. Coleridge and Southey pored over these and other accounts of the American continent.

As early as November, 1793, Robert Southey was envisioning a utopia in the US. In June 1794, Coleridge left Cambridge to visit Oxford, and there met Southey, a student and poet. Within weeks, Southey and Coleridge were deep in the planning stages of Pantisocracy.

In July, Coleridge left Oxford for a walking tour of Wales with his friend (and Oxford graduate), Joseph Hucks. Throughout July, Coleridge corresponded regularly with Southey about their plans. Coleridge even went so far as to share his enthusiasm for Pantisocracy with many of the people he and Hucks met along the road, offending several listeners with their radical ideas. During the walking tour Coleridge also encountered an old flame, Mary Evans, and his interaction with her momentarily drove thoughts of Pantisocracy from his mind. On August 3, Coleridge and Hucks rejoined Southey in Bristol.

In Bristol, Southey and Coleridge continued to flesh out their plans, and spoke openly of their radical ideas. One listener was John Poole, cousin of Tom Poole of Nether Stowey, who writes of his encounter with the two young men: “Each of them was shamefully hot with Democratic rage as regards politics, and both Infidel as to religion. I was extremely indignant…”.

During this time the young men also became acquainted with the family of Mrs. Fricker, a widow whose daughters seemed willing to join in the scheme (as Mrs. Southey and Coleridge). Southey became interested in Edith and Coleridge began showing interest in Sara.

In the autumn of 1794, Coleridge began seriously to investigate the practical problems of setting up a community in America. During this time he encountered George Dyer, a student familiar with Priestley (who at the time was already living in Pennsylvania), and also spoke with a land agent. In a letter to Southey on September 6 he writes: 

Neither Coleridge nor Southey possessed the requisite wealth, but plans were laid for a spring departure in 1795. The young men hoped that other, wealthier immigrants who would join in the endeavor would be willing to fund it. Returning to Cambridge in late September, Coleridge began to spread word of the plan.

Coleridge at this time envisioned the community including “twelve men with their families,” among whom the costs would be split, with the wealthier members of the community making up for the shortcomings of the poorer members. Besides money, other practical issues arose. Having little ability in farming or carpentry, the young men planned to acquire these skills over the winter in time for a March departure. Among the families who were planning to make the voyage were children, and Coleridge worried that they might already be deeply prejudiced by society, which could subvert and corrupt the Pantisocracy.

As the date set for departure arrived and the financial difficulties in undertaking the journey remained unsolved, the would-be emigrants began to lose excitement and resolve. Besides their lack of funds, other concerns challenged the Pantisocrats. Contrary to the glowing travel narratives that Coleridge pored over while researching the prospect of settling in America, other accounts of American life were less encouraging, and described a difficult and laborious existence. In a review of Thomas Cooper’s "Some Information Respecting America," (one of the positive accounts of the New World that Coleridge consulted) a reviewer describes Cooper and those like him as “rival auctioneers, or rather show-men, stationed for the allurement of incautious passengers. 'Pray, ladies and gentlemen, walk in and admire the wonders of Kentucky—Pray, stop and see the incomparable beauties of the Susquehanna.'”

Coleridge also faced personal challenges in carrying out the scheme. He received a letter from Mary Evans which argued against the plan, and his feelings for her for a time swayed him against Pantisocracy. Learning that she had become engaged, Coleridge turned his attention back to Pantisocracy and Sara Fricker. Under pressure from Southey to act with regard to Sara (both because of the demands of Pantisocracy and also because she was being courted by other men), Coleridge married Sara in October 1795.

As plans bogged down, Southey and Coleridge eventually reached an impasse. Southey at one point advocated taking servants to the new world to do the hard work, a proposition Coleridge scoffed at. Southey and other would-be Pantisocrats also considered a less ambitious plan: the purchase of a common farm in Wales. Coleridge, still dreaming of the new world, felt that this compromise failed to meet the standards of Pantisocracy. In a letter to Southey he complains that private resources would not be abandoned at the farm in Wales and that, "In short, we were to commence partners in a petty farming trade." By the winter of 1795, the dream of Pantisocracy had all but died out.

There are two of Coleridge’s poems that directly address the plans he and Southey were envisioning. "Pantisocracy," a sonnet sent to Southey in a letter of September 18, 1794, was not published during Coleridge’s lifetime. A second sonnet, "On the Prospect of Establishing a Pantisocracy," has also been attributed to Coleridge, and was first published in 1826. Many of Coleridge's other works of the time implicitly suggest the New World, and may owe a debt to his musings over the Susquehanna. An early version of the poem "To a Young Ass" also makes mention of Pantisocracy.

Pantisocracy presented Coleridge a practical outlet for ideas he had previously only considered theoretically. While the scheme never produced an actual community, it did impact Coleridge's philosophical thinking. His lectures of the time reflect his Pantisocratic thinking on social relations and wealth. He wrote of the scheme years afterward that it was “a plan as harmless as it was extravagant” but it can be argued that much of the fantastic imagery and political thoughts present in his work owe a debt both to Pantisocracy and to the research he conducted in preparation for his voyage. On a literal level, perhaps the greatest impact Pantisocracy had on the young Coleridge was the addition of Sara Fricker (and their subsequent family) to his life.


</doc>
<doc id="208561" url="https://en.wikipedia.org/wiki?curid=208561" title="Shadow Cabinet">
Shadow Cabinet

The Shadow Cabinet or Shadow Ministry is a feature of the Westminster system of government. It consists of a senior group of opposition spokespeople who, under the leadership of the Leader of the Opposition, form an alternative cabinet to that of the government, and whose members "shadow" or mirror the positions of each individual member of the Cabinet. It is the Shadow Cabinet's responsibility to scrutinise the policies and actions of the government, as well as to offer an alternative program. The Shadow Cabinet makes up the majority of the Official Opposition frontbench.

In most countries, a member of the shadow cabinet is referred to as a Shadow Minister. In the United Kingdom's House of Lords and in New Zealand, the term "spokesperson" is used instead of "shadow". In Canada, however, the term Opposition Critic is more common.

The shadow minister's duties may give them considerable prominence in the party caucus hierarchy especially if it is a high-profile portfolio, although their salary and benefits remain the same as a backbencher. Members of a shadow cabinet may not necessarily be appointed to the corresponding Cabinet post if and when their party forms a government.

In the United Kingdom, Canada and New Zealand the major opposition party and specifically its shadow cabinet is called "His" or "Her Majesty's Loyal Opposition". The adjective "loyal" is used because, while the role of the opposition is to oppose Her Majesty's Government, it does not dispute the sovereign's right to the throne and therefore the legitimacy of the government. However, in other countries that use the Westminster system, the opposition is known simply as "The Parliamentary Opposition".

Some parliamentary parties, notably the Australian Labor Party, elect all the members of their shadow cabinets in a party room ballot, with the Leader of the Opposition then allocating portfolios to the Shadow Ministers. In other parliamentary parties, the membership and composition of the Shadow Cabinet is generally determined solely by the Leader of the Opposition.

In many jurisdictions, third parties (which are neither participant in the government nor in the official opposition) may also form their own parliamentary front benches of spokespersons; however, parliamentary standing orders on the right of parties to speak often dictate that it can only be granted to a party or group if a minimum number of members can be recorded by the party. In Ireland, for example, technical groups are often formed by third parties and independent TDs in the Dáil Éireann in order to increase the members' right to speak against larger parties which can afford the right to speak as Front Benches in Government or Opposition.

While the practice of parliamentary shadow cabinets or frontbenches is not widespread in Germany, party leaders have often formed boards of experts and advisors ("teams of experts", or "Kompetenzteam", in CDU/CSU and SPD parlance; alternate "top team", or "Spitzenteam", in Bündnis '90/Die Grünen parlance).
In France, although the formation of a Shadow Cabinet is not compulsory and not common, several Shadow Cabinets have been formed.
























</doc>
<doc id="15723651" url="https://en.wikipedia.org/wiki?curid=15723651" title="Vote trading">
Vote trading

Vote trading is the practice of voting in the manner another person wishes on a bill, position on a more general issue, or favored candidate in exchange for the other person's vote in the manner one wishes on another position, proposal, or candidate. Nearly all voting systems do not make vote trading a formal process, so vote trading is very often informal and thus not binding.
One form of vote trading that is formal is one that involves the trading of proxy voting rights - party A gets Party B's voting right formally, eg as a filled in proxy form with signature, perhaps authenticated by secretariats, and in this case party A may use B's vote on issue 1, and B uses A's vote on issue 2... votes traded.

Vote trading frequently occurs between and among members of legislative bodies. For example, Congressman A might vote for a dam in Congressman B's district in exchange for Congressman B's vote for farm subsidies in Congressman A's district. One of the first examples of vote trading to occur in the United States was the Compromise of 1790, in which Thomas Jefferson made a deal with James Madison and Alexander Hamilton to move the capital from New York to a site along the Potomac (after a lengthy stay in Philadelphia) in exchange for federal assumption of debts incurred by the states in the Revolutionary War. Hindrances to vote trading in the U.S. Congress include its bicameral structure and the geographic representation basis of its members. Vote trading is encouraged, however, by Congress's relatively loose party discipline which facilitates policy cross-overs by individual congressmen, in sharp contrast to European countries. In any case, vote trading is effectively a binding contract in the house, as both participants can actually see each other at the time of voting. If one party breaks their promise the other might change their vote on the issues involved in the trade, and be rather unfriendly with the other party in future.

Vote trading occasionally occurs between United States citizens domiciled in different states (and therefore citizens of those respective states) to demonstrate support for third-party candidates while minimizing the risk that their more favored (or less disfavored) major-party candidate will lose electoral votes in the nationwide election ("i.e.", the "spoiler effect"). For example:
In either case, both candidates and both voters receive a net benefit at minimal (if any) cost:
Vote trading thereby improves the outcome as measured by both candidates' preference orders and according to both "maximax" and "maximin" evaluation standards, at least given the constraints on the set of possible outcomes imposed by the "bottleneck" effect of the winner-take-all electoral-vote allocation procedure.

Presidential vote trading between citizens has increased in popularity since the development of the Internet and World Wide Web facilitated interstate communications between individuals not personally known to each other but identifiable by user account names.

Corporate vote trading has been proposed as a way of improving corporate governance. In this context, vote trading refers to borrowing shares of a stock in time to be the shareholder of record on the day of an important vote.

A variant called vote pairing refers to voters on opposite sides in a single vote agreeing to abstain from voting or otherwise changing their vote. This technique is often used by legislators who do not wish to take time to come to the floor for a vote. A legislator will find a member on the opposite side of the issue who also desires to save time, and they will both agree to skip the vote, maintaining the balance of votes on each side.

"The Limits of Public Choice: A Sociological Critique of the Economic Theory" notes that vote trading is often considered immoral, since votes should be determined on the basis of the merits of the question. It is viewed as being less serious an offense than bribery, although in some countries it is still unlawful. However, vote-trading can also be viewed as beneficial to democracy in that it makes it possible for minorities to exert some influence and thus alleviate the tyranny of the majority. In this way, vote-trading is similar to coalition-building, which also involves an exchange of policies and bargaining over cabinet positions in order to gain the parliamentary majority needed for approval of the entire program.

There have been academic proposals to streamline the legislative vote trading process by creating a market brokered by party leaders in which members buy and sell votes at prices set by supply and demand.



</doc>
